{"trial_data": [["{\n  \"stub\": false,\n  \"trainable_name\": \"PPO\",\n  \"trial_id\": \"495f5_00000\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595ca020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1750504f5f323032352d31302d32315f31302d35392d3433948c0e747269616c5f6469725f6e616d65948c3c50504f5f57617265686f7573654d756c74694167656e74456e765f34393566355f30303030305f305f323032352d31302d32315f31302d35392d3433948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e74948875628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c362f686f6d652f7875657a68692f7461736b2d61737369676e6d656e742d726f626f7469632d77617265686f7573652f726573756c7473948c0673796e6365729468008c115f46696c6573797374656d53796e6365729493942981947d94286815681b68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032352d31302d32315f31302d35392d34339475622e\"\n  },\n  \"config\": {\n    \"exploration_config\": {},\n    \"extra_python_environs_for_driver\": {},\n    \"extra_python_environs_for_worker\": {},\n    \"placement_strategy\": \"PACK\",\n    \"num_gpus\": 1,\n    \"_fake_gpus\": false,\n    \"num_cpus_for_main_process\": 1,\n    \"eager_tracing\": true,\n    \"eager_max_retraces\": 20,\n    \"tf_session_args\": {\n      \"intra_op_parallelism_threads\": 2,\n      \"inter_op_parallelism_threads\": 2,\n      \"gpu_options\": {\n        \"allow_growth\": true\n      },\n      \"log_device_placement\": false,\n      \"device_count\": {\n        \"CPU\": 1\n      },\n      \"allow_soft_placement\": true\n    },\n    \"local_tf_session_args\": {\n      \"intra_op_parallelism_threads\": 8,\n      \"inter_op_parallelism_threads\": 8\n    },\n    \"torch_compile_learner\": false,\n    \"torch_compile_learner_what_to_compile\": \"forward_train\",\n    \"torch_compile_learner_dynamo_backend\": \"inductor\",\n    \"torch_compile_learner_dynamo_mode\": null,\n    \"torch_compile_worker\": false,\n    \"torch_compile_worker_dynamo_backend\": \"onnxrt\",\n    \"torch_compile_worker_dynamo_mode\": null,\n    \"torch_ddp_kwargs\": {},\n    \"torch_skip_nan_gradients\": false,\n    \"env\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005952a000000000000008c0b747261696e5f7574696c73948c1657617265686f7573654d756c74694167656e74456e769493942e\"\n    },\n    \"env_config\": {\n      \"env_id\": \"tarware-extralarge-14agvs-7pickers-partialobs-chg-v1\"\n    },\n    \"observation_space\": null,\n    \"action_space\": null,\n    \"clip_rewards\": null,\n    \"normalize_actions\": true,\n    \"clip_actions\": false,\n    \"_is_atari\": null,\n    \"disable_env_checking\": false,\n    \"render_env\": true,\n    \"action_mask_key\": \"action_mask\",\n    \"env_runner_cls\": null,\n    \"num_env_runners\": 3,\n    \"create_local_env_runner\": true,\n    \"num_envs_per_env_runner\": 1,\n    \"gym_env_vectorize_mode\": \"SYNC\",\n    \"num_cpus_per_env_runner\": 1,\n    \"num_gpus_per_env_runner\": 0,\n    \"custom_resources_per_env_runner\": {},\n    \"validate_env_runners_after_construction\": true,\n    \"episodes_to_numpy\": true,\n    \"max_requests_in_flight_per_env_runner\": 1,\n    \"sample_timeout_s\": 60.0,\n    \"_env_to_module_connector\": null,\n    \"add_default_connectors_to_env_to_module_pipeline\": true,\n    \"_module_to_env_connector\": null,\n    \"add_default_connectors_to_module_to_env_pipeline\": true,\n    \"merge_env_runner_states\": \"training_only\",\n    \"broadcast_env_runner_states\": true,\n    \"episode_lookback_horizon\": 1,\n    \"rollout_fragment_length\": \"auto\",\n    \"batch_mode\": \"truncate_episodes\",\n    \"compress_observations\": false,\n    \"remote_worker_envs\": false,\n    \"remote_env_batch_wait_ms\": 0,\n    \"enable_tf1_exec_eagerly\": false,\n    \"sample_collector\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059551000000000000008c357261792e726c6c69622e6576616c756174696f6e2e636f6c6c6563746f72732e73696d706c655f6c6973745f636f6c6c6563746f72948c1353696d706c654c697374436f6c6c6563746f729493942e\"\n    },\n    \"preprocessor_pref\": \"deepmind\",\n    \"observation_filter\": \"NoFilter\",\n    \"update_worker_filter_stats\": true,\n    \"use_worker_filter_stats\": true,\n    \"sampler_perf_stats_ema_coef\": null,\n    \"_is_online\": true,\n    \"num_learners\": 0,\n    \"num_gpus_per_learner\": 1,\n    \"num_cpus_per_learner\": \"auto\",\n    \"num_aggregator_actors_per_learner\": 0,\n    \"max_requests_in_flight_per_aggregator_actor\": 3,\n    \"local_gpu_idx\": 0,\n    \"max_requests_in_flight_per_learner\": 3,\n    \"gamma\": 0.99,\n    \"lr\": 5e-05,\n    \"grad_clip\": null,\n    \"grad_clip_by\": \"global_norm\",\n    \"_train_batch_size_per_learner\": null,\n    \"train_batch_size\": 4000,\n    \"num_epochs\": 10,\n    \"minibatch_size\": 256,\n    \"shuffle_batch_per_epoch\": true,\n    \"model\": {\n      \"fcnet_hiddens\": [\n        256,\n        256\n      ],\n      \"fcnet_activation\": \"tanh\",\n      \"fcnet_weights_initializer\": null,\n      \"fcnet_weights_initializer_config\": null,\n      \"fcnet_bias_initializer\": null,\n      \"fcnet_bias_initializer_config\": null,\n      \"conv_filters\": null,\n      \"conv_activation\": \"relu\",\n      \"conv_kernel_initializer\": null,\n      \"conv_kernel_initializer_config\": null,\n      \"conv_bias_initializer\": null,\n      \"conv_bias_initializer_config\": null,\n      \"conv_transpose_kernel_initializer\": null,\n      \"conv_transpose_kernel_initializer_config\": null,\n      \"conv_transpose_bias_initializer\": null,\n      \"conv_transpose_bias_initializer_config\": null,\n      \"post_fcnet_hiddens\": [],\n      \"post_fcnet_activation\": \"relu\",\n      \"post_fcnet_weights_initializer\": null,\n      \"post_fcnet_weights_initializer_config\": null,\n      \"post_fcnet_bias_initializer\": null,\n      \"post_fcnet_bias_initializer_config\": null,\n      \"free_log_std\": false,\n      \"log_std_clip_param\": 20.0,\n      \"no_final_linear\": false,\n      \"vf_share_layers\": false,\n      \"use_lstm\": false,\n      \"max_seq_len\": 20,\n      \"lstm_cell_size\": 256,\n      \"lstm_use_prev_action\": false,\n      \"lstm_use_prev_reward\": false,\n      \"lstm_weights_initializer\": null,\n      \"lstm_weights_initializer_config\": null,\n      \"lstm_bias_initializer\": null,\n      \"lstm_bias_initializer_config\": null,\n      \"_time_major\": false,\n      \"use_attention\": false,\n      \"attention_num_transformer_units\": 1,\n      \"attention_dim\": 64,\n      \"attention_num_heads\": 1,\n      \"attention_head_dim\": 32,\n      \"attention_memory_inference\": 50,\n      \"attention_memory_training\": 50,\n      \"attention_position_wise_mlp_dim\": 32,\n      \"attention_init_gru_gate_bias\": 2.0,\n      \"attention_use_n_prev_actions\": 0,\n      \"attention_use_n_prev_rewards\": 0,\n      \"framestack\": true,\n      \"dim\": 84,\n      \"grayscale\": false,\n      \"zero_mean\": true,\n      \"custom_model\": null,\n      \"custom_model_config\": {},\n      \"custom_action_dist\": null,\n      \"custom_preprocessor\": null,\n      \"encoder_latent_dim\": null,\n      \"always_check_shapes\": false,\n      \"lstm_use_prev_action_reward\": -1,\n      \"_use_default_native_models\": -1,\n      \"_disable_preprocessor_api\": false,\n      \"_disable_action_flattening\": false\n    },\n    \"_learner_connector\": null,\n    \"add_default_connectors_to_learner_pipeline\": true,\n    \"learner_config_dict\": {},\n    \"optimizer\": {},\n    \"_learner_class\": null,\n    \"callbacks_on_algorithm_init\": null,\n    \"callbacks_on_env_runners_recreated\": null,\n    \"callbacks_on_offline_eval_runners_recreated\": null,\n    \"callbacks_on_checkpoint_loaded\": null,\n    \"callbacks_on_environment_created\": null,\n    \"callbacks_on_episode_created\": null,\n    \"callbacks_on_episode_start\": null,\n    \"callbacks_on_episode_step\": null,\n    \"callbacks_on_episode_end\": null,\n    \"callbacks_on_evaluate_start\": null,\n    \"callbacks_on_evaluate_end\": null,\n    \"callbacks_on_evaluate_offline_start\": null,\n    \"callbacks_on_evaluate_offline_end\": null,\n    \"callbacks_on_sample_end\": null,\n    \"callbacks_on_train_result\": null,\n    \"explore\": true,\n    \"enable_rl_module_and_learner\": true,\n    \"enable_env_runner_and_connector_v2\": true,\n    \"_prior_exploration_config\": {\n      \"type\": \"StochasticSampling\"\n    },\n    \"count_steps_by\": \"env_steps\",\n    \"policy_map_capacity\": 100,\n    \"policy_mapping_fn\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059512020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b034b004b004b044b014b5b43047c005300944e859429288c086167656e745f6964948c07657069736f6465948c06776f726b6572948c066b77617267739474948c432f686f6d652f7875657a68692f7461736b2d61737369676e6d656e742d726f626f7469632d77617265686f7573652f736372697074732f747261696e5f70706f2e7079948c083c6c616d6264613e944b1e43020400942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f948c17747261696e2e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f9468098c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n    },\n    \"policies_to_train\": null,\n    \"policy_states_are_swappable\": false,\n    \"observation_fn\": null,\n    \"offline_data_class\": null,\n    \"input_read_method\": \"read_parquet\",\n    \"input_read_method_kwargs\": {},\n    \"input_read_schema\": {},\n    \"input_read_episodes\": false,\n    \"input_read_sample_batches\": false,\n    \"input_read_batch_size\": null,\n    \"input_filesystem\": null,\n    \"input_filesystem_kwargs\": {},\n    \"input_compress_columns\": [\n      \"obs\",\n      \"new_obs\"\n    ],\n    \"input_spaces_jsonable\": true,\n    \"materialize_data\": false,\n    \"materialize_mapped_data\": true,\n    \"map_batches_kwargs\": {},\n    \"iter_batches_kwargs\": {},\n    \"ignore_final_observation\": false,\n    \"prelearner_class\": null,\n    \"prelearner_buffer_class\": null,\n    \"prelearner_buffer_kwargs\": {},\n    \"prelearner_module_synch_period\": 10,\n    \"dataset_num_iters_per_learner\": null,\n    \"input_config\": {},\n    \"actions_in_input_normalized\": false,\n    \"postprocess_inputs\": false,\n    \"shuffle_buffer_size\": 0,\n    \"output\": null,\n    \"output_config\": {},\n    \"output_compress_columns\": [\n      \"obs\",\n      \"new_obs\"\n    ],\n    \"output_max_file_size\": 67108864,\n    \"output_max_rows_per_file\": null,\n    \"output_write_remaining_data\": false,\n    \"output_write_method\": \"write_parquet\",\n    \"output_write_method_kwargs\": {},\n    \"output_filesystem\": null,\n    \"output_filesystem_kwargs\": {},\n    \"output_write_episodes\": true,\n    \"offline_sampling\": false,\n    \"evaluation_interval\": 10,\n    \"evaluation_duration\": 5,\n    \"evaluation_duration_unit\": \"episodes\",\n    \"evaluation_sample_timeout_s\": 120.0,\n    \"evaluation_auto_duration_min_env_steps_per_sample\": 100,\n    \"evaluation_auto_duration_max_env_steps_per_sample\": 2000,\n    \"evaluation_parallel_to_training\": false,\n    \"evaluation_force_reset_envs_before_iteration\": true,\n    \"evaluation_config\": {\n      \"explore\": false\n    },\n    \"off_policy_estimation_methods\": {},\n    \"ope_split_batch_by_episode\": true,\n    \"evaluation_num_env_runners\": 0,\n    \"in_evaluation\": false,\n    \"sync_filters_on_rollout_workers_timeout_s\": 10.0,\n    \"offline_evaluation_interval\": null,\n    \"num_offline_eval_runners\": 0,\n    \"offline_evaluation_type\": null,\n    \"offline_eval_runner_class\": null,\n    \"offline_loss_for_module_fn\": null,\n    \"offline_evaluation_duration\": 1,\n    \"offline_evaluation_parallel_to_training\": false,\n    \"offline_evaluation_timeout_s\": 120.0,\n    \"num_cpus_per_offline_eval_runner\": 1,\n    \"num_gpus_per_offline_eval_runner\": 0,\n    \"custom_resources_per_offline_eval_runner\": {},\n    \"restart_failed_offline_eval_runners\": true,\n    \"ignore_offline_eval_runner_failures\": false,\n    \"max_num_offline_eval_runner_restarts\": 1000,\n    \"offline_eval_runner_restore_timeout_s\": 1800.0,\n    \"max_requests_in_flight_per_offline_eval_runner\": 1,\n    \"validate_offline_eval_runners_after_construction\": true,\n    \"offline_eval_runner_health_probe_timeout_s\": 30.0,\n    \"offline_eval_rl_module_inference_only\": false,\n    \"broadcast_offline_eval_runner_states\": false,\n    \"offline_eval_batch_size_per_runner\": 256,\n    \"dataset_num_iters_per_eval_runner\": 1,\n    \"keep_per_episode_custom_metrics\": false,\n    \"metrics_episode_collection_timeout_s\": 60.0,\n    \"metrics_num_episodes_for_smoothing\": 100,\n    \"min_time_s_per_iteration\": null,\n    \"min_train_timesteps_per_iteration\": 0,\n    \"min_sample_timesteps_per_iteration\": 0,\n    \"log_gradients\": false,\n    \"export_native_model_files\": false,\n    \"checkpoint_trainable_policies_only\": false,\n    \"logger_creator\": null,\n    \"logger_config\": null,\n    \"log_level\": \"WARN\",\n    \"log_sys_usage\": true,\n    \"fake_sampler\": false,\n    \"seed\": null,\n    \"restart_failed_env_runners\": true,\n    \"ignore_env_runner_failures\": false,\n    \"max_num_env_runner_restarts\": 1000,\n    \"delay_between_env_runner_restarts_s\": 60.0,\n    \"restart_failed_sub_environments\": false,\n    \"num_consecutive_env_runner_failures_tolerance\": 100,\n    \"env_runner_health_probe_timeout_s\": 30.0,\n    \"env_runner_restore_timeout_s\": 1800.0,\n    \"_model_config\": {},\n    \"_rl_module_spec\": null,\n    \"algorithm_config_overrides_per_module\": {},\n    \"_per_module_overrides\": {},\n    \"_validate_config\": true,\n    \"_use_msgpack_checkpoints\": false,\n    \"_torch_grad_scaler_class\": null,\n    \"_torch_lr_scheduler_classes\": null,\n    \"_tf_policy_handles_more_than_one_loss\": false,\n    \"_disable_preprocessor_api\": false,\n    \"_disable_action_flattening\": false,\n    \"_disable_initialize_loss_from_dummy_batch\": false,\n    \"_dont_auto_sync_env_runner_states\": false,\n    \"env_task_fn\": -1,\n    \"enable_connectors\": -1,\n    \"simple_optimizer\": -1,\n    \"policy_map_cache\": -1,\n    \"worker_cls\": -1,\n    \"synchronize_filters\": -1,\n    \"enable_async_evaluation\": -1,\n    \"custom_async_evaluation_function\": -1,\n    \"_enable_rl_module_api\": -1,\n    \"auto_wrap_old_gym_envs\": -1,\n    \"always_attach_evaluation_results\": -1,\n    \"replay_sequence_length\": null,\n    \"_disable_execution_plan_api\": -1,\n    \"use_critic\": true,\n    \"use_gae\": true,\n    \"use_kl_loss\": true,\n    \"kl_coeff\": 0.2,\n    \"kl_target\": 0.01,\n    \"vf_loss_coeff\": 1.0,\n    \"entropy_coeff\": 0.0,\n    \"clip_param\": 0.2,\n    \"vf_clip_param\": 10.0,\n    \"entropy_coeff_schedule\": null,\n    \"lr_schedule\": null,\n    \"sgd_minibatch_size\": -1,\n    \"vf_share_layers\": -1,\n    \"lambda\": 0.95,\n    \"input\": \"sampler\",\n    \"policies\": {\n      \"agent_0\": [\n        null,\n        null,\n        null,\n        {\n          \"model\": {\n            \"custom_model\": \"warehouse_marl_model\",\n            \"custom_model_config\": {}\n          }\n        }\n      ],\n      \"agent_1\": [\n        null,\n        null,\n        null,\n        {\n          \"model\": {\n            \"custom_model\": \"warehouse_marl_model\",\n            \"custom_model_config\": {}\n          }\n        }\n      ],\n      \"agent_2\": [\n        null,\n        null,\n        null,\n        {\n          \"model\": {\n            \"custom_model\": \"warehouse_marl_model\",\n            \"custom_model_config\": {}\n          }\n        }\n      ],\n      \"agent_3\": [\n        null,\n        null,\n        null,\n        {\n          \"model\": {\n            \"custom_model\": \"warehouse_marl_model\",\n            \"custom_model_config\": {}\n          }\n        }\n      ],\n      \"agent_4\": [\n        null,\n        null,\n        null,\n        {\n          \"model\": {\n            \"custom_model\": \"warehouse_marl_model\",\n            \"custom_model_config\": {}\n          }\n        }\n      ],\n      \"agent_5\": [\n        null,\n        null,\n        null,\n        {\n          \"model\": {\n            \"custom_model\": \"warehouse_marl_model\",\n            \"custom_model_config\": {}\n          }\n        }\n      ],\n      \"agent_6\": [\n        null,\n        null,\n        null,\n        {\n          \"model\": {\n            \"custom_model\": \"warehouse_marl_model\",\n            \"custom_model_config\": {}\n          }\n        }\n      ],\n      \"agent_7\": [\n        null,\n        null,\n        null,\n        {\n          \"model\": {\n            \"custom_model\": \"warehouse_marl_model\",\n            \"custom_model_config\": {}\n          }\n        }\n      ],\n      \"agent_8\": [\n        null,\n        null,\n        null,\n        {\n          \"model\": {\n            \"custom_model\": \"warehouse_marl_model\",\n            \"custom_model_config\": {}\n          }\n        }\n      ],\n      \"agent_9\": [\n        null,\n        null,\n        null,\n        {\n          \"model\": {\n            \"custom_model\": \"warehouse_marl_model\",\n            \"custom_model_config\": {}\n          }\n        }\n      ],\n      \"agent_10\": [\n        null,\n        null,\n        null,\n        {\n          \"model\": {\n            \"custom_model\": \"warehouse_marl_model\",\n            \"custom_model_config\": {}\n          }\n        }\n      ],\n      \"agent_11\": [\n        null,\n        null,\n        null,\n        {\n          \"model\": {\n            \"custom_model\": \"warehouse_marl_model\",\n            \"custom_model_config\": {}\n          }\n        }\n      ],\n      \"agent_12\": [\n        null,\n        null,\n        null,\n        {\n          \"model\": {\n            \"custom_model\": \"warehouse_marl_model\",\n            \"custom_model_config\": {}\n          }\n        }\n      ],\n      \"agent_13\": [\n        null,\n        null,\n        null,\n        {\n          \"model\": {\n            \"custom_model\": \"warehouse_marl_model\",\n            \"custom_model_config\": {}\n          }\n        }\n      ],\n      \"agent_14\": [\n        null,\n        null,\n        null,\n        {\n          \"model\": {\n            \"custom_model\": \"warehouse_marl_model\",\n            \"custom_model_config\": {}\n          }\n        }\n      ],\n      \"agent_15\": [\n        null,\n        null,\n        null,\n        {\n          \"model\": {\n            \"custom_model\": \"warehouse_marl_model\",\n            \"custom_model_config\": {}\n          }\n        }\n      ],\n      \"agent_16\": [\n        null,\n        null,\n        null,\n        {\n          \"model\": {\n            \"custom_model\": \"warehouse_marl_model\",\n            \"custom_model_config\": {}\n          }\n        }\n      ],\n      \"agent_17\": [\n        null,\n        null,\n        null,\n        {\n          \"model\": {\n            \"custom_model\": \"warehouse_marl_model\",\n            \"custom_model_config\": {}\n          }\n        }\n      ],\n      \"agent_18\": [\n        null,\n        null,\n        null,\n        {\n          \"model\": {\n            \"custom_model\": \"warehouse_marl_model\",\n            \"custom_model_config\": {}\n          }\n        }\n      ],\n      \"agent_19\": [\n        null,\n        null,\n        null,\n        {\n          \"model\": {\n            \"custom_model\": \"warehouse_marl_model\",\n            \"custom_model_config\": {}\n          }\n        }\n      ],\n      \"agent_20\": [\n        null,\n        null,\n        null,\n        {\n          \"model\": {\n            \"custom_model\": \"warehouse_marl_model\",\n            \"custom_model_config\": {}\n          }\n        }\n      ]\n    },\n    \"callbacks\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059533000000000000008c1d7261792e726c6c69622e63616c6c6261636b732e63616c6c6261636b73948c0d524c6c696243616c6c6261636b9493942e\"\n    },\n    \"create_env_on_driver\": false,\n    \"custom_eval_function\": null,\n    \"framework\": \"torch\"\n  },\n  \"_Trial__unresolved_config\": {\n    \"exploration_config\": {},\n    \"extra_python_environs_for_driver\": {},\n    \"extra_python_environs_for_worker\": {},\n    \"placement_strategy\": \"PACK\",\n    \"num_gpus\": 1,\n    \"_fake_gpus\": false,\n    \"num_cpus_for_main_process\": 1,\n    \"eager_tracing\": true,\n    \"eager_max_retraces\": 20,\n    \"tf_session_args\": {\n      \"intra_op_parallelism_threads\": 2,\n      \"inter_op_parallelism_threads\": 2,\n      \"gpu_options\": {\n        \"allow_growth\": true\n      },\n      \"log_device_placement\": false,\n      \"device_count\": {\n        \"CPU\": 1\n      },\n      \"allow_soft_placement\": true\n    },\n    \"local_tf_session_args\": {\n      \"intra_op_parallelism_threads\": 8,\n      \"inter_op_parallelism_threads\": 8\n    },\n    \"torch_compile_learner\": false,\n    \"torch_compile_learner_what_to_compile\": \"forward_train\",\n    \"torch_compile_learner_dynamo_backend\": \"inductor\",\n    \"torch_compile_learner_dynamo_mode\": null,\n    \"torch_compile_worker\": false,\n    \"torch_compile_worker_dynamo_backend\": \"onnxrt\",\n    \"torch_compile_worker_dynamo_mode\": null,\n    \"torch_ddp_kwargs\": {},\n    \"torch_skip_nan_gradients\": false,\n    \"env\": [\n      \"__ref_ph\",\n      \"1181ad55\"\n    ],\n    \"env_config\": {\n      \"env_id\": \"tarware-extralarge-14agvs-7pickers-partialobs-chg-v1\"\n    },\n    \"observation_space\": null,\n    \"action_space\": null,\n    \"clip_rewards\": null,\n    \"normalize_actions\": true,\n    \"clip_actions\": false,\n    \"_is_atari\": null,\n    \"disable_env_checking\": false,\n    \"render_env\": true,\n    \"action_mask_key\": \"action_mask\",\n    \"env_runner_cls\": null,\n    \"num_env_runners\": 3,\n    \"create_local_env_runner\": true,\n    \"num_envs_per_env_runner\": 1,\n    \"gym_env_vectorize_mode\": \"SYNC\",\n    \"num_cpus_per_env_runner\": 1,\n    \"num_gpus_per_env_runner\": 0,\n    \"custom_resources_per_env_runner\": {},\n    \"validate_env_runners_after_construction\": true,\n    \"episodes_to_numpy\": true,\n    \"max_requests_in_flight_per_env_runner\": 1,\n    \"sample_timeout_s\": 60.0,\n    \"_env_to_module_connector\": null,\n    \"add_default_connectors_to_env_to_module_pipeline\": true,\n    \"_module_to_env_connector\": null,\n    \"add_default_connectors_to_module_to_env_pipeline\": true,\n    \"merge_env_runner_states\": \"training_only\",\n    \"broadcast_env_runner_states\": true,\n    \"episode_lookback_horizon\": 1,\n    \"rollout_fragment_length\": \"auto\",\n    \"batch_mode\": \"truncate_episodes\",\n    \"compress_observations\": false,\n    \"remote_worker_envs\": false,\n    \"remote_env_batch_wait_ms\": 0,\n    \"enable_tf1_exec_eagerly\": false,\n    \"sample_collector\": [\n      \"__ref_ph\",\n      \"f176708f\"\n    ],\n    \"preprocessor_pref\": \"deepmind\",\n    \"observation_filter\": \"NoFilter\",\n    \"update_worker_filter_stats\": true,\n    \"use_worker_filter_stats\": true,\n    \"sampler_perf_stats_ema_coef\": null,\n    \"_is_online\": true,\n    \"num_learners\": 0,\n    \"num_gpus_per_learner\": 1,\n    \"num_cpus_per_learner\": \"auto\",\n    \"num_aggregator_actors_per_learner\": 0,\n    \"max_requests_in_flight_per_aggregator_actor\": 3,\n    \"local_gpu_idx\": 0,\n    \"max_requests_in_flight_per_learner\": 3,\n    \"gamma\": 0.99,\n    \"lr\": 5e-05,\n    \"grad_clip\": null,\n    \"grad_clip_by\": \"global_norm\",\n    \"_train_batch_size_per_learner\": null,\n    \"train_batch_size\": 4000,\n    \"num_epochs\": 10,\n    \"minibatch_size\": 256,\n    \"shuffle_batch_per_epoch\": true,\n    \"model\": {\n      \"fcnet_hiddens\": [\n        256,\n        256\n      ],\n      \"fcnet_activation\": \"tanh\",\n      \"fcnet_weights_initializer\": null,\n      \"fcnet_weights_initializer_config\": null,\n      \"fcnet_bias_initializer\": null,\n      \"fcnet_bias_initializer_config\": null,\n      \"conv_filters\": null,\n      \"conv_activation\": \"relu\",\n      \"conv_kernel_initializer\": null,\n      \"conv_kernel_initializer_config\": null,\n      \"conv_bias_initializer\": null,\n      \"conv_bias_initializer_config\": null,\n      \"conv_transpose_kernel_initializer\": null,\n      \"conv_transpose_kernel_initializer_config\": null,\n      \"conv_transpose_bias_initializer\": null,\n      \"conv_transpose_bias_initializer_config\": null,\n      \"post_fcnet_hiddens\": [],\n      \"post_fcnet_activation\": \"relu\",\n      \"post_fcnet_weights_initializer\": null,\n      \"post_fcnet_weights_initializer_config\": null,\n      \"post_fcnet_bias_initializer\": null,\n      \"post_fcnet_bias_initializer_config\": null,\n      \"free_log_std\": false,\n      \"log_std_clip_param\": 20.0,\n      \"no_final_linear\": false,\n      \"vf_share_layers\": false,\n      \"use_lstm\": false,\n      \"max_seq_len\": 20,\n      \"lstm_cell_size\": 256,\n      \"lstm_use_prev_action\": false,\n      \"lstm_use_prev_reward\": false,\n      \"lstm_weights_initializer\": null,\n      \"lstm_weights_initializer_config\": null,\n      \"lstm_bias_initializer\": null,\n      \"lstm_bias_initializer_config\": null,\n      \"_time_major\": false,\n      \"use_attention\": false,\n      \"attention_num_transformer_units\": 1,\n      \"attention_dim\": 64,\n      \"attention_num_heads\": 1,\n      \"attention_head_dim\": 32,\n      \"attention_memory_inference\": 50,\n      \"attention_memory_training\": 50,\n      \"attention_position_wise_mlp_dim\": 32,\n      \"attention_init_gru_gate_bias\": 2.0,\n      \"attention_use_n_prev_actions\": 0,\n      \"attention_use_n_prev_rewards\": 0,\n      \"framestack\": true,\n      \"dim\": 84,\n      \"grayscale\": false,\n      \"zero_mean\": true,\n      \"custom_model\": null,\n      \"custom_model_config\": {},\n      \"custom_action_dist\": null,\n      \"custom_preprocessor\": null,\n      \"encoder_latent_dim\": null,\n      \"always_check_shapes\": false,\n      \"lstm_use_prev_action_reward\": -1,\n      \"_use_default_native_models\": -1,\n      \"_disable_preprocessor_api\": false,\n      \"_disable_action_flattening\": false\n    },\n    \"_learner_connector\": null,\n    \"add_default_connectors_to_learner_pipeline\": true,\n    \"learner_config_dict\": {},\n    \"optimizer\": {},\n    \"_learner_class\": null,\n    \"callbacks_on_algorithm_init\": null,\n    \"callbacks_on_env_runners_recreated\": null,\n    \"callbacks_on_offline_eval_runners_recreated\": null,\n    \"callbacks_on_checkpoint_loaded\": null,\n    \"callbacks_on_environment_created\": null,\n    \"callbacks_on_episode_created\": null,\n    \"callbacks_on_episode_start\": null,\n    \"callbacks_on_episode_step\": null,\n    \"callbacks_on_episode_end\": null,\n    \"callbacks_on_evaluate_start\": null,\n    \"callbacks_on_evaluate_end\": null,\n    \"callbacks_on_evaluate_offline_start\": null,\n    \"callbacks_on_evaluate_offline_end\": null,\n    \"callbacks_on_sample_end\": null,\n    \"callbacks_on_train_result\": null,\n    \"explore\": true,\n    \"enable_rl_module_and_learner\": true,\n    \"enable_env_runner_and_connector_v2\": true,\n    \"_prior_exploration_config\": {\n      \"type\": \"StochasticSampling\"\n    },\n    \"count_steps_by\": \"env_steps\",\n    \"policy_map_capacity\": 100,\n    \"policy_mapping_fn\": [\n      \"__ref_ph\",\n      \"cdf20c8b\"\n    ],\n    \"policies_to_train\": null,\n    \"policy_states_are_swappable\": false,\n    \"observation_fn\": null,\n    \"offline_data_class\": null,\n    \"input_read_method\": \"read_parquet\",\n    \"input_read_method_kwargs\": {},\n    \"input_read_schema\": {},\n    \"input_read_episodes\": false,\n    \"input_read_sample_batches\": false,\n    \"input_read_batch_size\": null,\n    \"input_filesystem\": null,\n    \"input_filesystem_kwargs\": {},\n    \"input_compress_columns\": [\n      \"obs\",\n      \"new_obs\"\n    ],\n    \"input_spaces_jsonable\": true,\n    \"materialize_data\": false,\n    \"materialize_mapped_data\": true,\n    \"map_batches_kwargs\": {},\n    \"iter_batches_kwargs\": {},\n    \"ignore_final_observation\": false,\n    \"prelearner_class\": null,\n    \"prelearner_buffer_class\": null,\n    \"prelearner_buffer_kwargs\": {},\n    \"prelearner_module_synch_period\": 10,\n    \"dataset_num_iters_per_learner\": null,\n    \"input_config\": {},\n    \"actions_in_input_normalized\": false,\n    \"postprocess_inputs\": false,\n    \"shuffle_buffer_size\": 0,\n    \"output\": null,\n    \"output_config\": {},\n    \"output_compress_columns\": [\n      \"obs\",\n      \"new_obs\"\n    ],\n    \"output_max_file_size\": 67108864,\n    \"output_max_rows_per_file\": null,\n    \"output_write_remaining_data\": false,\n    \"output_write_method\": \"write_parquet\",\n    \"output_write_method_kwargs\": {},\n    \"output_filesystem\": null,\n    \"output_filesystem_kwargs\": {},\n    \"output_write_episodes\": true,\n    \"offline_sampling\": false,\n    \"evaluation_interval\": 10,\n    \"evaluation_duration\": 5,\n    \"evaluation_duration_unit\": \"episodes\",\n    \"evaluation_sample_timeout_s\": 120.0,\n    \"evaluation_auto_duration_min_env_steps_per_sample\": 100,\n    \"evaluation_auto_duration_max_env_steps_per_sample\": 2000,\n    \"evaluation_parallel_to_training\": false,\n    \"evaluation_force_reset_envs_before_iteration\": true,\n    \"evaluation_config\": {\n      \"explore\": false\n    },\n    \"off_policy_estimation_methods\": {},\n    \"ope_split_batch_by_episode\": true,\n    \"evaluation_num_env_runners\": 0,\n    \"in_evaluation\": false,\n    \"sync_filters_on_rollout_workers_timeout_s\": 10.0,\n    \"offline_evaluation_interval\": null,\n    \"num_offline_eval_runners\": 0,\n    \"offline_evaluation_type\": null,\n    \"offline_eval_runner_class\": null,\n    \"offline_loss_for_module_fn\": null,\n    \"offline_evaluation_duration\": 1,\n    \"offline_evaluation_parallel_to_training\": false,\n    \"offline_evaluation_timeout_s\": 120.0,\n    \"num_cpus_per_offline_eval_runner\": 1,\n    \"num_gpus_per_offline_eval_runner\": 0,\n    \"custom_resources_per_offline_eval_runner\": {},\n    \"restart_failed_offline_eval_runners\": true,\n    \"ignore_offline_eval_runner_failures\": false,\n    \"max_num_offline_eval_runner_restarts\": 1000,\n    \"offline_eval_runner_restore_timeout_s\": 1800.0,\n    \"max_requests_in_flight_per_offline_eval_runner\": 1,\n    \"validate_offline_eval_runners_after_construction\": true,\n    \"offline_eval_runner_health_probe_timeout_s\": 30.0,\n    \"offline_eval_rl_module_inference_only\": false,\n    \"broadcast_offline_eval_runner_states\": false,\n    \"offline_eval_batch_size_per_runner\": 256,\n    \"dataset_num_iters_per_eval_runner\": 1,\n    \"keep_per_episode_custom_metrics\": false,\n    \"metrics_episode_collection_timeout_s\": 60.0,\n    \"metrics_num_episodes_for_smoothing\": 100,\n    \"min_time_s_per_iteration\": null,\n    \"min_train_timesteps_per_iteration\": 0,\n    \"min_sample_timesteps_per_iteration\": 0,\n    \"log_gradients\": false,\n    \"export_native_model_files\": false,\n    \"checkpoint_trainable_policies_only\": false,\n    \"logger_creator\": null,\n    \"logger_config\": null,\n    \"log_level\": \"WARN\",\n    \"log_sys_usage\": true,\n    \"fake_sampler\": false,\n    \"seed\": null,\n    \"restart_failed_env_runners\": true,\n    \"ignore_env_runner_failures\": false,\n    \"max_num_env_runner_restarts\": 1000,\n    \"delay_between_env_runner_restarts_s\": 60.0,\n    \"restart_failed_sub_environments\": false,\n    \"num_consecutive_env_runner_failures_tolerance\": 100,\n    \"env_runner_health_probe_timeout_s\": 30.0,\n    \"env_runner_restore_timeout_s\": 1800.0,\n    \"_model_config\": {},\n    \"_rl_module_spec\": null,\n    \"algorithm_config_overrides_per_module\": {},\n    \"_per_module_overrides\": {},\n    \"_validate_config\": true,\n    \"_use_msgpack_checkpoints\": false,\n    \"_torch_grad_scaler_class\": null,\n    \"_torch_lr_scheduler_classes\": null,\n    \"_tf_policy_handles_more_than_one_loss\": false,\n    \"_disable_preprocessor_api\": false,\n    \"_disable_action_flattening\": false,\n    \"_disable_initialize_loss_from_dummy_batch\": false,\n    \"_dont_auto_sync_env_runner_states\": false,\n    \"env_task_fn\": -1,\n    \"enable_connectors\": -1,\n    \"simple_optimizer\": -1,\n    \"policy_map_cache\": -1,\n    \"worker_cls\": -1,\n    \"synchronize_filters\": -1,\n    \"enable_async_evaluation\": -1,\n    \"custom_async_evaluation_function\": -1,\n    \"_enable_rl_module_api\": -1,\n    \"auto_wrap_old_gym_envs\": -1,\n    \"always_attach_evaluation_results\": -1,\n    \"replay_sequence_length\": null,\n    \"_disable_execution_plan_api\": -1,\n    \"use_critic\": true,\n    \"use_gae\": true,\n    \"use_kl_loss\": true,\n    \"kl_coeff\": 0.2,\n    \"kl_target\": 0.01,\n    \"vf_loss_coeff\": 1.0,\n    \"entropy_coeff\": 0.0,\n    \"clip_param\": 0.2,\n    \"vf_clip_param\": 10.0,\n    \"entropy_coeff_schedule\": null,\n    \"lr_schedule\": null,\n    \"sgd_minibatch_size\": -1,\n    \"vf_share_layers\": -1,\n    \"lambda\": 0.95,\n    \"input\": \"sampler\",\n    \"policies\": {\n      \"agent_0\": [\n        null,\n        null,\n        null,\n        {\n          \"model\": {\n            \"custom_model\": \"warehouse_marl_model\",\n            \"custom_model_config\": {}\n          }\n        }\n      ],\n      \"agent_1\": [\n        null,\n        null,\n        null,\n        {\n          \"model\": {\n            \"custom_model\": \"warehouse_marl_model\",\n            \"custom_model_config\": {}\n          }\n        }\n      ],\n      \"agent_2\": [\n        null,\n        null,\n        null,\n        {\n          \"model\": {\n            \"custom_model\": \"warehouse_marl_model\",\n            \"custom_model_config\": {}\n          }\n        }\n      ],\n      \"agent_3\": [\n        null,\n        null,\n        null,\n        {\n          \"model\": {\n            \"custom_model\": \"warehouse_marl_model\",\n            \"custom_model_config\": {}\n          }\n        }\n      ],\n      \"agent_4\": [\n        null,\n        null,\n        null,\n        {\n          \"model\": {\n            \"custom_model\": \"warehouse_marl_model\",\n            \"custom_model_config\": {}\n          }\n        }\n      ],\n      \"agent_5\": [\n        null,\n        null,\n        null,\n        {\n          \"model\": {\n            \"custom_model\": \"warehouse_marl_model\",\n            \"custom_model_config\": {}\n          }\n        }\n      ],\n      \"agent_6\": [\n        null,\n        null,\n        null,\n        {\n          \"model\": {\n            \"custom_model\": \"warehouse_marl_model\",\n            \"custom_model_config\": {}\n          }\n        }\n      ],\n      \"agent_7\": [\n        null,\n        null,\n        null,\n        {\n          \"model\": {\n            \"custom_model\": \"warehouse_marl_model\",\n            \"custom_model_config\": {}\n          }\n        }\n      ],\n      \"agent_8\": [\n        null,\n        null,\n        null,\n        {\n          \"model\": {\n            \"custom_model\": \"warehouse_marl_model\",\n            \"custom_model_config\": {}\n          }\n        }\n      ],\n      \"agent_9\": [\n        null,\n        null,\n        null,\n        {\n          \"model\": {\n            \"custom_model\": \"warehouse_marl_model\",\n            \"custom_model_config\": {}\n          }\n        }\n      ],\n      \"agent_10\": [\n        null,\n        null,\n        null,\n        {\n          \"model\": {\n            \"custom_model\": \"warehouse_marl_model\",\n            \"custom_model_config\": {}\n          }\n        }\n      ],\n      \"agent_11\": [\n        null,\n        null,\n        null,\n        {\n          \"model\": {\n            \"custom_model\": \"warehouse_marl_model\",\n            \"custom_model_config\": {}\n          }\n        }\n      ],\n      \"agent_12\": [\n        null,\n        null,\n        null,\n        {\n          \"model\": {\n            \"custom_model\": \"warehouse_marl_model\",\n            \"custom_model_config\": {}\n          }\n        }\n      ],\n      \"agent_13\": [\n        null,\n        null,\n        null,\n        {\n          \"model\": {\n            \"custom_model\": \"warehouse_marl_model\",\n            \"custom_model_config\": {}\n          }\n        }\n      ],\n      \"agent_14\": [\n        null,\n        null,\n        null,\n        {\n          \"model\": {\n            \"custom_model\": \"warehouse_marl_model\",\n            \"custom_model_config\": {}\n          }\n        }\n      ],\n      \"agent_15\": [\n        null,\n        null,\n        null,\n        {\n          \"model\": {\n            \"custom_model\": \"warehouse_marl_model\",\n            \"custom_model_config\": {}\n          }\n        }\n      ],\n      \"agent_16\": [\n        null,\n        null,\n        null,\n        {\n          \"model\": {\n            \"custom_model\": \"warehouse_marl_model\",\n            \"custom_model_config\": {}\n          }\n        }\n      ],\n      \"agent_17\": [\n        null,\n        null,\n        null,\n        {\n          \"model\": {\n            \"custom_model\": \"warehouse_marl_model\",\n            \"custom_model_config\": {}\n          }\n        }\n      ],\n      \"agent_18\": [\n        null,\n        null,\n        null,\n        {\n          \"model\": {\n            \"custom_model\": \"warehouse_marl_model\",\n            \"custom_model_config\": {}\n          }\n        }\n      ],\n      \"agent_19\": [\n        null,\n        null,\n        null,\n        {\n          \"model\": {\n            \"custom_model\": \"warehouse_marl_model\",\n            \"custom_model_config\": {}\n          }\n        }\n      ],\n      \"agent_20\": [\n        null,\n        null,\n        null,\n        {\n          \"model\": {\n            \"custom_model\": \"warehouse_marl_model\",\n            \"custom_model_config\": {}\n          }\n        }\n      ]\n    },\n    \"callbacks\": [\n      \"__ref_ph\",\n      \"8913b504\"\n    ],\n    \"create_env_on_driver\": false,\n    \"custom_eval_function\": null,\n    \"framework\": \"torch\"\n  },\n  \"evaluated_params\": {},\n  \"experiment_tag\": \"0\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 10\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595e5000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d94287d94288c0343505594473ff00000000000008c0347505594473ff0000000000000757d946808473ff0000000000000737d946808473ff0000000000000737d946808473ff000000000000073658c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"RUNNING\",\n  \"relative_logdir\": \"PPO_WarehouseMultiAgentEnv_495f5_00000_0_2025-10-21_10-59-43\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1761037191.3371181,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"timers\": {\n      \"training_iteration\": 25.10474698148767,\n      \"restore_env_runners\": 1.775152007780685e-05,\n      \"training_step\": 25.104510079425125,\n      \"env_runner_sampling_timer\": 10.884857547115422,\n      \"learner_update_timer\": 14.184051073064248,\n      \"synch_weights\": 0.03309856041768848,\n      \"synch_env_connectors\": 0.0017402988769079856\n    },\n    \"env_runners\": {\n      \"num_module_steps_sampled_lifetime\": {\n        \"agent_15\": 24000.0,\n        \"agent_20\": 24000.0,\n        \"agent_2\": 24000.0,\n        \"agent_10\": 24000.0,\n        \"agent_19\": 24000.0,\n        \"agent_13\": 24000.0,\n        \"agent_16\": 24000.0,\n        \"agent_1\": 24000.0,\n        \"agent_4\": 24000.0,\n        \"agent_5\": 24000.0,\n        \"agent_14\": 24000.0,\n        \"agent_6\": 24000.0,\n        \"agent_3\": 24000.0,\n        \"agent_7\": 24000.0,\n        \"agent_17\": 24000.0,\n        \"agent_8\": 24000.0,\n        \"agent_0\": 24000.0,\n        \"agent_11\": 24000.0,\n        \"agent_12\": 24000.0,\n        \"agent_9\": 24000.0,\n        \"agent_18\": 24000.0\n      },\n      \"num_agent_steps_sampled_lifetime\": {\n        \"agent_8\": 24000.0,\n        \"agent_0\": 24000.0,\n        \"agent_11\": 24000.0,\n        \"agent_20\": 24000.0,\n        \"agent_12\": 24000.0,\n        \"agent_9\": 24000.0,\n        \"agent_15\": 24000.0,\n        \"agent_16\": 24000.0,\n        \"agent_2\": 24000.0,\n        \"agent_1\": 24000.0,\n        \"agent_10\": 24000.0,\n        \"agent_19\": 24000.0,\n        \"agent_13\": 24000.0,\n        \"agent_5\": 24000.0,\n        \"agent_14\": 24000.0,\n        \"agent_3\": 24000.0,\n        \"agent_4\": 24000.0,\n        \"agent_6\": 24000.0,\n        \"agent_7\": 24000.0,\n        \"agent_18\": 24000.0,\n        \"agent_17\": 24000.0\n      },\n      \"num_agent_steps_sampled\": {\n        \"agent_3\": 4000.0,\n        \"agent_4\": 4000.0,\n        \"agent_6\": 4000.0,\n        \"agent_7\": 4000.0,\n        \"agent_18\": 4000.0,\n        \"agent_17\": 4000.0,\n        \"agent_8\": 4000.0,\n        \"agent_0\": 4000.0,\n        \"agent_11\": 4000.0,\n        \"agent_20\": 4000.0,\n        \"agent_12\": 4000.0,\n        \"agent_9\": 4000.0,\n        \"agent_15\": 4000.0,\n        \"agent_16\": 4000.0,\n        \"agent_2\": 4000.0,\n        \"agent_1\": 4000.0,\n        \"agent_10\": 4000.0,\n        \"agent_19\": 4000.0,\n        \"agent_13\": 4000.0,\n        \"agent_5\": 4000.0,\n        \"agent_14\": 4000.0\n      },\n      \"module_episode_returns_mean\": {\n        \"agent_6\": -1.2770588235294145,\n        \"agent_7\": -2.132941176470596,\n        \"agent_18\": -4.496568627450995,\n        \"agent_17\": -4.446862745098052,\n        \"agent_8\": -1.9972549019607901,\n        \"agent_0\": -1.879705882352948,\n        \"agent_20\": -4.573823529411779,\n        \"agent_12\": -1.6871568627451035,\n        \"agent_19\": -4.426862745098052,\n        \"agent_11\": -1.668529411764711,\n        \"agent_9\": -2.121568627450987,\n        \"agent_15\": -4.307941176470601,\n        \"agent_16\": -4.484411764705898,\n        \"agent_2\": -1.3819607843137287,\n        \"agent_1\": -1.5888235294117692,\n        \"agent_10\": -2.008921568627457,\n        \"agent_4\": -1.5895098039215716,\n        \"agent_13\": -2.118627450980398,\n        \"agent_5\": -2.4234313725490266,\n        \"agent_14\": -4.432352941176485,\n        \"agent_3\": -2.402254901960791\n      },\n      \"agent_steps\": {\n        \"agent_19\": 500.0,\n        \"agent_13\": 500.0,\n        \"agent_5\": 500.0,\n        \"agent_14\": 500.0,\n        \"agent_3\": 500.0,\n        \"agent_4\": 500.0,\n        \"agent_6\": 500.0,\n        \"agent_18\": 500.0,\n        \"agent_7\": 500.0,\n        \"agent_17\": 500.0,\n        \"agent_8\": 500.0,\n        \"agent_0\": 500.0,\n        \"agent_11\": 500.0,\n        \"agent_20\": 500.0,\n        \"agent_12\": 500.0,\n        \"agent_9\": 500.0,\n        \"agent_15\": 500.0,\n        \"agent_16\": 500.0,\n        \"agent_2\": 500.0,\n        \"agent_1\": 500.0,\n        \"agent_10\": 500.0\n      },\n      \"module_to_env_connector\": {\n        \"timers\": {\n          \"connectors\": {\n            \"module_to_agent_unmapping\": 1.002482209024303e-05,\n            \"remove_single_ts_time_rank_from_batch\": 1.4093242275555993e-06,\n            \"un_batch_to_individual_items\": 0.00018842200496893522,\n            \"listify_data_for_vector_env\": 3.258184208650917e-05,\n            \"normalize_and_clip_actions\": 0.00011739232670045475,\n            \"tensor_to_numpy\": 0.0002592721138600847,\n            \"get_actions\": 0.0011927218339166637\n          }\n        },\n        \"connector_pipeline_timer\": 0.0018729672125500293\n      },\n      \"num_module_steps_sampled\": {\n        \"agent_5\": 4000.0,\n        \"agent_14\": 4000.0,\n        \"agent_6\": 4000.0,\n        \"agent_3\": 4000.0,\n        \"agent_7\": 4000.0,\n        \"agent_17\": 4000.0,\n        \"agent_8\": 4000.0,\n        \"agent_0\": 4000.0,\n        \"agent_11\": 4000.0,\n        \"agent_12\": 4000.0,\n        \"agent_9\": 4000.0,\n        \"agent_18\": 4000.0,\n        \"agent_15\": 4000.0,\n        \"agent_20\": 4000.0,\n        \"agent_10\": 4000.0,\n        \"agent_19\": 4000.0,\n        \"agent_13\": 4000.0,\n        \"agent_16\": 4000.0,\n        \"agent_2\": 4000.0,\n        \"agent_1\": 4000.0,\n        \"agent_4\": 4000.0\n      },\n      \"env_to_module_connector\": {\n        \"timers\": {\n          \"connectors\": {\n            \"add_states_from_episodes_to_batch\": 2.3421726507297737e-05,\n            \"batch_individual_items\": 0.00010100546806178463,\n            \"add_observations_from_episodes_to_batch\": 7.444056700609058e-05,\n            \"add_time_dim_to_batch_and_zero_pad\": 3.18414682565594e-05,\n            \"numpy_to_tensor\": 0.0001550664186335406,\n            \"agent_to_module_mapping\": 1.121463009165686e-05\n          }\n        },\n        \"connector_pipeline_timer\": 0.00044858052416618443\n      },\n      \"connector_pipeline_timer\": 0.0006737806834280491,\n      \"agent_episode_returns_mean\": {\n        \"agent_11\": -1.668529411764711,\n        \"agent_6\": -1.2770588235294145,\n        \"agent_12\": -1.6871568627451035,\n        \"agent_7\": -2.132941176470596,\n        \"agent_18\": -4.496568627450995,\n        \"agent_17\": -4.446862745098052,\n        \"agent_8\": -1.9972549019607901,\n        \"agent_0\": -1.879705882352948,\n        \"agent_20\": -4.573823529411779,\n        \"agent_19\": -4.426862745098052,\n        \"agent_9\": -2.121568627450987,\n        \"agent_15\": -4.307941176470601,\n        \"agent_16\": -4.484411764705898,\n        \"agent_2\": -1.3819607843137287,\n        \"agent_1\": -1.5888235294117692,\n        \"agent_10\": -2.008921568627457,\n        \"agent_4\": -1.5895098039215716,\n        \"agent_13\": -2.118627450980398,\n        \"agent_5\": -2.4234313725490266,\n        \"agent_14\": -4.432352941176485,\n        \"agent_3\": -2.402254901960791\n      },\n      \"timers\": {\n        \"connectors\": {\n          \"add_time_dim_to_batch_and_zero_pad\": 4.583634048079451e-05,\n          \"numpy_to_tensor\": 0.00018170633120462298,\n          \"agent_to_module_mapping\": 1.12936832010746e-05,\n          \"add_states_from_episodes_to_batch\": 2.319701404000322e-05,\n          \"batch_individual_items\": 0.00011492499227946003,\n          \"add_observations_from_episodes_to_batch\": 8.231331594288349e-05\n        }\n      },\n      \"episode_len_min\": 500,\n      \"weights_seq_no\": 5.0,\n      \"env_to_module_sum_episodes_length_in\": 394.7953752988912,\n      \"env_to_module_sum_episodes_length_out\": 394.7953752988912,\n      \"episode_duration_sec_mean\": 4.158014694685869,\n      \"episode_len_mean\": 500.0,\n      \"env_step_timer\": 0.0027740766678751687,\n      \"sample\": 10.716717756340303,\n      \"episode_return_min\": -77.91000000000034,\n      \"env_reset_timer\": 0.004376554667639234,\n      \"episode_len_max\": 500,\n      \"episode_return_max\": -43.350000000000165,\n      \"num_episodes_lifetime\": 46.0,\n      \"rlmodule_inference_timer\": 0.001998089100005526,\n      \"num_env_steps_sampled\": 4000.0,\n      \"episode_return_mean\": -57.446568627451164,\n      \"num_episodes\": 7.0,\n      \"num_env_steps_sampled_lifetime\": 24000.0,\n      \"time_between_sampling\": 14.444390896671555,\n      \"num_env_steps_sampled_lifetime_throughput\": 159.39507224364905\n    },\n    \"learners\": {\n      \"agent_10\": {\n        \"weights_seq_no\": 6.0,\n        \"total_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304c42634bd94869452942e\"\n        },\n        \"num_module_steps_trained_lifetime\": 241152,\n        \"module_train_batch_size_mean\": 256.0,\n        \"mean_kl_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430442471d3c94869452942e\"\n        },\n        \"num_module_steps_trained\": 40192,\n        \"entropy\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430432d6c34094869452942e\"\n        },\n        \"diff_num_grad_updates_vs_sampler_policy\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n        },\n        \"vf_explained_var\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243047251763f94869452942e\"\n        },\n        \"curr_kl_coeff\": 0.20000000298023224,\n        \"vf_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304e29d4b3a94869452942e\"\n        },\n        \"vf_loss_unclipped\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304e29d4b3a94869452942e\"\n        },\n        \"default_optimizer_learning_rate\": 5e-05,\n        \"curr_entropy_coeff\": 0.0,\n        \"num_trainable_parameters\": 781541,\n        \"policy_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430467323fbd94869452942e\"\n        },\n        \"num_module_steps_trained_lifetime_throughput\": 1591.8647800916358\n      },\n      \"agent_6\": {\n        \"total_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304f03b00be94869452942e\"\n        },\n        \"vf_explained_var\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304af73583f94869452942e\"\n        },\n        \"num_module_steps_trained_lifetime\": 241152,\n        \"curr_kl_coeff\": 0.20000000298023224,\n        \"mean_kl_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430462cc163c94869452942e\"\n        },\n        \"num_module_steps_trained\": 40192,\n        \"vf_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304c6988b3a94869452942e\"\n        },\n        \"diff_num_grad_updates_vs_sampler_policy\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n        },\n        \"vf_loss_unclipped\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304c6988b3a94869452942e\"\n        },\n        \"curr_entropy_coeff\": 0.0,\n        \"num_trainable_parameters\": 781541,\n        \"policy_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ae3503be94869452942e\"\n        },\n        \"default_optimizer_learning_rate\": 5e-05,\n        \"module_train_batch_size_mean\": 256.0,\n        \"entropy\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040ec3c34094869452942e\"\n        },\n        \"weights_seq_no\": 6.0,\n        \"num_module_steps_trained_lifetime_throughput\": 1591.8658345488564\n      },\n      \"agent_16\": {\n        \"diff_num_grad_updates_vs_sampler_policy\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n        },\n        \"vf_explained_var\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430426b85a3f94869452942e\"\n        },\n        \"curr_kl_coeff\": 0.20000000298023224,\n        \"vf_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430442bbdd3a94869452942e\"\n        },\n        \"vf_loss_unclipped\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430442bbdd3a94869452942e\"\n        },\n        \"default_optimizer_learning_rate\": 5e-05,\n        \"curr_entropy_coeff\": 0.0,\n        \"num_trainable_parameters\": 321253,\n        \"policy_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430492905d3d94869452942e\"\n        },\n        \"entropy\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430476c5c34094869452942e\"\n        },\n        \"weights_seq_no\": 6.0,\n        \"total_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ae006b3d94869452942e\"\n        },\n        \"num_module_steps_trained_lifetime\": 241152,\n        \"module_train_batch_size_mean\": 256.0,\n        \"mean_kl_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304182d023c94869452942e\"\n        },\n        \"num_module_steps_trained\": 40192,\n        \"num_module_steps_trained_lifetime_throughput\": 1591.8593263736066\n      },\n      \"agent_5\": {\n        \"vf_loss_unclipped\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243049a03f73994869452942e\"\n        },\n        \"default_optimizer_learning_rate\": 5e-05,\n        \"module_train_batch_size_mean\": 256.0,\n        \"num_trainable_parameters\": 781541,\n        \"entropy\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304c3b3c34094869452942e\"\n        },\n        \"weights_seq_no\": 6.0,\n        \"total_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304c8eb81bc94869452942e\"\n        },\n        \"vf_explained_var\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243047782733f94869452942e\"\n        },\n        \"num_module_steps_trained_lifetime\": 241152,\n        \"curr_kl_coeff\": 0.20000000298023224,\n        \"mean_kl_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304f2b11c3c94869452942e\"\n        },\n        \"num_module_steps_trained\": 40192,\n        \"vf_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243049a03f73994869452942e\"\n        },\n        \"diff_num_grad_updates_vs_sampler_policy\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n        },\n        \"curr_entropy_coeff\": 0.0,\n        \"policy_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243043c7395bc94869452942e\"\n        },\n        \"num_module_steps_trained_lifetime_throughput\": 1591.861850367351\n      },\n      \"agent_11\": {\n        \"num_module_steps_trained_lifetime\": 241152,\n        \"curr_kl_coeff\": 0.20000000298023224,\n        \"mean_kl_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304d3a41f3c94869452942e\"\n        },\n        \"num_module_steps_trained\": 40192,\n        \"vf_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430441b0a63a94869452942e\"\n        },\n        \"diff_num_grad_updates_vs_sampler_policy\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n        },\n        \"vf_loss_unclipped\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430441b0a63a94869452942e\"\n        },\n        \"curr_entropy_coeff\": 0.0,\n        \"num_trainable_parameters\": 781541,\n        \"policy_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243049872a0bd94869452942e\"\n        },\n        \"default_optimizer_learning_rate\": 5e-05,\n        \"module_train_batch_size_mean\": 256.0,\n        \"entropy\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304c2b3c34094869452942e\"\n        },\n        \"weights_seq_no\": 6.0,\n        \"total_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430421da99bd94869452942e\"\n        },\n        \"vf_explained_var\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304d73c593f94869452942e\"\n        },\n        \"num_module_steps_trained_lifetime_throughput\": 1591.867590742575\n      },\n      \"agent_20\": {\n        \"curr_entropy_coeff\": 0.0,\n        \"num_trainable_parameters\": 321253,\n        \"policy_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304745191bd94869452942e\"\n        },\n        \"default_optimizer_learning_rate\": 5e-05,\n        \"module_train_batch_size_mean\": 256.0,\n        \"entropy\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243042cb0c34094869452942e\"\n        },\n        \"weights_seq_no\": 6.0,\n        \"total_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243044daf88bd94869452942e\"\n        },\n        \"vf_explained_var\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430465ff473f94869452942e\"\n        },\n        \"num_module_steps_trained_lifetime\": 241152,\n        \"curr_kl_coeff\": 0.20000000298023224,\n        \"mean_kl_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304672a013c94869452942e\"\n        },\n        \"num_module_steps_trained\": 40192,\n        \"vf_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304b9ef2c3b94869452942e\"\n        },\n        \"diff_num_grad_updates_vs_sampler_policy\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n        },\n        \"vf_loss_unclipped\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304b9ef2c3b94869452942e\"\n        },\n        \"num_module_steps_trained_lifetime_throughput\": 1591.8602752991162\n      },\n      \"__all_modules__\": {\n        \"num_non_trainable_parameters\": 0,\n        \"learner_connector\": {\n          \"timers\": {\n            \"connectors\": {\n              \"add_columns_from_episodes_to_train_batch\": 0.6733561091402839,\n              \"general_advantage_estimation\": 0.10243857991950835,\n              \"batch_individual_items\": 1.0375086348200784,\n              \"add_observations_from_episodes_to_batch\": 0.0012850938029720588,\n              \"numpy_to_tensor\": 0.03390702297966587,\n              \"agent_to_module_mapping\": 0.038058187737068254,\n              \"add_states_from_episodes_to_batch\": 3.2298296915306924e-05,\n              \"add_time_dim_to_batch_and_zero_pad\": 5.863167693485768e-05,\n              \"add_one_ts_to_episodes_and_truncate\": 0.14530727109049152\n            }\n          },\n          \"connector_pipeline_timer\": 2.0324515798615774\n        },\n        \"num_module_steps_trained_lifetime\": 5064192,\n        \"learner_connector_sum_episodes_length_out\": 4000.0,\n        \"num_env_steps_trained_lifetime\": 3768000,\n        \"num_trainable_parameters\": 13190345,\n        \"num_env_steps_trained\": 628000,\n        \"learner_connector_sum_episodes_length_in\": 4000.0,\n        \"num_module_steps_trained\": 844032,\n        \"num_env_steps_trained_lifetime_throughput\": 24872.83194309265,\n        \"num_module_steps_trained_throughput\": 0.0,\n        \"num_module_steps_trained_lifetime_throughput\": 33429.15565871061\n      },\n      \"agent_13\": {\n        \"module_train_batch_size_mean\": 256.0,\n        \"entropy\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430426dac34094869452942e\"\n        },\n        \"weights_seq_no\": 6.0,\n        \"total_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304842ff2bd94869452942e\"\n        },\n        \"vf_explained_var\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243044a6d573f94869452942e\"\n        },\n        \"num_module_steps_trained_lifetime\": 241152,\n        \"curr_kl_coeff\": 0.20000000298023224,\n        \"mean_kl_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243044d97093c94869452942e\"\n        },\n        \"num_module_steps_trained\": 40192,\n        \"vf_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304abb2a33a94869452942e\"\n        },\n        \"diff_num_grad_updates_vs_sampler_policy\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n        },\n        \"vf_loss_unclipped\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304abb2a33a94869452942e\"\n        },\n        \"curr_entropy_coeff\": 0.0,\n        \"num_trainable_parameters\": 781541,\n        \"policy_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304e62ef8bd94869452942e\"\n        },\n        \"default_optimizer_learning_rate\": 5e-05,\n        \"num_module_steps_trained_lifetime_throughput\": 1591.863927936419\n      },\n      \"agent_8\": {\n        \"total_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304cb14a4bd94869452942e\"\n        },\n        \"vf_explained_var\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430499415f3f94869452942e\"\n        },\n        \"num_module_steps_trained_lifetime\": 241152,\n        \"curr_kl_coeff\": 0.20000000298023224,\n        \"mean_kl_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243048f7dfd3b94869452942e\"\n        },\n        \"num_module_steps_trained\": 40192,\n        \"vf_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243049eb16e3a94869452942e\"\n        },\n        \"diff_num_grad_updates_vs_sampler_policy\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n        },\n        \"curr_entropy_coeff\": 0.0,\n        \"policy_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243045a1da9bd94869452942e\"\n        },\n        \"vf_loss_unclipped\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243049eb16e3a94869452942e\"\n        },\n        \"default_optimizer_learning_rate\": 5e-05,\n        \"num_trainable_parameters\": 781541,\n        \"module_train_batch_size_mean\": 256.0,\n        \"entropy\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243048218c44094869452942e\"\n        },\n        \"weights_seq_no\": 6.0,\n        \"num_module_steps_trained_lifetime_throughput\": 1591.8656248442353\n      },\n      \"agent_9\": {\n        \"curr_entropy_coeff\": 0.0,\n        \"policy_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243044d4317bd94869452942e\"\n        },\n        \"vf_loss_unclipped\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243049bfd173a94869452942e\"\n        },\n        \"default_optimizer_learning_rate\": 5e-05,\n        \"module_train_batch_size_mean\": 256.0,\n        \"num_trainable_parameters\": 781541,\n        \"entropy\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243042fccc34094869452942e\"\n        },\n        \"weights_seq_no\": 6.0,\n        \"total_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304e03a0dbd94869452942e\"\n        },\n        \"vf_explained_var\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304328e703f94869452942e\"\n        },\n        \"num_module_steps_trained_lifetime\": 241152,\n        \"curr_kl_coeff\": 0.20000000298023224,\n        \"mean_kl_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243046229193c94869452942e\"\n        },\n        \"num_module_steps_trained\": 40192,\n        \"vf_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243049bfd173a94869452942e\"\n        },\n        \"diff_num_grad_updates_vs_sampler_policy\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n        },\n        \"num_module_steps_trained_lifetime_throughput\": 1591.8600701838775\n      },\n      \"agent_1\": {\n        \"module_train_batch_size_mean\": 256.0,\n        \"entropy\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243041523c44094869452942e\"\n        },\n        \"weights_seq_no\": 6.0,\n        \"total_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430402a3b9bd94869452942e\"\n        },\n        \"vf_explained_var\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243044020623f94869452942e\"\n        },\n        \"num_module_steps_trained_lifetime\": 241152,\n        \"curr_kl_coeff\": 0.20000000298023224,\n        \"mean_kl_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430400620c3c94869452942e\"\n        },\n        \"num_module_steps_trained\": 40192,\n        \"vf_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ac092d3a94869452942e\"\n        },\n        \"diff_num_grad_updates_vs_sampler_policy\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n        },\n        \"vf_loss_unclipped\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ac092d3a94869452942e\"\n        },\n        \"curr_entropy_coeff\": 0.0,\n        \"num_trainable_parameters\": 781541,\n        \"policy_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304887fbebd94869452942e\"\n        },\n        \"default_optimizer_learning_rate\": 5e-05,\n        \"num_module_steps_trained_lifetime_throughput\": 1591.8637218293245\n      },\n      \"agent_19\": {\n        \"vf_explained_var\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430428114f3f94869452942e\"\n        },\n        \"num_module_steps_trained_lifetime\": 241152,\n        \"curr_kl_coeff\": 0.20000000298023224,\n        \"mean_kl_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304491b003c94869452942e\"\n        },\n        \"num_module_steps_trained\": 40192,\n        \"vf_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243049c4ce93a94869452942e\"\n        },\n        \"diff_num_grad_updates_vs_sampler_policy\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n        },\n        \"curr_entropy_coeff\": 0.0,\n        \"policy_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243047d0ad5bd94869452942e\"\n        },\n        \"vf_loss_unclipped\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243049c4ce93a94869452942e\"\n        },\n        \"default_optimizer_learning_rate\": 5e-05,\n        \"module_train_batch_size_mean\": 256.0,\n        \"num_trainable_parameters\": 321253,\n        \"entropy\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243046385c34094869452942e\"\n        },\n        \"weights_seq_no\": 6.0,\n        \"total_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243046a31cebd94869452942e\"\n        },\n        \"num_module_steps_trained_lifetime_throughput\": 1591.8661372291976\n      },\n      \"agent_17\": {\n        \"vf_explained_var\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304f9254e3f94869452942e\"\n        },\n        \"num_module_steps_trained_lifetime\": 241152,\n        \"curr_kl_coeff\": 0.20000000298023224,\n        \"mean_kl_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304d0c4f13b94869452942e\"\n        },\n        \"vf_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304d675983a94869452942e\"\n        },\n        \"vf_loss_unclipped\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304d675983a94869452942e\"\n        },\n        \"default_optimizer_learning_rate\": 5e-05,\n        \"curr_entropy_coeff\": 0.0,\n        \"num_trainable_parameters\": 321253,\n        \"policy_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430470418abd94869452942e\"\n        },\n        \"weights_seq_no\": 6.0,\n        \"total_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304efd984bd94869452942e\"\n        },\n        \"module_train_batch_size_mean\": 256.0,\n        \"num_module_steps_trained\": 40192,\n        \"entropy\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304b8acc34094869452942e\"\n        },\n        \"diff_num_grad_updates_vs_sampler_policy\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n        },\n        \"num_module_steps_trained_lifetime_throughput\": 1591.8660739711981\n      },\n      \"agent_3\": {\n        \"curr_kl_coeff\": 0.20000000298023224,\n        \"vf_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ad251c3a94869452942e\"\n        },\n        \"vf_loss_unclipped\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ad251c3a94869452942e\"\n        },\n        \"default_optimizer_learning_rate\": 5e-05,\n        \"curr_entropy_coeff\": 0.0,\n        \"num_trainable_parameters\": 781541,\n        \"policy_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304117a23bd94869452942e\"\n        },\n        \"entropy\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430460c5c34094869452942e\"\n        },\n        \"weights_seq_no\": 6.0,\n        \"total_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243043ce118bd94869452942e\"\n        },\n        \"num_module_steps_trained_lifetime\": 241152,\n        \"module_train_batch_size_mean\": 256.0,\n        \"mean_kl_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304fe24233c94869452942e\"\n        },\n        \"num_module_steps_trained\": 40192,\n        \"diff_num_grad_updates_vs_sampler_policy\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n        },\n        \"vf_explained_var\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304af776f3f94869452942e\"\n        },\n        \"num_module_steps_trained_lifetime_throughput\": 1591.8607209225213\n      },\n      \"agent_15\": {\n        \"total_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243041c7dc6bd94869452942e\"\n        },\n        \"vf_explained_var\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243045cc9603f94869452942e\"\n        },\n        \"num_module_steps_trained_lifetime\": 241152,\n        \"curr_kl_coeff\": 0.20000000298023224,\n        \"mean_kl_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304e4daef3b94869452942e\"\n        },\n        \"num_module_steps_trained\": 40192,\n        \"vf_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430402e7c13a94869452942e\"\n        },\n        \"diff_num_grad_updates_vs_sampler_policy\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n        },\n        \"vf_loss_unclipped\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430402e7c13a94869452942e\"\n        },\n        \"curr_entropy_coeff\": 0.0,\n        \"num_trainable_parameters\": 321253,\n        \"policy_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243043f84ccbd94869452942e\"\n        },\n        \"default_optimizer_learning_rate\": 5e-05,\n        \"module_train_batch_size_mean\": 256.0,\n        \"entropy\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430448d1c34094869452942e\"\n        },\n        \"weights_seq_no\": 6.0,\n        \"num_module_steps_trained_lifetime_throughput\": 1591.865394031671\n      },\n      \"agent_12\": {\n        \"total_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304d9e4abbd94869452942e\"\n        },\n        \"num_module_steps_trained_lifetime\": 241152,\n        \"module_train_batch_size_mean\": 256.0,\n        \"num_module_steps_trained\": 40192,\n        \"entropy\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243045209c44094869452942e\"\n        },\n        \"diff_num_grad_updates_vs_sampler_policy\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n        },\n        \"vf_explained_var\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430421406d3f94869452942e\"\n        },\n        \"curr_kl_coeff\": 0.20000000298023224,\n        \"mean_kl_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304b175163c94869452942e\"\n        },\n        \"vf_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304c025e93994869452942e\"\n        },\n        \"vf_loss_unclipped\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304c025e93994869452942e\"\n        },\n        \"default_optimizer_learning_rate\": 5e-05,\n        \"curr_entropy_coeff\": 0.0,\n        \"num_trainable_parameters\": 781541,\n        \"policy_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304f090b0bd94869452942e\"\n        },\n        \"weights_seq_no\": 6.0,\n        \"num_module_steps_trained_lifetime_throughput\": 1591.865176465816\n      },\n      \"agent_18\": {\n        \"diff_num_grad_updates_vs_sampler_policy\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n        },\n        \"vf_explained_var\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304de69413f94869452942e\"\n        },\n        \"num_module_steps_trained_lifetime\": 241152,\n        \"curr_kl_coeff\": 0.20000000298023224,\n        \"mean_kl_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430464be013c94869452942e\"\n        },\n        \"vf_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040a680d3b94869452942e\"\n        },\n        \"vf_loss_unclipped\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040a680d3b94869452942e\"\n        },\n        \"default_optimizer_learning_rate\": 5e-05,\n        \"curr_entropy_coeff\": 0.0,\n        \"num_trainable_parameters\": 321253,\n        \"policy_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304f50287bd94869452942e\"\n        },\n        \"weights_seq_no\": 6.0,\n        \"total_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304b0b27ebd94869452942e\"\n        },\n        \"module_train_batch_size_mean\": 256.0,\n        \"num_module_steps_trained\": 40192,\n        \"entropy\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430472b3c34094869452942e\"\n        },\n        \"num_module_steps_trained_lifetime_throughput\": 1591.8652741005903\n      },\n      \"agent_7\": {\n        \"num_module_steps_trained_lifetime\": 241152,\n        \"curr_kl_coeff\": 0.20000000298023224,\n        \"mean_kl_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430496db203c94869452942e\"\n        },\n        \"num_module_steps_trained\": 40192,\n        \"vf_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243044f8f433a94869452942e\"\n        },\n        \"diff_num_grad_updates_vs_sampler_policy\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n        },\n        \"vf_loss_unclipped\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243044f8f433a94869452942e\"\n        },\n        \"curr_entropy_coeff\": 0.0,\n        \"num_trainable_parameters\": 781541,\n        \"policy_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243043d29c1bd94869452942e\"\n        },\n        \"default_optimizer_learning_rate\": 5e-05,\n        \"module_train_batch_size_mean\": 256.0,\n        \"entropy\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430415f2c34094869452942e\"\n        },\n        \"weights_seq_no\": 6.0,\n        \"total_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304a19cbbbd94869452942e\"\n        },\n        \"vf_explained_var\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430434b8683f94869452942e\"\n        },\n        \"num_module_steps_trained_lifetime_throughput\": 1591.8670843881143\n      },\n      \"agent_14\": {\n        \"diff_num_grad_updates_vs_sampler_policy\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n        },\n        \"curr_entropy_coeff\": 0.0,\n        \"policy_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430454c6c0bd94869452942e\"\n        },\n        \"vf_loss_unclipped\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304d6d1b33a94869452942e\"\n        },\n        \"default_optimizer_learning_rate\": 5e-05,\n        \"module_train_batch_size_mean\": 256.0,\n        \"num_trainable_parameters\": 321253,\n        \"entropy\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040090c34094869452942e\"\n        },\n        \"weights_seq_no\": 6.0,\n        \"total_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304c34bbabd94869452942e\"\n        },\n        \"vf_explained_var\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304dbc9603f94869452942e\"\n        },\n        \"num_module_steps_trained_lifetime\": 241152,\n        \"curr_kl_coeff\": 0.20000000298023224,\n        \"mean_kl_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430499c3123c94869452942e\"\n        },\n        \"num_module_steps_trained\": 40192,\n        \"vf_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304d6d1b33a94869452942e\"\n        },\n        \"num_module_steps_trained_lifetime_throughput\": 1591.8574526959803\n      },\n      \"agent_0\": {\n        \"num_trainable_parameters\": 781541,\n        \"entropy\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304b6c3c34094869452942e\"\n        },\n        \"weights_seq_no\": 6.0,\n        \"total_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304699c983c94869452942e\"\n        },\n        \"vf_explained_var\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243045aeb693f94869452942e\"\n        },\n        \"num_module_steps_trained_lifetime\": 241152,\n        \"curr_kl_coeff\": 0.20000000298023224,\n        \"module_train_batch_size_mean\": 256.0,\n        \"mean_kl_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304046d0a3c94869452942e\"\n        },\n        \"num_module_steps_trained\": 40192,\n        \"vf_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430440f6fa3994869452942e\"\n        },\n        \"diff_num_grad_updates_vs_sampler_policy\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n        },\n        \"curr_entropy_coeff\": 0.0,\n        \"policy_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ddd8863c94869452942e\"\n        },\n        \"vf_loss_unclipped\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430440f6fa3994869452942e\"\n        },\n        \"default_optimizer_learning_rate\": 5e-05,\n        \"num_module_steps_trained_lifetime_throughput\": 1591.8631284728958\n      },\n      \"agent_2\": {\n        \"num_trainable_parameters\": 781541,\n        \"policy_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243041aea37bd94869452942e\"\n        },\n        \"default_optimizer_learning_rate\": 5e-05,\n        \"module_train_batch_size_mean\": 256.0,\n        \"entropy\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243049bf6c34094869452942e\"\n        },\n        \"weights_seq_no\": 6.0,\n        \"total_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430406252ebd94869452942e\"\n        },\n        \"vf_explained_var\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243049fba6c3f94869452942e\"\n        },\n        \"num_module_steps_trained_lifetime\": 241152,\n        \"curr_kl_coeff\": 0.20000000298023224,\n        \"mean_kl_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304bb67153c94869452942e\"\n        },\n        \"num_module_steps_trained\": 40192,\n        \"vf_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304502c133a94869452942e\"\n        },\n        \"diff_num_grad_updates_vs_sampler_policy\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n        },\n        \"vf_loss_unclipped\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304502c133a94869452942e\"\n        },\n        \"curr_entropy_coeff\": 0.0,\n        \"num_module_steps_trained_lifetime_throughput\": 1591.8603777466215\n      },\n      \"agent_4\": {\n        \"num_module_steps_trained_lifetime\": 241152,\n        \"curr_kl_coeff\": 0.20000000298023224,\n        \"module_train_batch_size_mean\": 256.0,\n        \"mean_kl_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304be10153c94869452942e\"\n        },\n        \"num_module_steps_trained\": 40192,\n        \"vf_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243046b6bb63a94869452942e\"\n        },\n        \"diff_num_grad_updates_vs_sampler_policy\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n        },\n        \"vf_explained_var\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304c641663f94869452942e\"\n        },\n        \"policy_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243049815b4bd94869452942e\"\n        },\n        \"vf_loss_unclipped\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243046b6bb63a94869452942e\"\n        },\n        \"default_optimizer_learning_rate\": 5e-05,\n        \"curr_entropy_coeff\": 0.0,\n        \"num_trainable_parameters\": 781541,\n        \"entropy\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430466aac34094869452942e\"\n        },\n        \"weights_seq_no\": 6.0,\n        \"total_loss\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304e481adbd94869452942e\"\n        },\n        \"num_module_steps_trained_lifetime_throughput\": 1591.8663201603033\n      }\n    },\n    \"num_training_step_calls_per_iteration\": 1,\n    \"num_env_steps_sampled_lifetime\": 24000.0,\n    \"fault_tolerance\": {\n      \"num_healthy_workers\": 3,\n      \"num_remote_worker_restarts\": 0\n    },\n    \"env_runner_group\": {\n      \"actor_manager_num_outstanding_async_reqs\": 0\n    },\n    \"done\": false,\n    \"training_iteration\": 6,\n    \"trial_id\": \"495f5_00000\",\n    \"date\": \"2025-10-21_11-02-22\",\n    \"timestamp\": 1761037342,\n    \"time_this_iter_s\": 25.530882835388184,\n    \"time_total_s\": 151.17440128326416,\n    \"pid\": 3202121,\n    \"hostname\": \"xuezhi-Precision-3660\",\n    \"node_ip\": \"130.238.16.41\",\n    \"config\": {\n      \"exploration_config\": {},\n      \"extra_python_environs_for_driver\": {},\n      \"extra_python_environs_for_worker\": {},\n      \"placement_strategy\": \"PACK\",\n      \"num_gpus\": 1,\n      \"_fake_gpus\": false,\n      \"num_cpus_for_main_process\": 1,\n      \"eager_tracing\": true,\n      \"eager_max_retraces\": 20,\n      \"tf_session_args\": {\n        \"intra_op_parallelism_threads\": 2,\n        \"inter_op_parallelism_threads\": 2,\n        \"gpu_options\": {\n          \"allow_growth\": true\n        },\n        \"log_device_placement\": false,\n        \"device_count\": {\n          \"CPU\": 1\n        },\n        \"allow_soft_placement\": true\n      },\n      \"local_tf_session_args\": {\n        \"intra_op_parallelism_threads\": 8,\n        \"inter_op_parallelism_threads\": 8\n      },\n      \"torch_compile_learner\": false,\n      \"torch_compile_learner_what_to_compile\": \"forward_train\",\n      \"torch_compile_learner_dynamo_backend\": \"inductor\",\n      \"torch_compile_learner_dynamo_mode\": null,\n      \"torch_compile_worker\": false,\n      \"torch_compile_worker_dynamo_backend\": \"onnxrt\",\n      \"torch_compile_worker_dynamo_mode\": null,\n      \"torch_ddp_kwargs\": {},\n      \"torch_skip_nan_gradients\": false,\n      \"env\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b747261696e5f7574696c73948c1657617265686f7573654d756c74694167656e74456e769493942e\"\n      },\n      \"env_config\": {\n        \"env_id\": \"tarware-extralarge-14agvs-7pickers-partialobs-chg-v1\"\n      },\n      \"observation_space\": null,\n      \"action_space\": null,\n      \"clip_rewards\": null,\n      \"normalize_actions\": true,\n      \"clip_actions\": false,\n      \"_is_atari\": null,\n      \"disable_env_checking\": false,\n      \"render_env\": true,\n      \"action_mask_key\": \"action_mask\",\n      \"env_runner_cls\": null,\n      \"num_env_runners\": 3,\n      \"create_local_env_runner\": true,\n      \"num_envs_per_env_runner\": 1,\n      \"gym_env_vectorize_mode\": \"SYNC\",\n      \"num_cpus_per_env_runner\": 1,\n      \"num_gpus_per_env_runner\": 0,\n      \"custom_resources_per_env_runner\": {},\n      \"validate_env_runners_after_construction\": true,\n      \"episodes_to_numpy\": true,\n      \"max_requests_in_flight_per_env_runner\": 1,\n      \"sample_timeout_s\": 60.0,\n      \"_env_to_module_connector\": null,\n      \"add_default_connectors_to_env_to_module_pipeline\": true,\n      \"_module_to_env_connector\": null,\n      \"add_default_connectors_to_module_to_env_pipeline\": true,\n      \"merge_env_runner_states\": \"training_only\",\n      \"broadcast_env_runner_states\": true,\n      \"episode_lookback_horizon\": 1,\n      \"rollout_fragment_length\": \"auto\",\n      \"batch_mode\": \"truncate_episodes\",\n      \"compress_observations\": false,\n      \"remote_worker_envs\": false,\n      \"remote_env_batch_wait_ms\": 0,\n      \"enable_tf1_exec_eagerly\": false,\n      \"sample_collector\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059551000000000000008c357261792e726c6c69622e6576616c756174696f6e2e636f6c6c6563746f72732e73696d706c655f6c6973745f636f6c6c6563746f72948c1353696d706c654c697374436f6c6c6563746f729493942e\"\n      },\n      \"preprocessor_pref\": \"deepmind\",\n      \"observation_filter\": \"NoFilter\",\n      \"update_worker_filter_stats\": true,\n      \"use_worker_filter_stats\": true,\n      \"sampler_perf_stats_ema_coef\": null,\n      \"_is_online\": true,\n      \"num_learners\": 0,\n      \"num_gpus_per_learner\": 1,\n      \"num_cpus_per_learner\": \"auto\",\n      \"num_aggregator_actors_per_learner\": 0,\n      \"max_requests_in_flight_per_aggregator_actor\": 3,\n      \"local_gpu_idx\": 0,\n      \"max_requests_in_flight_per_learner\": 3,\n      \"gamma\": 0.99,\n      \"lr\": 5e-05,\n      \"grad_clip\": null,\n      \"grad_clip_by\": \"global_norm\",\n      \"_train_batch_size_per_learner\": null,\n      \"train_batch_size\": 4000,\n      \"num_epochs\": 10,\n      \"minibatch_size\": 256,\n      \"shuffle_batch_per_epoch\": true,\n      \"model\": {\n        \"fcnet_hiddens\": [\n          256,\n          256\n        ],\n        \"fcnet_activation\": \"tanh\",\n        \"fcnet_weights_initializer\": null,\n        \"fcnet_weights_initializer_config\": null,\n        \"fcnet_bias_initializer\": null,\n        \"fcnet_bias_initializer_config\": null,\n        \"conv_filters\": null,\n        \"conv_activation\": \"relu\",\n        \"conv_kernel_initializer\": null,\n        \"conv_kernel_initializer_config\": null,\n        \"conv_bias_initializer\": null,\n        \"conv_bias_initializer_config\": null,\n        \"conv_transpose_kernel_initializer\": null,\n        \"conv_transpose_kernel_initializer_config\": null,\n        \"conv_transpose_bias_initializer\": null,\n        \"conv_transpose_bias_initializer_config\": null,\n        \"post_fcnet_hiddens\": [],\n        \"post_fcnet_activation\": \"relu\",\n        \"post_fcnet_weights_initializer\": null,\n        \"post_fcnet_weights_initializer_config\": null,\n        \"post_fcnet_bias_initializer\": null,\n        \"post_fcnet_bias_initializer_config\": null,\n        \"free_log_std\": false,\n        \"log_std_clip_param\": 20.0,\n        \"no_final_linear\": false,\n        \"vf_share_layers\": false,\n        \"use_lstm\": false,\n        \"max_seq_len\": 20,\n        \"lstm_cell_size\": 256,\n        \"lstm_use_prev_action\": false,\n        \"lstm_use_prev_reward\": false,\n        \"lstm_weights_initializer\": null,\n        \"lstm_weights_initializer_config\": null,\n        \"lstm_bias_initializer\": null,\n        \"lstm_bias_initializer_config\": null,\n        \"_time_major\": false,\n        \"use_attention\": false,\n        \"attention_num_transformer_units\": 1,\n        \"attention_dim\": 64,\n        \"attention_num_heads\": 1,\n        \"attention_head_dim\": 32,\n        \"attention_memory_inference\": 50,\n        \"attention_memory_training\": 50,\n        \"attention_position_wise_mlp_dim\": 32,\n        \"attention_init_gru_gate_bias\": 2.0,\n        \"attention_use_n_prev_actions\": 0,\n        \"attention_use_n_prev_rewards\": 0,\n        \"framestack\": true,\n        \"dim\": 84,\n        \"grayscale\": false,\n        \"zero_mean\": true,\n        \"custom_model\": null,\n        \"custom_model_config\": {},\n        \"custom_action_dist\": null,\n        \"custom_preprocessor\": null,\n        \"encoder_latent_dim\": null,\n        \"always_check_shapes\": false,\n        \"lstm_use_prev_action_reward\": -1,\n        \"_use_default_native_models\": -1,\n        \"_disable_preprocessor_api\": false,\n        \"_disable_action_flattening\": false\n      },\n      \"_learner_connector\": null,\n      \"add_default_connectors_to_learner_pipeline\": true,\n      \"learner_config_dict\": {},\n      \"optimizer\": {},\n      \"_learner_class\": null,\n      \"callbacks_on_algorithm_init\": null,\n      \"callbacks_on_env_runners_recreated\": null,\n      \"callbacks_on_offline_eval_runners_recreated\": null,\n      \"callbacks_on_checkpoint_loaded\": null,\n      \"callbacks_on_environment_created\": null,\n      \"callbacks_on_episode_created\": null,\n      \"callbacks_on_episode_start\": null,\n      \"callbacks_on_episode_step\": null,\n      \"callbacks_on_episode_end\": null,\n      \"callbacks_on_evaluate_start\": null,\n      \"callbacks_on_evaluate_end\": null,\n      \"callbacks_on_evaluate_offline_start\": null,\n      \"callbacks_on_evaluate_offline_end\": null,\n      \"callbacks_on_sample_end\": null,\n      \"callbacks_on_train_result\": null,\n      \"explore\": true,\n      \"enable_rl_module_and_learner\": true,\n      \"enable_env_runner_and_connector_v2\": true,\n      \"_prior_exploration_config\": {\n        \"type\": \"StochasticSampling\"\n      },\n      \"count_steps_by\": \"env_steps\",\n      \"policy_map_capacity\": 100,\n      \"policy_mapping_fn\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059512020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b034b004b004b044b014b5b43047c005300944e859429288c086167656e745f6964948c07657069736f6465948c06776f726b6572948c066b77617267739474948c432f686f6d652f7875657a68692f7461736b2d61737369676e6d656e742d726f626f7469632d77617265686f7573652f736372697074732f747261696e5f70706f2e7079948c083c6c616d6264613e944b1e43020400942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f948c17747261696e2e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f9468098c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n      },\n      \"policies_to_train\": null,\n      \"policy_states_are_swappable\": false,\n      \"observation_fn\": null,\n      \"offline_data_class\": null,\n      \"input_read_method\": \"read_parquet\",\n      \"input_read_method_kwargs\": {},\n      \"input_read_schema\": {},\n      \"input_read_episodes\": false,\n      \"input_read_sample_batches\": false,\n      \"input_read_batch_size\": null,\n      \"input_filesystem\": null,\n      \"input_filesystem_kwargs\": {},\n      \"input_compress_columns\": [\n        \"obs\",\n        \"new_obs\"\n      ],\n      \"input_spaces_jsonable\": true,\n      \"materialize_data\": false,\n      \"materialize_mapped_data\": true,\n      \"map_batches_kwargs\": {},\n      \"iter_batches_kwargs\": {},\n      \"ignore_final_observation\": false,\n      \"prelearner_class\": null,\n      \"prelearner_buffer_class\": null,\n      \"prelearner_buffer_kwargs\": {},\n      \"prelearner_module_synch_period\": 10,\n      \"dataset_num_iters_per_learner\": null,\n      \"input_config\": {},\n      \"actions_in_input_normalized\": false,\n      \"postprocess_inputs\": false,\n      \"shuffle_buffer_size\": 0,\n      \"output\": null,\n      \"output_config\": {},\n      \"output_compress_columns\": [\n        \"obs\",\n        \"new_obs\"\n      ],\n      \"output_max_file_size\": 67108864,\n      \"output_max_rows_per_file\": null,\n      \"output_write_remaining_data\": false,\n      \"output_write_method\": \"write_parquet\",\n      \"output_write_method_kwargs\": {},\n      \"output_filesystem\": null,\n      \"output_filesystem_kwargs\": {},\n      \"output_write_episodes\": true,\n      \"offline_sampling\": false,\n      \"evaluation_interval\": 10,\n      \"evaluation_duration\": 5,\n      \"evaluation_duration_unit\": \"episodes\",\n      \"evaluation_sample_timeout_s\": 120.0,\n      \"evaluation_auto_duration_min_env_steps_per_sample\": 100,\n      \"evaluation_auto_duration_max_env_steps_per_sample\": 2000,\n      \"evaluation_parallel_to_training\": false,\n      \"evaluation_force_reset_envs_before_iteration\": true,\n      \"evaluation_config\": {\n        \"explore\": false\n      },\n      \"off_policy_estimation_methods\": {},\n      \"ope_split_batch_by_episode\": true,\n      \"evaluation_num_env_runners\": 0,\n      \"in_evaluation\": false,\n      \"sync_filters_on_rollout_workers_timeout_s\": 10.0,\n      \"offline_evaluation_interval\": null,\n      \"num_offline_eval_runners\": 0,\n      \"offline_evaluation_type\": null,\n      \"offline_eval_runner_class\": null,\n      \"offline_loss_for_module_fn\": null,\n      \"offline_evaluation_duration\": 1,\n      \"offline_evaluation_parallel_to_training\": false,\n      \"offline_evaluation_timeout_s\": 120.0,\n      \"num_cpus_per_offline_eval_runner\": 1,\n      \"num_gpus_per_offline_eval_runner\": 0,\n      \"custom_resources_per_offline_eval_runner\": {},\n      \"restart_failed_offline_eval_runners\": true,\n      \"ignore_offline_eval_runner_failures\": false,\n      \"max_num_offline_eval_runner_restarts\": 1000,\n      \"offline_eval_runner_restore_timeout_s\": 1800.0,\n      \"max_requests_in_flight_per_offline_eval_runner\": 1,\n      \"validate_offline_eval_runners_after_construction\": true,\n      \"offline_eval_runner_health_probe_timeout_s\": 30.0,\n      \"offline_eval_rl_module_inference_only\": false,\n      \"broadcast_offline_eval_runner_states\": false,\n      \"offline_eval_batch_size_per_runner\": 256,\n      \"dataset_num_iters_per_eval_runner\": 1,\n      \"keep_per_episode_custom_metrics\": false,\n      \"metrics_episode_collection_timeout_s\": 60.0,\n      \"metrics_num_episodes_for_smoothing\": 100,\n      \"min_time_s_per_iteration\": null,\n      \"min_train_timesteps_per_iteration\": 0,\n      \"min_sample_timesteps_per_iteration\": 0,\n      \"log_gradients\": false,\n      \"export_native_model_files\": false,\n      \"checkpoint_trainable_policies_only\": false,\n      \"logger_creator\": null,\n      \"logger_config\": null,\n      \"log_level\": \"WARN\",\n      \"log_sys_usage\": true,\n      \"fake_sampler\": false,\n      \"seed\": null,\n      \"restart_failed_env_runners\": true,\n      \"ignore_env_runner_failures\": false,\n      \"max_num_env_runner_restarts\": 1000,\n      \"delay_between_env_runner_restarts_s\": 60.0,\n      \"restart_failed_sub_environments\": false,\n      \"num_consecutive_env_runner_failures_tolerance\": 100,\n      \"env_runner_health_probe_timeout_s\": 30.0,\n      \"env_runner_restore_timeout_s\": 1800.0,\n      \"_model_config\": {},\n      \"_rl_module_spec\": null,\n      \"algorithm_config_overrides_per_module\": {},\n      \"_per_module_overrides\": {},\n      \"_validate_config\": true,\n      \"_use_msgpack_checkpoints\": false,\n      \"_torch_grad_scaler_class\": null,\n      \"_torch_lr_scheduler_classes\": null,\n      \"_tf_policy_handles_more_than_one_loss\": false,\n      \"_disable_preprocessor_api\": false,\n      \"_disable_action_flattening\": false,\n      \"_disable_initialize_loss_from_dummy_batch\": false,\n      \"_dont_auto_sync_env_runner_states\": false,\n      \"env_task_fn\": -1,\n      \"enable_connectors\": -1,\n      \"simple_optimizer\": true,\n      \"policy_map_cache\": -1,\n      \"worker_cls\": -1,\n      \"synchronize_filters\": -1,\n      \"enable_async_evaluation\": -1,\n      \"custom_async_evaluation_function\": -1,\n      \"_enable_rl_module_api\": -1,\n      \"auto_wrap_old_gym_envs\": -1,\n      \"always_attach_evaluation_results\": -1,\n      \"replay_sequence_length\": null,\n      \"_disable_execution_plan_api\": -1,\n      \"use_critic\": true,\n      \"use_gae\": true,\n      \"use_kl_loss\": true,\n      \"kl_coeff\": 0.2,\n      \"kl_target\": 0.01,\n      \"vf_loss_coeff\": 1.0,\n      \"entropy_coeff\": 0.0,\n      \"clip_param\": 0.2,\n      \"vf_clip_param\": 10.0,\n      \"entropy_coeff_schedule\": null,\n      \"lr_schedule\": null,\n      \"sgd_minibatch_size\": -1,\n      \"vf_share_layers\": -1,\n      \"__stdout_file__\": null,\n      \"__stderr_file__\": null,\n      \"lambda\": 0.95,\n      \"input\": \"sampler\",\n      \"policies\": {\n        \"agent_0\": [\n          null,\n          null,\n          null,\n          {\n            \"model\": {\n              \"custom_model\": \"warehouse_marl_model\",\n              \"custom_model_config\": {}\n            }\n          }\n        ],\n        \"agent_1\": [\n          null,\n          null,\n          null,\n          {\n            \"model\": {\n              \"custom_model\": \"warehouse_marl_model\",\n              \"custom_model_config\": {}\n            }\n          }\n        ],\n        \"agent_2\": [\n          null,\n          null,\n          null,\n          {\n            \"model\": {\n              \"custom_model\": \"warehouse_marl_model\",\n              \"custom_model_config\": {}\n            }\n          }\n        ],\n        \"agent_3\": [\n          null,\n          null,\n          null,\n          {\n            \"model\": {\n              \"custom_model\": \"warehouse_marl_model\",\n              \"custom_model_config\": {}\n            }\n          }\n        ],\n        \"agent_4\": [\n          null,\n          null,\n          null,\n          {\n            \"model\": {\n              \"custom_model\": \"warehouse_marl_model\",\n              \"custom_model_config\": {}\n            }\n          }\n        ],\n        \"agent_5\": [\n          null,\n          null,\n          null,\n          {\n            \"model\": {\n              \"custom_model\": \"warehouse_marl_model\",\n              \"custom_model_config\": {}\n            }\n          }\n        ],\n        \"agent_6\": [\n          null,\n          null,\n          null,\n          {\n            \"model\": {\n              \"custom_model\": \"warehouse_marl_model\",\n              \"custom_model_config\": {}\n            }\n          }\n        ],\n        \"agent_7\": [\n          null,\n          null,\n          null,\n          {\n            \"model\": {\n              \"custom_model\": \"warehouse_marl_model\",\n              \"custom_model_config\": {}\n            }\n          }\n        ],\n        \"agent_8\": [\n          null,\n          null,\n          null,\n          {\n            \"model\": {\n              \"custom_model\": \"warehouse_marl_model\",\n              \"custom_model_config\": {}\n            }\n          }\n        ],\n        \"agent_9\": [\n          null,\n          null,\n          null,\n          {\n            \"model\": {\n              \"custom_model\": \"warehouse_marl_model\",\n              \"custom_model_config\": {}\n            }\n          }\n        ],\n        \"agent_10\": [\n          null,\n          null,\n          null,\n          {\n            \"model\": {\n              \"custom_model\": \"warehouse_marl_model\",\n              \"custom_model_config\": {}\n            }\n          }\n        ],\n        \"agent_11\": [\n          null,\n          null,\n          null,\n          {\n            \"model\": {\n              \"custom_model\": \"warehouse_marl_model\",\n              \"custom_model_config\": {}\n            }\n          }\n        ],\n        \"agent_12\": [\n          null,\n          null,\n          null,\n          {\n            \"model\": {\n              \"custom_model\": \"warehouse_marl_model\",\n              \"custom_model_config\": {}\n            }\n          }\n        ],\n        \"agent_13\": [\n          null,\n          null,\n          null,\n          {\n            \"model\": {\n              \"custom_model\": \"warehouse_marl_model\",\n              \"custom_model_config\": {}\n            }\n          }\n        ],\n        \"agent_14\": [\n          null,\n          null,\n          null,\n          {\n            \"model\": {\n              \"custom_model\": \"warehouse_marl_model\",\n              \"custom_model_config\": {}\n            }\n          }\n        ],\n        \"agent_15\": [\n          null,\n          null,\n          null,\n          {\n            \"model\": {\n              \"custom_model\": \"warehouse_marl_model\",\n              \"custom_model_config\": {}\n            }\n          }\n        ],\n        \"agent_16\": [\n          null,\n          null,\n          null,\n          {\n            \"model\": {\n              \"custom_model\": \"warehouse_marl_model\",\n              \"custom_model_config\": {}\n            }\n          }\n        ],\n        \"agent_17\": [\n          null,\n          null,\n          null,\n          {\n            \"model\": {\n              \"custom_model\": \"warehouse_marl_model\",\n              \"custom_model_config\": {}\n            }\n          }\n        ],\n        \"agent_18\": [\n          null,\n          null,\n          null,\n          {\n            \"model\": {\n              \"custom_model\": \"warehouse_marl_model\",\n              \"custom_model_config\": {}\n            }\n          }\n        ],\n        \"agent_19\": [\n          null,\n          null,\n          null,\n          {\n            \"model\": {\n              \"custom_model\": \"warehouse_marl_model\",\n              \"custom_model_config\": {}\n            }\n          }\n        ],\n        \"agent_20\": [\n          null,\n          null,\n          null,\n          {\n            \"model\": {\n              \"custom_model\": \"warehouse_marl_model\",\n              \"custom_model_config\": {}\n            }\n          }\n        ]\n      },\n      \"callbacks\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059533000000000000008c1d7261792e726c6c69622e63616c6c6261636b732e63616c6c6261636b73948c0d524c6c696243616c6c6261636b9493942e\"\n      },\n      \"create_env_on_driver\": false,\n      \"custom_eval_function\": null,\n      \"framework\": \"torch\"\n    },\n    \"time_since_restore\": 151.17440128326416,\n    \"iterations_since_restore\": 6,\n    \"perf\": {\n      \"cpu_util_percent\": 7.931428571428572,\n      \"ram_util_percent\": 25.157142857142862,\n      \"gpu_util_percent0\": 0.2914285714285715,\n      \"vram_util_percent0\": 0.12023448949682461\n    },\n    \"experiment_tag\": \"0\"\n  },\n  \"last_result_time\": 1761037342.733112,\n  \"metric_analysis\": {\n    \"num_training_step_calls_per_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1.0,\n      \"last\": 1,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"num_env_steps_sampled_lifetime\": {\n      \"max\": 24000.0,\n      \"min\": 4000.0,\n      \"avg\": 14000.0,\n      \"last\": 24000.0,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 14000.0\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 6,\n      \"min\": 1,\n      \"avg\": 3.5,\n      \"last\": 6,\n      \"last-5-avg\": 4.0,\n      \"last-10-avg\": 3.5\n    },\n    \"time_this_iter_s\": {\n      \"max\": 25.73229742050171,\n      \"min\": 24.435375928878784,\n      \"avg\": 25.195733547210693,\n      \"last\": 25.530882835388184,\n      \"last-5-avg\": 25.212528276443482,\n      \"last-10-avg\": 25.195733547210693\n    },\n    \"time_total_s\": {\n      \"max\": 151.17440128326416,\n      \"min\": 25.111759901046753,\n      \"avg\": 87.68275209267934,\n      \"last\": 151.17440128326416,\n      \"last-5-avg\": 100.19695053100585,\n      \"last-10-avg\": 87.68275209267934\n    },\n    \"time_since_restore\": {\n      \"max\": 151.17440128326416,\n      \"min\": 25.111759901046753,\n      \"avg\": 87.68275209267934,\n      \"last\": 151.17440128326416,\n      \"last-5-avg\": 100.19695053100585,\n      \"last-10-avg\": 87.68275209267934\n    },\n    \"iterations_since_restore\": {\n      \"max\": 6,\n      \"min\": 1,\n      \"avg\": 3.5,\n      \"last\": 6,\n      \"last-5-avg\": 4.0,\n      \"last-10-avg\": 3.5\n    },\n    \"timers/training_iteration\": {\n      \"max\": 25.10474698148767,\n      \"min\": 25.09278540754749,\n      \"avg\": 25.097548987577415,\n      \"last\": 25.10474698148767,\n      \"last-5-avg\": 25.097149487499497,\n      \"last-10-avg\": 25.097548987577415\n    },\n    \"timers/restore_env_runners\": {\n      \"max\": 1.8043967429548502e-05,\n      \"min\": 1.775152007780685e-05,\n      \"avg\": 1.790504046334294e-05,\n      \"last\": 1.775152007780685e-05,\n      \"last-5-avg\": 1.7877255070101832e-05,\n      \"last-10-avg\": 1.7905040463342945e-05\n    },\n    \"timers/training_step\": {\n      \"max\": 25.104510079425125,\n      \"min\": 25.092556628796153,\n      \"avg\": 25.097317153070072,\n      \"last\": 25.104510079425125,\n      \"last-5-avg\": 25.096916618088944,\n      \"last-10-avg\": 25.09731715307007\n    },\n    \"timers/env_runner_sampling_timer\": {\n      \"max\": 10.884857547115422,\n      \"min\": 10.858867636143694,\n      \"avg\": 10.868747352992168,\n      \"last\": 10.884857547115422,\n      \"last-5-avg\": 10.87047843538586,\n      \"last-10-avg\": 10.868747352992168\n    },\n    \"timers/learner_update_timer\": {\n      \"max\": 14.203331599012017,\n      \"min\": 14.184051073064248,\n      \"avg\": 14.192825643302605,\n      \"last\": 14.184051073064248,\n      \"last-5-avg\": 14.190724452160723,\n      \"last-10-avg\": 14.192825643302605\n    },\n    \"timers/synch_weights\": {\n      \"max\": 0.0334121219930239,\n      \"min\": 0.03309856041768848,\n      \"avg\": 0.033251766995272165,\n      \"last\": 0.03309856041768848,\n      \"last-5-avg\": 0.03321969599572181,\n      \"last-10-avg\": 0.03325176699527216\n    },\n    \"env_runners/connector_pipeline_timer\": {\n      \"max\": 0.0006737806834280491,\n      \"min\": 0.0006737806834280491,\n      \"avg\": 0.0006737806834280491,\n      \"last\": 0.0006737806834280491,\n      \"last-5-avg\": 0.0006737806834280491,\n      \"last-10-avg\": 0.0006737806834280491\n    },\n    \"env_runners/episode_len_min\": {\n      \"max\": 500,\n      \"min\": 500,\n      \"avg\": 500.0,\n      \"last\": 500,\n      \"last-5-avg\": 500.0,\n      \"last-10-avg\": 500.0\n    },\n    \"env_runners/weights_seq_no\": {\n      \"max\": 5.0,\n      \"min\": 0.0,\n      \"avg\": 2.5,\n      \"last\": 5.0,\n      \"last-5-avg\": 3.0,\n      \"last-10-avg\": 2.5\n    },\n    \"env_runners/env_to_module_sum_episodes_length_in\": {\n      \"max\": 397.98660082785995,\n      \"min\": 160.24153986333874,\n      \"avg\": 269.4388872787314,\n      \"last\": 394.7953752988912,\n      \"last-5-avg\": 272.99234114707133,\n      \"last-10-avg\": 269.43888727873133\n    },\n    \"env_runners/env_to_module_sum_episodes_length_out\": {\n      \"max\": 397.98660082785995,\n      \"min\": 160.24153986333874,\n      \"avg\": 269.4388872787314,\n      \"last\": 394.7953752988912,\n      \"last-5-avg\": 272.99234114707133,\n      \"last-10-avg\": 269.43888727873133\n    },\n    \"env_runners/episode_duration_sec_mean\": {\n      \"max\": 4.158014694685869,\n      \"min\": 3.9165431209995103,\n      \"avg\": 4.013558643457433,\n      \"last\": 4.158014694685869,\n      \"last-5-avg\": 4.025310994847295,\n      \"last-10-avg\": 4.013558643457433\n    },\n    \"env_runners/episode_len_mean\": {\n      \"max\": 500.0,\n      \"min\": 500.0,\n      \"avg\": 500.0,\n      \"last\": 500.0,\n      \"last-5-avg\": 500.0,\n      \"last-10-avg\": 500.0\n    },\n    \"env_runners/env_step_timer\": {\n      \"max\": 0.0028718662780152612,\n      \"min\": 0.0025604236423828973,\n      \"avg\": 0.0027323225375133126,\n      \"last\": 0.0027740766678751687,\n      \"last-5-avg\": 0.0027667023165393956,\n      \"last-10-avg\": 0.0027323225375133126\n    },\n    \"env_runners/sample\": {\n      \"max\": 10.716717756340303,\n      \"min\": 10.688538465329326,\n      \"avg\": 10.699181365924122,\n      \"last\": 10.716717756340303,\n      \"last-5-avg\": 10.701117636975072,\n      \"last-10-avg\": 10.699181365924124\n    },\n    \"env_runners/episode_return_min\": {\n      \"max\": -70.3000000000003,\n      \"min\": -77.91000000000034,\n      \"avg\": -76.64166666666699,\n      \"last\": -77.91000000000034,\n      \"last-5-avg\": -77.91000000000034,\n      \"last-10-avg\": -76.64166666666699\n    },\n    \"env_runners/env_reset_timer\": {\n      \"max\": 0.004376554667639234,\n      \"min\": 0.004376554667639234,\n      \"avg\": 0.004376554667639233,\n      \"last\": 0.004376554667639234,\n      \"last-5-avg\": 0.004376554667639234,\n      \"last-10-avg\": 0.004376554667639234\n    },\n    \"env_runners/episode_len_max\": {\n      \"max\": 500,\n      \"min\": 500,\n      \"avg\": 500.0,\n      \"last\": 500,\n      \"last-5-avg\": 500.0,\n      \"last-10-avg\": 500.0\n    },\n    \"env_runners/episode_return_max\": {\n      \"max\": -43.350000000000165,\n      \"min\": -53.53000000000022,\n      \"avg\": -46.156666666666844,\n      \"last\": -43.350000000000165,\n      \"last-5-avg\": -44.68200000000017,\n      \"last-10-avg\": -46.156666666666844\n    },\n    \"env_runners/num_episodes_lifetime\": {\n      \"max\": 46.0,\n      \"min\": 6.0,\n      \"avg\": 26.333333333333332,\n      \"last\": 46.0,\n      \"last-5-avg\": 30.4,\n      \"last-10-avg\": 26.333333333333332\n    },\n    \"env_runners/rlmodule_inference_timer\": {\n      \"max\": 0.002056736905495737,\n      \"min\": 0.001935597836601962,\n      \"avg\": 0.0019887030760666513,\n      \"last\": 0.001998089100005526,\n      \"last-5-avg\": 0.00199932412395959,\n      \"last-10-avg\": 0.0019887030760666518\n    },\n    \"env_runners/num_env_steps_sampled\": {\n      \"max\": 4000.0,\n      \"min\": 4000.0,\n      \"avg\": 4000.0,\n      \"last\": 4000.0,\n      \"last-5-avg\": 4000.0,\n      \"last-10-avg\": 4000.0\n    },\n    \"env_runners/episode_return_mean\": {\n      \"max\": -57.446568627451164,\n      \"min\": -61.13666666666691,\n      \"avg\": -59.413544860368575,\n      \"last\": -57.446568627451164,\n      \"last-5-avg\": -59.06892049910891,\n      \"last-10-avg\": -59.413544860368575\n    },\n    \"env_runners/num_episodes\": {\n      \"max\": 9.0,\n      \"min\": 6.0,\n      \"avg\": 7.666666666666666,\n      \"last\": 7.0,\n      \"last-5-avg\": 8.0,\n      \"last-10-avg\": 7.666666666666667\n    },\n    \"env_runners/num_env_steps_sampled_lifetime\": {\n      \"max\": 24000.0,\n      \"min\": 4000.0,\n      \"avg\": 14000.0,\n      \"last\": 24000.0,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 14000.0\n    },\n    \"env_runners/num_env_steps_sampled_lifetime_throughput\": {\n      \"max\": 159.83036241391514,\n      \"min\": 159.39507224364905,\n      \"avg\": NaN,\n      \"last\": 159.39507224364905,\n      \"last-5-avg\": 159.64964960889742,\n      \"last-10-avg\": NaN\n    },\n    \"fault_tolerance/num_healthy_workers\": {\n      \"max\": 3,\n      \"min\": 3,\n      \"avg\": 3.0,\n      \"last\": 3,\n      \"last-5-avg\": 3.0,\n      \"last-10-avg\": 3.0\n    },\n    \"fault_tolerance/num_remote_worker_restarts\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"env_runner_group/actor_manager_num_outstanding_async_reqs\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"perf/cpu_util_percent\": {\n      \"max\": 7.968571428571428,\n      \"min\": 7.0685714285714285,\n      \"avg\": 7.637212885154061,\n      \"last\": 7.931428571428572,\n      \"last-5-avg\": 7.750941176470588,\n      \"last-10-avg\": 7.637212885154061\n    },\n    \"perf/ram_util_percent\": {\n      \"max\": 25.85,\n      \"min\": 24.15714285714286,\n      \"avg\": 25.22214285714286,\n      \"last\": 25.157142857142862,\n      \"last-5-avg\": 25.43514285714286,\n      \"last-10-avg\": 25.22214285714286\n    },\n    \"perf/gpu_util_percent0\": {\n      \"max\": 0.2982352941176471,\n      \"min\": 0.28714285714285714,\n      \"avg\": 0.2907058823529412,\n      \"last\": 0.2914285714285715,\n      \"last-5-avg\": 0.291418487394958,\n      \"last-10-avg\": 0.2907058823529412\n    },\n    \"perf/vram_util_percent0\": {\n      \"max\": 0.12053876753437086,\n      \"min\": 0.09340917021425083,\n      \"avg\": 0.11532390093311382,\n      \"last\": 0.12023448949682461,\n      \"last-5-avg\": 0.11970684707688643,\n      \"last-10-avg\": 0.11532390093311383\n    },\n    \"env_runners/num_module_steps_sampled_lifetime/agent_15\": {\n      \"max\": 24000.0,\n      \"min\": 4000.0,\n      \"avg\": 14000.0,\n      \"last\": 24000.0,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 14000.0\n    },\n    \"env_runners/num_module_steps_sampled_lifetime/agent_20\": {\n      \"max\": 24000.0,\n      \"min\": 4000.0,\n      \"avg\": 14000.0,\n      \"last\": 24000.0,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 14000.0\n    },\n    \"env_runners/num_module_steps_sampled_lifetime/agent_2\": {\n      \"max\": 24000.0,\n      \"min\": 4000.0,\n      \"avg\": 14000.0,\n      \"last\": 24000.0,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 14000.0\n    },\n    \"env_runners/num_module_steps_sampled_lifetime/agent_10\": {\n      \"max\": 24000.0,\n      \"min\": 4000.0,\n      \"avg\": 14000.0,\n      \"last\": 24000.0,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 14000.0\n    },\n    \"env_runners/num_module_steps_sampled_lifetime/agent_19\": {\n      \"max\": 24000.0,\n      \"min\": 4000.0,\n      \"avg\": 14000.0,\n      \"last\": 24000.0,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 14000.0\n    },\n    \"env_runners/num_module_steps_sampled_lifetime/agent_13\": {\n      \"max\": 24000.0,\n      \"min\": 4000.0,\n      \"avg\": 14000.0,\n      \"last\": 24000.0,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 14000.0\n    },\n    \"env_runners/num_module_steps_sampled_lifetime/agent_16\": {\n      \"max\": 24000.0,\n      \"min\": 4000.0,\n      \"avg\": 14000.0,\n      \"last\": 24000.0,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 14000.0\n    },\n    \"env_runners/num_module_steps_sampled_lifetime/agent_1\": {\n      \"max\": 24000.0,\n      \"min\": 4000.0,\n      \"avg\": 14000.0,\n      \"last\": 24000.0,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 14000.0\n    },\n    \"env_runners/num_module_steps_sampled_lifetime/agent_4\": {\n      \"max\": 24000.0,\n      \"min\": 4000.0,\n      \"avg\": 14000.0,\n      \"last\": 24000.0,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 14000.0\n    },\n    \"env_runners/num_module_steps_sampled_lifetime/agent_5\": {\n      \"max\": 24000.0,\n      \"min\": 4000.0,\n      \"avg\": 14000.0,\n      \"last\": 24000.0,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 14000.0\n    },\n    \"env_runners/num_module_steps_sampled_lifetime/agent_14\": {\n      \"max\": 24000.0,\n      \"min\": 4000.0,\n      \"avg\": 14000.0,\n      \"last\": 24000.0,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 14000.0\n    },\n    \"env_runners/num_module_steps_sampled_lifetime/agent_6\": {\n      \"max\": 24000.0,\n      \"min\": 4000.0,\n      \"avg\": 14000.0,\n      \"last\": 24000.0,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 14000.0\n    },\n    \"env_runners/num_module_steps_sampled_lifetime/agent_3\": {\n      \"max\": 24000.0,\n      \"min\": 4000.0,\n      \"avg\": 14000.0,\n      \"last\": 24000.0,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 14000.0\n    },\n    \"env_runners/num_module_steps_sampled_lifetime/agent_7\": {\n      \"max\": 24000.0,\n      \"min\": 4000.0,\n      \"avg\": 14000.0,\n      \"last\": 24000.0,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 14000.0\n    },\n    \"env_runners/num_module_steps_sampled_lifetime/agent_17\": {\n      \"max\": 24000.0,\n      \"min\": 4000.0,\n      \"avg\": 14000.0,\n      \"last\": 24000.0,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 14000.0\n    },\n    \"env_runners/num_module_steps_sampled_lifetime/agent_8\": {\n      \"max\": 24000.0,\n      \"min\": 4000.0,\n      \"avg\": 14000.0,\n      \"last\": 24000.0,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 14000.0\n    },\n    \"env_runners/num_module_steps_sampled_lifetime/agent_0\": {\n      \"max\": 24000.0,\n      \"min\": 4000.0,\n      \"avg\": 14000.0,\n      \"last\": 24000.0,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 14000.0\n    },\n    \"env_runners/num_module_steps_sampled_lifetime/agent_11\": {\n      \"max\": 24000.0,\n      \"min\": 4000.0,\n      \"avg\": 14000.0,\n      \"last\": 24000.0,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 14000.0\n    },\n    \"env_runners/num_module_steps_sampled_lifetime/agent_12\": {\n      \"max\": 24000.0,\n      \"min\": 4000.0,\n      \"avg\": 14000.0,\n      \"last\": 24000.0,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 14000.0\n    },\n    \"env_runners/num_module_steps_sampled_lifetime/agent_9\": {\n      \"max\": 24000.0,\n      \"min\": 4000.0,\n      \"avg\": 14000.0,\n      \"last\": 24000.0,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 14000.0\n    },\n    \"env_runners/num_module_steps_sampled_lifetime/agent_18\": {\n      \"max\": 24000.0,\n      \"min\": 4000.0,\n      \"avg\": 14000.0,\n      \"last\": 24000.0,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 14000.0\n    },\n    \"env_runners/num_agent_steps_sampled_lifetime/agent_8\": {\n      \"max\": 24000.0,\n      \"min\": 4000.0,\n      \"avg\": 14000.0,\n      \"last\": 24000.0,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 14000.0\n    },\n    \"env_runners/num_agent_steps_sampled_lifetime/agent_0\": {\n      \"max\": 24000.0,\n      \"min\": 4000.0,\n      \"avg\": 14000.0,\n      \"last\": 24000.0,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 14000.0\n    },\n    \"env_runners/num_agent_steps_sampled_lifetime/agent_11\": {\n      \"max\": 24000.0,\n      \"min\": 4000.0,\n      \"avg\": 14000.0,\n      \"last\": 24000.0,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 14000.0\n    },\n    \"env_runners/num_agent_steps_sampled_lifetime/agent_20\": {\n      \"max\": 24000.0,\n      \"min\": 4000.0,\n      \"avg\": 14000.0,\n      \"last\": 24000.0,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 14000.0\n    },\n    \"env_runners/num_agent_steps_sampled_lifetime/agent_12\": {\n      \"max\": 24000.0,\n      \"min\": 4000.0,\n      \"avg\": 14000.0,\n      \"last\": 24000.0,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 14000.0\n    },\n    \"env_runners/num_agent_steps_sampled_lifetime/agent_9\": {\n      \"max\": 24000.0,\n      \"min\": 4000.0,\n      \"avg\": 14000.0,\n      \"last\": 24000.0,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 14000.0\n    },\n    \"env_runners/num_agent_steps_sampled_lifetime/agent_15\": {\n      \"max\": 24000.0,\n      \"min\": 4000.0,\n      \"avg\": 14000.0,\n      \"last\": 24000.0,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 14000.0\n    },\n    \"env_runners/num_agent_steps_sampled_lifetime/agent_16\": {\n      \"max\": 24000.0,\n      \"min\": 4000.0,\n      \"avg\": 14000.0,\n      \"last\": 24000.0,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 14000.0\n    },\n    \"env_runners/num_agent_steps_sampled_lifetime/agent_2\": {\n      \"max\": 24000.0,\n      \"min\": 4000.0,\n      \"avg\": 14000.0,\n      \"last\": 24000.0,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 14000.0\n    },\n    \"env_runners/num_agent_steps_sampled_lifetime/agent_1\": {\n      \"max\": 24000.0,\n      \"min\": 4000.0,\n      \"avg\": 14000.0,\n      \"last\": 24000.0,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 14000.0\n    },\n    \"env_runners/num_agent_steps_sampled_lifetime/agent_10\": {\n      \"max\": 24000.0,\n      \"min\": 4000.0,\n      \"avg\": 14000.0,\n      \"last\": 24000.0,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 14000.0\n    },\n    \"env_runners/num_agent_steps_sampled_lifetime/agent_19\": {\n      \"max\": 24000.0,\n      \"min\": 4000.0,\n      \"avg\": 14000.0,\n      \"last\": 24000.0,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 14000.0\n    },\n    \"env_runners/num_agent_steps_sampled_lifetime/agent_13\": {\n      \"max\": 24000.0,\n      \"min\": 4000.0,\n      \"avg\": 14000.0,\n      \"last\": 24000.0,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 14000.0\n    },\n    \"env_runners/num_agent_steps_sampled_lifetime/agent_5\": {\n      \"max\": 24000.0,\n      \"min\": 4000.0,\n      \"avg\": 14000.0,\n      \"last\": 24000.0,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 14000.0\n    },\n    \"env_runners/num_agent_steps_sampled_lifetime/agent_14\": {\n      \"max\": 24000.0,\n      \"min\": 4000.0,\n      \"avg\": 14000.0,\n      \"last\": 24000.0,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 14000.0\n    },\n    \"env_runners/num_agent_steps_sampled_lifetime/agent_3\": {\n      \"max\": 24000.0,\n      \"min\": 4000.0,\n      \"avg\": 14000.0,\n      \"last\": 24000.0,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 14000.0\n    },\n    \"env_runners/num_agent_steps_sampled_lifetime/agent_4\": {\n      \"max\": 24000.0,\n      \"min\": 4000.0,\n      \"avg\": 14000.0,\n      \"last\": 24000.0,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 14000.0\n    },\n    \"env_runners/num_agent_steps_sampled_lifetime/agent_6\": {\n      \"max\": 24000.0,\n      \"min\": 4000.0,\n      \"avg\": 14000.0,\n      \"last\": 24000.0,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 14000.0\n    },\n    \"env_runners/num_agent_steps_sampled_lifetime/agent_7\": {\n      \"max\": 24000.0,\n      \"min\": 4000.0,\n      \"avg\": 14000.0,\n      \"last\": 24000.0,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 14000.0\n    },\n    \"env_runners/num_agent_steps_sampled_lifetime/agent_18\": {\n      \"max\": 24000.0,\n      \"min\": 4000.0,\n      \"avg\": 14000.0,\n      \"last\": 24000.0,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 14000.0\n    },\n    \"env_runners/num_agent_steps_sampled_lifetime/agent_17\": {\n      \"max\": 24000.0,\n      \"min\": 4000.0,\n      \"avg\": 14000.0,\n      \"last\": 24000.0,\n      \"last-5-avg\": 16000.0,\n      \"last-10-avg\": 14000.0\n    },\n    \"env_runners/num_agent_steps_sampled/agent_3\": {\n      \"max\": 4000.0,\n      \"min\": 4000.0,\n      \"avg\": 4000.0,\n      \"last\": 4000.0,\n      \"last-5-avg\": 4000.0,\n      \"last-10-avg\": 4000.0\n    },\n    \"env_runners/num_agent_steps_sampled/agent_4\": {\n      \"max\": 4000.0,\n      \"min\": 4000.0,\n      \"avg\": 4000.0,\n      \"last\": 4000.0,\n      \"last-5-avg\": 4000.0,\n      \"last-10-avg\": 4000.0\n    },\n    \"env_runners/num_agent_steps_sampled/agent_6\": {\n      \"max\": 4000.0,\n      \"min\": 4000.0,\n      \"avg\": 4000.0,\n      \"last\": 4000.0,\n      \"last-5-avg\": 4000.0,\n      \"last-10-avg\": 4000.0\n    },\n    \"env_runners/num_agent_steps_sampled/agent_7\": {\n      \"max\": 4000.0,\n      \"min\": 4000.0,\n      \"avg\": 4000.0,\n      \"last\": 4000.0,\n      \"last-5-avg\": 4000.0,\n      \"last-10-avg\": 4000.0\n    },\n    \"env_runners/num_agent_steps_sampled/agent_18\": {\n      \"max\": 4000.0,\n      \"min\": 4000.0,\n      \"avg\": 4000.0,\n      \"last\": 4000.0,\n      \"last-5-avg\": 4000.0,\n      \"last-10-avg\": 4000.0\n    },\n    \"env_runners/num_agent_steps_sampled/agent_17\": {\n      \"max\": 4000.0,\n      \"min\": 4000.0,\n      \"avg\": 4000.0,\n      \"last\": 4000.0,\n      \"last-5-avg\": 4000.0,\n      \"last-10-avg\": 4000.0\n    },\n    \"env_runners/num_agent_steps_sampled/agent_8\": {\n      \"max\": 4000.0,\n      \"min\": 4000.0,\n      \"avg\": 4000.0,\n      \"last\": 4000.0,\n      \"last-5-avg\": 4000.0,\n      \"last-10-avg\": 4000.0\n    },\n    \"env_runners/num_agent_steps_sampled/agent_0\": {\n      \"max\": 4000.0,\n      \"min\": 4000.0,\n      \"avg\": 4000.0,\n      \"last\": 4000.0,\n      \"last-5-avg\": 4000.0,\n      \"last-10-avg\": 4000.0\n    },\n    \"env_runners/num_agent_steps_sampled/agent_11\": {\n      \"max\": 4000.0,\n      \"min\": 4000.0,\n      \"avg\": 4000.0,\n      \"last\": 4000.0,\n      \"last-5-avg\": 4000.0,\n      \"last-10-avg\": 4000.0\n    },\n    \"env_runners/num_agent_steps_sampled/agent_20\": {\n      \"max\": 4000.0,\n      \"min\": 4000.0,\n      \"avg\": 4000.0,\n      \"last\": 4000.0,\n      \"last-5-avg\": 4000.0,\n      \"last-10-avg\": 4000.0\n    },\n    \"env_runners/num_agent_steps_sampled/agent_12\": {\n      \"max\": 4000.0,\n      \"min\": 4000.0,\n      \"avg\": 4000.0,\n      \"last\": 4000.0,\n      \"last-5-avg\": 4000.0,\n      \"last-10-avg\": 4000.0\n    },\n    \"env_runners/num_agent_steps_sampled/agent_9\": {\n      \"max\": 4000.0,\n      \"min\": 4000.0,\n      \"avg\": 4000.0,\n      \"last\": 4000.0,\n      \"last-5-avg\": 4000.0,\n      \"last-10-avg\": 4000.0\n    },\n    \"env_runners/num_agent_steps_sampled/agent_15\": {\n      \"max\": 4000.0,\n      \"min\": 4000.0,\n      \"avg\": 4000.0,\n      \"last\": 4000.0,\n      \"last-5-avg\": 4000.0,\n      \"last-10-avg\": 4000.0\n    },\n    \"env_runners/num_agent_steps_sampled/agent_16\": {\n      \"max\": 4000.0,\n      \"min\": 4000.0,\n      \"avg\": 4000.0,\n      \"last\": 4000.0,\n      \"last-5-avg\": 4000.0,\n      \"last-10-avg\": 4000.0\n    },\n    \"env_runners/num_agent_steps_sampled/agent_2\": {\n      \"max\": 4000.0,\n      \"min\": 4000.0,\n      \"avg\": 4000.0,\n      \"last\": 4000.0,\n      \"last-5-avg\": 4000.0,\n      \"last-10-avg\": 4000.0\n    },\n    \"env_runners/num_agent_steps_sampled/agent_1\": {\n      \"max\": 4000.0,\n      \"min\": 4000.0,\n      \"avg\": 4000.0,\n      \"last\": 4000.0,\n      \"last-5-avg\": 4000.0,\n      \"last-10-avg\": 4000.0\n    },\n    \"env_runners/num_agent_steps_sampled/agent_10\": {\n      \"max\": 4000.0,\n      \"min\": 4000.0,\n      \"avg\": 4000.0,\n      \"last\": 4000.0,\n      \"last-5-avg\": 4000.0,\n      \"last-10-avg\": 4000.0\n    },\n    \"env_runners/num_agent_steps_sampled/agent_19\": {\n      \"max\": 4000.0,\n      \"min\": 4000.0,\n      \"avg\": 4000.0,\n      \"last\": 4000.0,\n      \"last-5-avg\": 4000.0,\n      \"last-10-avg\": 4000.0\n    },\n    \"env_runners/num_agent_steps_sampled/agent_13\": {\n      \"max\": 4000.0,\n      \"min\": 4000.0,\n      \"avg\": 4000.0,\n      \"last\": 4000.0,\n      \"last-5-avg\": 4000.0,\n      \"last-10-avg\": 4000.0\n    },\n    \"env_runners/num_agent_steps_sampled/agent_5\": {\n      \"max\": 4000.0,\n      \"min\": 4000.0,\n      \"avg\": 4000.0,\n      \"last\": 4000.0,\n      \"last-5-avg\": 4000.0,\n      \"last-10-avg\": 4000.0\n    },\n    \"env_runners/num_agent_steps_sampled/agent_14\": {\n      \"max\": 4000.0,\n      \"min\": 4000.0,\n      \"avg\": 4000.0,\n      \"last\": 4000.0,\n      \"last-5-avg\": 4000.0,\n      \"last-10-avg\": 4000.0\n    },\n    \"env_runners/module_episode_returns_mean/agent_6\": {\n      \"max\": -1.2770588235294145,\n      \"min\": -2.476666666666676,\n      \"avg\": -1.7995528817587685,\n      \"last\": -1.2770588235294145,\n      \"last-5-avg\": -1.6641301247771874,\n      \"last-10-avg\": -1.7995528817587687\n    },\n    \"env_runners/module_episode_returns_mean/agent_7\": {\n      \"max\": -2.061666666666673,\n      \"min\": -2.8783333333333463,\n      \"avg\": -2.445868983957228,\n      \"last\": -2.132941176470596,\n      \"last-5-avg\": -2.3593761140820044,\n      \"last-10-avg\": -2.445868983957228\n    },\n    \"env_runners/module_episode_returns_mean/agent_18\": {\n      \"max\": -4.465294117647072,\n      \"min\": -4.578333333333354,\n      \"avg\": -4.516254901960799,\n      \"last\": -4.496568627450995,\n      \"last-5-avg\": -4.5038392156862885,\n      \"last-10-avg\": -4.516254901960799\n    },\n    \"env_runners/module_episode_returns_mean/agent_17\": {\n      \"max\": -4.414215686274522,\n      \"min\": -4.490000000000019,\n      \"avg\": -4.451982768865136,\n      \"last\": -4.446862745098052,\n      \"last-5-avg\": -4.4443793226381585,\n      \"last-10-avg\": -4.451982768865136\n    },\n    \"env_runners/module_episode_returns_mean/agent_8\": {\n      \"max\": -0.5000000000000003,\n      \"min\": -2.3902941176470662,\n      \"avg\": -1.9037026143790903,\n      \"last\": -1.9972549019607901,\n      \"last-5-avg\": -2.1844431372549087,\n      \"last-10-avg\": -1.9037026143790905\n    },\n    \"env_runners/module_episode_returns_mean/agent_0\": {\n      \"max\": -1.879705882352948,\n      \"min\": -2.3526666666666745,\n      \"avg\": -2.1392311348782007,\n      \"last\": -1.879705882352948,\n      \"last-5-avg\": -2.104077361853839,\n      \"last-10-avg\": -2.1392311348782007\n    },\n    \"env_runners/module_episode_returns_mean/agent_20\": {\n      \"max\": -4.535882352941189,\n      \"min\": -4.808333333333356,\n      \"avg\": -4.609471182412375,\n      \"last\": -4.573823529411779,\n      \"last-5-avg\": -4.569698752228179,\n      \"last-10-avg\": -4.609471182412375\n    },\n    \"env_runners/module_episode_returns_mean/agent_12\": {\n      \"max\": -1.235000000000004,\n      \"min\": -1.751363636363641,\n      \"avg\": -1.6376325014854474,\n      \"last\": -1.6871568627451035,\n      \"last-5-avg\": -1.7181590017825363,\n      \"last-10-avg\": -1.6376325014854476\n    },\n    \"env_runners/module_episode_returns_mean/agent_19\": {\n      \"max\": -4.426862745098052,\n      \"min\": -4.685333333333349,\n      \"avg\": -4.569757278669059,\n      \"last\": -4.426862745098052,\n      \"last-5-avg\": -4.5573754010695335,\n      \"last-10-avg\": -4.5697572786690595\n    },\n    \"env_runners/module_episode_returns_mean/agent_11\": {\n      \"max\": -1.5500000000000045,\n      \"min\": -2.8500000000000134,\n      \"avg\": -2.0114973262032154,\n      \"last\": -1.668529411764711,\n      \"last-5-avg\": -1.843796791443856,\n      \"last-10-avg\": -2.0114973262032154\n    },\n    \"env_runners/module_episode_returns_mean/agent_9\": {\n      \"max\": -2.121568627450987,\n      \"min\": -2.8683333333333465,\n      \"avg\": -2.3414818775995325,\n      \"last\": -2.121568627450987,\n      \"last-5-avg\": -2.2361115864527705,\n      \"last-10-avg\": -2.341481877599533\n    },\n    \"env_runners/module_episode_returns_mean/agent_15\": {\n      \"max\": -4.307941176470601,\n      \"min\": -4.785000000000022,\n      \"avg\": -4.5300311942959155,\n      \"last\": -4.307941176470601,\n      \"last-5-avg\": -4.479037433155094,\n      \"last-10-avg\": -4.5300311942959155\n    },\n    \"env_runners/module_episode_returns_mean/agent_16\": {\n      \"max\": -4.484411764705898,\n      \"min\": -4.735000000000022,\n      \"avg\": -4.610448603683913,\n      \"last\": -4.484411764705898,\n      \"last-5-avg\": -4.585538324420692,\n      \"last-10-avg\": -4.610448603683913\n    },\n    \"env_runners/module_episode_returns_mean/agent_2\": {\n      \"max\": -1.3819607843137287,\n      \"min\": -2.7500000000000124,\n      \"avg\": -1.9156871657754069,\n      \"last\": -1.3819607843137287,\n      \"last-5-avg\": -1.7488245989304858,\n      \"last-10-avg\": -1.9156871657754069\n    },\n    \"env_runners/module_episode_returns_mean/agent_1\": {\n      \"max\": -1.5888235294117692,\n      \"min\": -3.1460000000000106,\n      \"avg\": -2.4798773024361336,\n      \"last\": -1.5888235294117692,\n      \"last-5-avg\": -2.4565194295900254,\n      \"last-10-avg\": -2.4798773024361336\n    },\n    \"env_runners/module_episode_returns_mean/agent_10\": {\n      \"max\": -2.008921568627457,\n      \"min\": -3.428333333333349,\n      \"avg\": -2.7670606060606158,\n      \"last\": -2.008921568627457,\n      \"last-5-avg\": -2.6348060606060693,\n      \"last-10-avg\": -2.7670606060606158\n    },\n    \"env_runners/module_episode_returns_mean/agent_4\": {\n      \"max\": -0.9926666666666676,\n      \"min\": -1.5895098039215716,\n      \"avg\": -1.3094322638146192,\n      \"last\": -1.5895098039215716,\n      \"last-5-avg\": -1.2813187165775424,\n      \"last-10-avg\": -1.3094322638146192\n    },\n    \"env_runners/module_episode_returns_mean/agent_13\": {\n      \"max\": -0.5000000000000003,\n      \"min\": -2.118627450980398,\n      \"avg\": -1.3608600713012513,\n      \"last\": -2.118627450980398,\n      \"last-5-avg\": -1.5330320855615016,\n      \"last-10-avg\": -1.360860071301251\n    },\n    \"env_runners/module_episode_returns_mean/agent_5\": {\n      \"max\": -1.179333333333336,\n      \"min\": -2.4234313725490266,\n      \"avg\": -1.5879087938205623,\n      \"last\": -2.4234313725490266,\n      \"last-5-avg\": -1.6514905525846744,\n      \"last-10-avg\": -1.5879087938205625\n    },\n    \"env_runners/module_episode_returns_mean/agent_14\": {\n      \"max\": -4.432352941176485,\n      \"min\": -4.734000000000017,\n      \"avg\": -4.607624183006553,\n      \"last\": -4.432352941176485,\n      \"last-5-avg\": -4.583482352941192,\n      \"last-10-avg\": -4.607624183006553\n    },\n    \"env_runners/module_episode_returns_mean/agent_3\": {\n      \"max\": -1.2616666666666712,\n      \"min\": -2.402254901960791,\n      \"avg\": -1.8181812240047597,\n      \"last\": -2.402254901960791,\n      \"last-5-avg\": -1.9294841354723773,\n      \"last-10-avg\": -1.8181812240047597\n    },\n    \"env_runners/agent_steps/agent_19\": {\n      \"max\": 500.0,\n      \"min\": 500.0,\n      \"avg\": 500.0,\n      \"last\": 500.0,\n      \"last-5-avg\": 500.0,\n      \"last-10-avg\": 500.0\n    },\n    \"env_runners/agent_steps/agent_13\": {\n      \"max\": 500.0,\n      \"min\": 500.0,\n      \"avg\": 500.0,\n      \"last\": 500.0,\n      \"last-5-avg\": 500.0,\n      \"last-10-avg\": 500.0\n    },\n    \"env_runners/agent_steps/agent_5\": {\n      \"max\": 500.0,\n      \"min\": 500.0,\n      \"avg\": 500.0,\n      \"last\": 500.0,\n      \"last-5-avg\": 500.0,\n      \"last-10-avg\": 500.0\n    },\n    \"env_runners/agent_steps/agent_14\": {\n      \"max\": 500.0,\n      \"min\": 500.0,\n      \"avg\": 500.0,\n      \"last\": 500.0,\n      \"last-5-avg\": 500.0,\n      \"last-10-avg\": 500.0\n    },\n    \"env_runners/agent_steps/agent_3\": {\n      \"max\": 500.0,\n      \"min\": 500.0,\n      \"avg\": 500.0,\n      \"last\": 500.0,\n      \"last-5-avg\": 500.0,\n      \"last-10-avg\": 500.0\n    },\n    \"env_runners/agent_steps/agent_4\": {\n      \"max\": 500.0,\n      \"min\": 500.0,\n      \"avg\": 500.0,\n      \"last\": 500.0,\n      \"last-5-avg\": 500.0,\n      \"last-10-avg\": 500.0\n    },\n    \"env_runners/agent_steps/agent_6\": {\n      \"max\": 500.0,\n      \"min\": 500.0,\n      \"avg\": 500.0,\n      \"last\": 500.0,\n      \"last-5-avg\": 500.0,\n      \"last-10-avg\": 500.0\n    },\n    \"env_runners/agent_steps/agent_18\": {\n      \"max\": 500.0,\n      \"min\": 500.0,\n      \"avg\": 500.0,\n      \"last\": 500.0,\n      \"last-5-avg\": 500.0,\n      \"last-10-avg\": 500.0\n    },\n    \"env_runners/agent_steps/agent_7\": {\n      \"max\": 500.0,\n      \"min\": 500.0,\n      \"avg\": 500.0,\n      \"last\": 500.0,\n      \"last-5-avg\": 500.0,\n      \"last-10-avg\": 500.0\n    },\n    \"env_runners/agent_steps/agent_17\": {\n      \"max\": 500.0,\n      \"min\": 500.0,\n      \"avg\": 500.0,\n      \"last\": 500.0,\n      \"last-5-avg\": 500.0,\n      \"last-10-avg\": 500.0\n    },\n    \"env_runners/agent_steps/agent_8\": {\n      \"max\": 500.0,\n      \"min\": 500.0,\n      \"avg\": 500.0,\n      \"last\": 500.0,\n      \"last-5-avg\": 500.0,\n      \"last-10-avg\": 500.0\n    },\n    \"env_runners/agent_steps/agent_0\": {\n      \"max\": 500.0,\n      \"min\": 500.0,\n      \"avg\": 500.0,\n      \"last\": 500.0,\n      \"last-5-avg\": 500.0,\n      \"last-10-avg\": 500.0\n    },\n    \"env_runners/agent_steps/agent_11\": {\n      \"max\": 500.0,\n      \"min\": 500.0,\n      \"avg\": 500.0,\n      \"last\": 500.0,\n      \"last-5-avg\": 500.0,\n      \"last-10-avg\": 500.0\n    },\n    \"env_runners/agent_steps/agent_20\": {\n      \"max\": 500.0,\n      \"min\": 500.0,\n      \"avg\": 500.0,\n      \"last\": 500.0,\n      \"last-5-avg\": 500.0,\n      \"last-10-avg\": 500.0\n    },\n    \"env_runners/agent_steps/agent_12\": {\n      \"max\": 500.0,\n      \"min\": 500.0,\n      \"avg\": 500.0,\n      \"last\": 500.0,\n      \"last-5-avg\": 500.0,\n      \"last-10-avg\": 500.0\n    },\n    \"env_runners/agent_steps/agent_9\": {\n      \"max\": 500.0,\n      \"min\": 500.0,\n      \"avg\": 500.0,\n      \"last\": 500.0,\n      \"last-5-avg\": 500.0,\n      \"last-10-avg\": 500.0\n    },\n    \"env_runners/agent_steps/agent_15\": {\n      \"max\": 500.0,\n      \"min\": 500.0,\n      \"avg\": 500.0,\n      \"last\": 500.0,\n      \"last-5-avg\": 500.0,\n      \"last-10-avg\": 500.0\n    },\n    \"env_runners/agent_steps/agent_16\": {\n      \"max\": 500.0,\n      \"min\": 500.0,\n      \"avg\": 500.0,\n      \"last\": 500.0,\n      \"last-5-avg\": 500.0,\n      \"last-10-avg\": 500.0\n    },\n    \"env_runners/agent_steps/agent_2\": {\n      \"max\": 500.0,\n      \"min\": 500.0,\n      \"avg\": 500.0,\n      \"last\": 500.0,\n      \"last-5-avg\": 500.0,\n      \"last-10-avg\": 500.0\n    },\n    \"env_runners/agent_steps/agent_1\": {\n      \"max\": 500.0,\n      \"min\": 500.0,\n      \"avg\": 500.0,\n      \"last\": 500.0,\n      \"last-5-avg\": 500.0,\n      \"last-10-avg\": 500.0\n    },\n    \"env_runners/agent_steps/agent_10\": {\n      \"max\": 500.0,\n      \"min\": 500.0,\n      \"avg\": 500.0,\n      \"last\": 500.0,\n      \"last-5-avg\": 500.0,\n      \"last-10-avg\": 500.0\n    },\n    \"env_runners/module_to_env_connector/connector_pipeline_timer\": {\n      \"max\": 0.00197820424574904,\n      \"min\": 0.0017648505346216266,\n      \"avg\": 0.0018665815674860442,\n      \"last\": 0.0018729672125500293,\n      \"last-5-avg\": 0.0018847413977676898,\n      \"last-10-avg\": 0.0018665815674860445\n    },\n    \"env_runners/num_module_steps_sampled/agent_5\": {\n      \"max\": 4000.0,\n      \"min\": 4000.0,\n      \"avg\": 4000.0,\n      \"last\": 4000.0,\n      \"last-5-avg\": 4000.0,\n      \"last-10-avg\": 4000.0\n    },\n    \"env_runners/num_module_steps_sampled/agent_14\": {\n      \"max\": 4000.0,\n      \"min\": 4000.0,\n      \"avg\": 4000.0,\n      \"last\": 4000.0,\n      \"last-5-avg\": 4000.0,\n      \"last-10-avg\": 4000.0\n    },\n    \"env_runners/num_module_steps_sampled/agent_6\": {\n      \"max\": 4000.0,\n      \"min\": 4000.0,\n      \"avg\": 4000.0,\n      \"last\": 4000.0,\n      \"last-5-avg\": 4000.0,\n      \"last-10-avg\": 4000.0\n    },\n    \"env_runners/num_module_steps_sampled/agent_3\": {\n      \"max\": 4000.0,\n      \"min\": 4000.0,\n      \"avg\": 4000.0,\n      \"last\": 4000.0,\n      \"last-5-avg\": 4000.0,\n      \"last-10-avg\": 4000.0\n    },\n    \"env_runners/num_module_steps_sampled/agent_7\": {\n      \"max\": 4000.0,\n      \"min\": 4000.0,\n      \"avg\": 4000.0,\n      \"last\": 4000.0,\n      \"last-5-avg\": 4000.0,\n      \"last-10-avg\": 4000.0\n    },\n    \"env_runners/num_module_steps_sampled/agent_17\": {\n      \"max\": 4000.0,\n      \"min\": 4000.0,\n      \"avg\": 4000.0,\n      \"last\": 4000.0,\n      \"last-5-avg\": 4000.0,\n      \"last-10-avg\": 4000.0\n    },\n    \"env_runners/num_module_steps_sampled/agent_8\": {\n      \"max\": 4000.0,\n      \"min\": 4000.0,\n      \"avg\": 4000.0,\n      \"last\": 4000.0,\n      \"last-5-avg\": 4000.0,\n      \"last-10-avg\": 4000.0\n    },\n    \"env_runners/num_module_steps_sampled/agent_0\": {\n      \"max\": 4000.0,\n      \"min\": 4000.0,\n      \"avg\": 4000.0,\n      \"last\": 4000.0,\n      \"last-5-avg\": 4000.0,\n      \"last-10-avg\": 4000.0\n    },\n    \"env_runners/num_module_steps_sampled/agent_11\": {\n      \"max\": 4000.0,\n      \"min\": 4000.0,\n      \"avg\": 4000.0,\n      \"last\": 4000.0,\n      \"last-5-avg\": 4000.0,\n      \"last-10-avg\": 4000.0\n    },\n    \"env_runners/num_module_steps_sampled/agent_12\": {\n      \"max\": 4000.0,\n      \"min\": 4000.0,\n      \"avg\": 4000.0,\n      \"last\": 4000.0,\n      \"last-5-avg\": 4000.0,\n      \"last-10-avg\": 4000.0\n    },\n    \"env_runners/num_module_steps_sampled/agent_9\": {\n      \"max\": 4000.0,\n      \"min\": 4000.0,\n      \"avg\": 4000.0,\n      \"last\": 4000.0,\n      \"last-5-avg\": 4000.0,\n      \"last-10-avg\": 4000.0\n    },\n    \"env_runners/num_module_steps_sampled/agent_18\": {\n      \"max\": 4000.0,\n      \"min\": 4000.0,\n      \"avg\": 4000.0,\n      \"last\": 4000.0,\n      \"last-5-avg\": 4000.0,\n      \"last-10-avg\": 4000.0\n    },\n    \"env_runners/num_module_steps_sampled/agent_15\": {\n      \"max\": 4000.0,\n      \"min\": 4000.0,\n      \"avg\": 4000.0,\n      \"last\": 4000.0,\n      \"last-5-avg\": 4000.0,\n      \"last-10-avg\": 4000.0\n    },\n    \"env_runners/num_module_steps_sampled/agent_20\": {\n      \"max\": 4000.0,\n      \"min\": 4000.0,\n      \"avg\": 4000.0,\n      \"last\": 4000.0,\n      \"last-5-avg\": 4000.0,\n      \"last-10-avg\": 4000.0\n    },\n    \"env_runners/num_module_steps_sampled/agent_10\": {\n      \"max\": 4000.0,\n      \"min\": 4000.0,\n      \"avg\": 4000.0,\n      \"last\": 4000.0,\n      \"last-5-avg\": 4000.0,\n      \"last-10-avg\": 4000.0\n    },\n    \"env_runners/num_module_steps_sampled/agent_19\": {\n      \"max\": 4000.0,\n      \"min\": 4000.0,\n      \"avg\": 4000.0,\n      \"last\": 4000.0,\n      \"last-5-avg\": 4000.0,\n      \"last-10-avg\": 4000.0\n    },\n    \"env_runners/num_module_steps_sampled/agent_13\": {\n      \"max\": 4000.0,\n      \"min\": 4000.0,\n      \"avg\": 4000.0,\n      \"last\": 4000.0,\n      \"last-5-avg\": 4000.0,\n      \"last-10-avg\": 4000.0\n    },\n    \"env_runners/num_module_steps_sampled/agent_16\": {\n      \"max\": 4000.0,\n      \"min\": 4000.0,\n      \"avg\": 4000.0,\n      \"last\": 4000.0,\n      \"last-5-avg\": 4000.0,\n      \"last-10-avg\": 4000.0\n    },\n    \"env_runners/num_module_steps_sampled/agent_2\": {\n      \"max\": 4000.0,\n      \"min\": 4000.0,\n      \"avg\": 4000.0,\n      \"last\": 4000.0,\n      \"last-5-avg\": 4000.0,\n      \"last-10-avg\": 4000.0\n    },\n    \"env_runners/num_module_steps_sampled/agent_1\": {\n      \"max\": 4000.0,\n      \"min\": 4000.0,\n      \"avg\": 4000.0,\n      \"last\": 4000.0,\n      \"last-5-avg\": 4000.0,\n      \"last-10-avg\": 4000.0\n    },\n    \"env_runners/num_module_steps_sampled/agent_4\": {\n      \"max\": 4000.0,\n      \"min\": 4000.0,\n      \"avg\": 4000.0,\n      \"last\": 4000.0,\n      \"last-5-avg\": 4000.0,\n      \"last-10-avg\": 4000.0\n    },\n    \"env_runners/env_to_module_connector/connector_pipeline_timer\": {\n      \"max\": 0.0004725917648813888,\n      \"min\": 0.00042004872722600783,\n      \"avg\": 0.00044437991178451915,\n      \"last\": 0.00044858052416618443,\n      \"last-5-avg\": 0.00044924614869622134,\n      \"last-10-avg\": 0.0004443799117845191\n    },\n    \"env_runners/agent_episode_returns_mean/agent_11\": {\n      \"max\": -1.5500000000000045,\n      \"min\": -2.8500000000000134,\n      \"avg\": -2.0114973262032154,\n      \"last\": -1.668529411764711,\n      \"last-5-avg\": -1.843796791443856,\n      \"last-10-avg\": -2.0114973262032154\n    },\n    \"env_runners/agent_episode_returns_mean/agent_6\": {\n      \"max\": -1.2770588235294145,\n      \"min\": -2.476666666666676,\n      \"avg\": -1.7995528817587685,\n      \"last\": -1.2770588235294145,\n      \"last-5-avg\": -1.6641301247771874,\n      \"last-10-avg\": -1.7995528817587687\n    },\n    \"env_runners/agent_episode_returns_mean/agent_12\": {\n      \"max\": -1.235000000000004,\n      \"min\": -1.751363636363641,\n      \"avg\": -1.6376325014854474,\n      \"last\": -1.6871568627451035,\n      \"last-5-avg\": -1.7181590017825363,\n      \"last-10-avg\": -1.6376325014854476\n    },\n    \"env_runners/agent_episode_returns_mean/agent_7\": {\n      \"max\": -2.061666666666673,\n      \"min\": -2.8783333333333463,\n      \"avg\": -2.445868983957228,\n      \"last\": -2.132941176470596,\n      \"last-5-avg\": -2.3593761140820044,\n      \"last-10-avg\": -2.445868983957228\n    },\n    \"env_runners/agent_episode_returns_mean/agent_18\": {\n      \"max\": -4.465294117647072,\n      \"min\": -4.578333333333354,\n      \"avg\": -4.516254901960799,\n      \"last\": -4.496568627450995,\n      \"last-5-avg\": -4.5038392156862885,\n      \"last-10-avg\": -4.516254901960799\n    },\n    \"env_runners/agent_episode_returns_mean/agent_17\": {\n      \"max\": -4.414215686274522,\n      \"min\": -4.490000000000019,\n      \"avg\": -4.451982768865136,\n      \"last\": -4.446862745098052,\n      \"last-5-avg\": -4.4443793226381585,\n      \"last-10-avg\": -4.451982768865136\n    },\n    \"env_runners/agent_episode_returns_mean/agent_8\": {\n      \"max\": -0.5000000000000003,\n      \"min\": -2.3902941176470662,\n      \"avg\": -1.9037026143790903,\n      \"last\": -1.9972549019607901,\n      \"last-5-avg\": -2.1844431372549087,\n      \"last-10-avg\": -1.9037026143790905\n    },\n    \"env_runners/agent_episode_returns_mean/agent_0\": {\n      \"max\": -1.879705882352948,\n      \"min\": -2.3526666666666745,\n      \"avg\": -2.1392311348782007,\n      \"last\": -1.879705882352948,\n      \"last-5-avg\": -2.104077361853839,\n      \"last-10-avg\": -2.1392311348782007\n    },\n    \"env_runners/agent_episode_returns_mean/agent_20\": {\n      \"max\": -4.535882352941189,\n      \"min\": -4.808333333333356,\n      \"avg\": -4.609471182412375,\n      \"last\": -4.573823529411779,\n      \"last-5-avg\": -4.569698752228179,\n      \"last-10-avg\": -4.609471182412375\n    },\n    \"env_runners/agent_episode_returns_mean/agent_19\": {\n      \"max\": -4.426862745098052,\n      \"min\": -4.685333333333349,\n      \"avg\": -4.569757278669059,\n      \"last\": -4.426862745098052,\n      \"last-5-avg\": -4.5573754010695335,\n      \"last-10-avg\": -4.5697572786690595\n    },\n    \"env_runners/agent_episode_returns_mean/agent_9\": {\n      \"max\": -2.121568627450987,\n      \"min\": -2.8683333333333465,\n      \"avg\": -2.3414818775995325,\n      \"last\": -2.121568627450987,\n      \"last-5-avg\": -2.2361115864527705,\n      \"last-10-avg\": -2.341481877599533\n    },\n    \"env_runners/agent_episode_returns_mean/agent_15\": {\n      \"max\": -4.307941176470601,\n      \"min\": -4.785000000000022,\n      \"avg\": -4.5300311942959155,\n      \"last\": -4.307941176470601,\n      \"last-5-avg\": -4.479037433155094,\n      \"last-10-avg\": -4.5300311942959155\n    },\n    \"env_runners/agent_episode_returns_mean/agent_16\": {\n      \"max\": -4.484411764705898,\n      \"min\": -4.735000000000022,\n      \"avg\": -4.610448603683913,\n      \"last\": -4.484411764705898,\n      \"last-5-avg\": -4.585538324420692,\n      \"last-10-avg\": -4.610448603683913\n    },\n    \"env_runners/agent_episode_returns_mean/agent_2\": {\n      \"max\": -1.3819607843137287,\n      \"min\": -2.7500000000000124,\n      \"avg\": -1.9156871657754069,\n      \"last\": -1.3819607843137287,\n      \"last-5-avg\": -1.7488245989304858,\n      \"last-10-avg\": -1.9156871657754069\n    },\n    \"env_runners/agent_episode_returns_mean/agent_1\": {\n      \"max\": -1.5888235294117692,\n      \"min\": -3.1460000000000106,\n      \"avg\": -2.4798773024361336,\n      \"last\": -1.5888235294117692,\n      \"last-5-avg\": -2.4565194295900254,\n      \"last-10-avg\": -2.4798773024361336\n    },\n    \"env_runners/agent_episode_returns_mean/agent_10\": {\n      \"max\": -2.008921568627457,\n      \"min\": -3.428333333333349,\n      \"avg\": -2.7670606060606158,\n      \"last\": -2.008921568627457,\n      \"last-5-avg\": -2.6348060606060693,\n      \"last-10-avg\": -2.7670606060606158\n    },\n    \"env_runners/agent_episode_returns_mean/agent_4\": {\n      \"max\": -0.9926666666666676,\n      \"min\": -1.5895098039215716,\n      \"avg\": -1.3094322638146192,\n      \"last\": -1.5895098039215716,\n      \"last-5-avg\": -1.2813187165775424,\n      \"last-10-avg\": -1.3094322638146192\n    },\n    \"env_runners/agent_episode_returns_mean/agent_13\": {\n      \"max\": -0.5000000000000003,\n      \"min\": -2.118627450980398,\n      \"avg\": -1.3608600713012513,\n      \"last\": -2.118627450980398,\n      \"last-5-avg\": -1.5330320855615016,\n      \"last-10-avg\": -1.360860071301251\n    },\n    \"env_runners/agent_episode_returns_mean/agent_5\": {\n      \"max\": -1.179333333333336,\n      \"min\": -2.4234313725490266,\n      \"avg\": -1.5879087938205623,\n      \"last\": -2.4234313725490266,\n      \"last-5-avg\": -1.6514905525846744,\n      \"last-10-avg\": -1.5879087938205625\n    },\n    \"env_runners/agent_episode_returns_mean/agent_14\": {\n      \"max\": -4.432352941176485,\n      \"min\": -4.734000000000017,\n      \"avg\": -4.607624183006553,\n      \"last\": -4.432352941176485,\n      \"last-5-avg\": -4.583482352941192,\n      \"last-10-avg\": -4.607624183006553\n    },\n    \"env_runners/agent_episode_returns_mean/agent_3\": {\n      \"max\": -1.2616666666666712,\n      \"min\": -2.402254901960791,\n      \"avg\": -1.8181812240047597,\n      \"last\": -2.402254901960791,\n      \"last-5-avg\": -1.9294841354723773,\n      \"last-10-avg\": -1.8181812240047597\n    },\n    \"learners/agent_10/weights_seq_no\": {\n      \"max\": 6.0,\n      \"min\": 1.0,\n      \"avg\": 3.5,\n      \"last\": 6.0,\n      \"last-5-avg\": 4.0,\n      \"last-10-avg\": 3.5\n    },\n    \"learners/agent_10/total_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243048cc1c4bb94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430458ca13be94869452942e\"\n      },\n      \"avg\": -0.05875319646050532,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304c42634bd94869452942e\"\n      },\n      \"last-5-avg\": -0.04163852222263813,\n      \"last-10-avg\": -0.05875319646050533\n    },\n    \"learners/agent_10/num_module_steps_trained_lifetime\": {\n      \"max\": 241152,\n      \"min\": 40192,\n      \"avg\": 140672.0,\n      \"last\": 241152,\n      \"last-5-avg\": 160768.0,\n      \"last-10-avg\": 140672.0\n    },\n    \"learners/agent_10/module_train_batch_size_mean\": {\n      \"max\": 256.0,\n      \"min\": 256.0,\n      \"avg\": 256.0,\n      \"last\": 256.0,\n      \"last-5-avg\": 256.0,\n      \"last-10-avg\": 256.0\n    },\n    \"learners/agent_10/mean_kl_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243044171213c94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304a1900e3c94869452942e\"\n      },\n      \"avg\": 0.009307990471522013,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430442471d3c94869452942e\"\n      },\n      \"last-5-avg\": 0.00919885616749525,\n      \"last-10-avg\": 0.009307990471522013\n    },\n    \"learners/agent_10/num_module_steps_trained\": {\n      \"max\": 40192,\n      \"min\": 40192,\n      \"avg\": 40192.0,\n      \"last\": 40192,\n      \"last-5-avg\": 40192.0,\n      \"last-10-avg\": 40192.0\n    },\n    \"learners/agent_10/entropy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ef89c44094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430432d6c34094869452942e\"\n      },\n      \"avg\": 6.130536874135335,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430432d6c34094869452942e\"\n      },\n      \"last-5-avg\": 6.128276729583741,\n      \"last-10-avg\": 6.130536874135335\n    },\n    \"learners/agent_10/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"avg\": 1.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"learners/agent_10/vf_explained_var\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243047251763f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040aac613f94869452942e\"\n      },\n      \"avg\": 0.9260491728782654,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243047251763f94869452942e\"\n      },\n      \"last-5-avg\": 0.92517591714859,\n      \"last-10-avg\": 0.9260491728782654\n    },\n    \"learners/agent_10/curr_kl_coeff\": {\n      \"max\": 0.20000000298023224,\n      \"min\": 0.20000000298023224,\n      \"avg\": 0.20000000298023224,\n      \"last\": 0.20000000298023224,\n      \"last-5-avg\": 0.20000000298023224,\n      \"last-10-avg\": 0.20000000298023224\n    },\n    \"learners/agent_10/vf_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304c702ab3a94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304656b183a94869452942e\"\n      },\n      \"avg\": 0.0009634910675231368,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304e29d4b3a94869452942e\"\n      },\n      \"last-5-avg\": 0.0009143064147792756,\n      \"last-10-avg\": 0.0009634910675231367\n    },\n    \"learners/agent_10/vf_loss_unclipped\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304c702ab3a94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304656b183a94869452942e\"\n      },\n      \"avg\": 0.0009634910675231368,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304e29d4b3a94869452942e\"\n      },\n      \"last-5-avg\": 0.0009143064147792756,\n      \"last-10-avg\": 0.0009634910675231367\n    },\n    \"learners/agent_10/default_optimizer_learning_rate\": {\n      \"max\": 5e-05,\n      \"min\": 5e-05,\n      \"avg\": 5e-05,\n      \"last\": 5e-05,\n      \"last-5-avg\": 5e-05,\n      \"last-10-avg\": 5e-05\n    },\n    \"learners/agent_10/curr_entropy_coeff\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"learners/agent_10/num_trainable_parameters\": {\n      \"max\": 781541,\n      \"min\": 781541,\n      \"avg\": 781541.0,\n      \"last\": 781541,\n      \"last-5-avg\": 781541.0,\n      \"last-10-avg\": 781541.0\n    },\n    \"learners/agent_10/policy_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304b3a60cbc94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304000c17be94869452942e\"\n      },\n      \"avg\": -0.06157828293119867,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430467323fbd94869452942e\"\n      },\n      \"last-5-avg\": -0.04439259674400091,\n      \"last-10-avg\": -0.06157828293119868\n    },\n    \"learners/agent_10/num_module_steps_trained_lifetime_throughput\": {\n      \"max\": 1594.7391773334928,\n      \"min\": 1591.8647800916358,\n      \"avg\": NaN,\n      \"last\": 1591.8647800916358,\n      \"last-5-avg\": NaN,\n      \"last-10-avg\": NaN\n    },\n    \"learners/agent_6/total_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430496f3173d94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040e472bbe94869452942e\"\n      },\n      \"avg\": -0.07472461710373561,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304f03b00be94869452942e\"\n      },\n      \"last-5-avg\": -0.056216892600059507,\n      \"last-10-avg\": -0.07472461710373561\n    },\n    \"learners/agent_6/vf_explained_var\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430449ac763f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304fcbb573f94869452942e\"\n      },\n      \"avg\": 0.9003106753031412,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304af73583f94869452942e\"\n      },\n      \"last-5-avg\": 0.8983456373214722,\n      \"last-10-avg\": 0.9003106753031412\n    },\n    \"learners/agent_6/num_module_steps_trained_lifetime\": {\n      \"max\": 241152,\n      \"min\": 40192,\n      \"avg\": 140672.0,\n      \"last\": 241152,\n      \"last-5-avg\": 160768.0,\n      \"last-10-avg\": 140672.0\n    },\n    \"learners/agent_6/curr_kl_coeff\": {\n      \"max\": 0.20000000298023224,\n      \"min\": 0.20000000298023224,\n      \"avg\": 0.20000000298023224,\n      \"last\": 0.20000000298023224,\n      \"last-5-avg\": 0.20000000298023224,\n      \"last-10-avg\": 0.20000000298023224\n    },\n    \"learners/agent_6/mean_kl_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304e19a1d3c94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040ec1093c94869452942e\"\n      },\n      \"avg\": 0.009134874679148197,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430462cc163c94869452942e\"\n      },\n      \"last-5-avg\": 0.00903796050697565,\n      \"last-10-avg\": 0.009134874679148197\n    },\n    \"learners/agent_6/num_module_steps_trained\": {\n      \"max\": 40192,\n      \"min\": 40192,\n      \"avg\": 40192.0,\n      \"last\": 40192,\n      \"last-5-avg\": 40192.0,\n      \"last-10-avg\": 40192.0\n    },\n    \"learners/agent_6/vf_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304d0b2a13a94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430404b91a3a94869452942e\"\n      },\n      \"avg\": 0.0009245770440126458,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304c6988b3a94869452942e\"\n      },\n      \"last-5-avg\": 0.0008627601433545351,\n      \"last-10-avg\": 0.0009245770440126458\n    },\n    \"learners/agent_6/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"avg\": 1.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"learners/agent_6/vf_loss_unclipped\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304d0b2a13a94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430404b91a3a94869452942e\"\n      },\n      \"avg\": 0.0009245770440126458,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304c6988b3a94869452942e\"\n      },\n      \"last-5-avg\": 0.0008627601433545351,\n      \"last-10-avg\": 0.0009245770440126458\n    },\n    \"learners/agent_6/curr_entropy_coeff\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"learners/agent_6/num_trainable_parameters\": {\n      \"max\": 781541,\n      \"min\": 781541,\n      \"avg\": 781541.0,\n      \"last\": 781541,\n      \"last-5-avg\": 781541.0,\n      \"last-10-avg\": 781541.0\n    },\n    \"learners/agent_6/policy_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430435fe0c3d94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ca822ebe94869452942e\"\n      },\n      \"avg\": -0.07747616805136204,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ae3503be94869452942e\"\n      },\n      \"last-5-avg\": -0.058887242525815967,\n      \"last-10-avg\": -0.07747616805136204\n    },\n    \"learners/agent_6/default_optimizer_learning_rate\": {\n      \"max\": 5e-05,\n      \"min\": 5e-05,\n      \"avg\": 5e-05,\n      \"last\": 5e-05,\n      \"last-5-avg\": 5e-05,\n      \"last-10-avg\": 5e-05\n    },\n    \"learners/agent_6/module_train_batch_size_mean\": {\n      \"max\": 256.0,\n      \"min\": 256.0,\n      \"avg\": 256.0,\n      \"last\": 256.0,\n      \"last-5-avg\": 256.0,\n      \"last-10-avg\": 256.0\n    },\n    \"learners/agent_6/entropy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304a088c44094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040ec3c34094869452942e\"\n      },\n      \"avg\": 6.128647645314534,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040ec3c34094869452942e\"\n      },\n      \"last-5-avg\": 6.126041603088379,\n      \"last-10-avg\": 6.128647645314534\n    },\n    \"learners/agent_6/weights_seq_no\": {\n      \"max\": 6.0,\n      \"min\": 1.0,\n      \"avg\": 3.5,\n      \"last\": 6.0,\n      \"last-5-avg\": 4.0,\n      \"last-10-avg\": 3.5\n    },\n    \"learners/agent_6/num_module_steps_trained_lifetime_throughput\": {\n      \"max\": 1594.7404850604278,\n      \"min\": 1591.8658345488564,\n      \"avg\": NaN,\n      \"last\": 1591.8658345488564,\n      \"last-5-avg\": NaN,\n      \"last-10-avg\": NaN\n    },\n    \"learners/agent_16/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"avg\": 1.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"learners/agent_16/vf_explained_var\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040ab96e3f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243044cfd4f3f94869452942e\"\n      },\n      \"avg\": 0.8496989607810974,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430426b85a3f94869452942e\"\n      },\n      \"last-5-avg\": 0.8511691451072693,\n      \"last-10-avg\": 0.8496989607810974\n    },\n    \"learners/agent_16/curr_kl_coeff\": {\n      \"max\": 0.20000000298023224,\n      \"min\": 0.20000000298023224,\n      \"avg\": 0.20000000298023224,\n      \"last\": 0.20000000298023224,\n      \"last-5-avg\": 0.20000000298023224,\n      \"last-10-avg\": 0.20000000298023224\n    },\n    \"learners/agent_16/vf_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304a8047f3b94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243043873cb3a94869452942e\"\n      },\n      \"avg\": 0.0027549742565800743,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430442bbdd3a94869452942e\"\n      },\n      \"last-5-avg\": 0.0026608138345181943,\n      \"last-10-avg\": 0.0027549742565800748\n    },\n    \"learners/agent_16/vf_loss_unclipped\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304a8047f3b94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243043873cb3a94869452942e\"\n      },\n      \"avg\": 0.0027549742565800743,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430442bbdd3a94869452942e\"\n      },\n      \"last-5-avg\": 0.0026608138345181943,\n      \"last-10-avg\": 0.0027549742565800748\n    },\n    \"learners/agent_16/default_optimizer_learning_rate\": {\n      \"max\": 5e-05,\n      \"min\": 5e-05,\n      \"avg\": 5e-05,\n      \"last\": 5e-05,\n      \"last-5-avg\": 5e-05,\n      \"last-10-avg\": 5e-05\n    },\n    \"learners/agent_16/curr_entropy_coeff\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"learners/agent_16/num_trainable_parameters\": {\n      \"max\": 321253,\n      \"min\": 321253,\n      \"avg\": 321253.0,\n      \"last\": 321253,\n      \"last-5-avg\": 321253.0,\n      \"last-10-avg\": 321253.0\n    },\n    \"learners/agent_16/policy_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430492905d3d94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243043a9f93be94869452942e\"\n      },\n      \"avg\": -0.09293487574905157,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430492905d3d94869452942e\"\n      },\n      \"last-5-avg\": -0.05385701544582844,\n      \"last-10-avg\": -0.09293487574905157\n    },\n    \"learners/agent_16/entropy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304eca3c44094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430476c5c34094869452942e\"\n      },\n      \"avg\": 6.13050389289856,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430476c5c34094869452942e\"\n      },\n      \"last-5-avg\": 6.127602672576904,\n      \"last-10-avg\": 6.13050389289856\n    },\n    \"learners/agent_16/weights_seq_no\": {\n      \"max\": 6.0,\n      \"min\": 1.0,\n      \"avg\": 3.5,\n      \"last\": 6.0,\n      \"last-5-avg\": 4.0,\n      \"last-10-avg\": 3.5\n    },\n    \"learners/agent_16/total_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ae006b3d94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304c03491be94869452942e\"\n      },\n      \"avg\": -0.08867383660981432,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ae006b3d94869452942e\"\n      },\n      \"last-5-avg\": -0.04968748881947249,\n      \"last-10-avg\": -0.08867383660981432\n    },\n    \"learners/agent_16/num_module_steps_trained_lifetime\": {\n      \"max\": 241152,\n      \"min\": 40192,\n      \"avg\": 140672.0,\n      \"last\": 241152,\n      \"last-5-avg\": 160768.0,\n      \"last-10-avg\": 140672.0\n    },\n    \"learners/agent_16/module_train_batch_size_mean\": {\n      \"max\": 256.0,\n      \"min\": 256.0,\n      \"avg\": 256.0,\n      \"last\": 256.0,\n      \"last-5-avg\": 256.0,\n      \"last-10-avg\": 256.0\n    },\n    \"learners/agent_16/mean_kl_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304182d023c94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430406aeec3b94869452942e\"\n      },\n      \"avg\": 0.007530313450843096,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304182d023c94869452942e\"\n      },\n      \"last-5-avg\": 0.007543562911450863,\n      \"last-10-avg\": 0.007530313450843096\n    },\n    \"learners/agent_16/num_module_steps_trained\": {\n      \"max\": 40192,\n      \"min\": 40192,\n      \"avg\": 40192.0,\n      \"last\": 40192,\n      \"last-5-avg\": 40192.0,\n      \"last-10-avg\": 40192.0\n    },\n    \"learners/agent_16/num_module_steps_trained_lifetime_throughput\": {\n      \"max\": 1594.7324009964439,\n      \"min\": 1591.8593263736066,\n      \"avg\": NaN,\n      \"last\": 1591.8593263736066,\n      \"last-5-avg\": NaN,\n      \"last-10-avg\": NaN\n    },\n    \"learners/agent_5/vf_loss_unclipped\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243044a305a3a94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430484e8be3994869452942e\"\n      },\n      \"avg\": 0.0005533216123391563,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243049a03f73994869452942e\"\n      },\n      \"last-5-avg\": 0.0004975212214048952,\n      \"last-10-avg\": 0.0005533216123391563\n    },\n    \"learners/agent_5/default_optimizer_learning_rate\": {\n      \"max\": 5e-05,\n      \"min\": 5e-05,\n      \"avg\": 5e-05,\n      \"last\": 5e-05,\n      \"last-5-avg\": 5e-05,\n      \"last-10-avg\": 5e-05\n    },\n    \"learners/agent_5/module_train_batch_size_mean\": {\n      \"max\": 256.0,\n      \"min\": 256.0,\n      \"avg\": 256.0,\n      \"last\": 256.0,\n      \"last-5-avg\": 256.0,\n      \"last-10-avg\": 256.0\n    },\n    \"learners/agent_5/num_trainable_parameters\": {\n      \"max\": 781541,\n      \"min\": 781541,\n      \"avg\": 781541.0,\n      \"last\": 781541,\n      \"last-5-avg\": 781541.0,\n      \"last-10-avg\": 781541.0\n    },\n    \"learners/agent_5/entropy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430419a8c44094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304c3b3c34094869452942e\"\n      },\n      \"avg\": 6.131990194320679,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304c3b3c34094869452942e\"\n      },\n      \"last-5-avg\": 6.129284286499024,\n      \"last-10-avg\": 6.131990194320679\n    },\n    \"learners/agent_5/weights_seq_no\": {\n      \"max\": 6.0,\n      \"min\": 1.0,\n      \"avg\": 3.5,\n      \"last\": 6.0,\n      \"last-5-avg\": 4.0,\n      \"last-10-avg\": 3.5\n    },\n    \"learners/agent_5/total_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243049333553d94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243043fb560be94869452942e\"\n      },\n      \"avg\": -0.052762984608610466,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304c8eb81bc94869452942e\"\n      },\n      \"last-5-avg\": -0.04963332489132881,\n      \"last-10-avg\": -0.05276298460861047\n    },\n    \"learners/agent_5/vf_explained_var\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ce24783f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430425346a3f94869452942e\"\n      },\n      \"avg\": 0.9471995135148366,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243047782733f94869452942e\"\n      },\n      \"last-5-avg\": 0.9438336372375489,\n      \"last-10-avg\": 0.9471995135148367\n    },\n    \"learners/agent_5/num_module_steps_trained_lifetime\": {\n      \"max\": 241152,\n      \"min\": 40192,\n      \"avg\": 140672.0,\n      \"last\": 241152,\n      \"last-5-avg\": 160768.0,\n      \"last-10-avg\": 140672.0\n    },\n    \"learners/agent_5/curr_kl_coeff\": {\n      \"max\": 0.20000000298023224,\n      \"min\": 0.20000000298023224,\n      \"avg\": 0.20000000298023224,\n      \"last\": 0.20000000298023224,\n      \"last-5-avg\": 0.20000000298023224,\n      \"last-10-avg\": 0.20000000298023224\n    },\n    \"learners/agent_5/mean_kl_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304f2b11c3c94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304309b103c94869452942e\"\n      },\n      \"avg\": 0.009312181733548641,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304f2b11c3c94869452942e\"\n      },\n      \"last-5-avg\": 0.009409405663609505,\n      \"last-10-avg\": 0.009312181733548641\n    },\n    \"learners/agent_5/num_module_steps_trained\": {\n      \"max\": 40192,\n      \"min\": 40192,\n      \"avg\": 40192.0,\n      \"last\": 40192,\n      \"last-5-avg\": 40192.0,\n      \"last-10-avg\": 40192.0\n    },\n    \"learners/agent_5/vf_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243044a305a3a94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430484e8be3994869452942e\"\n      },\n      \"avg\": 0.0005533216123391563,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243049a03f73994869452942e\"\n      },\n      \"last-5-avg\": 0.0004975212214048952,\n      \"last-10-avg\": 0.0005533216123391563\n    },\n    \"learners/agent_5/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"avg\": 1.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"learners/agent_5/curr_entropy_coeff\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"learners/agent_5/policy_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243041e144c3d94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ec1463be94869452942e\"\n      },\n      \"avg\": -0.055178736957410976,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243043c7395bc94869452942e\"\n      },\n      \"last-5-avg\": -0.052012721076607704,\n      \"last-10-avg\": -0.05517873695741097\n    },\n    \"learners/agent_5/num_module_steps_trained_lifetime_throughput\": {\n      \"max\": 1594.7355792723272,\n      \"min\": 1591.861850367351,\n      \"avg\": NaN,\n      \"last\": 1591.861850367351,\n      \"last-5-avg\": NaN,\n      \"last-10-avg\": NaN\n    },\n    \"learners/agent_11/num_module_steps_trained_lifetime\": {\n      \"max\": 241152,\n      \"min\": 40192,\n      \"avg\": 140672.0,\n      \"last\": 241152,\n      \"last-5-avg\": 160768.0,\n      \"last-10-avg\": 140672.0\n    },\n    \"learners/agent_11/curr_kl_coeff\": {\n      \"max\": 0.20000000298023224,\n      \"min\": 0.20000000298023224,\n      \"avg\": 0.20000000298023224,\n      \"last\": 0.20000000298023224,\n      \"last-5-avg\": 0.20000000298023224,\n      \"last-10-avg\": 0.20000000298023224\n    },\n    \"learners/agent_11/mean_kl_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243046e85293c94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243047e34043c94869452942e\"\n      },\n      \"avg\": 0.009100034522513548,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304d3a41f3c94869452942e\"\n      },\n      \"last-5-avg\": 0.008850690722465516,\n      \"last-10-avg\": 0.009100034522513548\n    },\n    \"learners/agent_11/num_module_steps_trained\": {\n      \"max\": 40192,\n      \"min\": 40192,\n      \"avg\": 40192.0,\n      \"last\": 40192,\n      \"last-5-avg\": 40192.0,\n      \"last-10-avg\": 40192.0\n    },\n    \"learners/agent_11/vf_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243042a52433b94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430433b3823a94869452942e\"\n      },\n      \"avg\": 0.0016034182432728508,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430441b0a63a94869452942e\"\n      },\n      \"last-5-avg\": 0.001328029646538198,\n      \"last-10-avg\": 0.001603418243272851\n    },\n    \"learners/agent_11/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"avg\": 1.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"learners/agent_11/vf_loss_unclipped\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243042a52433b94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430433b3823a94869452942e\"\n      },\n      \"avg\": 0.0016034182432728508,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430441b0a63a94869452942e\"\n      },\n      \"last-5-avg\": 0.001328029646538198,\n      \"last-10-avg\": 0.001603418243272851\n    },\n    \"learners/agent_11/curr_entropy_coeff\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"learners/agent_11/num_trainable_parameters\": {\n      \"max\": 781541,\n      \"min\": 781541,\n      \"avg\": 781541.0,\n      \"last\": 781541,\n      \"last-5-avg\": 781541.0,\n      \"last-10-avg\": 781541.0\n    },\n    \"learners/agent_11/policy_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243047f2325bd94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304247c4fbe94869452942e\"\n      },\n      \"avg\": -0.11353130452334881,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243049872a0bd94869452942e\"\n      },\n      \"last-5-avg\": -0.1217629723250866,\n      \"last-10-avg\": -0.11353130452334881\n    },\n    \"learners/agent_11/default_optimizer_learning_rate\": {\n      \"max\": 5e-05,\n      \"min\": 5e-05,\n      \"avg\": 5e-05,\n      \"last\": 5e-05,\n      \"last-5-avg\": 5e-05,\n      \"last-10-avg\": 5e-05\n    },\n    \"learners/agent_11/module_train_batch_size_mean\": {\n      \"max\": 256.0,\n      \"min\": 256.0,\n      \"avg\": 256.0,\n      \"last\": 256.0,\n      \"last-5-avg\": 256.0,\n      \"last-10-avg\": 256.0\n    },\n    \"learners/agent_11/entropy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304eea3c44094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304c2b3c34094869452942e\"\n      },\n      \"avg\": 6.13177490234375,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304c2b3c34094869452942e\"\n      },\n      \"last-5-avg\": 6.12912769317627,\n      \"last-10-avg\": 6.13177490234375\n    },\n    \"learners/agent_11/weights_seq_no\": {\n      \"max\": 6.0,\n      \"min\": 1.0,\n      \"avg\": 3.5,\n      \"last\": 6.0,\n      \"last-5-avg\": 4.0,\n      \"last-10-avg\": 3.5\n    },\n    \"learners/agent_11/total_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243045b4d17bd94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430429b44cbe94869452942e\"\n      },\n      \"avg\": -0.11010787698129812,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430421da99bd94869452942e\"\n      },\n      \"last-5-avg\": -0.11866480186581611,\n      \"last-10-avg\": -0.11010787698129813\n    },\n    \"learners/agent_11/vf_explained_var\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243045e81713f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243047b95423f94869452942e\"\n      },\n      \"avg\": 0.8664371967315674,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304d73c593f94869452942e\"\n      },\n      \"last-5-avg\": 0.8877059578895569,\n      \"last-10-avg\": 0.8664371967315674\n    },\n    \"learners/agent_11/num_module_steps_trained_lifetime_throughput\": {\n      \"max\": 1594.7423503841883,\n      \"min\": 1591.867590742575,\n      \"avg\": NaN,\n      \"last\": 1591.867590742575,\n      \"last-5-avg\": NaN,\n      \"last-10-avg\": NaN\n    },\n    \"learners/agent_20/curr_entropy_coeff\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"learners/agent_20/num_trainable_parameters\": {\n      \"max\": 321253,\n      \"min\": 321253,\n      \"avg\": 321253.0,\n      \"last\": 321253,\n      \"last-5-avg\": 321253.0,\n      \"last-10-avg\": 321253.0\n    },\n    \"learners/agent_20/policy_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430407790abc94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304a1e332be94869452942e\"\n      },\n      \"avg\": -0.09157810158406694,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304745191bd94869452942e\"\n      },\n      \"last-5-avg\": -0.09075620528310538,\n      \"last-10-avg\": -0.09157810158406694\n    },\n    \"learners/agent_20/default_optimizer_learning_rate\": {\n      \"max\": 5e-05,\n      \"min\": 5e-05,\n      \"avg\": 5e-05,\n      \"last\": 5e-05,\n      \"last-5-avg\": 5e-05,\n      \"last-10-avg\": 5e-05\n    },\n    \"learners/agent_20/module_train_batch_size_mean\": {\n      \"max\": 256.0,\n      \"min\": 256.0,\n      \"avg\": 256.0,\n      \"last\": 256.0,\n      \"last-5-avg\": 256.0,\n      \"last-10-avg\": 256.0\n    },\n    \"learners/agent_20/entropy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243045297c44094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243042cb0c34094869452942e\"\n      },\n      \"avg\": 6.129532972971598,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243042cb0c34094869452942e\"\n      },\n      \"last-5-avg\": 6.126745223999023,\n      \"last-10-avg\": 6.129532972971599\n    },\n    \"learners/agent_20/weights_seq_no\": {\n      \"max\": 6.0,\n      \"min\": 1.0,\n      \"avg\": 3.5,\n      \"last\": 6.0,\n      \"last-5-avg\": 4.0,\n      \"last-10-avg\": 3.5\n    },\n    \"learners/agent_20/total_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304fd72b2bb94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430428802ebe94869452942e\"\n      },\n      \"avg\": -0.08760734810493886,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243044daf88bd94869452942e\"\n      },\n      \"last-5-avg\": -0.08673212574794889,\n      \"last-10-avg\": -0.08760734810493886\n    },\n    \"learners/agent_20/vf_explained_var\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ce15663f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243043ab9403f94869452942e\"\n      },\n      \"avg\": 0.8285202284653981,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430465ff473f94869452942e\"\n      },\n      \"last-5-avg\": 0.8144702315330505,\n      \"last-10-avg\": 0.8285202284653982\n    },\n    \"learners/agent_20/num_module_steps_trained_lifetime\": {\n      \"max\": 241152,\n      \"min\": 40192,\n      \"avg\": 140672.0,\n      \"last\": 241152,\n      \"last-5-avg\": 160768.0,\n      \"last-10-avg\": 140672.0\n    },\n    \"learners/agent_20/curr_kl_coeff\": {\n      \"max\": 0.20000000298023224,\n      \"min\": 0.20000000298023224,\n      \"avg\": 0.20000000298023224,\n      \"last\": 0.20000000298023224,\n      \"last-5-avg\": 0.20000000298023224,\n      \"last-10-avg\": 0.20000000298023224\n    },\n    \"learners/agent_20/mean_kl_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430414b6043c94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243045686fb3b94869452942e\"\n      },\n      \"avg\": 0.007851985283195972,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304672a013c94869452942e\"\n      },\n      \"last-5-avg\": 0.007802372053265572,\n      \"last-10-avg\": 0.007851985283195972\n    },\n    \"learners/agent_20/num_module_steps_trained\": {\n      \"max\": 40192,\n      \"min\": 40192,\n      \"avg\": 40192.0,\n      \"last\": 40192,\n      \"last-5-avg\": 40192.0,\n      \"last-10-avg\": 40192.0\n    },\n    \"learners/agent_20/vf_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430455153b3b94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430490adbe3a94869452942e\"\n      },\n      \"avg\": 0.0024003564224888882,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304b9ef2c3b94869452942e\"\n      },\n      \"last-5-avg\": 0.002463602926582098,\n      \"last-10-avg\": 0.0024003564224888882\n    },\n    \"learners/agent_20/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"avg\": 1.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"learners/agent_20/vf_loss_unclipped\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430455153b3b94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430490adbe3a94869452942e\"\n      },\n      \"avg\": 0.0024003564224888882,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304b9ef2c3b94869452942e\"\n      },\n      \"last-5-avg\": 0.002463602926582098,\n      \"last-10-avg\": 0.0024003564224888882\n    },\n    \"learners/agent_20/num_module_steps_trained_lifetime_throughput\": {\n      \"max\": 1594.7335590041528,\n      \"min\": 1591.8602752991162,\n      \"avg\": NaN,\n      \"last\": 1591.8602752991162,\n      \"last-5-avg\": NaN,\n      \"last-10-avg\": NaN\n    },\n    \"learners/__all_modules__/num_non_trainable_parameters\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"learners/__all_modules__/num_module_steps_trained_lifetime\": {\n      \"max\": 5064192,\n      \"min\": 844032,\n      \"avg\": 2954112.0,\n      \"last\": 5064192,\n      \"last-5-avg\": 3376128.0,\n      \"last-10-avg\": 2954112.0\n    },\n    \"learners/__all_modules__/learner_connector_sum_episodes_length_out\": {\n      \"max\": 4000.0,\n      \"min\": 4000.0,\n      \"avg\": 4000.0,\n      \"last\": 4000.0,\n      \"last-5-avg\": 4000.0,\n      \"last-10-avg\": 4000.0\n    },\n    \"learners/__all_modules__/num_env_steps_trained_lifetime\": {\n      \"max\": 3768000,\n      \"min\": 628000,\n      \"avg\": 2198000.0,\n      \"last\": 3768000,\n      \"last-5-avg\": 2512000.0,\n      \"last-10-avg\": 2198000.0\n    },\n    \"learners/__all_modules__/num_trainable_parameters\": {\n      \"max\": 13190345,\n      \"min\": 13190345,\n      \"avg\": 13190345.0,\n      \"last\": 13190345,\n      \"last-5-avg\": 13190345.0,\n      \"last-10-avg\": 13190345.0\n    },\n    \"learners/__all_modules__/num_env_steps_trained\": {\n      \"max\": 628000,\n      \"min\": 628000,\n      \"avg\": 628000.0,\n      \"last\": 628000,\n      \"last-5-avg\": 628000.0,\n      \"last-10-avg\": 628000.0\n    },\n    \"learners/__all_modules__/learner_connector_sum_episodes_length_in\": {\n      \"max\": 4000.0,\n      \"min\": 4000.0,\n      \"avg\": 4000.0,\n      \"last\": 4000.0,\n      \"last-5-avg\": 4000.0,\n      \"last-10-avg\": 4000.0\n    },\n    \"learners/__all_modules__/num_module_steps_trained\": {\n      \"max\": 844032,\n      \"min\": 844032,\n      \"avg\": 844032.0,\n      \"last\": 844032,\n      \"last-5-avg\": 844032.0,\n      \"last-10-avg\": 844032.0\n    },\n    \"learners/__all_modules__/num_env_steps_trained_lifetime_throughput\": {\n      \"max\": 24917.73120698315,\n      \"min\": 24872.83194309265,\n      \"avg\": NaN,\n      \"last\": 24872.83194309265,\n      \"last-5-avg\": NaN,\n      \"last-10-avg\": NaN\n    },\n    \"learners/__all_modules__/num_module_steps_trained_throughput\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": NaN,\n      \"last\": 0.0,\n      \"last-5-avg\": NaN,\n      \"last-10-avg\": NaN\n    },\n    \"learners/__all_modules__/num_module_steps_trained_lifetime_throughput\": {\n      \"max\": 33489.516910507,\n      \"min\": 33429.15565871061,\n      \"avg\": NaN,\n      \"last\": 33429.15565871061,\n      \"last-5-avg\": NaN,\n      \"last-10-avg\": NaN\n    },\n    \"learners/agent_13/module_train_batch_size_mean\": {\n      \"max\": 256.0,\n      \"min\": 256.0,\n      \"avg\": 256.0,\n      \"last\": 256.0,\n      \"last-5-avg\": 256.0,\n      \"last-10-avg\": 256.0\n    },\n    \"learners/agent_13/entropy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243047aa8c44094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430406c9c34094869452942e\"\n      },\n      \"avg\": 6.129175821940104,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430426dac34094869452942e\"\n      },\n      \"last-5-avg\": 6.125897789001465,\n      \"last-10-avg\": 6.1291758219401045\n    },\n    \"learners/agent_13/weights_seq_no\": {\n      \"max\": 6.0,\n      \"min\": 1.0,\n      \"avg\": 3.5,\n      \"last\": 6.0,\n      \"last-5-avg\": 4.0,\n      \"last-10-avg\": 3.5\n    },\n    \"learners/agent_13/total_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243046774703b94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243049e4d2abe94869452942e\"\n      },\n      \"avg\": -0.09188082041994979,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304842ff2bd94869452942e\"\n      },\n      \"last-5-avg\": -0.09011649009771645,\n      \"last-10-avg\": -0.09188082041994979\n    },\n    \"learners/agent_13/vf_explained_var\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ddf56e3f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243044a6d573f94869452942e\"\n      },\n      \"avg\": 0.9070036113262177,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243044a6d573f94869452942e\"\n      },\n      \"last-5-avg\": 0.9017165184020997,\n      \"last-10-avg\": 0.9070036113262177\n    },\n    \"learners/agent_13/num_module_steps_trained_lifetime\": {\n      \"max\": 241152,\n      \"min\": 40192,\n      \"avg\": 140672.0,\n      \"last\": 241152,\n      \"last-5-avg\": 160768.0,\n      \"last-10-avg\": 140672.0\n    },\n    \"learners/agent_13/curr_kl_coeff\": {\n      \"max\": 0.20000000298023224,\n      \"min\": 0.20000000298023224,\n      \"avg\": 0.20000000298023224,\n      \"last\": 0.20000000298023224,\n      \"last-5-avg\": 0.20000000298023224,\n      \"last-10-avg\": 0.20000000298023224\n    },\n    \"learners/agent_13/mean_kl_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430434dc2b3c94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243044d97093c94869452942e\"\n      },\n      \"avg\": 0.009394002923121056,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243044d97093c94869452942e\"\n      },\n      \"last-5-avg\": 0.00945893432945013,\n      \"last-10-avg\": 0.009394002923121056\n    },\n    \"learners/agent_13/num_module_steps_trained\": {\n      \"max\": 40192,\n      \"min\": 40192,\n      \"avg\": 40192.0,\n      \"last\": 40192,\n      \"last-5-avg\": 40192.0,\n      \"last-10-avg\": 40192.0\n    },\n    \"learners/agent_13/vf_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304abb2a33a94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243046e37b53994869452942e\"\n      },\n      \"avg\": 0.0006505628310454388,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304abb2a33a94869452942e\"\n      },\n      \"last-5-avg\": 0.0007044429890811444,\n      \"last-10-avg\": 0.0006505628310454389\n    },\n    \"learners/agent_13/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"avg\": 1.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"learners/agent_13/vf_loss_unclipped\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304abb2a33a94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243046e37b53994869452942e\"\n      },\n      \"avg\": 0.0006505628310454388,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304abb2a33a94869452942e\"\n      },\n      \"last-5-avg\": 0.0007044429890811444,\n      \"last-10-avg\": 0.0006505628310454389\n    },\n    \"learners/agent_13/curr_entropy_coeff\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"learners/agent_13/num_trainable_parameters\": {\n      \"max\": 781541,\n      \"min\": 781541,\n      \"avg\": 781541.0,\n      \"last\": 781541,\n      \"last-5-avg\": 781541.0,\n      \"last-10-avg\": 781541.0\n    },\n    \"learners/agent_13/policy_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243048037873a94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430416dc2cbe94869452942e\"\n      },\n      \"avg\": -0.09441018725434938,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304e62ef8bd94869452942e\"\n      },\n      \"last-5-avg\": -0.09271272271871567,\n      \"last-10-avg\": -0.0944101872543494\n    },\n    \"learners/agent_13/default_optimizer_learning_rate\": {\n      \"max\": 5e-05,\n      \"min\": 5e-05,\n      \"avg\": 5e-05,\n      \"last\": 5e-05,\n      \"last-5-avg\": 5e-05,\n      \"last-10-avg\": 5e-05\n    },\n    \"learners/agent_13/num_module_steps_trained_lifetime_throughput\": {\n      \"max\": 1594.7381358708662,\n      \"min\": 1591.863927936419,\n      \"avg\": NaN,\n      \"last\": 1591.863927936419,\n      \"last-5-avg\": NaN,\n      \"last-10-avg\": NaN\n    },\n    \"learners/agent_8/total_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243046b51b63d94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304f589f8bd94869452942e\"\n      },\n      \"avg\": -0.044660791754722595,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304cb14a4bd94869452942e\"\n      },\n      \"last-5-avg\": -0.07139744609594345,\n      \"last-10-avg\": -0.044660791754722595\n    },\n    \"learners/agent_8/vf_explained_var\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430450d7773f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430499415f3f94869452942e\"\n      },\n      \"avg\": 0.9249509970347086,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430499415f3f94869452942e\"\n      },\n      \"last-5-avg\": 0.9163153648376465,\n      \"last-10-avg\": 0.9249509970347086\n    },\n    \"learners/agent_8/num_module_steps_trained_lifetime\": {\n      \"max\": 241152,\n      \"min\": 40192,\n      \"avg\": 140672.0,\n      \"last\": 241152,\n      \"last-5-avg\": 160768.0,\n      \"last-10-avg\": 140672.0\n    },\n    \"learners/agent_8/curr_kl_coeff\": {\n      \"max\": 0.20000000298023224,\n      \"min\": 0.20000000298023224,\n      \"avg\": 0.20000000298023224,\n      \"last\": 0.20000000298023224,\n      \"last-5-avg\": 0.20000000298023224,\n      \"last-10-avg\": 0.20000000298023224\n    },\n    \"learners/agent_8/mean_kl_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243043527163c94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243048f7dfd3b94869452942e\"\n      },\n      \"avg\": 0.008634787440920869,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243048f7dfd3b94869452942e\"\n      },\n      \"last-5-avg\": 0.00868574408814311,\n      \"last-10-avg\": 0.008634787440920869\n    },\n    \"learners/agent_8/num_module_steps_trained\": {\n      \"max\": 40192,\n      \"min\": 40192,\n      \"avg\": 40192.0,\n      \"last\": 40192,\n      \"last-5-avg\": 40192.0,\n      \"last-10-avg\": 40192.0\n    },\n    \"learners/agent_8/vf_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304a39b883a94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304fecc113a94869452942e\"\n      },\n      \"avg\": 0.0008712681301403791,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243049eb16e3a94869452942e\"\n      },\n      \"last-5-avg\": 0.0008835139335133136,\n      \"last-10-avg\": 0.0008712681301403791\n    },\n    \"learners/agent_8/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"avg\": 1.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"learners/agent_8/curr_entropy_coeff\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"learners/agent_8/policy_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304043ab13d94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243045220febd94869452942e\"\n      },\n      \"avg\": -0.0472590196877718,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243045a1da9bd94869452942e\"\n      },\n      \"last-5-avg\": -0.07401811107993125,\n      \"last-10-avg\": -0.0472590196877718\n    },\n    \"learners/agent_8/vf_loss_unclipped\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304a39b883a94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304fecc113a94869452942e\"\n      },\n      \"avg\": 0.0008712681301403791,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243049eb16e3a94869452942e\"\n      },\n      \"last-5-avg\": 0.0008835139335133136,\n      \"last-10-avg\": 0.0008712681301403791\n    },\n    \"learners/agent_8/default_optimizer_learning_rate\": {\n      \"max\": 5e-05,\n      \"min\": 5e-05,\n      \"avg\": 5e-05,\n      \"last\": 5e-05,\n      \"last-5-avg\": 5e-05,\n      \"last-10-avg\": 5e-05\n    },\n    \"learners/agent_8/num_trainable_parameters\": {\n      \"max\": 781541,\n      \"min\": 781541,\n      \"avg\": 781541.0,\n      \"last\": 781541,\n      \"last-5-avg\": 781541.0,\n      \"last-10-avg\": 781541.0\n    },\n    \"learners/agent_8/module_train_batch_size_mean\": {\n      \"max\": 256.0,\n      \"min\": 256.0,\n      \"avg\": 256.0,\n      \"last\": 256.0,\n      \"last-5-avg\": 256.0,\n      \"last-10-avg\": 256.0\n    },\n    \"learners/agent_8/entropy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430417c3c44094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243048218c44094869452942e\"\n      },\n      \"avg\": 6.137369314829508,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243048218c44094869452942e\"\n      },\n      \"last-5-avg\": 6.135080242156983,\n      \"last-10-avg\": 6.137369314829509\n    },\n    \"learners/agent_8/weights_seq_no\": {\n      \"max\": 6.0,\n      \"min\": 1.0,\n      \"avg\": 3.5,\n      \"last\": 6.0,\n      \"last-5-avg\": 4.0,\n      \"last-10-avg\": 3.5\n    },\n    \"learners/agent_8/num_module_steps_trained_lifetime_throughput\": {\n      \"max\": 1594.740191144325,\n      \"min\": 1591.8656248442353,\n      \"avg\": NaN,\n      \"last\": 1591.8656248442353,\n      \"last-5-avg\": NaN,\n      \"last-10-avg\": NaN\n    },\n    \"learners/agent_9/curr_entropy_coeff\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"learners/agent_9/policy_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243044d4317bd94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304aea05fbe94869452942e\"\n      },\n      \"avg\": -0.10587477994461854,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243044d4317bd94869452942e\"\n      },\n      \"last-5-avg\": -0.09830673709511757,\n      \"last-10-avg\": -0.10587477994461854\n    },\n    \"learners/agent_9/vf_loss_unclipped\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243044ae6013b94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ca29013a94869452942e\"\n      },\n      \"avg\": 0.0009667988730749736,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243049bfd173a94869452942e\"\n      },\n      \"last-5-avg\": 0.0007637366303242743,\n      \"last-10-avg\": 0.0009667988730749736\n    },\n    \"learners/agent_9/default_optimizer_learning_rate\": {\n      \"max\": 5e-05,\n      \"min\": 5e-05,\n      \"avg\": 5e-05,\n      \"last\": 5e-05,\n      \"last-5-avg\": 5e-05,\n      \"last-10-avg\": 5e-05\n    },\n    \"learners/agent_9/module_train_batch_size_mean\": {\n      \"max\": 256.0,\n      \"min\": 256.0,\n      \"avg\": 256.0,\n      \"last\": 256.0,\n      \"last-5-avg\": 256.0,\n      \"last-10-avg\": 256.0\n    },\n    \"learners/agent_9/num_trainable_parameters\": {\n      \"max\": 781541,\n      \"min\": 781541,\n      \"avg\": 781541.0,\n      \"last\": 781541,\n      \"last-5-avg\": 781541.0,\n      \"last-10-avg\": 781541.0\n    },\n    \"learners/agent_9/entropy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304eaa6c44094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243042fccc34094869452942e\"\n      },\n      \"avg\": 6.132969538370768,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243042fccc34094869452942e\"\n      },\n      \"last-5-avg\": 6.130488395690918,\n      \"last-10-avg\": 6.1329695383707685\n    },\n    \"learners/agent_9/weights_seq_no\": {\n      \"max\": 6.0,\n      \"min\": 1.0,\n      \"avg\": 3.5,\n      \"last\": 6.0,\n      \"last-5-avg\": 4.0,\n      \"last-10-avg\": 3.5\n    },\n    \"learners/agent_9/total_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304e03a0dbd94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304f4b75cbe94869452942e\"\n      },\n      \"avg\": -0.10304730385541916,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304e03a0dbd94869452942e\"\n      },\n      \"last-5-avg\": -0.09568814635276794,\n      \"last-10-avg\": -0.10304730385541916\n    },\n    \"learners/agent_9/vf_explained_var\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304aa23713f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304e761643f94869452942e\"\n      },\n      \"avg\": 0.9270224769910176,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304328e703f94869452942e\"\n      },\n      \"last-5-avg\": 0.9300272226333618,\n      \"last-10-avg\": 0.9270224769910177\n    },\n    \"learners/agent_9/num_module_steps_trained_lifetime\": {\n      \"max\": 241152,\n      \"min\": 40192,\n      \"avg\": 140672.0,\n      \"last\": 241152,\n      \"last-5-avg\": 160768.0,\n      \"last-10-avg\": 140672.0\n    },\n    \"learners/agent_9/curr_kl_coeff\": {\n      \"max\": 0.20000000298023224,\n      \"min\": 0.20000000298023224,\n      \"avg\": 0.20000000298023224,\n      \"last\": 0.20000000298023224,\n      \"last-5-avg\": 0.20000000298023224,\n      \"last-10-avg\": 0.20000000298023224\n    },\n    \"learners/agent_9/mean_kl_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ce201f3c94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304643f0a3c94869452942e\"\n      },\n      \"avg\": 0.009303410382320482,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243046229193c94869452942e\"\n      },\n      \"last-5-avg\": 0.009274285286664963,\n      \"last-10-avg\": 0.009303410382320484\n    },\n    \"learners/agent_9/num_module_steps_trained\": {\n      \"max\": 40192,\n      \"min\": 40192,\n      \"avg\": 40192.0,\n      \"last\": 40192,\n      \"last-5-avg\": 40192.0,\n      \"last-10-avg\": 40192.0\n    },\n    \"learners/agent_9/vf_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243044ae6013b94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ca29013a94869452942e\"\n      },\n      \"avg\": 0.0009667988730749736,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243049bfd173a94869452942e\"\n      },\n      \"last-5-avg\": 0.0007637366303242743,\n      \"last-10-avg\": 0.0009667988730749736\n    },\n    \"learners/agent_9/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"avg\": 1.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"learners/agent_9/num_module_steps_trained_lifetime_throughput\": {\n      \"max\": 1594.7333041317452,\n      \"min\": 1591.8600701838775,\n      \"avg\": NaN,\n      \"last\": 1591.8600701838775,\n      \"last-5-avg\": NaN,\n      \"last-10-avg\": NaN\n    },\n    \"learners/agent_1/module_train_batch_size_mean\": {\n      \"max\": 256.0,\n      \"min\": 256.0,\n      \"avg\": 256.0,\n      \"last\": 256.0,\n      \"last-5-avg\": 256.0,\n      \"last-10-avg\": 256.0\n    },\n    \"learners/agent_1/entropy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243049eadc44094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243041523c44094869452942e\"\n      },\n      \"avg\": 6.137191931406656,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243041523c44094869452942e\"\n      },\n      \"last-5-avg\": 6.135391616821289,\n      \"last-10-avg\": 6.137191931406657\n    },\n    \"learners/agent_1/weights_seq_no\": {\n      \"max\": 6.0,\n      \"min\": 1.0,\n      \"avg\": 3.5,\n      \"last\": 6.0,\n      \"last-5-avg\": 4.0,\n      \"last-10-avg\": 3.5\n    },\n    \"learners/agent_1/total_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304d43680bd94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304c9a42fbe94869452942e\"\n      },\n      \"avg\": -0.11552214249968529,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430402a3b9bd94869452942e\"\n      },\n      \"last-5-avg\": -0.11863733381032944,\n      \"last-10-avg\": -0.11552214249968529\n    },\n    \"learners/agent_1/vf_explained_var\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430427d56b3f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243041e8d403f94869452942e\"\n      },\n      \"avg\": 0.8458378215630848,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243044020623f94869452942e\"\n      },\n      \"last-5-avg\": 0.838399600982666,\n      \"last-10-avg\": 0.845837821563085\n    },\n    \"learners/agent_1/num_module_steps_trained_lifetime\": {\n      \"max\": 241152,\n      \"min\": 40192,\n      \"avg\": 140672.0,\n      \"last\": 241152,\n      \"last-5-avg\": 160768.0,\n      \"last-10-avg\": 140672.0\n    },\n    \"learners/agent_1/curr_kl_coeff\": {\n      \"max\": 0.20000000298023224,\n      \"min\": 0.20000000298023224,\n      \"avg\": 0.20000000298023224,\n      \"last\": 0.20000000298023224,\n      \"last-5-avg\": 0.20000000298023224,\n      \"last-10-avg\": 0.20000000298023224\n    },\n    \"learners/agent_1/mean_kl_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304b2ec193c94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430441ad013c94869452942e\"\n      },\n      \"avg\": 0.008486717628935972,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430400620c3c94869452942e\"\n      },\n      \"last-5-avg\": 0.008379578590393066,\n      \"last-10-avg\": 0.008486717628935972\n    },\n    \"learners/agent_1/num_module_steps_trained\": {\n      \"max\": 40192,\n      \"min\": 40192,\n      \"avg\": 40192.0,\n      \"last\": 40192,\n      \"last-5-avg\": 40192.0,\n      \"last-10-avg\": 40192.0\n    },\n    \"learners/agent_1/vf_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304426a063c94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ac092d3a94869452942e\"\n      },\n      \"avg\": 0.0027512118103913963,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ac092d3a94869452942e\"\n      },\n      \"last-5-avg\": 0.0027771413559094073,\n      \"last-10-avg\": 0.0027512118103913963\n    },\n    \"learners/agent_1/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"avg\": 1.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"learners/agent_1/vf_loss_unclipped\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304426a063c94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ac092d3a94869452942e\"\n      },\n      \"avg\": 0.0027512118103913963,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ac092d3a94869452942e\"\n      },\n      \"last-5-avg\": 0.0027771413559094073,\n      \"last-10-avg\": 0.0027512118103913963\n    },\n    \"learners/agent_1/curr_entropy_coeff\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"learners/agent_1/num_trainable_parameters\": {\n      \"max\": 781541,\n      \"min\": 781541,\n      \"avg\": 781541.0,\n      \"last\": 781541,\n      \"last-5-avg\": 781541.0,\n      \"last-10-avg\": 781541.0\n    },\n    \"learners/agent_1/policy_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304180a86bd94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304b4d933be94869452942e\"\n      },\n      \"avg\": -0.11997069542606673,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304887fbebd94869452942e\"\n      },\n      \"last-5-avg\": -0.12309038639068604,\n      \"last-10-avg\": -0.11997069542606671\n    },\n    \"learners/agent_1/default_optimizer_learning_rate\": {\n      \"max\": 5e-05,\n      \"min\": 5e-05,\n      \"avg\": 5e-05,\n      \"last\": 5e-05,\n      \"last-5-avg\": 5e-05,\n      \"last-10-avg\": 5e-05\n    },\n    \"learners/agent_1/num_module_steps_trained_lifetime_throughput\": {\n      \"max\": 1594.7379071915432,\n      \"min\": 1591.8637218293245,\n      \"avg\": NaN,\n      \"last\": 1591.8637218293245,\n      \"last-5-avg\": NaN,\n      \"last-10-avg\": NaN\n    },\n    \"learners/agent_19/vf_explained_var\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304e317653f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304026c4e3f94869452942e\"\n      },\n      \"avg\": 0.856761743625005,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430428114f3f94869452942e\"\n      },\n      \"last-5-avg\": 0.8533154129981995,\n      \"last-10-avg\": 0.8567617436250051\n    },\n    \"learners/agent_19/num_module_steps_trained_lifetime\": {\n      \"max\": 241152,\n      \"min\": 40192,\n      \"avg\": 140672.0,\n      \"last\": 241152,\n      \"last-5-avg\": 160768.0,\n      \"last-10-avg\": 140672.0\n    },\n    \"learners/agent_19/curr_kl_coeff\": {\n      \"max\": 0.20000000298023224,\n      \"min\": 0.20000000298023224,\n      \"avg\": 0.20000000298023224,\n      \"last\": 0.20000000298023224,\n      \"last-5-avg\": 0.20000000298023224,\n      \"last-10-avg\": 0.20000000298023224\n    },\n    \"learners/agent_19/mean_kl_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304fcc6023c94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304fab1f13b94869452942e\"\n      },\n      \"avg\": 0.007707901997491717,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304491b003c94869452942e\"\n      },\n      \"last-5-avg\": 0.007694012857973576,\n      \"last-10-avg\": 0.007707901997491717\n    },\n    \"learners/agent_19/num_module_steps_trained\": {\n      \"max\": 40192,\n      \"min\": 40192,\n      \"avg\": 40192.0,\n      \"last\": 40192,\n      \"last-5-avg\": 40192.0,\n      \"last-10-avg\": 40192.0\n    },\n    \"learners/agent_19/vf_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430462c0013b94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ac0d933a94869452942e\"\n      },\n      \"avg\": 0.0015992144860016802,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243049c4ce93a94869452942e\"\n      },\n      \"last-5-avg\": 0.0015421643387526275,\n      \"last-10-avg\": 0.0015992144860016804\n    },\n    \"learners/agent_19/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"avg\": 1.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"learners/agent_19/curr_entropy_coeff\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"learners/agent_19/policy_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304e52437bd94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304dd6f24be94869452942e\"\n      },\n      \"avg\": -0.0988558412839969,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243047d0ad5bd94869452942e\"\n      },\n      \"last-5-avg\": -0.10968442559242249,\n      \"last-10-avg\": -0.0988558412839969\n    },\n    \"learners/agent_19/vf_loss_unclipped\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430462c0013b94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ac0d933a94869452942e\"\n      },\n      \"avg\": 0.0015992144860016802,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243049c4ce93a94869452942e\"\n      },\n      \"last-5-avg\": 0.0015421643387526275,\n      \"last-10-avg\": 0.0015992144860016804\n    },\n    \"learners/agent_19/default_optimizer_learning_rate\": {\n      \"max\": 5e-05,\n      \"min\": 5e-05,\n      \"avg\": 5e-05,\n      \"last\": 5e-05,\n      \"last-5-avg\": 5e-05,\n      \"last-10-avg\": 5e-05\n    },\n    \"learners/agent_19/module_train_batch_size_mean\": {\n      \"max\": 256.0,\n      \"min\": 256.0,\n      \"avg\": 256.0,\n      \"last\": 256.0,\n      \"last-5-avg\": 256.0,\n      \"last-10-avg\": 256.0\n    },\n    \"learners/agent_19/num_trainable_parameters\": {\n      \"max\": 321253,\n      \"min\": 321253,\n      \"avg\": 321253.0,\n      \"last\": 321253,\n      \"last-5-avg\": 321253.0,\n      \"last-10-avg\": 321253.0\n    },\n    \"learners/agent_19/entropy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304a87bc44094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243046385c34094869452942e\"\n      },\n      \"avg\": 6.124325752258301,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243046385c34094869452942e\"\n      },\n      \"last-5-avg\": 6.121171951293945,\n      \"last-10-avg\": 6.124325752258301\n    },\n    \"learners/agent_19/weights_seq_no\": {\n      \"max\": 6.0,\n      \"min\": 1.0,\n      \"avg\": 3.5,\n      \"last\": 6.0,\n      \"last-5-avg\": 4.0,\n      \"last-10-avg\": 3.5\n    },\n    \"learners/agent_19/total_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304de0d29bd94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304fcbd21be94869452942e\"\n      },\n      \"avg\": -0.0957150471707185,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243046a31cebd94869452942e\"\n      },\n      \"last-5-avg\": -0.1066034585237503,\n      \"last-10-avg\": -0.0957150471707185\n    },\n    \"learners/agent_19/num_module_steps_trained_lifetime_throughput\": {\n      \"max\": 1594.740842069193,\n      \"min\": 1591.8661372291976,\n      \"avg\": NaN,\n      \"last\": 1591.8661372291976,\n      \"last-5-avg\": NaN,\n      \"last-10-avg\": NaN\n    },\n    \"learners/agent_17/vf_explained_var\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430414396c3f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304f9254e3f94869452942e\"\n      },\n      \"avg\": 0.8714523911476135,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304f9254e3f94869452942e\"\n      },\n      \"last-5-avg\": 0.8809782266616821,\n      \"last-10-avg\": 0.8714523911476135\n    },\n    \"learners/agent_17/num_module_steps_trained_lifetime\": {\n      \"max\": 241152,\n      \"min\": 40192,\n      \"avg\": 140672.0,\n      \"last\": 241152,\n      \"last-5-avg\": 160768.0,\n      \"last-10-avg\": 140672.0\n    },\n    \"learners/agent_17/curr_kl_coeff\": {\n      \"max\": 0.20000000298023224,\n      \"min\": 0.20000000298023224,\n      \"avg\": 0.20000000298023224,\n      \"last\": 0.20000000298023224,\n      \"last-5-avg\": 0.20000000298023224,\n      \"last-10-avg\": 0.20000000298023224\n    },\n    \"learners/agent_17/mean_kl_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304dc3ef43b94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304af4ceb3b94869452942e\"\n      },\n      \"avg\": 0.007327909115701914,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304d0c4f13b94869452942e\"\n      },\n      \"last-5-avg\": 0.007357336487621069,\n      \"last-10-avg\": 0.007327909115701914\n    },\n    \"learners/agent_17/vf_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040adc4b3b94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304e69a923a94869452942e\"\n      },\n      \"avg\": 0.0016695131198503077,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304d675983a94869452942e\"\n      },\n      \"last-5-avg\": 0.0013812858378514647,\n      \"last-10-avg\": 0.0016695131198503077\n    },\n    \"learners/agent_17/vf_loss_unclipped\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040adc4b3b94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304e69a923a94869452942e\"\n      },\n      \"avg\": 0.0016695131198503077,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304d675983a94869452942e\"\n      },\n      \"last-5-avg\": 0.0013812858378514647,\n      \"last-10-avg\": 0.0016695131198503077\n    },\n    \"learners/agent_17/default_optimizer_learning_rate\": {\n      \"max\": 5e-05,\n      \"min\": 5e-05,\n      \"avg\": 5e-05,\n      \"last\": 5e-05,\n      \"last-5-avg\": 5e-05,\n      \"last-10-avg\": 5e-05\n    },\n    \"learners/agent_17/curr_entropy_coeff\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"learners/agent_17/num_trainable_parameters\": {\n      \"max\": 321253,\n      \"min\": 321253,\n      \"avg\": 321253.0,\n      \"last\": 321253,\n      \"last-5-avg\": 321253.0,\n      \"last-10-avg\": 321253.0\n    },\n    \"learners/agent_17/policy_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304f995a33c94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304fe4b31be94869452942e\"\n      },\n      \"avg\": -0.07828390815605721,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430470418abd94869452942e\"\n      },\n      \"last-5-avg\": -0.07515524886548519,\n      \"last-10-avg\": -0.0782839081560572\n    },\n    \"learners/agent_17/weights_seq_no\": {\n      \"max\": 6.0,\n      \"min\": 1.0,\n      \"avg\": 3.5,\n      \"last\": 6.0,\n      \"last-5-avg\": 4.0,\n      \"last-10-avg\": 3.5\n    },\n    \"learners/agent_17/total_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430441f1ba3c94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243045da82ebe94869452942e\"\n      },\n      \"avg\": -0.07514881684134403,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304efd984bd94869452942e\"\n      },\n      \"last-5-avg\": -0.07230249904096127,\n      \"last-10-avg\": -0.07514881684134404\n    },\n    \"learners/agent_17/module_train_batch_size_mean\": {\n      \"max\": 256.0,\n      \"min\": 256.0,\n      \"avg\": 256.0,\n      \"last\": 256.0,\n      \"last-5-avg\": 256.0,\n      \"last-10-avg\": 256.0\n    },\n    \"learners/agent_17/num_module_steps_trained\": {\n      \"max\": 40192,\n      \"min\": 40192,\n      \"avg\": 40192.0,\n      \"last\": 40192,\n      \"last-5-avg\": 40192.0,\n      \"last-10-avg\": 40192.0\n    },\n    \"learners/agent_17/entropy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304de5bc44094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304b8acc34094869452942e\"\n      },\n      \"avg\": 6.125620683034261,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304b8acc34094869452942e\"\n      },\n      \"last-5-avg\": 6.123501968383789,\n      \"last-10-avg\": 6.125620683034261\n    },\n    \"learners/agent_17/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"avg\": 1.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"learners/agent_17/num_module_steps_trained_lifetime_throughput\": {\n      \"max\": 1594.7407699307948,\n      \"min\": 1591.8660739711981,\n      \"avg\": NaN,\n      \"last\": 1591.8660739711981,\n      \"last-5-avg\": NaN,\n      \"last-10-avg\": NaN\n    },\n    \"learners/agent_3/curr_kl_coeff\": {\n      \"max\": 0.20000000298023224,\n      \"min\": 0.20000000298023224,\n      \"avg\": 0.20000000298023224,\n      \"last\": 0.20000000298023224,\n      \"last-5-avg\": 0.20000000298023224,\n      \"last-10-avg\": 0.20000000298023224\n    },\n    \"learners/agent_3/vf_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430493372b3a94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304e2a1bc3994869452942e\"\n      },\n      \"avg\": 0.0004885892121819779,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ad251c3a94869452942e\"\n      },\n      \"last-5-avg\": 0.0004884366819169373,\n      \"last-10-avg\": 0.0004885892121819779\n    },\n    \"learners/agent_3/vf_loss_unclipped\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430493372b3a94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304e2a1bc3994869452942e\"\n      },\n      \"avg\": 0.0004885892121819779,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ad251c3a94869452942e\"\n      },\n      \"last-5-avg\": 0.0004884366819169373,\n      \"last-10-avg\": 0.0004885892121819779\n    },\n    \"learners/agent_3/default_optimizer_learning_rate\": {\n      \"max\": 5e-05,\n      \"min\": 5e-05,\n      \"avg\": 5e-05,\n      \"last\": 5e-05,\n      \"last-5-avg\": 5e-05,\n      \"last-10-avg\": 5e-05\n    },\n    \"learners/agent_3/curr_entropy_coeff\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"learners/agent_3/num_trainable_parameters\": {\n      \"max\": 781541,\n      \"min\": 781541,\n      \"avg\": 781541.0,\n      \"last\": 781541,\n      \"last-5-avg\": 781541.0,\n      \"last-10-avg\": 781541.0\n    },\n    \"learners/agent_3/policy_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304117a23bd94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243045f1f2dbe94869452942e\"\n      },\n      \"avg\": -0.10792508038381735,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304117a23bd94869452942e\"\n      },\n      \"last-5-avg\": -0.09569709971547127,\n      \"last-10-avg\": -0.10792508038381736\n    },\n    \"learners/agent_3/entropy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243045e8ec44094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430460c5c34094869452942e\"\n      },\n      \"avg\": 6.1295387744903564,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430460c5c34094869452942e\"\n      },\n      \"last-5-avg\": 6.1269707679748535,\n      \"last-10-avg\": 6.1295387744903564\n    },\n    \"learners/agent_3/weights_seq_no\": {\n      \"max\": 6.0,\n      \"min\": 1.0,\n      \"avg\": 3.5,\n      \"last\": 6.0,\n      \"last-5-avg\": 4.0,\n      \"last-10-avg\": 3.5\n    },\n    \"learners/agent_3/total_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243043ce118bd94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430467c02abe94869452942e\"\n      },\n      \"avg\": -0.1055968776345253,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243043ce118bd94869452942e\"\n      },\n      \"last-5-avg\": -0.09336633682250976,\n      \"last-10-avg\": -0.1055968776345253\n    },\n    \"learners/agent_3/num_module_steps_trained_lifetime\": {\n      \"max\": 241152,\n      \"min\": 40192,\n      \"avg\": 140672.0,\n      \"last\": 241152,\n      \"last-5-avg\": 160768.0,\n      \"last-10-avg\": 140672.0\n    },\n    \"learners/agent_3/module_train_batch_size_mean\": {\n      \"max\": 256.0,\n      \"min\": 256.0,\n      \"avg\": 256.0,\n      \"last\": 256.0,\n      \"last-5-avg\": 256.0,\n      \"last-10-avg\": 256.0\n    },\n    \"learners/agent_3/mean_kl_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304fe24233c94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304adb60e3c94869452942e\"\n      },\n      \"avg\": 0.009198070658991735,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304fe24233c94869452942e\"\n      },\n      \"last-5-avg\": 0.009211641550064088,\n      \"last-10-avg\": 0.009198070658991734\n    },\n    \"learners/agent_3/num_module_steps_trained\": {\n      \"max\": 40192,\n      \"min\": 40192,\n      \"avg\": 40192.0,\n      \"last\": 40192,\n      \"last-5-avg\": 40192.0,\n      \"last-10-avg\": 40192.0\n    },\n    \"learners/agent_3/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"avg\": 1.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"learners/agent_3/vf_explained_var\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243048bef753f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304dc1f6a3f94869452942e\"\n      },\n      \"avg\": 0.9423560599486033,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304af776f3f94869452942e\"\n      },\n      \"last-5-avg\": 0.9386899948120118,\n      \"last-10-avg\": 0.9423560599486033\n    },\n    \"learners/agent_3/num_module_steps_trained_lifetime_throughput\": {\n      \"max\": 1594.7341610742433,\n      \"min\": 1591.8607209225213,\n      \"avg\": NaN,\n      \"last\": 1591.8607209225213,\n      \"last-5-avg\": NaN,\n      \"last-10-avg\": NaN\n    },\n    \"learners/agent_15/total_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243042c408b3d94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304524d3fbe94869452942e\"\n      },\n      \"avg\": -0.04882497837146123,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243041c7dc6bd94869452942e\"\n      },\n      \"last-5-avg\": -0.07218867242336273,\n      \"last-10-avg\": -0.048824978371461235\n    },\n    \"learners/agent_15/vf_explained_var\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243047a81673f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430446d94d3f94869452942e\"\n      },\n      \"avg\": 0.8697814842065175,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243045cc9603f94869452942e\"\n      },\n      \"last-5-avg\": 0.8628738999366761,\n      \"last-10-avg\": 0.8697814842065176\n    },\n    \"learners/agent_15/num_module_steps_trained_lifetime\": {\n      \"max\": 241152,\n      \"min\": 40192,\n      \"avg\": 140672.0,\n      \"last\": 241152,\n      \"last-5-avg\": 160768.0,\n      \"last-10-avg\": 140672.0\n    },\n    \"learners/agent_15/curr_kl_coeff\": {\n      \"max\": 0.20000000298023224,\n      \"min\": 0.20000000298023224,\n      \"avg\": 0.20000000298023224,\n      \"last\": 0.20000000298023224,\n      \"last-5-avg\": 0.20000000298023224,\n      \"last-10-avg\": 0.20000000298023224\n    },\n    \"learners/agent_15/mean_kl_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430456daf33b94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243046e2fee3b94869452942e\"\n      },\n      \"avg\": 0.00736928932989637,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304e4daef3b94869452942e\"\n      },\n      \"last-5-avg\": 0.007354787364602089,\n      \"last-10-avg\": 0.007369289329896371\n    },\n    \"learners/agent_15/num_module_steps_trained\": {\n      \"max\": 40192,\n      \"min\": 40192,\n      \"avg\": 40192.0,\n      \"last\": 40192,\n      \"last-5-avg\": 40192.0,\n      \"last-10-avg\": 40192.0\n    },\n    \"learners/agent_15/vf_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430427df063b94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430402e7c13a94869452942e\"\n      },\n      \"avg\": 0.001757165688710908,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430402e7c13a94869452942e\"\n      },\n      \"last-5-avg\": 0.001805238239467144,\n      \"last-10-avg\": 0.0017571656887109082\n    },\n    \"learners/agent_15/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"avg\": 1.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"learners/agent_15/vf_loss_unclipped\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430427df063b94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430402e7c13a94869452942e\"\n      },\n      \"avg\": 0.001757165688710908,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430402e7c13a94869452942e\"\n      },\n      \"last-5-avg\": 0.001805238239467144,\n      \"last-10-avg\": 0.0017571656887109082\n    },\n    \"learners/agent_15/curr_entropy_coeff\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"learners/agent_15/num_trainable_parameters\": {\n      \"max\": 321253,\n      \"min\": 321253,\n      \"avg\": 321253.0,\n      \"last\": 321253,\n      \"last-5-avg\": 321253.0,\n      \"last-10-avg\": 321253.0\n    },\n    \"learners/agent_15/policy_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243049a18853d94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243042ad542be94869452942e\"\n      },\n      \"avg\": -0.052055995290478066,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243043f84ccbd94869452942e\"\n      },\n      \"last-5-avg\": -0.07546486034989357,\n      \"last-10-avg\": -0.05205599529047807\n    },\n    \"learners/agent_15/default_optimizer_learning_rate\": {\n      \"max\": 5e-05,\n      \"min\": 5e-05,\n      \"avg\": 5e-05,\n      \"last\": 5e-05,\n      \"last-5-avg\": 5e-05,\n      \"last-10-avg\": 5e-05\n    },\n    \"learners/agent_15/module_train_batch_size_mean\": {\n      \"max\": 256.0,\n      \"min\": 256.0,\n      \"avg\": 256.0,\n      \"last\": 256.0,\n      \"last-5-avg\": 256.0,\n      \"last-10-avg\": 256.0\n    },\n    \"learners/agent_15/entropy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304b974c44094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430448d1c34094869452942e\"\n      },\n      \"avg\": 6.129847526550293,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430448d1c34094869452942e\"\n      },\n      \"last-5-avg\": 6.127967357635498,\n      \"last-10-avg\": 6.129847526550293\n    },\n    \"learners/agent_15/weights_seq_no\": {\n      \"max\": 6.0,\n      \"min\": 1.0,\n      \"avg\": 3.5,\n      \"last\": 6.0,\n      \"last-5-avg\": 4.0,\n      \"last-10-avg\": 3.5\n    },\n    \"learners/agent_15/num_module_steps_trained_lifetime_throughput\": {\n      \"max\": 1594.7399268409147,\n      \"min\": 1591.865394031671,\n      \"avg\": NaN,\n      \"last\": 1591.865394031671,\n      \"last-5-avg\": NaN,\n      \"last-10-avg\": NaN\n    },\n    \"learners/agent_12/total_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304c9a4043d94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304353528be94869452942e\"\n      },\n      \"avg\": -0.08184919320046902,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304d9e4abbd94869452942e\"\n      },\n      \"last-5-avg\": -0.06536593809723854,\n      \"last-10-avg\": -0.08184919320046902\n    },\n    \"learners/agent_12/num_module_steps_trained_lifetime\": {\n      \"max\": 241152,\n      \"min\": 40192,\n      \"avg\": 140672.0,\n      \"last\": 241152,\n      \"last-5-avg\": 160768.0,\n      \"last-10-avg\": 140672.0\n    },\n    \"learners/agent_12/module_train_batch_size_mean\": {\n      \"max\": 256.0,\n      \"min\": 256.0,\n      \"avg\": 256.0,\n      \"last\": 256.0,\n      \"last-5-avg\": 256.0,\n      \"last-10-avg\": 256.0\n    },\n    \"learners/agent_12/num_module_steps_trained\": {\n      \"max\": 40192,\n      \"min\": 40192,\n      \"avg\": 40192.0,\n      \"last\": 40192,\n      \"last-5-avg\": 40192.0,\n      \"last-10-avg\": 40192.0\n    },\n    \"learners/agent_12/entropy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430490a5c44094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243045209c44094869452942e\"\n      },\n      \"avg\": 6.135584831237793,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243045209c44094869452942e\"\n      },\n      \"last-5-avg\": 6.133659744262696,\n      \"last-10-avg\": 6.135584831237793\n    },\n    \"learners/agent_12/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"avg\": 1.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"learners/agent_12/vf_explained_var\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040040733f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040263673f94869452942e\"\n      },\n      \"avg\": 0.9282910823822021,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430421406d3f94869452942e\"\n      },\n      \"last-5-avg\": 0.9239102363586426,\n      \"last-10-avg\": 0.9282910823822021\n    },\n    \"learners/agent_12/curr_kl_coeff\": {\n      \"max\": 0.20000000298023224,\n      \"min\": 0.20000000298023224,\n      \"avg\": 0.20000000298023224,\n      \"last\": 0.20000000298023224,\n      \"last-5-avg\": 0.20000000298023224,\n      \"last-10-avg\": 0.20000000298023224\n    },\n    \"learners/agent_12/mean_kl_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243047a7c1f3c94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243043ba3033c94869452942e\"\n      },\n      \"avg\": 0.008997843290368715,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304b175163c94869452942e\"\n      },\n      \"last-5-avg\": 0.00885055847465992,\n      \"last-10-avg\": 0.008997843290368715\n    },\n    \"learners/agent_12/vf_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304887b393a94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304c025e93994869452942e\"\n      },\n      \"avg\": 0.0006131791645505776,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304c025e93994869452942e\"\n      },\n      \"last-5-avg\": 0.0006069728289730847,\n      \"last-10-avg\": 0.0006131791645505776\n    },\n    \"learners/agent_12/vf_loss_unclipped\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304887b393a94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304c025e93994869452942e\"\n      },\n      \"avg\": 0.0006131791645505776,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304c025e93994869452942e\"\n      },\n      \"last-5-avg\": 0.0006069728289730847,\n      \"last-10-avg\": 0.0006131791645505776\n    },\n    \"learners/agent_12/default_optimizer_learning_rate\": {\n      \"max\": 5e-05,\n      \"min\": 5e-05,\n      \"avg\": 5e-05,\n      \"last\": 5e-05,\n      \"last-5-avg\": 5e-05,\n      \"last-10-avg\": 5e-05\n    },\n    \"learners/agent_12/curr_entropy_coeff\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"learners/agent_12/num_trainable_parameters\": {\n      \"max\": 781541,\n      \"min\": 781541,\n      \"avg\": 781541.0,\n      \"last\": 781541,\n      \"last-5-avg\": 781541.0,\n      \"last-10-avg\": 781541.0\n    },\n    \"learners/agent_12/policy_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243043b1bf43c94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430470dc2abe94869452942e\"\n      },\n      \"avg\": -0.08426194172352552,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304f090b0bd94869452942e\"\n      },\n      \"last-5-avg\": -0.06774302460253238,\n      \"last-10-avg\": -0.08426194172352552\n    },\n    \"learners/agent_12/weights_seq_no\": {\n      \"max\": 6.0,\n      \"min\": 1.0,\n      \"avg\": 3.5,\n      \"last\": 6.0,\n      \"last-5-avg\": 4.0,\n      \"last-10-avg\": 3.5\n    },\n    \"learners/agent_12/num_module_steps_trained_lifetime_throughput\": {\n      \"max\": 1594.7396572191146,\n      \"min\": 1591.865176465816,\n      \"avg\": NaN,\n      \"last\": 1591.865176465816,\n      \"last-5-avg\": NaN,\n      \"last-10-avg\": NaN\n    },\n    \"learners/agent_18/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"avg\": 1.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"learners/agent_18/vf_explained_var\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304d609723f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430499bc403f94869452942e\"\n      },\n      \"avg\": 0.8502048949400584,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304de69413f94869452942e\"\n      },\n      \"last-5-avg\": 0.8311533570289612,\n      \"last-10-avg\": 0.8502048949400584\n    },\n    \"learners/agent_18/num_module_steps_trained_lifetime\": {\n      \"max\": 241152,\n      \"min\": 40192,\n      \"avg\": 140672.0,\n      \"last\": 241152,\n      \"last-5-avg\": 160768.0,\n      \"last-10-avg\": 140672.0\n    },\n    \"learners/agent_18/curr_kl_coeff\": {\n      \"max\": 0.20000000298023224,\n      \"min\": 0.20000000298023224,\n      \"avg\": 0.20000000298023224,\n      \"last\": 0.20000000298023224,\n      \"last-5-avg\": 0.20000000298023224,\n      \"last-10-avg\": 0.20000000298023224\n    },\n    \"learners/agent_18/mean_kl_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430464be013c94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304104cf53b94869452942e\"\n      },\n      \"avg\": 0.007623754053687056,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430464be013c94869452942e\"\n      },\n      \"last-5-avg\": 0.007623820286244154,\n      \"last-10-avg\": 0.007623754053687056\n    },\n    \"learners/agent_18/vf_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304883e103b94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243046205813a94869452942e\"\n      },\n      \"avg\": 0.0014759882857712605,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040a680d3b94869452942e\"\n      },\n      \"last-5-avg\": 0.001541246031410992,\n      \"last-10-avg\": 0.0014759882857712607\n    },\n    \"learners/agent_18/vf_loss_unclipped\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304883e103b94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243046205813a94869452942e\"\n      },\n      \"avg\": 0.0014759882857712605,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040a680d3b94869452942e\"\n      },\n      \"last-5-avg\": 0.001541246031410992,\n      \"last-10-avg\": 0.0014759882857712607\n    },\n    \"learners/agent_18/default_optimizer_learning_rate\": {\n      \"max\": 5e-05,\n      \"min\": 5e-05,\n      \"avg\": 5e-05,\n      \"last\": 5e-05,\n      \"last-5-avg\": 5e-05,\n      \"last-10-avg\": 5e-05\n    },\n    \"learners/agent_18/curr_entropy_coeff\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"learners/agent_18/num_trainable_parameters\": {\n      \"max\": 321253,\n      \"min\": 321253,\n      \"avg\": 321253.0,\n      \"last\": 321253,\n      \"last-5-avg\": 321253.0,\n      \"last-10-avg\": 321253.0\n    },\n    \"learners/agent_18/policy_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304b72ee83b94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ca4b14be94869452942e\"\n      },\n      \"avg\": -0.042343516290808715,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304f50287bd94869452942e\"\n      },\n      \"last-5-avg\": -0.043986886460334065,\n      \"last-10-avg\": -0.042343516290808715\n    },\n    \"learners/agent_18/weights_seq_no\": {\n      \"max\": 6.0,\n      \"min\": 1.0,\n      \"avg\": 3.5,\n      \"last\": 6.0,\n      \"last-5-avg\": 4.0,\n      \"last-10-avg\": 3.5\n    },\n    \"learners/agent_18/total_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243049fbf1c3c94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304cc9811be94869452942e\"\n      },\n      \"avg\": -0.039342776891620204,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304b0b27ebd94869452942e\"\n      },\n      \"last-5-avg\": -0.04092087785247713,\n      \"last-10-avg\": -0.03934277689162021\n    },\n    \"learners/agent_18/module_train_batch_size_mean\": {\n      \"max\": 256.0,\n      \"min\": 256.0,\n      \"avg\": 256.0,\n      \"last\": 256.0,\n      \"last-5-avg\": 256.0,\n      \"last-10-avg\": 256.0\n    },\n    \"learners/agent_18/num_module_steps_trained\": {\n      \"max\": 40192,\n      \"min\": 40192,\n      \"avg\": 40192.0,\n      \"last\": 40192,\n      \"last-5-avg\": 40192.0,\n      \"last-10-avg\": 40192.0\n    },\n    \"learners/agent_18/entropy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243048794c44094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430472b3c34094869452942e\"\n      },\n      \"avg\": 6.129108667373657,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430472b3c34094869452942e\"\n      },\n      \"last-5-avg\": 6.126304244995117,\n      \"last-10-avg\": 6.129108667373657\n    },\n    \"learners/agent_18/num_module_steps_trained_lifetime_throughput\": {\n      \"max\": 1594.7397837097524,\n      \"min\": 1591.8652741005903,\n      \"avg\": NaN,\n      \"last\": 1591.8652741005903,\n      \"last-5-avg\": NaN,\n      \"last-10-avg\": NaN\n    },\n    \"learners/agent_7/num_module_steps_trained_lifetime\": {\n      \"max\": 241152,\n      \"min\": 40192,\n      \"avg\": 140672.0,\n      \"last\": 241152,\n      \"last-5-avg\": 160768.0,\n      \"last-10-avg\": 140672.0\n    },\n    \"learners/agent_7/curr_kl_coeff\": {\n      \"max\": 0.20000000298023224,\n      \"min\": 0.20000000298023224,\n      \"avg\": 0.20000000298023224,\n      \"last\": 0.20000000298023224,\n      \"last-5-avg\": 0.20000000298023224,\n      \"last-10-avg\": 0.20000000298023224\n    },\n    \"learners/agent_7/mean_kl_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243041bf5233c94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304c4e9043c94869452942e\"\n      },\n      \"avg\": 0.00921233557164669,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430496db203c94869452942e\"\n      },\n      \"last-5-avg\": 0.009053369052708149,\n      \"last-10-avg\": 0.00921233557164669\n    },\n    \"learners/agent_7/num_module_steps_trained\": {\n      \"max\": 40192,\n      \"min\": 40192,\n      \"avg\": 40192.0,\n      \"last\": 40192,\n      \"last-5-avg\": 40192.0,\n      \"last-10-avg\": 40192.0\n    },\n    \"learners/agent_7/vf_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304dbbb183b94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304158ce03994869452942e\"\n      },\n      \"avg\": 0.0009375877416459844,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243044f8f433a94869452942e\"\n      },\n      \"last-5-avg\": 0.0009201180946547538,\n      \"last-10-avg\": 0.0009375877416459844\n    },\n    \"learners/agent_7/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"avg\": 1.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"learners/agent_7/vf_loss_unclipped\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304dbbb183b94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304158ce03994869452942e\"\n      },\n      \"avg\": 0.0009375877416459844,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243044f8f433a94869452942e\"\n      },\n      \"last-5-avg\": 0.0009201180946547538,\n      \"last-10-avg\": 0.0009375877416459844\n    },\n    \"learners/agent_7/curr_entropy_coeff\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"learners/agent_7/num_trainable_parameters\": {\n      \"max\": 781541,\n      \"min\": 781541,\n      \"avg\": 781541.0,\n      \"last\": 781541,\n      \"last-5-avg\": 781541.0,\n      \"last-10-avg\": 781541.0\n    },\n    \"learners/agent_7/policy_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243048eab71bd94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040a7a38be94869452942e\"\n      },\n      \"avg\": -0.11336919665336609,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243043d29c1bd94869452942e\"\n      },\n      \"last-5-avg\": -0.10333754122257233,\n      \"last-10-avg\": -0.11336919665336609\n    },\n    \"learners/agent_7/default_optimizer_learning_rate\": {\n      \"max\": 5e-05,\n      \"min\": 5e-05,\n      \"avg\": 5e-05,\n      \"last\": 5e-05,\n      \"last-5-avg\": 5e-05,\n      \"last-10-avg\": 5e-05\n    },\n    \"learners/agent_7/module_train_batch_size_mean\": {\n      \"max\": 256.0,\n      \"min\": 256.0,\n      \"avg\": 256.0,\n      \"last\": 256.0,\n      \"last-5-avg\": 256.0,\n      \"last-10-avg\": 256.0\n    },\n    \"learners/agent_7/entropy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304e3abc44094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430415f2c34094869452942e\"\n      },\n      \"avg\": 6.135793844858805,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430415f2c34094869452942e\"\n      },\n      \"last-5-avg\": 6.133756160736084,\n      \"last-10-avg\": 6.135793844858806\n    },\n    \"learners/agent_7/weights_seq_no\": {\n      \"max\": 6.0,\n      \"min\": 1.0,\n      \"avg\": 3.5,\n      \"last\": 6.0,\n      \"last-5-avg\": 4.0,\n      \"last-10-avg\": 3.5\n    },\n    \"learners/agent_7/total_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243049ad568bd94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304c54934be94869452942e\"\n      },\n      \"avg\": -0.11058914288878441,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304a19cbbbd94869452942e\"\n      },\n      \"last-5-avg\": -0.10060674995183945,\n      \"last-10-avg\": -0.11058914288878441\n    },\n    \"learners/agent_7/vf_explained_var\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040d2e783f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430451e15f3f94869452942e\"\n      },\n      \"avg\": 0.9152265091737111,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430434b8683f94869452942e\"\n      },\n      \"last-5-avg\": 0.9181279540061951,\n      \"last-10-avg\": 0.9152265091737112\n    },\n    \"learners/agent_7/num_module_steps_trained_lifetime_throughput\": {\n      \"max\": 1594.7417255938317,\n      \"min\": 1591.8670843881143,\n      \"avg\": NaN,\n      \"last\": 1591.8670843881143,\n      \"last-5-avg\": NaN,\n      \"last-10-avg\": NaN\n    },\n    \"learners/agent_14/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"avg\": 1.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"learners/agent_14/curr_entropy_coeff\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"learners/agent_14/policy_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243041008a7bd94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304f89803be94869452942e\"\n      },\n      \"avg\": -0.10318822413682938,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430454c6c0bd94869452942e\"\n      },\n      \"last-5-avg\": -0.10610295534133911,\n      \"last-10-avg\": -0.10318822413682938\n    },\n    \"learners/agent_14/vf_loss_unclipped\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243047b71f53a94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243042efd913a94869452942e\"\n      },\n      \"avg\": 0.0013609939293625453,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304d6d1b33a94869452942e\"\n      },\n      \"last-5-avg\": 0.0012586759869009257,\n      \"last-10-avg\": 0.0013609939293625455\n    },\n    \"learners/agent_14/default_optimizer_learning_rate\": {\n      \"max\": 5e-05,\n      \"min\": 5e-05,\n      \"avg\": 5e-05,\n      \"last\": 5e-05,\n      \"last-5-avg\": 5e-05,\n      \"last-10-avg\": 5e-05\n    },\n    \"learners/agent_14/module_train_batch_size_mean\": {\n      \"max\": 256.0,\n      \"min\": 256.0,\n      \"avg\": 256.0,\n      \"last\": 256.0,\n      \"last-5-avg\": 256.0,\n      \"last-10-avg\": 256.0\n    },\n    \"learners/agent_14/num_trainable_parameters\": {\n      \"max\": 321253,\n      \"min\": 321253,\n      \"avg\": 321253.0,\n      \"last\": 321253,\n      \"last-5-avg\": 321253.0,\n      \"last-10-avg\": 321253.0\n    },\n    \"learners/agent_14/entropy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ad7ac44094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040090c34094869452942e\"\n      },\n      \"avg\": 6.125626722971598,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040090c34094869452942e\"\n      },\n      \"last-5-avg\": 6.122757053375244,\n      \"last-10-avg\": 6.125626722971599\n    },\n    \"learners/agent_14/weights_seq_no\": {\n      \"max\": 6.0,\n      \"min\": 1.0,\n      \"avg\": 3.5,\n      \"last\": 6.0,\n      \"last-5-avg\": 4.0,\n      \"last-10-avg\": 3.5\n    },\n    \"learners/agent_14/total_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ce2ba1bd94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304a5ae00be94869452942e\"\n      },\n      \"avg\": -0.10017131889859834,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304c34bbabd94869452942e\"\n      },\n      \"last-5-avg\": -0.10319980978965759,\n      \"last-10-avg\": -0.10017131889859836\n    },\n    \"learners/agent_14/vf_explained_var\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243042324643f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304b7694f3f94869452942e\"\n      },\n      \"avg\": 0.8512857854366302,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304dbc9603f94869452942e\"\n      },\n      \"last-5-avg\": 0.859501576423645,\n      \"last-10-avg\": 0.8512857854366302\n    },\n    \"learners/agent_14/num_module_steps_trained_lifetime\": {\n      \"max\": 241152,\n      \"min\": 40192,\n      \"avg\": 140672.0,\n      \"last\": 241152,\n      \"last-5-avg\": 160768.0,\n      \"last-10-avg\": 140672.0\n    },\n    \"learners/agent_14/curr_kl_coeff\": {\n      \"max\": 0.20000000298023224,\n      \"min\": 0.20000000298023224,\n      \"avg\": 0.20000000298023224,\n      \"last\": 0.20000000298023224,\n      \"last-5-avg\": 0.20000000298023224,\n      \"last-10-avg\": 0.20000000298023224\n    },\n    \"learners/agent_14/mean_kl_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430499c3123c94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304b132fb3b94869452942e\"\n      },\n      \"avg\": 0.008279536152258515,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430499c3123c94869452942e\"\n      },\n      \"last-5-avg\": 0.008222321700304746,\n      \"last-10-avg\": 0.008279536152258515\n    },\n    \"learners/agent_14/num_module_steps_trained\": {\n      \"max\": 40192,\n      \"min\": 40192,\n      \"avg\": 40192.0,\n      \"last\": 40192,\n      \"last-5-avg\": 40192.0,\n      \"last-10-avg\": 40192.0\n    },\n    \"learners/agent_14/vf_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243047b71f53a94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243042efd913a94869452942e\"\n      },\n      \"avg\": 0.0013609939293625453,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304d6d1b33a94869452942e\"\n      },\n      \"last-5-avg\": 0.0012586759869009257,\n      \"last-10-avg\": 0.0013609939293625455\n    },\n    \"learners/agent_14/num_module_steps_trained_lifetime_throughput\": {\n      \"max\": 1594.7301861022295,\n      \"min\": 1591.8574526959803,\n      \"avg\": NaN,\n      \"last\": 1591.8574526959803,\n      \"last-5-avg\": NaN,\n      \"last-10-avg\": NaN\n    },\n    \"learners/agent_0/num_trainable_parameters\": {\n      \"max\": 781541,\n      \"min\": 781541,\n      \"avg\": 781541.0,\n      \"last\": 781541,\n      \"last-5-avg\": 781541.0,\n      \"last-10-avg\": 781541.0\n    },\n    \"learners/agent_0/entropy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304f0a8c44094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304b6c3c34094869452942e\"\n      },\n      \"avg\": 6.1313683191935215,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304b6c3c34094869452942e\"\n      },\n      \"last-5-avg\": 6.128517532348633,\n      \"last-10-avg\": 6.131368319193522\n    },\n    \"learners/agent_0/weights_seq_no\": {\n      \"max\": 6.0,\n      \"min\": 1.0,\n      \"avg\": 3.5,\n      \"last\": 6.0,\n      \"last-5-avg\": 4.0,\n      \"last-10-avg\": 3.5\n    },\n    \"learners/agent_0/total_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304699c983c94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430432e054be94869452942e\"\n      },\n      \"avg\": -0.07210324813301364,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304699c983c94869452942e\"\n      },\n      \"last-5-avg\": -0.08349341712892056,\n      \"last-10-avg\": -0.07210324813301365\n    },\n    \"learners/agent_0/vf_explained_var\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243045561763f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243045aeb693f94869452942e\"\n      },\n      \"avg\": 0.9389480153719584,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243045aeb693f94869452942e\"\n      },\n      \"last-5-avg\": 0.9342530846595765,\n      \"last-10-avg\": 0.9389480153719584\n    },\n    \"learners/agent_0/num_module_steps_trained_lifetime\": {\n      \"max\": 241152,\n      \"min\": 40192,\n      \"avg\": 140672.0,\n      \"last\": 241152,\n      \"last-5-avg\": 160768.0,\n      \"last-10-avg\": 140672.0\n    },\n    \"learners/agent_0/curr_kl_coeff\": {\n      \"max\": 0.20000000298023224,\n      \"min\": 0.20000000298023224,\n      \"avg\": 0.20000000298023224,\n      \"last\": 0.20000000298023224,\n      \"last-5-avg\": 0.20000000298023224,\n      \"last-10-avg\": 0.20000000298023224\n    },\n    \"learners/agent_0/module_train_batch_size_mean\": {\n      \"max\": 256.0,\n      \"min\": 256.0,\n      \"avg\": 256.0,\n      \"last\": 256.0,\n      \"last-5-avg\": 256.0,\n      \"last-10-avg\": 256.0\n    },\n    \"learners/agent_0/mean_kl_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304b04f1c3c94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243044e2a093c94869452942e\"\n      },\n      \"avg\": 0.008920569904148579,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304046d0a3c94869452942e\"\n      },\n      \"last-5-avg\": 0.008796587213873863,\n      \"last-10-avg\": 0.008920569904148579\n    },\n    \"learners/agent_0/num_module_steps_trained\": {\n      \"max\": 40192,\n      \"min\": 40192,\n      \"avg\": 40192.0,\n      \"last\": 40192,\n      \"last-5-avg\": 40192.0,\n      \"last-10-avg\": 40192.0\n    },\n    \"learners/agent_0/vf_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304a255913a94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430440f6fa3994869452942e\"\n      },\n      \"avg\": 0.0006941981264390051,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430440f6fa3994869452942e\"\n      },\n      \"last-5-avg\": 0.0007136335130780936,\n      \"last-10-avg\": 0.0006941981264390051\n    },\n    \"learners/agent_0/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"avg\": 1.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"learners/agent_0/curr_entropy_coeff\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"learners/agent_0/policy_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ddd8863c94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ccb957be94869452942e\"\n      },\n      \"avg\": -0.07458156067878008,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ddd8863c94869452942e\"\n      },\n      \"last-5-avg\": -0.08596637062728404,\n      \"last-10-avg\": -0.07458156067878008\n    },\n    \"learners/agent_0/vf_loss_unclipped\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304a255913a94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430440f6fa3994869452942e\"\n      },\n      \"avg\": 0.0006941981264390051,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430440f6fa3994869452942e\"\n      },\n      \"last-5-avg\": 0.0007136335130780936,\n      \"last-10-avg\": 0.0006941981264390051\n    },\n    \"learners/agent_0/default_optimizer_learning_rate\": {\n      \"max\": 5e-05,\n      \"min\": 5e-05,\n      \"avg\": 5e-05,\n      \"last\": 5e-05,\n      \"last-5-avg\": 5e-05,\n      \"last-10-avg\": 5e-05\n    },\n    \"learners/agent_0/num_module_steps_trained_lifetime_throughput\": {\n      \"max\": 1594.7371783189953,\n      \"min\": 1591.8631284728958,\n      \"avg\": NaN,\n      \"last\": 1591.8631284728958,\n      \"last-5-avg\": NaN,\n      \"last-10-avg\": NaN\n    },\n    \"learners/agent_2/num_trainable_parameters\": {\n      \"max\": 781541,\n      \"min\": 781541,\n      \"avg\": 781541.0,\n      \"last\": 781541,\n      \"last-5-avg\": 781541.0,\n      \"last-10-avg\": 781541.0\n    },\n    \"learners/agent_2/policy_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243041aea37bd94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243041ec7fdbd94869452942e\"\n      },\n      \"avg\": -0.08598622679710388,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243041aea37bd94869452942e\"\n      },\n      \"last-5-avg\": -0.08798101097345352,\n      \"last-10-avg\": -0.08598622679710388\n    },\n    \"learners/agent_2/default_optimizer_learning_rate\": {\n      \"max\": 5e-05,\n      \"min\": 5e-05,\n      \"avg\": 5e-05,\n      \"last\": 5e-05,\n      \"last-5-avg\": 5e-05,\n      \"last-10-avg\": 5e-05\n    },\n    \"learners/agent_2/module_train_batch_size_mean\": {\n      \"max\": 256.0,\n      \"min\": 256.0,\n      \"avg\": 256.0,\n      \"last\": 256.0,\n      \"last-5-avg\": 256.0,\n      \"last-10-avg\": 256.0\n    },\n    \"learners/agent_2/entropy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ee93c44094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243049bf6c34094869452942e\"\n      },\n      \"avg\": 6.134047190348307,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243049bf6c34094869452942e\"\n      },\n      \"last-5-avg\": 6.132245063781738,\n      \"last-10-avg\": 6.134047190348308\n    },\n    \"learners/agent_2/weights_seq_no\": {\n      \"max\": 6.0,\n      \"min\": 1.0,\n      \"avg\": 3.5,\n      \"last\": 6.0,\n      \"last-5-avg\": 4.0,\n      \"last-10-avg\": 3.5\n    },\n    \"learners/agent_2/total_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430406252ebd94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243041cabf9bd94869452942e\"\n      },\n      \"avg\": -0.08355209603905678,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430406252ebd94869452942e\"\n      },\n      \"last-5-avg\": -0.0856939896941185,\n      \"last-10-avg\": -0.08355209603905678\n    },\n    \"learners/agent_2/vf_explained_var\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304a9c8743f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243049fba6c3f94869452942e\"\n      },\n      \"avg\": 0.9422280987103779,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243049fba6c3f94869452942e\"\n      },\n      \"last-5-avg\": 0.9425264954566955,\n      \"last-10-avg\": 0.942228098710378\n    },\n    \"learners/agent_2/num_module_steps_trained_lifetime\": {\n      \"max\": 241152,\n      \"min\": 40192,\n      \"avg\": 140672.0,\n      \"last\": 241152,\n      \"last-5-avg\": 160768.0,\n      \"last-10-avg\": 140672.0\n    },\n    \"learners/agent_2/curr_kl_coeff\": {\n      \"max\": 0.20000000298023224,\n      \"min\": 0.20000000298023224,\n      \"avg\": 0.20000000298023224,\n      \"last\": 0.20000000298023224,\n      \"last-5-avg\": 0.20000000298023224,\n      \"last-10-avg\": 0.20000000298023224\n    },\n    \"learners/agent_2/mean_kl_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304e0bf1e3c94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243041268033c94869452942e\"\n      },\n      \"avg\": 0.008871686489631733,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304bb67153c94869452942e\"\n      },\n      \"last-5-avg\": 0.008708163537085057,\n      \"last-10-avg\": 0.008871686489631733\n    },\n    \"learners/agent_2/num_module_steps_trained\": {\n      \"max\": 40192,\n      \"min\": 40192,\n      \"avg\": 40192.0,\n      \"last\": 40192,\n      \"last-5-avg\": 40192.0,\n      \"last-10-avg\": 40192.0\n    },\n    \"learners/agent_2/vf_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243045375a13a94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243042c00d33994869452942e\"\n      },\n      \"avg\": 0.000659789783336843,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304502c133a94869452942e\"\n      },\n      \"last-5-avg\": 0.0005453819292597472,\n      \"last-10-avg\": 0.000659789783336843\n    },\n    \"learners/agent_2/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"avg\": 1.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"learners/agent_2/vf_loss_unclipped\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243045375a13a94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243042c00d33994869452942e\"\n      },\n      \"avg\": 0.000659789783336843,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304502c133a94869452942e\"\n      },\n      \"last-5-avg\": 0.0005453819292597472,\n      \"last-10-avg\": 0.000659789783336843\n    },\n    \"learners/agent_2/curr_entropy_coeff\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"learners/agent_2/num_module_steps_trained_lifetime_throughput\": {\n      \"max\": 1594.733739024414,\n      \"min\": 1591.8603777466215,\n      \"avg\": NaN,\n      \"last\": 1591.8603777466215,\n      \"last-5-avg\": NaN,\n      \"last-10-avg\": NaN\n    },\n    \"learners/agent_4/num_module_steps_trained_lifetime\": {\n      \"max\": 241152,\n      \"min\": 40192,\n      \"avg\": 140672.0,\n      \"last\": 241152,\n      \"last-5-avg\": 160768.0,\n      \"last-10-avg\": 140672.0\n    },\n    \"learners/agent_4/curr_kl_coeff\": {\n      \"max\": 0.20000000298023224,\n      \"min\": 0.20000000298023224,\n      \"avg\": 0.20000000298023224,\n      \"last\": 0.20000000298023224,\n      \"last-5-avg\": 0.20000000298023224,\n      \"last-10-avg\": 0.20000000298023224\n    },\n    \"learners/agent_4/module_train_batch_size_mean\": {\n      \"max\": 256.0,\n      \"min\": 256.0,\n      \"avg\": 256.0,\n      \"last\": 256.0,\n      \"last-5-avg\": 256.0,\n      \"last-10-avg\": 256.0\n    },\n    \"learners/agent_4/mean_kl_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430430d11c3c94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304be10153c94869452942e\"\n      },\n      \"avg\": 0.009263602240631977,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304be10153c94869452942e\"\n      },\n      \"last-5-avg\": 0.00925731360912323,\n      \"last-10-avg\": 0.009263602240631977\n    },\n    \"learners/agent_4/num_module_steps_trained\": {\n      \"max\": 40192,\n      \"min\": 40192,\n      \"avg\": 40192.0,\n      \"last\": 40192,\n      \"last-5-avg\": 40192.0,\n      \"last-10-avg\": 40192.0\n    },\n    \"learners/agent_4/vf_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243046b6bb63a94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304a9c8b53994869452942e\"\n      },\n      \"avg\": 0.0007011073709387953,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243046b6bb63a94869452942e\"\n      },\n      \"last-5-avg\": 0.0006111668597441166,\n      \"last-10-avg\": 0.0007011073709387953\n    },\n    \"learners/agent_4/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"avg\": 1.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"learners/agent_4/vf_explained_var\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040248783f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304c641663f94869452942e\"\n      },\n      \"avg\": 0.9364412625630696,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304c641663f94869452942e\"\n      },\n      \"last-5-avg\": 0.9419018626213074,\n      \"last-10-avg\": 0.9364412625630697\n    },\n    \"learners/agent_4/policy_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243044ca6ff3c94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430491420fbe94869452942e\"\n      },\n      \"avg\": -0.06452729366719723,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243049815b4bd94869452942e\"\n      },\n      \"last-5-avg\": -0.0494522787630558,\n      \"last-10-avg\": -0.06452729366719723\n    },\n    \"learners/agent_4/vf_loss_unclipped\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243046b6bb63a94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304a9c8b53994869452942e\"\n      },\n      \"avg\": 0.0007011073709387953,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243046b6bb63a94869452942e\"\n      },\n      \"last-5-avg\": 0.0006111668597441166,\n      \"last-10-avg\": 0.0007011073709387953\n    },\n    \"learners/agent_4/default_optimizer_learning_rate\": {\n      \"max\": 5e-05,\n      \"min\": 5e-05,\n      \"avg\": 5e-05,\n      \"last\": 5e-05,\n      \"last-5-avg\": 5e-05,\n      \"last-10-avg\": 5e-05\n    },\n    \"learners/agent_4/curr_entropy_coeff\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"learners/agent_4/num_trainable_parameters\": {\n      \"max\": 781541,\n      \"min\": 781541,\n      \"avg\": 781541.0,\n      \"last\": 781541,\n      \"last-5-avg\": 781541.0,\n      \"last-10-avg\": 781541.0\n    },\n    \"learners/agent_4/entropy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243042898c44094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430466aac34094869452942e\"\n      },\n      \"avg\": 6.128872076670328,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430466aac34094869452942e\"\n      },\n      \"last-5-avg\": 6.125931739807129,\n      \"last-10-avg\": 6.128872076670329\n    },\n    \"learners/agent_4/weights_seq_no\": {\n      \"max\": 6.0,\n      \"min\": 1.0,\n      \"avg\": 3.5,\n      \"last\": 6.0,\n      \"last-5-avg\": 4.0,\n      \"last-10-avg\": 3.5\n    },\n    \"learners/agent_4/total_loss\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304da34093d94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243048f2d0cbe94869452942e\"\n      },\n      \"avg\": -0.061973461881279945,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304e481adbd94869452942e\"\n      },\n      \"last-5-avg\": -0.046989645808935165,\n      \"last-10-avg\": -0.061973461881279945\n    },\n    \"learners/agent_4/num_module_steps_trained_lifetime_throughput\": {\n      \"max\": 1594.7410463226238,\n      \"min\": 1591.8663201603033,\n      \"avg\": NaN,\n      \"last\": 1591.8663201603033,\n      \"last-5-avg\": NaN,\n      \"last-10-avg\": NaN\n    },\n    \"env_runners/timers/connectors/add_time_dim_to_batch_and_zero_pad\": {\n      \"max\": 4.583634048079451e-05,\n      \"min\": 4.583634048079451e-05,\n      \"avg\": 4.583634048079452e-05,\n      \"last\": 4.583634048079451e-05,\n      \"last-5-avg\": 4.583634048079451e-05,\n      \"last-10-avg\": 4.583634048079451e-05\n    },\n    \"env_runners/timers/connectors/numpy_to_tensor\": {\n      \"max\": 0.00018170633120462298,\n      \"min\": 0.00018170633120462298,\n      \"avg\": 0.00018170633120462298,\n      \"last\": 0.00018170633120462298,\n      \"last-5-avg\": 0.00018170633120462298,\n      \"last-10-avg\": 0.00018170633120462298\n    },\n    \"env_runners/timers/connectors/agent_to_module_mapping\": {\n      \"max\": 1.12936832010746e-05,\n      \"min\": 1.12936832010746e-05,\n      \"avg\": 1.12936832010746e-05,\n      \"last\": 1.12936832010746e-05,\n      \"last-5-avg\": 1.12936832010746e-05,\n      \"last-10-avg\": 1.12936832010746e-05\n    },\n    \"env_runners/timers/connectors/add_states_from_episodes_to_batch\": {\n      \"max\": 2.319701404000322e-05,\n      \"min\": 2.319701404000322e-05,\n      \"avg\": 2.3197014040003225e-05,\n      \"last\": 2.319701404000322e-05,\n      \"last-5-avg\": 2.319701404000322e-05,\n      \"last-10-avg\": 2.319701404000322e-05\n    },\n    \"env_runners/timers/connectors/batch_individual_items\": {\n      \"max\": 0.00011492499227946003,\n      \"min\": 0.00011492499227946003,\n      \"avg\": 0.00011492499227946003,\n      \"last\": 0.00011492499227946003,\n      \"last-5-avg\": 0.00011492499227946003,\n      \"last-10-avg\": 0.00011492499227946003\n    },\n    \"env_runners/timers/connectors/add_observations_from_episodes_to_batch\": {\n      \"max\": 8.231331594288349e-05,\n      \"min\": 8.231331594288349e-05,\n      \"avg\": 8.231331594288349e-05,\n      \"last\": 8.231331594288349e-05,\n      \"last-5-avg\": 8.231331594288349e-05,\n      \"last-10-avg\": 8.231331594288349e-05\n    },\n    \"learners/__all_modules__/learner_connector/connector_pipeline_timer\": {\n      \"max\": 2.0425242190249264,\n      \"min\": 2.0324515798615774,\n      \"avg\": 2.037374936541232,\n      \"last\": 2.0324515798615774,\n      \"last-5-avg\": 2.0363450800444935,\n      \"last-10-avg\": 2.0373749365412324\n    },\n    \"env_runners/module_to_env_connector/timers/connectors/module_to_agent_unmapping\": {\n      \"max\": 1.0597716527142319e-05,\n      \"min\": 9.437172356553722e-06,\n      \"avg\": 1.0021904835801303e-05,\n      \"last\": 1.002482209024303e-05,\n      \"last-5-avg\": 1.0095635693632473e-05,\n      \"last-10-avg\": 1.0021904835801305e-05\n    },\n    \"env_runners/module_to_env_connector/timers/connectors/remove_single_ts_time_rank_from_batch\": {\n      \"max\": 1.4989357216184152e-06,\n      \"min\": 1.2799136268905104e-06,\n      \"avg\": 1.3874236751705857e-06,\n      \"last\": 1.4093242275555993e-06,\n      \"last-5-avg\": 1.408925684826601e-06,\n      \"last-10-avg\": 1.387423675170586e-06\n    },\n    \"env_runners/module_to_env_connector/timers/connectors/un_batch_to_individual_items\": {\n      \"max\": 0.000198548853691445,\n      \"min\": 0.0001734705569840578,\n      \"avg\": 0.0001857274745203329,\n      \"last\": 0.00018842200496893522,\n      \"last-5-avg\": 0.0001881788580275879,\n      \"last-10-avg\": 0.00018572747452033286\n    },\n    \"env_runners/module_to_env_connector/timers/connectors/listify_data_for_vector_env\": {\n      \"max\": 3.456251798284847e-05,\n      \"min\": 3.0874151466101966e-05,\n      \"avg\": 3.262494930190236e-05,\n      \"last\": 3.258184208650917e-05,\n      \"last-5-avg\": 3.2958463845193814e-05,\n      \"last-10-avg\": 3.2624949301902364e-05\n    },\n    \"env_runners/module_to_env_connector/timers/connectors/normalize_and_clip_actions\": {\n      \"max\": 0.0001242106924245399,\n      \"min\": 0.00011095082046969937,\n      \"avg\": 0.00011721729858507576,\n      \"last\": 0.00011739232670045475,\n      \"last-5-avg\": 0.00011834504438980296,\n      \"last-10-avg\": 0.00011721729858507576\n    },\n    \"env_runners/module_to_env_connector/timers/connectors/tensor_to_numpy\": {\n      \"max\": 0.0002732888363963698,\n      \"min\": 0.00024547012419306856,\n      \"avg\": 0.0002588069527825756,\n      \"last\": 0.0002592721138600847,\n      \"last-5-avg\": 0.0002612546714961166,\n      \"last-10-avg\": 0.00025880695278257564\n    },\n    \"env_runners/module_to_env_connector/timers/connectors/get_actions\": {\n      \"max\": 0.0012604344474434793,\n      \"min\": 0.0011247153995975487,\n      \"avg\": 0.0011900400101165038,\n      \"last\": 0.0011927218339166637,\n      \"last-5-avg\": 0.0012009248062905488,\n      \"last-10-avg\": 0.0011900400101165038\n    },\n    \"env_runners/env_to_module_connector/timers/connectors/add_states_from_episodes_to_batch\": {\n      \"max\": 2.4607546631545286e-05,\n      \"min\": 2.19527234887981e-05,\n      \"avg\": 2.3321041707419923e-05,\n      \"last\": 2.3421726507297737e-05,\n      \"last-5-avg\": 2.3594705351144288e-05,\n      \"last-10-avg\": 2.3321041707419923e-05\n    },\n    \"env_runners/env_to_module_connector/timers/connectors/batch_individual_items\": {\n      \"max\": 0.00010610980089727868,\n      \"min\": 9.5352459940887e-05,\n      \"avg\": 0.00010052308913027753,\n      \"last\": 0.00010100546806178463,\n      \"last-5-avg\": 0.00010155721496815561,\n      \"last-10-avg\": 0.00010052308913027753\n    },\n    \"env_runners/env_to_module_connector/timers/connectors/add_observations_from_episodes_to_batch\": {\n      \"max\": 7.794992182833819e-05,\n      \"min\": 6.875407990054241e-05,\n      \"avg\": 7.314009059146947e-05,\n      \"last\": 7.444056700609058e-05,\n      \"last-5-avg\": 7.400620030792175e-05,\n      \"last-10-avg\": 7.314009059146947e-05\n    },\n    \"env_runners/env_to_module_connector/timers/connectors/add_time_dim_to_batch_and_zero_pad\": {\n      \"max\": 3.4009584298549654e-05,\n      \"min\": 2.9580275185679434e-05,\n      \"avg\": 3.154149597659644e-05,\n      \"last\": 3.18414682565594e-05,\n      \"last-5-avg\": 3.192615865207374e-05,\n      \"last-10-avg\": 3.154149597659644e-05\n    },\n    \"env_runners/env_to_module_connector/timers/connectors/numpy_to_tensor\": {\n      \"max\": 0.00016376367836644853,\n      \"min\": 0.00014526848834400555,\n      \"avg\": 0.00015354328624103274,\n      \"last\": 0.0001550664186335406,\n      \"last-5-avg\": 0.0001551982458204382,\n      \"last-10-avg\": 0.00015354328624103277\n    },\n    \"env_runners/env_to_module_connector/timers/connectors/agent_to_module_mapping\": {\n      \"max\": 1.1959504144307726e-05,\n      \"min\": 1.0552172116378384e-05,\n      \"avg\": 1.1167443672154083e-05,\n      \"last\": 1.121463009165686e-05,\n      \"last-5-avg\": 1.128392330455215e-05,\n      \"last-10-avg\": 1.1167443672154086e-05\n    },\n    \"learners/__all_modules__/learner_connector/timers/connectors/add_columns_from_episodes_to_train_batch\": {\n      \"max\": 0.6741728929919191,\n      \"min\": 0.6733561091402839,\n      \"avg\": 0.6737393103981051,\n      \"last\": 0.6733561091402839,\n      \"last-5-avg\": 0.6736525938793425,\n      \"last-10-avg\": 0.6737393103981053\n    },\n    \"learners/__all_modules__/learner_connector/timers/connectors/general_advantage_estimation\": {\n      \"max\": 0.10464156599482521,\n      \"min\": 0.10243857991950835,\n      \"avg\": 0.1035284864117044,\n      \"last\": 0.10243857991950835,\n      \"last-5-avg\": 0.10330587049508025,\n      \"last-10-avg\": 0.10352848641170441\n    },\n    \"learners/__all_modules__/learner_connector/timers/connectors/batch_individual_items\": {\n      \"max\": 1.0406374110025354,\n      \"min\": 1.0375086348200784,\n      \"avg\": 1.0390114448435093,\n      \"last\": 1.0375086348200784,\n      \"last-5-avg\": 1.0386862516117041,\n      \"last-10-avg\": 1.0390114448435093\n    },\n    \"learners/__all_modules__/learner_connector/timers/connectors/add_observations_from_episodes_to_batch\": {\n      \"max\": 0.0012919679866172373,\n      \"min\": 0.0012850938029720588,\n      \"avg\": 0.0012886553595436762,\n      \"last\": 0.0012850938029720588,\n      \"last-5-avg\": 0.0012879928341289642,\n      \"last-10-avg\": 0.0012886553595436764\n    },\n    \"learners/__all_modules__/learner_connector/timers/connectors/numpy_to_tensor\": {\n      \"max\": 0.033909254998434335,\n      \"min\": 0.033891120949624945,\n      \"avg\": 0.03389841713220199,\n      \"last\": 0.03390702297966587,\n      \"last-5-avg\": 0.033896249558955524,\n      \"last-10-avg\": 0.03389841713220199\n    },\n    \"learners/__all_modules__/learner_connector/timers/connectors/agent_to_module_mapping\": {\n      \"max\": 0.03808368964586407,\n      \"min\": 0.038058187737068254,\n      \"avg\": 0.03806869545377537,\n      \"last\": 0.038058187737068254,\n      \"last-5-avg\": 0.0380695345393426,\n      \"last-10-avg\": 0.03806869545377537\n    },\n    \"learners/__all_modules__/learner_connector/timers/connectors/add_states_from_episodes_to_batch\": {\n      \"max\": 3.2473457222629805e-05,\n      \"min\": 2.3617986956378445e-05,\n      \"avg\": 2.800617880008061e-05,\n      \"last\": 3.2298296915306924e-05,\n      \"last-5-avg\": 2.8879811623769277e-05,\n      \"last-10-avg\": 2.800617880008061e-05\n    },\n    \"learners/__all_modules__/learner_connector/timers/connectors/add_time_dim_to_batch_and_zero_pad\": {\n      \"max\": 5.873898044228554e-05,\n      \"min\": 5.862654204302816e-05,\n      \"avg\": 5.868134090598231e-05,\n      \"last\": 5.863167693485768e-05,\n      \"last-5-avg\": 5.866981299872166e-05,\n      \"last-10-avg\": 5.868134090598231e-05\n    },\n    \"learners/__all_modules__/learner_connector/timers/connectors/add_one_ts_to_episodes_and_truncate\": {\n      \"max\": 0.1492120120092295,\n      \"min\": 0.14530727109049152,\n      \"avg\": 0.147247336678282,\n      \"last\": 0.14530727109049152,\n      \"last-5-avg\": 0.1468544016120925,\n      \"last-10-avg\": 0.14724733667828202\n    },\n    \"timers/synch_env_connectors\": {\n      \"max\": 0.0017413428660231294,\n      \"min\": 0.0017319669714197516,\n      \"avg\": 0.0017357377064977997,\n      \"last\": 0.0017402988769079856,\n      \"last-5-avg\": 0.0017364918535134094,\n      \"last-10-avg\": 0.0017364918535134094\n    },\n    \"env_runners/time_between_sampling\": {\n      \"max\": 14.463528301334009,\n      \"min\": 14.444390896671555,\n      \"avg\": 14.455426650483332,\n      \"last\": 14.444390896671555,\n      \"last-5-avg\": 14.4538063203132,\n      \"last-10-avg\": 14.4538063203132\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"num_training_step_calls_per_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b014b014b014b01652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952e000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b014b014b014b014b01652e\"\n      }\n    },\n    \"num_env_steps_sampled_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b024b034b044b054b06652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952e000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b054b06652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740386f74cc000000474039294d9800000047403933e718000000474039bb77d800000047403987e7f0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740391c9c4c0000004740386f74cc000000474039294d9800000047403933e718000000474039bb77d800000047403987e7f0000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474048c6088c000000474052ad57ac000000474058fa517200000047405f692f68000000474062e594b2000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740391c9c4c000000474048c6088c000000474052ad57ac000000474058fa517200000047405f692f68000000474062e594b2000000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474048c6088c000000474052ad57ac000000474058fa517200000047405f692f68000000474062e594b2000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740391c9c4c000000474048c6088c000000474052ad57ac000000474058fa517200000047405f692f68000000474062e594b2000000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b024b034b044b054b06652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952e000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b054b06652e\"\n      }\n    },\n    \"timers/training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403917c0c8d2f66647403917e51da8490e4740391824923ff7af47403919bec6371b9b4740391ad0b2bbd821652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474039197be0ee400047403917c0c8d2f66647403917e51da8490e4740391824923ff7af47403919bec6371b9b4740391ad0b2bbd821652e\"\n      }\n    },\n    \"timers/restore_env_runners\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473ef2df687ae147ae473ef2d29f13404ea5473ef2bdb2907faa04473ef2ad94c75faae0473ef29d232bc7abba652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473ef2eba400000000473ef2df687ae147ae473ef2d29f13404ea5473ef2bdb2907faa04473ef2ad94c75faae0473ef29d232bc7abba652e\"\n      }\n    },\n    \"timers/training_step\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403917b1ca8db51e47403917d5f9a847c9474039181550b1ac3047403919af6218c2c94740391ac12c2d3bb8652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474039196d0635000047403917b1ca8db51e47403917d5f9a847c9474039181550b1ac3047403919af6218c2c94740391ac12c2d3bb8652e\"\n      }\n    },\n    \"timers/env_runner_sampling_timer\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474025b7bd7fb1a8f5474025b9846a4f5a78474025bc864586b32a474025c1988369e203474025c50c0c64f583652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474025b85df88c8000474025b7bd7fb1a8f5474025b9846a4f5a78474025bc864586b32a474025c1988369e203474025c50c0c64f583652e\"\n      }\n    },\n    \"timers/learner_update_timer\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847402c654db642beb847402c63d7e51d952147402c615bf677b63347402c5f83aa3e879447402c5e3bf1373595652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847402c681b1450000047402c654db642beb847402c63d7e51d952147402c615bf677b63347402c5f83aa3e879447402c5e3bf1373595652e\"\n      }\n    },\n    \"timers/synch_weights\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fa1126552c7ae14473fa1096d3ada29c7473fa101c3e1ffa95c473fa0fafa52238144473fa0f24b6513ca36652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fa11b64c6800000473fa1126552c7ae14473fa1096d3ada29c7473fa101c3e1ffa95c473fa0fafa52238144473fa0f24b6513ca36652e\"\n      }\n    },\n    \"env_runners/connector_pipeline_timer\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000001514463f94869452946807680d4308000000001514463f94869452946807680d4308000000001514463f94869452946807680d4308000000001514463f94869452946807680d4308000000001514463f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595e9000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000001514463f94869452946807680d4308000000001514463f94869452946807680d4308000000001514463f94869452946807680d4308000000001514463f94869452946807680d4308000000001514463f94869452946807680d4308000000001514463f9486945294652e\"\n      }\n    },\n    \"env_runners/episode_len_min\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284df4014df4014df4014df4014df401652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284df4014df4014df4014df4014df4014df401652e\"\n      }\n    },\n    \"env_runners/weights_seq_no\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473ff0000000000000474000000000000000474008000000000000474010000000000000474014000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000473ff0000000000000474000000000000000474008000000000000474010000000000000474014000000000000652e\"\n      }\n    },\n    \"env_runners/env_to_module_sum_episodes_length_in\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080cb7ceb1ba07644094869452946807680d4308d71df31dc9df784094869452946807680d43082999f65199756f4094869452946807680d4308779289546c08644094869452946807680d43088b0c73dbb9ac78409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595e9000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a15ee6e47d756f4094869452946807680d43080cb7ceb1ba07644094869452946807680d4308d71df31dc9df784094869452946807680d43082999f65199756f4094869452946807680d4308779289546c08644094869452946807680d43088b0c73dbb9ac78409486945294652e\"\n      }\n    },\n    \"env_runners/env_to_module_sum_episodes_length_out\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080cb7ceb1ba07644094869452946807680d4308d71df31dc9df784094869452946807680d43082999f65199756f4094869452946807680d4308779289546c08644094869452946807680d43088b0c73dbb9ac78409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595e9000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a15ee6e47d756f4094869452946807680d43080cb7ceb1ba07644094869452946807680d4308d71df31dc9df784094869452946807680d43082999f65199756f4094869452946807680d4308779289546c08644094869452946807680d43088b0c73dbb9ac78409486945294652e\"\n      }\n    },\n    \"env_runners/episode_duration_sec_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847400f55148f50888947400fad6cb313a2e7474010059d06c9d55647401058eb5dea3233474010a1ce9aa7da5a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847400fa36c8ccf000047400f55148f50888947400fad6cb313a2e7474010059d06c9d55647401058eb5dea3233474010a1ce9aa7da5a652e\"\n      }\n    },\n    \"env_runners/episode_len_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f400000000000652e\"\n      }\n    },\n    \"env_runners/env_step_timer\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308b066688cbd2c653f94869452946807680d4308db2db206c477663f94869452946807680d430821acd1dd116e673f94869452946807680d4308d90ec377bd86673f94869452946807680d430898771512a9b9663f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595e9000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430873a4daf998f9643f94869452946807680d4308b066688cbd2c653f94869452946807680d4308db2db206c477663f94869452946807680d430821acd1dd116e673f94869452946807680d4308d90ec377bd86673f94869452946807680d430898771512a9b9663f9486945294652e\"\n      }\n    },\n    \"env_runners/sample\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430846411d1d8860254094869452946807680d4308294971ef5e62254094869452946807680d430860946e12c665254094869452946807680d43080d8f29b4396b254094869452946807680d430861e337a1f56e25409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595e9000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430854d538250661254094869452946807680d430846411d1d8860254094869452946807680d4308294971ef5e62254094869452946807680d430860946e12c665254094869452946807680d43080d8f29b4396b254094869452946807680d430861e337a1f56e25409486945294652e\"\n      }\n    },\n    \"env_runners/episode_return_min\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847c0537a3d70a3d72247c0537a3d70a3d72247c0537a3d70a3d72247c0537a3d70a3d72247c0537a3d70a3d722652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847c05193333333334847c0537a3d70a3d72247c0537a3d70a3d72247c0537a3d70a3d72247c0537a3d70a3d72247c0537a3d70a3d722652e\"\n      }\n    },\n    \"env_runners/env_reset_timer\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a9aaaa7226ed713f94869452946807680d4308a9aaaa7226ed713f94869452946807680d4308a9aaaa7226ed713f94869452946807680d4308a9aaaa7226ed713f94869452946807680d4308a9aaaa7226ed713f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595e9000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a9aaaa7226ed713f94869452946807680d4308a9aaaa7226ed713f94869452946807680d4308a9aaaa7226ed713f94869452946807680d4308a9aaaa7226ed713f94869452946807680d4308a9aaaa7226ed713f94869452946807680d4308a9aaaa7226ed713f9486945294652e\"\n      }\n    },\n    \"env_runners/episode_len_max\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284df4014df4014df4014df4014df401652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284df4014df4014df4014df4014df4014df401652e\"\n      }\n    },\n    \"env_runners/episode_return_max\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847c0490147ae147afe47c045accccccccce447c045accccccccce447c045accccccccce447c045accccccccce4652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847c04ac3d70a3d70c347c0490147ae147afe47c045accccccccce447c045accccccccce447c045accccccccce447c045accccccccce4652e\"\n      }\n    },\n    \"env_runners/num_episodes_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847402e00000000000047403600000000000047403e000000000000474043800000000000474047000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847401800000000000047402e00000000000047403600000000000047403e000000000000474043800000000000474047000000000000652e\"\n      }\n    },\n    \"env_runners/rlmodule_inference_timer\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243087fdd453b6209603f94869452946807680d4308d5d8428d8534603f94869452946807680d43087fcbdb374ad9603f94869452946807680d4308d11e00e9f06e603f94869452946807680d4308e03bd9ea4b5e603f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595e9000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f0ae025a7cb65f3f94869452946807680d43087fdd453b6209603f94869452946807680d4308d5d8428d8534603f94869452946807680d43087fcbdb374ad9603f94869452946807680d4308d11e00e9f06e603f94869452946807680d4308e03bd9ea4b5e603f9486945294652e\"\n      }\n    },\n    \"env_runners/num_env_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      }\n    },\n    \"env_runners/episode_return_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847c04e794237fa89ff47c04dc9315693158447c04d9a9fbe76c8d047c04d15df7912ac5c47c04cb92929292943652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847c04e917e4b17e4d447c04e794237fa89ff47c04dc9315693158447c04d9a9fbe76c8d047c04d15df7912ac5c47c04cb92929292943652e\"\n      }\n    },\n    \"env_runners/num_episodes\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847402200000000000047401c00000000000047402000000000000047402200000000000047401c000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847401800000000000047402200000000000047401c00000000000047402000000000000047402200000000000047401c000000000000652e\"\n      }\n    },\n    \"env_runners/num_env_steps_sampled_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      }\n    },\n    \"env_runners/num_env_steps_sampled_lifetime_throughput\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474063f9b4d83838e5474063fa92543272fb474063f681fded6c7a474063f0840cfe3277474063eca46e8bc0f6652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428477ff8000000000000474063f9b4d83838e5474063fa92543272fb474063f681fded6c7a474063f0840cfe3277474063eca46e8bc0f6652e\"\n      }\n    },\n    \"fault_tolerance/num_healthy_workers\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b034b034b034b034b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952e000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b034b034b034b034b034b03652e\"\n      }\n    },\n    \"fault_tolerance/num_remote_worker_restarts\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952e000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b00652e\"\n      }\n    },\n    \"env_runner_group/actor_manager_num_outstanding_async_reqs\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952e000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b00652e\"\n      }\n    },\n    \"perf/cpu_util_percent\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a8a8a8a8a8a81d4094869452946807680d43083ba8833aa8831e4094869452946807680d4308874da521e73e1f4094869452946807680d430896374630d1df1f4094869452946807680d430804625369c8b91f409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595e9000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308fd9dac9637461c4094869452946807680d4308a8a8a8a8a8a81d4094869452946807680d43083ba8833aa8831e4094869452946807680d4308874da521e73e1f4094869452946807680d430896374630d1df1f4094869452946807680d430804625369c8b91f409486945294652e\"\n      }\n    },\n    \"perf/ram_util_percent\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a99999999d9394094869452946807680d4308a521e73ebb80394094869452946807680d4308bb80d8541a72394094869452946807680d4308ba1e85eb5138394094869452946807680d4308853aa8833a2839409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595e9000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308843aa8833a28384094869452946807680d43089a99999999d9394094869452946807680d4308a521e73ebb80394094869452946807680d4308bb80d8541a72394094869452946807680d4308ba1e85eb5138394094869452946807680d4308853aa8833a2839409486945294652e\"\n      }\n    },\n    \"perf/gpu_util_percent0\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430817e3af7c4916d33f94869452946807680d43083b6572aba27cd23f94869452946807680d4308e513346aff85d23f94869452946807680d4308913cd30a5181d23f94869452946807680d43083af7d905c4a6d23f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595e9000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083c592d6f8c60d23f94869452946807680d430817e3af7c4916d33f94869452946807680d43083b6572aba27cd23f94869452946807680d4308e513346aff85d23f94869452946807680d4308913cd30a5181d23f94869452946807680d43083af7d905c4a6d23f9486945294652e\"\n      }\n    },\n    \"perf/vram_util_percent0\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430839c838bde0fcbd3f94869452946807680d430868d7ccb28acdbe3f94869452946807680d43083047cac5cdcbbe3f94869452946807680d430837d475f0a0dbbe3f94869452946807680d430852783d00b0c7be3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595e9000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f47937d3a9e9b73f94869452946807680d430839c838bde0fcbd3f94869452946807680d430868d7ccb28acdbe3f94869452946807680d43083047cac5cdcbbe3f94869452946807680d430837d475f0a0dbbe3f94869452946807680d430852783d00b0c7be3f9486945294652e\"\n      }\n    },\n    \"env_runners/num_module_steps_sampled_lifetime/agent_15\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      }\n    },\n    \"env_runners/num_module_steps_sampled_lifetime/agent_20\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      }\n    },\n    \"env_runners/num_module_steps_sampled_lifetime/agent_2\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      }\n    },\n    \"env_runners/num_module_steps_sampled_lifetime/agent_10\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      }\n    },\n    \"env_runners/num_module_steps_sampled_lifetime/agent_19\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      }\n    },\n    \"env_runners/num_module_steps_sampled_lifetime/agent_13\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      }\n    },\n    \"env_runners/num_module_steps_sampled_lifetime/agent_16\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      }\n    },\n    \"env_runners/num_module_steps_sampled_lifetime/agent_1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      }\n    },\n    \"env_runners/num_module_steps_sampled_lifetime/agent_4\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      }\n    },\n    \"env_runners/num_module_steps_sampled_lifetime/agent_5\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      }\n    },\n    \"env_runners/num_module_steps_sampled_lifetime/agent_14\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      }\n    },\n    \"env_runners/num_module_steps_sampled_lifetime/agent_6\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      }\n    },\n    \"env_runners/num_module_steps_sampled_lifetime/agent_3\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      }\n    },\n    \"env_runners/num_module_steps_sampled_lifetime/agent_7\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      }\n    },\n    \"env_runners/num_module_steps_sampled_lifetime/agent_17\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      }\n    },\n    \"env_runners/num_module_steps_sampled_lifetime/agent_8\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      }\n    },\n    \"env_runners/num_module_steps_sampled_lifetime/agent_0\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      }\n    },\n    \"env_runners/num_module_steps_sampled_lifetime/agent_11\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      }\n    },\n    \"env_runners/num_module_steps_sampled_lifetime/agent_12\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      }\n    },\n    \"env_runners/num_module_steps_sampled_lifetime/agent_9\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      }\n    },\n    \"env_runners/num_module_steps_sampled_lifetime/agent_18\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      }\n    },\n    \"env_runners/num_agent_steps_sampled_lifetime/agent_8\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      }\n    },\n    \"env_runners/num_agent_steps_sampled_lifetime/agent_0\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      }\n    },\n    \"env_runners/num_agent_steps_sampled_lifetime/agent_11\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      }\n    },\n    \"env_runners/num_agent_steps_sampled_lifetime/agent_20\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      }\n    },\n    \"env_runners/num_agent_steps_sampled_lifetime/agent_12\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      }\n    },\n    \"env_runners/num_agent_steps_sampled_lifetime/agent_9\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      }\n    },\n    \"env_runners/num_agent_steps_sampled_lifetime/agent_15\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      }\n    },\n    \"env_runners/num_agent_steps_sampled_lifetime/agent_16\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      }\n    },\n    \"env_runners/num_agent_steps_sampled_lifetime/agent_2\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      }\n    },\n    \"env_runners/num_agent_steps_sampled_lifetime/agent_1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      }\n    },\n    \"env_runners/num_agent_steps_sampled_lifetime/agent_10\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      }\n    },\n    \"env_runners/num_agent_steps_sampled_lifetime/agent_19\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      }\n    },\n    \"env_runners/num_agent_steps_sampled_lifetime/agent_13\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      }\n    },\n    \"env_runners/num_agent_steps_sampled_lifetime/agent_5\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      }\n    },\n    \"env_runners/num_agent_steps_sampled_lifetime/agent_14\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      }\n    },\n    \"env_runners/num_agent_steps_sampled_lifetime/agent_3\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      }\n    },\n    \"env_runners/num_agent_steps_sampled_lifetime/agent_4\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      }\n    },\n    \"env_runners/num_agent_steps_sampled_lifetime/agent_6\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      }\n    },\n    \"env_runners/num_agent_steps_sampled_lifetime/agent_7\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      }\n    },\n    \"env_runners/num_agent_steps_sampled_lifetime/agent_18\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      }\n    },\n    \"env_runners/num_agent_steps_sampled_lifetime/agent_17\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740bf4000000000004740c77000000000004740cf4000000000004740d38800000000004740d7700000000000652e\"\n      }\n    },\n    \"env_runners/num_agent_steps_sampled/agent_3\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      }\n    },\n    \"env_runners/num_agent_steps_sampled/agent_4\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      }\n    },\n    \"env_runners/num_agent_steps_sampled/agent_6\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      }\n    },\n    \"env_runners/num_agent_steps_sampled/agent_7\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      }\n    },\n    \"env_runners/num_agent_steps_sampled/agent_18\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      }\n    },\n    \"env_runners/num_agent_steps_sampled/agent_17\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      }\n    },\n    \"env_runners/num_agent_steps_sampled/agent_8\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      }\n    },\n    \"env_runners/num_agent_steps_sampled/agent_0\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      }\n    },\n    \"env_runners/num_agent_steps_sampled/agent_11\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      }\n    },\n    \"env_runners/num_agent_steps_sampled/agent_20\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      }\n    },\n    \"env_runners/num_agent_steps_sampled/agent_12\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      }\n    },\n    \"env_runners/num_agent_steps_sampled/agent_9\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      }\n    },\n    \"env_runners/num_agent_steps_sampled/agent_15\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      }\n    },\n    \"env_runners/num_agent_steps_sampled/agent_16\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      }\n    },\n    \"env_runners/num_agent_steps_sampled/agent_2\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      }\n    },\n    \"env_runners/num_agent_steps_sampled/agent_1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      }\n    },\n    \"env_runners/num_agent_steps_sampled/agent_10\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      }\n    },\n    \"env_runners/num_agent_steps_sampled/agent_19\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      }\n    },\n    \"env_runners/num_agent_steps_sampled/agent_13\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      }\n    },\n    \"env_runners/num_agent_steps_sampled/agent_5\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      }\n    },\n    \"env_runners/num_agent_steps_sampled/agent_14\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      }\n    },\n    \"env_runners/module_episode_returns_mean/agent_6\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847c0018ead65b7a33647bffc9138c9138ca347bffa0f04c756b2ec47bff6f4f4f4f4f50247bff46ed53ba2087b652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847c003d0369d0369e547c0018ead65b7a33647bffc9138c9138ca347bffa0f04c756b2ec47bff6f4f4f4f4f50247bff46ed53ba2087b652e\"\n      }\n    },\n    \"env_runners/module_episode_returns_mean/agent_7\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847c00644444444445947c0039403b9403ba747c002f92c5f92c60c47c0007e4b17e4b18d47c001104376a9dd22652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847c00706d3a06d3a2447c00644444444445947c0039403b9403ba747c002f92c5f92c60c47c0007e4b17e4b18d47c001104376a9dd22652e\"\n      }\n    },\n    \"env_runners/module_episode_returns_mean/agent_18\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847c0120da740da741d47c0121999999999a947c0121374bc6a7f0c47c011dc760fa942eb47c011fc7c7c7c7c8d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847c01250369d0369e747c0120da740da741d47c0121999999999a947c0121374bc6a7f0c47c011dc760fa942eb47c011fc7c7c7c7c8d652e\"\n      }\n    },\n    \"env_runners/module_episode_returns_mean/agent_17\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847c011dfea27983c2247c011cea96cea96df47c011c2e6bdc8058547c011a8282828283647c011c996632ffcd8652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847c011f5c28f5c290b47c011dfea27983c2247c011cea96cea96df47c011c2e6bdc8058547c011a8282828283647c011c996632ffcd8652e\"\n      }\n    },\n    \"env_runners/module_episode_returns_mean/agent_8\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847c000aaaaaaaaaab747c00170a3d70a3d7f47c0022bb0cf87d9d547c0031f5285b8ec3047bffff4c18e5b280f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847bfe000000000000347c000aaaaaaaaaab747c00170a3d70a3d7f47c0022bb0cf87d9d547c0031f5285b8ec3047bffff4c18e5b280f652e\"\n      }\n    },\n    \"env_runners/module_episode_returns_mean/agent_0\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847c002d242e6bdc81747bfffa10c1a10c1bc47c001fb38a94d243e47c000821bb54ee89347bffe134679ace032652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847c002851eb851eb9547c002d242e6bdc81747bfffa10c1a10c1bc47c001fb38a94d243e47c000821bb54ee89347bffe134679ace032652e\"\n      }\n    },\n    \"env_runners/module_episode_returns_mean/agent_20\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847c012353f7ced917947c0123de7cbde7ccd47c012815d867c3ee347c01224be57f18b3347c0124b986531fedc652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847c0133bbbbbbbbbd547c012353f7ced917947c0123de7cbde7ccd47c012815d867c3ee347c01224be57f18b3347c0124b986531fedc652e\"\n      }\n    },\n    \"env_runners/module_episode_returns_mean/agent_12\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847bffb6f46508dfeba47bffc0595e0595e1a47bffbd5acb6f4652247bffb2ac45df7914147bffafe9831cb6517652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847bff3c28f5c28f5d547bffb6f46508dfeba47bffc0595e0595e1a47bffbd5acb6f4652247bffb2ac45df7914147bffafe9831cb6517652e\"\n      }\n    },\n    \"env_runners/module_episode_returns_mean/agent_19\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847c012bdc805761a0347c01263244e3244f647c0124f87d9c54a7c47c01200336699cd0f47c011b51b81e84ec4652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847c01286d3a06d3a1d47c012bdc805761a0347c01263244e3244f647c0124f87d9c54a7c47c01200336699cd0f47c011b51b81e84ec4652e\"\n      }\n    },\n    \"env_runners/module_episode_returns_mean/agent_11\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847c0001735ee402bbf47bfff350fd350fd4f47c0004f3078263ac547bff8cccccccccce147bffab24be57f18c9652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847c006cccccccccceb47c0001735ee402bbf47bfff350fd350fd4f47c0004f3078263ac547bff8cccccccccce147bffab24be57f18c9652e\"\n      }\n    },\n    \"env_runners/module_episode_returns_mean/agent_9\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847c00308dfea27985047c0018c9138c9139c47c0011529a485cd8b47c002ce349b0167df47c000f8f8f8f8f908652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847c006f258bf258c1047c00308dfea27985047c0018c9138c9139c47c0011529a485cd8b47c002ce349b0167df47c000f8f8f8f8f908652e\"\n      }\n    },\n    \"env_runners/module_episode_returns_mean/agent_15\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847c012d867c3ece2b647c01206843068431647c011ced916872b1347c011ab91f85ec53a47c0113b54ee8821ca652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847c01323d70a3d70bd47c012d867c3ece2b647c01206843068431647c011ced916872b1347c011ab91f85ec53a47c0113b54ee8821ca652e\"\n      }\n    },\n    \"env_runners/module_episode_returns_mean/agent_16\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847c012a06d3a06d3b147c01283421834219347c01277777777778947c0122ac45df7913b47c011f009a33cd682652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847c012f0a3d70a3d8947c012a06d3a06d3b147c01283421834219347c01277777777778947c0122ac45df7913b47c011f009a33cd682652e\"\n      }\n    },\n    \"env_runners/module_episode_returns_mean/agent_2\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847c001258bf258bf3347bfff69315693158047bffcb020c49ba5f747bff767009a33cd7447bff61c82e94fb62b652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847c00600000000001c47c001258bf258bf3347bfff69315693158047bffcb020c49ba5f747bff767009a33cd7447bff61c82e94fb62b652e\"\n      }\n    },\n    \"env_runners/module_episode_returns_mean/agent_1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847c0092b020c49ba7647c006ca01dca01dde47c00483c131d5acc747c00114141414142247bff96bd2389f0580652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847c004c5f92c5f92de47c0092b020c49ba7647c006ca01dca01dde47c00483c131d5acc747c00114141414142247bff96bd2389f0580652e\"\n      }\n    },\n    \"env_runners/module_episode_returns_mean/agent_10\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847c009e60f04c756ce47c007d9d52d9d52f047c0051bfd44f3079547c00276430fdca98647c000124578abdf20652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847c00b6d3a06d3a09147c009e60f04c756ce47c007d9d52d9d52f047c0051bfd44f3079547c00276430fdca98647c000124578abdf20652e\"\n      }\n    },\n    \"env_runners/module_episode_returns_mean/agent_4\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847bfefc3ece2a5349947bff421834218342c47bff36872b020c4a647bff5a6da0d4073b547bff96ea1d5083b7c652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847bff733333333334147bfefc3ece2a5349947bff421834218342c47bff36872b020c4a647bff5a6da0d4073b547bff96ea1d5083b7c652e\"\n      }\n    },\n    \"env_runners/module_episode_returns_mean/agent_13\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847bfee19f0fb38a95c47bff3498ab498ab5947bff54bc6a7ef9dc447c0008e27c15af49c47c000f2f2f2f2f300652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847bfe000000000000347bfee19f0fb38a95c47bff3498ab498ab5947bff54bc6a7ef9dc447c0008e27c15af49c47c000f2f2f2f2f300652e\"\n      }\n    },\n    \"env_runners/module_episode_returns_mean/agent_5\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847bff2de8ca11bfd5147bff4ec736ec736f747bff74e81b4e81b5f47bffe3ea50b71d85147c003632ffcc99673652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847bff451eb851eb86547bff2de8ca11bfd5147bff4ec736ec736f747bff74e81b4e81b5f47bffe3ea50b71d85147c003632ffcc99673652e\"\n      }\n    },\n    \"env_runners/module_episode_returns_mean/agent_14\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847c012ef9db22d0e6947c012947ae147ae2747c012604189374bda47c0120c5925f2bf9b47c011bababababacb652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847c012e9d0369d038347c012ef9db22d0e6947c012947ae147ae2747c012604189374bda47c0120c5925f2bf9b47c011bababababacb652e\"\n      }\n    },\n    \"env_runners/module_episode_returns_mean/agent_3\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847bff77a32846ff52f47bffcf02caf02cb0a47bfff3cc1e098eaf647c0002288ef55bc3047c00337d16b049e47652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847bff42fc962fc964447bff77a32846ff52f47bffcf02caf02cb0a47bfff3cc1e098eaf647c0002288ef55bc3047c00337d16b049e47652e\"\n      }\n    },\n    \"env_runners/agent_steps/agent_19\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f400000000000652e\"\n      }\n    },\n    \"env_runners/agent_steps/agent_13\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f400000000000652e\"\n      }\n    },\n    \"env_runners/agent_steps/agent_5\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f400000000000652e\"\n      }\n    },\n    \"env_runners/agent_steps/agent_14\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f400000000000652e\"\n      }\n    },\n    \"env_runners/agent_steps/agent_3\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f400000000000652e\"\n      }\n    },\n    \"env_runners/agent_steps/agent_4\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f400000000000652e\"\n      }\n    },\n    \"env_runners/agent_steps/agent_6\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f400000000000652e\"\n      }\n    },\n    \"env_runners/agent_steps/agent_18\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f400000000000652e\"\n      }\n    },\n    \"env_runners/agent_steps/agent_7\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f400000000000652e\"\n      }\n    },\n    \"env_runners/agent_steps/agent_17\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f400000000000652e\"\n      }\n    },\n    \"env_runners/agent_steps/agent_8\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f400000000000652e\"\n      }\n    },\n    \"env_runners/agent_steps/agent_0\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f400000000000652e\"\n      }\n    },\n    \"env_runners/agent_steps/agent_11\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f400000000000652e\"\n      }\n    },\n    \"env_runners/agent_steps/agent_20\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f400000000000652e\"\n      }\n    },\n    \"env_runners/agent_steps/agent_12\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f400000000000652e\"\n      }\n    },\n    \"env_runners/agent_steps/agent_9\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f400000000000652e\"\n      }\n    },\n    \"env_runners/agent_steps/agent_15\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f400000000000652e\"\n      }\n    },\n    \"env_runners/agent_steps/agent_16\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f400000000000652e\"\n      }\n    },\n    \"env_runners/agent_steps/agent_2\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f400000000000652e\"\n      }\n    },\n    \"env_runners/agent_steps/agent_1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f400000000000652e\"\n      }\n    },\n    \"env_runners/agent_steps/agent_10\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f40000000000047407f400000000000652e\"\n      }\n    },\n    \"env_runners/module_to_env_connector/connector_pipeline_timer\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308509a06d551ea5c3f94869452946807680d4308a024f364f86c5e3f94869452946807680d430838244a519834603f94869452946807680d430810b9073d9ef55f3f94869452946807680d4308e015293bcbaf5e3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595e9000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243088c2cb8d92b185d3f94869452946807680d4308509a06d551ea5c3f94869452946807680d4308a024f364f86c5e3f94869452946807680d430838244a519834603f94869452946807680d430810b9073d9ef55f3f94869452946807680d4308e015293bcbaf5e3f9486945294652e\"\n      }\n    },\n    \"env_runners/num_module_steps_sampled/agent_5\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      }\n    },\n    \"env_runners/num_module_steps_sampled/agent_14\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      }\n    },\n    \"env_runners/num_module_steps_sampled/agent_6\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      }\n    },\n    \"env_runners/num_module_steps_sampled/agent_3\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      }\n    },\n    \"env_runners/num_module_steps_sampled/agent_7\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      }\n    },\n    \"env_runners/num_module_steps_sampled/agent_17\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      }\n    },\n    \"env_runners/num_module_steps_sampled/agent_8\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      }\n    },\n    \"env_runners/num_module_steps_sampled/agent_0\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      }\n    },\n    \"env_runners/num_module_steps_sampled/agent_11\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      }\n    },\n    \"env_runners/num_module_steps_sampled/agent_12\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      }\n    },\n    \"env_runners/num_module_steps_sampled/agent_9\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      }\n    },\n    \"env_runners/num_module_steps_sampled/agent_18\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      }\n    },\n    \"env_runners/num_module_steps_sampled/agent_15\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      }\n    },\n    \"env_runners/num_module_steps_sampled/agent_20\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      }\n    },\n    \"env_runners/num_module_steps_sampled/agent_10\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      }\n    },\n    \"env_runners/num_module_steps_sampled/agent_19\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      }\n    },\n    \"env_runners/num_module_steps_sampled/agent_13\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      }\n    },\n    \"env_runners/num_module_steps_sampled/agent_16\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      }\n    },\n    \"env_runners/num_module_steps_sampled/agent_2\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      }\n    },\n    \"env_runners/num_module_steps_sampled/agent_1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      }\n    },\n    \"env_runners/num_module_steps_sampled/agent_4\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      }\n    },\n    \"env_runners/env_to_module_connector/connector_pipeline_timer\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308b2337145db9a3b3f94869452946807680d43081c33b6486e003d3f94869452946807680d430801a3ad2cc6f83e3f94869452946807680d4308fb88fa2b813b3e3f94869452946807680d4308d78750aeee653d3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595e9000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080048d18b3f873b3f94869452946807680d4308b2337145db9a3b3f94869452946807680d43081c33b6486e003d3f94869452946807680d430801a3ad2cc6f83e3f94869452946807680d4308fb88fa2b813b3e3f94869452946807680d4308d78750aeee653d3f9486945294652e\"\n      }\n    },\n    \"env_runners/agent_episode_returns_mean/agent_11\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847c0001735ee402bbf47bfff350fd350fd4f47c0004f3078263ac547bff8cccccccccce147bffab24be57f18c9652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847c006cccccccccceb47c0001735ee402bbf47bfff350fd350fd4f47c0004f3078263ac547bff8cccccccccce147bffab24be57f18c9652e\"\n      }\n    },\n    \"env_runners/agent_episode_returns_mean/agent_6\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847c0018ead65b7a33647bffc9138c9138ca347bffa0f04c756b2ec47bff6f4f4f4f4f50247bff46ed53ba2087b652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847c003d0369d0369e547c0018ead65b7a33647bffc9138c9138ca347bffa0f04c756b2ec47bff6f4f4f4f4f50247bff46ed53ba2087b652e\"\n      }\n    },\n    \"env_runners/agent_episode_returns_mean/agent_12\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847bffb6f46508dfeba47bffc0595e0595e1a47bffbd5acb6f4652247bffb2ac45df7914147bffafe9831cb6517652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847bff3c28f5c28f5d547bffb6f46508dfeba47bffc0595e0595e1a47bffbd5acb6f4652247bffb2ac45df7914147bffafe9831cb6517652e\"\n      }\n    },\n    \"env_runners/agent_episode_returns_mean/agent_7\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847c00644444444445947c0039403b9403ba747c002f92c5f92c60c47c0007e4b17e4b18d47c001104376a9dd22652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847c00706d3a06d3a2447c00644444444445947c0039403b9403ba747c002f92c5f92c60c47c0007e4b17e4b18d47c001104376a9dd22652e\"\n      }\n    },\n    \"env_runners/agent_episode_returns_mean/agent_18\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847c0120da740da741d47c0121999999999a947c0121374bc6a7f0c47c011dc760fa942eb47c011fc7c7c7c7c8d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847c01250369d0369e747c0120da740da741d47c0121999999999a947c0121374bc6a7f0c47c011dc760fa942eb47c011fc7c7c7c7c8d652e\"\n      }\n    },\n    \"env_runners/agent_episode_returns_mean/agent_17\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847c011dfea27983c2247c011cea96cea96df47c011c2e6bdc8058547c011a8282828283647c011c996632ffcd8652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847c011f5c28f5c290b47c011dfea27983c2247c011cea96cea96df47c011c2e6bdc8058547c011a8282828283647c011c996632ffcd8652e\"\n      }\n    },\n    \"env_runners/agent_episode_returns_mean/agent_8\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847c000aaaaaaaaaab747c00170a3d70a3d7f47c0022bb0cf87d9d547c0031f5285b8ec3047bffff4c18e5b280f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847bfe000000000000347c000aaaaaaaaaab747c00170a3d70a3d7f47c0022bb0cf87d9d547c0031f5285b8ec3047bffff4c18e5b280f652e\"\n      }\n    },\n    \"env_runners/agent_episode_returns_mean/agent_0\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847c002d242e6bdc81747bfffa10c1a10c1bc47c001fb38a94d243e47c000821bb54ee89347bffe134679ace032652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847c002851eb851eb9547c002d242e6bdc81747bfffa10c1a10c1bc47c001fb38a94d243e47c000821bb54ee89347bffe134679ace032652e\"\n      }\n    },\n    \"env_runners/agent_episode_returns_mean/agent_20\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847c012353f7ced917947c0123de7cbde7ccd47c012815d867c3ee347c01224be57f18b3347c0124b986531fedc652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847c0133bbbbbbbbbd547c012353f7ced917947c0123de7cbde7ccd47c012815d867c3ee347c01224be57f18b3347c0124b986531fedc652e\"\n      }\n    },\n    \"env_runners/agent_episode_returns_mean/agent_19\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847c012bdc805761a0347c01263244e3244f647c0124f87d9c54a7c47c01200336699cd0f47c011b51b81e84ec4652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847c01286d3a06d3a1d47c012bdc805761a0347c01263244e3244f647c0124f87d9c54a7c47c01200336699cd0f47c011b51b81e84ec4652e\"\n      }\n    },\n    \"env_runners/agent_episode_returns_mean/agent_9\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847c00308dfea27985047c0018c9138c9139c47c0011529a485cd8b47c002ce349b0167df47c000f8f8f8f8f908652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847c006f258bf258c1047c00308dfea27985047c0018c9138c9139c47c0011529a485cd8b47c002ce349b0167df47c000f8f8f8f8f908652e\"\n      }\n    },\n    \"env_runners/agent_episode_returns_mean/agent_15\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847c012d867c3ece2b647c01206843068431647c011ced916872b1347c011ab91f85ec53a47c0113b54ee8821ca652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847c01323d70a3d70bd47c012d867c3ece2b647c01206843068431647c011ced916872b1347c011ab91f85ec53a47c0113b54ee8821ca652e\"\n      }\n    },\n    \"env_runners/agent_episode_returns_mean/agent_16\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847c012a06d3a06d3b147c01283421834219347c01277777777778947c0122ac45df7913b47c011f009a33cd682652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847c012f0a3d70a3d8947c012a06d3a06d3b147c01283421834219347c01277777777778947c0122ac45df7913b47c011f009a33cd682652e\"\n      }\n    },\n    \"env_runners/agent_episode_returns_mean/agent_2\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847c001258bf258bf3347bfff69315693158047bffcb020c49ba5f747bff767009a33cd7447bff61c82e94fb62b652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847c00600000000001c47c001258bf258bf3347bfff69315693158047bffcb020c49ba5f747bff767009a33cd7447bff61c82e94fb62b652e\"\n      }\n    },\n    \"env_runners/agent_episode_returns_mean/agent_1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847c0092b020c49ba7647c006ca01dca01dde47c00483c131d5acc747c00114141414142247bff96bd2389f0580652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847c004c5f92c5f92de47c0092b020c49ba7647c006ca01dca01dde47c00483c131d5acc747c00114141414142247bff96bd2389f0580652e\"\n      }\n    },\n    \"env_runners/agent_episode_returns_mean/agent_10\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847c009e60f04c756ce47c007d9d52d9d52f047c0051bfd44f3079547c00276430fdca98647c000124578abdf20652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847c00b6d3a06d3a09147c009e60f04c756ce47c007d9d52d9d52f047c0051bfd44f3079547c00276430fdca98647c000124578abdf20652e\"\n      }\n    },\n    \"env_runners/agent_episode_returns_mean/agent_4\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847bfefc3ece2a5349947bff421834218342c47bff36872b020c4a647bff5a6da0d4073b547bff96ea1d5083b7c652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847bff733333333334147bfefc3ece2a5349947bff421834218342c47bff36872b020c4a647bff5a6da0d4073b547bff96ea1d5083b7c652e\"\n      }\n    },\n    \"env_runners/agent_episode_returns_mean/agent_13\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847bfee19f0fb38a95c47bff3498ab498ab5947bff54bc6a7ef9dc447c0008e27c15af49c47c000f2f2f2f2f300652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847bfe000000000000347bfee19f0fb38a95c47bff3498ab498ab5947bff54bc6a7ef9dc447c0008e27c15af49c47c000f2f2f2f2f300652e\"\n      }\n    },\n    \"env_runners/agent_episode_returns_mean/agent_5\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847bff2de8ca11bfd5147bff4ec736ec736f747bff74e81b4e81b5f47bffe3ea50b71d85147c003632ffcc99673652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847bff451eb851eb86547bff2de8ca11bfd5147bff4ec736ec736f747bff74e81b4e81b5f47bffe3ea50b71d85147c003632ffcc99673652e\"\n      }\n    },\n    \"env_runners/agent_episode_returns_mean/agent_14\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847c012ef9db22d0e6947c012947ae147ae2747c012604189374bda47c0120c5925f2bf9b47c011bababababacb652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847c012e9d0369d038347c012ef9db22d0e6947c012947ae147ae2747c012604189374bda47c0120c5925f2bf9b47c011bababababacb652e\"\n      }\n    },\n    \"env_runners/agent_episode_returns_mean/agent_3\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847bff77a32846ff52f47bffcf02caf02cb0a47bfff3cc1e098eaf647c0002288ef55bc3047c00337d16b049e47652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847bff42fc962fc964447bff77a32846ff52f47bffcf02caf02cb0a47bfff3cc1e098eaf647c0002288ef55bc3047c00337d16b049e47652e\"\n      }\n    },\n    \"learners/agent_10/weights_seq_no\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474000000000000000474008000000000000474010000000000000474014000000000000474018000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473ff0000000000000474000000000000000474008000000000000474010000000000000474014000000000000474018000000000000652e\"\n      }\n    },\n    \"learners/agent_10/total_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243045dd565bd94869452946807680d4304528815bd94869452946807680d4304915286bd94869452946807680d43048cc1c4bb94869452946807680d4304c42634bd9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430458ca13be94869452946807680d43045dd565bd94869452946807680d4304528815bd94869452946807680d4304915286bd94869452946807680d43048cc1c4bb94869452946807680d4304c42634bd9486945294652e\"\n      }\n    },\n    \"learners/agent_10/num_module_steps_trained_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a003a01004a00d701004a007402004a001103004a00ae0300652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953e000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d009d4a003a01004a00d701004a007402004a001103004a00ae0300652e\"\n      }\n    },\n    \"learners/agent_10/module_train_batch_size_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000652e\"\n      }\n    },\n    \"learners/agent_10/mean_kl_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304a1900e3c94869452946807680d43047e481c3c94869452946807680d430432de123c94869452946807680d43046c93163c94869452946807680d430442471d3c9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243044171213c94869452946807680d4304a1900e3c94869452946807680d43047e481c3c94869452946807680d430432de123c94869452946807680d43046c93163c94869452946807680d430442471d3c9486945294652e\"\n      }\n    },\n    \"learners/agent_10/num_module_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d009d4d009d4d009d4d009d4d009d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d009d4d009d4d009d4d009d4d009d4d009d652e\"\n      }\n    },\n    \"learners/agent_10/entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243043168c44094869452946807680d43049426c44094869452946807680d4304d822c44094869452946807680d430468fec34094869452946807680d430432d6c3409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ef89c44094869452946807680d43043168c44094869452946807680d43049426c44094869452946807680d4304d822c44094869452946807680d430468fec34094869452946807680d430432d6c3409486945294652e\"\n      }\n    },\n    \"learners/agent_10/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f9486945294652e\"\n      }\n    },\n    \"learners/agent_10/vf_explained_var\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040aac613f94869452946807680d43043aea723f94869452946807680d4304eeab643f94869452946807680d430401a6703f94869452946807680d43047251763f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304b52f6e3f94869452946807680d43040aac613f94869452946807680d43043aea723f94869452946807680d4304eeab643f94869452946807680d430401a6703f94869452946807680d43047251763f9486945294652e\"\n      }\n    },\n    \"learners/agent_10/curr_kl_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000652e\"\n      }\n    },\n    \"learners/agent_10/vf_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304c702ab3a94869452946807680d4304656b183a94869452946807680d4304eae7983a94869452946807680d4304aa87423a94869452946807680d4304e29d4b3a9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430436859e3a94869452946807680d4304c702ab3a94869452946807680d4304656b183a94869452946807680d4304eae7983a94869452946807680d4304aa87423a94869452946807680d4304e29d4b3a9486945294652e\"\n      }\n    },\n    \"learners/agent_10/vf_loss_unclipped\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304c702ab3a94869452946807680d4304656b183a94869452946807680d4304eae7983a94869452946807680d4304aa87423a94869452946807680d4304e29d4b3a9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430436859e3a94869452946807680d4304c702ab3a94869452946807680d4304656b183a94869452946807680d4304eae7983a94869452946807680d4304aa87423a94869452946807680d4304e29d4b3a9486945294652e\"\n      }\n    },\n    \"learners/agent_10/default_optimizer_learning_rate\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d652e\"\n      }\n    },\n    \"learners/agent_10/curr_entropy_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    },\n    \"learners/agent_10/num_trainable_parameters\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b00652e\"\n      }\n    },\n    \"learners/agent_10/policy_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304474e72bd94869452946807680d43046aba1fbd94869452946807680d430425628cbd94869452946807680d4304b3a60cbc94869452946807680d430467323fbd9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304000c17be94869452946807680d4304474e72bd94869452946807680d43046aba1fbd94869452946807680d430425628cbd94869452946807680d4304b3a60cbc94869452946807680d430467323fbd9486945294652e\"\n      }\n    },\n    \"learners/agent_10/num_module_steps_trained_lifetime_throughput\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428477ff8000000000000474098eaf4eae7252f474098eaa413c26ebe474098e3a9a7de9da3474098df7588e98f3b652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428477ff8000000000000477ff8000000000000474098eaf4eae7252f474098eaa413c26ebe474098e3a9a7de9da3474098df7588e98f3b652e\"\n      }\n    },\n    \"learners/agent_6/total_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304c6c48cbd94869452946807680d43047b789ebd94869452946807680d4304c0db3fbd94869452946807680d430496f3173d94869452946807680d4304f03b00be9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040e472bbe94869452946807680d4304c6c48cbd94869452946807680d43047b789ebd94869452946807680d4304c0db3fbd94869452946807680d430496f3173d94869452946807680d4304f03b00be9486945294652e\"\n      }\n    },\n    \"learners/agent_6/vf_explained_var\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430449ac763f94869452946807680d43043c0b6d3f94869452946807680d4304b6fa693f94869452946807680d4304fcbb573f94869452946807680d4304af73583f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304aafe683f94869452946807680d430449ac763f94869452946807680d43043c0b6d3f94869452946807680d4304b6fa693f94869452946807680d4304fcbb573f94869452946807680d4304af73583f9486945294652e\"\n      }\n    },\n    \"learners/agent_6/num_module_steps_trained_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a003a01004a00d701004a007402004a001103004a00ae0300652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953e000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d009d4a003a01004a00d701004a007402004a001103004a00ae0300652e\"\n      }\n    },\n    \"learners/agent_6/curr_kl_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000652e\"\n      }\n    },\n    \"learners/agent_6/mean_kl_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304d36b1b3c94869452946807680d43041fa8113c94869452946807680d43040ec1093c94869452946807680d430463c2163c94869452946807680d430462cc163c9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304e19a1d3c94869452946807680d4304d36b1b3c94869452946807680d43041fa8113c94869452946807680d43040ec1093c94869452946807680d430463c2163c94869452946807680d430462cc163c9486945294652e\"\n      }\n    },\n    \"learners/agent_6/num_module_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d009d4d009d4d009d4d009d4d009d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d009d4d009d4d009d4d009d4d009d4d009d652e\"\n      }\n    },\n    \"learners/agent_6/vf_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ad9c543a94869452946807680d43047db2843a94869452946807680d430404b91a3a94869452946807680d43040dea5a3a94869452946807680d4304c6988b3a9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304d0b2a13a94869452946807680d4304ad9c543a94869452946807680d43047db2843a94869452946807680d430404b91a3a94869452946807680d43040dea5a3a94869452946807680d4304c6988b3a9486945294652e\"\n      }\n    },\n    \"learners/agent_6/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f9486945294652e\"\n      }\n    },\n    \"learners/agent_6/vf_loss_unclipped\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ad9c543a94869452946807680d43047db2843a94869452946807680d430404b91a3a94869452946807680d43040dea5a3a94869452946807680d4304c6988b3a9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304d0b2a13a94869452946807680d4304ad9c543a94869452946807680d43047db2843a94869452946807680d430404b91a3a94869452946807680d43040dea5a3a94869452946807680d4304c6988b3a9486945294652e\"\n      }\n    },\n    \"learners/agent_6/curr_entropy_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    },\n    \"learners/agent_6/num_trainable_parameters\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b00652e\"\n      }\n    },\n    \"learners/agent_6/policy_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304b05092bd94869452946807680d4304792fa4bd94869452946807680d4304ea2949bd94869452946807680d430435fe0c3d94869452946807680d4304ae3503be9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ca822ebe94869452946807680d4304b05092bd94869452946807680d4304792fa4bd94869452946807680d4304ea2949bd94869452946807680d430435fe0c3d94869452946807680d4304ae3503be9486945294652e\"\n      }\n    },\n    \"learners/agent_6/default_optimizer_learning_rate\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d652e\"\n      }\n    },\n    \"learners/agent_6/module_train_batch_size_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000652e\"\n      }\n    },\n    \"learners/agent_6/entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ba60c44094869452946807680d43045d23c44094869452946807680d4304defdc34094869452946807680d4304a7e5c34094869452946807680d43040ec3c3409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304a088c44094869452946807680d4304ba60c44094869452946807680d43045d23c44094869452946807680d4304defdc34094869452946807680d4304a7e5c34094869452946807680d43040ec3c3409486945294652e\"\n      }\n    },\n    \"learners/agent_6/weights_seq_no\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474000000000000000474008000000000000474010000000000000474014000000000000474018000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473ff0000000000000474000000000000000474008000000000000474010000000000000474014000000000000474018000000000000652e\"\n      }\n    },\n    \"learners/agent_6/num_module_steps_trained_lifetime_throughput\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428477ff8000000000000474098eaf641b736db474098eaa54ed2cd78474098e3aaf2dd9234474098df769d54fc57652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428477ff8000000000000477ff8000000000000474098eaf641b736db474098eaa54ed2cd78474098e3aaf2dd9234474098df769d54fc57652e\"\n      }\n    },\n    \"learners/agent_16/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f9486945294652e\"\n      }\n    },\n    \"learners/agent_16/vf_explained_var\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243045324503f94869452946807680d43040ab96e3f94869452946807680d43044cec573f94869452946807680d43044cfd4f3f94869452946807680d430426b85a3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243041fa4573f94869452946807680d43045324503f94869452946807680d43040ab96e3f94869452946807680d43044cec573f94869452946807680d43044cfd4f3f94869452946807680d430426b85a3f9486945294652e\"\n      }\n    },\n    \"learners/agent_16/curr_kl_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000652e\"\n      }\n    },\n    \"learners/agent_16/vf_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304a8047f3b94869452946807680d43043873cb3a94869452946807680d43040284523b94869452946807680d430457c5413b94869452946807680d430442bbdd3a9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243048c67533b94869452946807680d4304a8047f3b94869452946807680d43043873cb3a94869452946807680d43040284523b94869452946807680d430457c5413b94869452946807680d430442bbdd3a9486945294652e\"\n      }\n    },\n    \"learners/agent_16/vf_loss_unclipped\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304a8047f3b94869452946807680d43043873cb3a94869452946807680d43040284523b94869452946807680d430457c5413b94869452946807680d430442bbdd3a9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243048c67533b94869452946807680d4304a8047f3b94869452946807680d43043873cb3a94869452946807680d43040284523b94869452946807680d430457c5413b94869452946807680d430442bbdd3a9486945294652e\"\n      }\n    },\n    \"learners/agent_16/default_optimizer_learning_rate\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d652e\"\n      }\n    },\n    \"learners/agent_16/curr_entropy_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    },\n    \"learners/agent_16/num_trainable_parameters\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284ae5e604004ae5e604004ae5e604004ae5e604004ae5e60400652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284ae5e604004ae5e604004ae5e604004ae5e604004ae5e604004ae5e60400652e\"\n      }\n    },\n    \"learners/agent_16/policy_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430493944abd94869452946807680d43041c5c9abb94869452946807680d4304155b4ebe94869452946807680d430403a18abd94869452946807680d430492905d3d9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243043a9f93be94869452946807680d430493944abd94869452946807680d43041c5c9abb94869452946807680d4304155b4ebe94869452946807680d430403a18abd94869452946807680d430492905d3d9486945294652e\"\n      }\n    },\n    \"learners/agent_16/entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304fc68c44094869452946807680d4304303dc44094869452946807680d43046317c44094869452946807680d430496e7c34094869452946807680d430476c5c3409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304eca3c44094869452946807680d4304fc68c44094869452946807680d4304303dc44094869452946807680d43046317c44094869452946807680d430496e7c34094869452946807680d430476c5c3409486945294652e\"\n      }\n    },\n    \"learners/agent_16/weights_seq_no\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474000000000000000474008000000000000474010000000000000474014000000000000474018000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473ff0000000000000474000000000000000474008000000000000474010000000000000474014000000000000474018000000000000652e\"\n      }\n    },\n    \"learners/agent_16/total_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243043fa834bd94869452946807680d4304738bdbba94869452946807680d4304549649be94869452946807680d4304275e81bd94869452946807680d4304ae006b3d9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304c03491be94869452946807680d43043fa834bd94869452946807680d4304738bdbba94869452946807680d4304549649be94869452946807680d4304275e81bd94869452946807680d4304ae006b3d9486945294652e\"\n      }\n    },\n    \"learners/agent_16/num_module_steps_trained_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a003a01004a00d701004a007402004a001103004a00ae0300652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953e000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d009d4a003a01004a00d701004a007402004a001103004a00ae0300652e\"\n      }\n    },\n    \"learners/agent_16/module_train_batch_size_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000652e\"\n      }\n    },\n    \"learners/agent_16/mean_kl_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243049e61ef3b94869452946807680d4304400ef33b94869452946807680d430406aeec3b94869452946807680d4304f13b003c94869452946807680d4304182d023c9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243042095f43b94869452946807680d43049e61ef3b94869452946807680d4304400ef33b94869452946807680d430406aeec3b94869452946807680d4304f13b003c94869452946807680d4304182d023c9486945294652e\"\n      }\n    },\n    \"learners/agent_16/num_module_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d009d4d009d4d009d4d009d4d009d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d009d4d009d4d009d4d009d4d009d4d009d652e\"\n      }\n    },\n    \"learners/agent_16/num_module_steps_trained_lifetime_throughput\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428477ff8000000000000474098eaedfa86dd23474098ea9d65353910474098e3a3673eb159474098df6ff340bcec652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428477ff8000000000000477ff8000000000000474098eaedfa86dd23474098ea9d65353910474098e3a3673eb159474098df6ff340bcec652e\"\n      }\n    },\n    \"learners/agent_5/vf_loss_unclipped\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304fe860f3a94869452946807680d430484e8be3994869452946807680d4304cf8ce33994869452946807680d4304f7d82f3a94869452946807680d43049a03f7399486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243044a305a3a94869452946807680d4304fe860f3a94869452946807680d430484e8be3994869452946807680d4304cf8ce33994869452946807680d4304f7d82f3a94869452946807680d43049a03f7399486945294652e\"\n      }\n    },\n    \"learners/agent_5/default_optimizer_learning_rate\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d652e\"\n      }\n    },\n    \"learners/agent_5/module_train_batch_size_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000652e\"\n      }\n    },\n    \"learners/agent_5/num_trainable_parameters\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b00652e\"\n      }\n    },\n    \"learners/agent_5/entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243041770c44094869452946807680d43043054c44094869452946807680d4304683ec44094869452946807680d43040af9c34094869452946807680d4304c3b3c3409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430419a8c44094869452946807680d43041770c44094869452946807680d43043054c44094869452946807680d4304683ec44094869452946807680d43040af9c34094869452946807680d4304c3b3c3409486945294652e\"\n      }\n    },\n    \"learners/agent_5/weights_seq_no\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474000000000000000474008000000000000474010000000000000474014000000000000474018000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473ff0000000000000474000000000000000474008000000000000474010000000000000474014000000000000474018000000000000652e\"\n      }\n    },\n    \"learners/agent_5/total_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430462c135bd94869452946807680d43049333553d94869452946807680d43043fb560be94869452946807680d4304c449a8bc94869452946807680d4304c8eb81bc9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304371b8cbd94869452946807680d430462c135bd94869452946807680d43049333553d94869452946807680d43043fb560be94869452946807680d4304c449a8bc94869452946807680d4304c8eb81bc9486945294652e\"\n      }\n    },\n    \"learners/agent_5/vf_explained_var\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304f6df6b3f94869452946807680d4304ce24783f94869452946807680d43040860763f94869452946807680d430425346a3f94869452946807680d43047782733f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430499ca763f94869452946807680d4304f6df6b3f94869452946807680d4304ce24783f94869452946807680d43040860763f94869452946807680d430425346a3f94869452946807680d43047782733f9486945294652e\"\n      }\n    },\n    \"learners/agent_5/num_module_steps_trained_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a003a01004a00d701004a007402004a001103004a00ae0300652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953e000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d009d4a003a01004a00d701004a007402004a001103004a00ae0300652e\"\n      }\n    },\n    \"learners/agent_5/curr_kl_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000652e\"\n      }\n    },\n    \"learners/agent_5/mean_kl_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304caf81b3c94869452946807680d4304fea0183c94869452946807680d43046b581a3c94869452946807680d4304652d173c94869452946807680d4304f2b11c3c9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304309b103c94869452946807680d4304caf81b3c94869452946807680d4304fea0183c94869452946807680d43046b581a3c94869452946807680d4304652d173c94869452946807680d4304f2b11c3c9486945294652e\"\n      }\n    },\n    \"learners/agent_5/num_module_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d009d4d009d4d009d4d009d4d009d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d009d4d009d4d009d4d009d4d009d4d009d652e\"\n      }\n    },\n    \"learners/agent_5/vf_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304fe860f3a94869452946807680d430484e8be3994869452946807680d4304cf8ce33994869452946807680d4304f7d82f3a94869452946807680d43049a03f7399486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243044a305a3a94869452946807680d4304fe860f3a94869452946807680d430484e8be3994869452946807680d4304cf8ce33994869452946807680d4304f7d82f3a94869452946807680d43049a03f7399486945294652e\"\n      }\n    },\n    \"learners/agent_5/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f9486945294652e\"\n      }\n    },\n    \"learners/agent_5/curr_entropy_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    },\n    \"learners/agent_5/policy_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304edcb3fbd94869452946807680d43041e144c3d94869452946807680d4304ec1463be94869452946807680d4304afe6bcbc94869452946807680d43043c7395bc9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304126d91bd94869452946807680d4304edcb3fbd94869452946807680d43041e144c3d94869452946807680d4304ec1463be94869452946807680d4304afe6bcbc94869452946807680d43043c7395bc9486945294652e\"\n      }\n    },\n    \"learners/agent_5/num_module_steps_trained_lifetime_throughput\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428477ff8000000000000474098eaf13bb1590b474098eaa0835a9a97474098e3a6527bb130474098df7288e71746652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428477ff8000000000000477ff8000000000000474098eaf13bb1590b474098eaa0835a9a97474098e3a6527bb130474098df7288e71746652e\"\n      }\n    },\n    \"learners/agent_11/num_module_steps_trained_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a003a01004a00d701004a007402004a001103004a00ae0300652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953e000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d009d4a003a01004a00d701004a007402004a001103004a00ae0300652e\"\n      }\n    },\n    \"learners/agent_11/curr_kl_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000652e\"\n      }\n    },\n    \"learners/agent_11/mean_kl_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304fc72123c94869452946807680d4304c4f1113c94869452946807680d43047e34043c94869452946807680d43045fce0c3c94869452946807680d4304d3a41f3c9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243046e85293c94869452946807680d4304fc72123c94869452946807680d4304c4f1113c94869452946807680d43047e34043c94869452946807680d43045fce0c3c94869452946807680d4304d3a41f3c9486945294652e\"\n      }\n    },\n    \"learners/agent_11/num_module_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d009d4d009d4d009d4d009d4d009d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d009d4d009d4d009d4d009d4d009d4d009d652e\"\n      }\n    },\n    \"learners/agent_11/vf_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243048172d03a94869452946807680d4304b88cd23a94869452946807680d4304baf3993a94869452946807680d430433b3823a94869452946807680d430441b0a63a9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243042a52433b94869452946807680d43048172d03a94869452946807680d4304b88cd23a94869452946807680d4304baf3993a94869452946807680d430433b3823a94869452946807680d430441b0a63a9486945294652e\"\n      }\n    },\n    \"learners/agent_11/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f9486945294652e\"\n      }\n    },\n    \"learners/agent_11/vf_loss_unclipped\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243048172d03a94869452946807680d4304b88cd23a94869452946807680d4304baf3993a94869452946807680d430433b3823a94869452946807680d430441b0a63a9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243042a52433b94869452946807680d43048172d03a94869452946807680d4304b88cd23a94869452946807680d4304baf3993a94869452946807680d430433b3823a94869452946807680d430441b0a63a9486945294652e\"\n      }\n    },\n    \"learners/agent_11/curr_entropy_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    },\n    \"learners/agent_11/num_trainable_parameters\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b00652e\"\n      }\n    },\n    \"learners/agent_11/policy_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243047f2325bd94869452946807680d4304548518be94869452946807680d430486e90dbe94869452946807680d4304247c4fbe94869452946807680d43049872a0bd9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304473894bd94869452946807680d43047f2325bd94869452946807680d4304548518be94869452946807680d430486e90dbe94869452946807680d4304247c4fbe94869452946807680d43049872a0bd9486945294652e\"\n      }\n    },\n    \"learners/agent_11/default_optimizer_learning_rate\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d652e\"\n      }\n    },\n    \"learners/agent_11/module_train_batch_size_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000652e\"\n      }\n    },\n    \"learners/agent_11/entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243047f81c44094869452946807680d43045e4ac44094869452946807680d4304fe19c44094869452946807680d4304750fc44094869452946807680d4304c2b3c3409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304eea3c44094869452946807680d43047f81c44094869452946807680d43045e4ac44094869452946807680d4304fe19c44094869452946807680d4304750fc44094869452946807680d4304c2b3c3409486945294652e\"\n      }\n    },\n    \"learners/agent_11/weights_seq_no\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474000000000000000474008000000000000474010000000000000474014000000000000474018000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473ff0000000000000474000000000000000474008000000000000474010000000000000474014000000000000474018000000000000652e\"\n      }\n    },\n    \"learners/agent_11/total_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243045b4d17bd94869452946807680d4304340d15be94869452946807680d4304900e0bbe94869452946807680d430429b44cbe94869452946807680d430421da99bd9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304c6e089bd94869452946807680d43045b4d17bd94869452946807680d4304340d15be94869452946807680d4304900e0bbe94869452946807680d430429b44cbe94869452946807680d430421da99bd9486945294652e\"\n      }\n    },\n    \"learners/agent_11/vf_explained_var\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304d6d15e3f94869452946807680d43045e81713f94869452946807680d43044f08653f94869452946807680d430423ab613f94869452946807680d4304d73c593f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243047b95423f94869452946807680d4304d6d15e3f94869452946807680d43045e81713f94869452946807680d43044f08653f94869452946807680d430423ab613f94869452946807680d4304d73c593f9486945294652e\"\n      }\n    },\n    \"learners/agent_11/num_module_steps_trained_lifetime_throughput\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428477ff8000000000000474098eaf82ab2f90c474098eaa724710c26474098e3acc4242424474098df7869b526b0652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428477ff8000000000000477ff8000000000000474098eaf82ab2f90c474098eaa724710c26474098e3acc4242424474098df7869b526b0652e\"\n      }\n    },\n    \"learners/agent_20/curr_entropy_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    },\n    \"learners/agent_20/num_trainable_parameters\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284ae5e604004ae5e604004ae5e604004ae5e604004ae5e60400652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284ae5e604004ae5e604004ae5e604004ae5e604004ae5e604004ae5e60400652e\"\n      }\n    },\n    \"learners/agent_20/policy_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430407790abc94869452946807680d4304e0a50cbe94869452946807680d4304b7487fbd94869452946807680d4304a1e332be94869452946807680d4304745191bd9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304daf7c3bd94869452946807680d430407790abc94869452946807680d4304e0a50cbe94869452946807680d4304b7487fbd94869452946807680d4304a1e332be94869452946807680d4304745191bd9486945294652e\"\n      }\n    },\n    \"learners/agent_20/default_optimizer_learning_rate\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d652e\"\n      }\n    },\n    \"learners/agent_20/module_train_batch_size_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000652e\"\n      }\n    },\n    \"learners/agent_20/entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304f45fc44094869452946807680d4304872cc44094869452946807680d43044218c44094869452946807680d430493f2c34094869452946807680d43042cb0c3409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243045297c44094869452946807680d4304f45fc44094869452946807680d4304872cc44094869452946807680d43044218c44094869452946807680d430493f2c34094869452946807680d43042cb0c3409486945294652e\"\n      }\n    },\n    \"learners/agent_20/weights_seq_no\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474000000000000000474008000000000000474010000000000000474014000000000000474018000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473ff0000000000000474000000000000000474008000000000000474010000000000000474014000000000000474018000000000000652e\"\n      }\n    },\n    \"learners/agent_20/total_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304fd72b2bb94869452946807680d4304981608be94869452946807680d4304273e6ebd94869452946807680d430428802ebe94869452946807680d43044daf88bd9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304d361bcbd94869452946807680d4304fd72b2bb94869452946807680d4304981608be94869452946807680d4304273e6ebd94869452946807680d430428802ebe94869452946807680d43044daf88bd9486945294652e\"\n      }\n    },\n    \"learners/agent_20/vf_explained_var\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304807a5c3f94869452946807680d43043ab9403f94869452946807680d4304281d4f3f94869452946807680d430454355e3f94869452946807680d430465ff473f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ce15663f94869452946807680d4304807a5c3f94869452946807680d43043ab9403f94869452946807680d4304281d4f3f94869452946807680d430454355e3f94869452946807680d430465ff473f9486945294652e\"\n      }\n    },\n    \"learners/agent_20/num_module_steps_trained_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a003a01004a00d701004a007402004a001103004a00ae0300652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953e000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d009d4a003a01004a00d701004a007402004a001103004a00ae0300652e\"\n      }\n    },\n    \"learners/agent_20/curr_kl_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000652e\"\n      }\n    },\n    \"learners/agent_20/mean_kl_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243047a22fe3b94869452946807680d4304abeb023c94869452946807680d43044082fc3b94869452946807680d43045686fb3b94869452946807680d4304672a013c9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430414b6043c94869452946807680d43047a22fe3b94869452946807680d4304abeb023c94869452946807680d43044082fc3b94869452946807680d43045686fb3b94869452946807680d4304672a013c9486945294652e\"\n      }\n    },\n    \"learners/agent_20/num_module_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d009d4d009d4d009d4d009d4d009d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d009d4d009d4d009d4d009d4d009d4d009d652e\"\n      }\n    },\n    \"learners/agent_20/vf_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430490adbe3a94869452946807680d430455153b3b94869452946807680d430430a82b3b94869452946807680d4304f841343b94869452946807680d4304b9ef2c3b9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304cc95083b94869452946807680d430490adbe3a94869452946807680d430455153b3b94869452946807680d430430a82b3b94869452946807680d4304f841343b94869452946807680d4304b9ef2c3b9486945294652e\"\n      }\n    },\n    \"learners/agent_20/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f9486945294652e\"\n      }\n    },\n    \"learners/agent_20/vf_loss_unclipped\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430490adbe3a94869452946807680d430455153b3b94869452946807680d430430a82b3b94869452946807680d4304f841343b94869452946807680d4304b9ef2c3b9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304cc95083b94869452946807680d430490adbe3a94869452946807680d430455153b3b94869452946807680d430430a82b3b94869452946807680d4304f841343b94869452946807680d4304b9ef2c3b9486945294652e\"\n      }\n    },\n    \"learners/agent_20/num_module_steps_trained_lifetime_throughput\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428477ff8000000000000474098eaef2a177217474098ea9e8720d1fd474098e3a47bedda93474098df70ec020d0b652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428477ff8000000000000477ff8000000000000474098eaef2a177217474098ea9e8720d1fd474098e3a47bedda93474098df70ec020d0b652e\"\n      }\n    },\n    \"learners/__all_modules__/num_non_trainable_parameters\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952e000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b00652e\"\n      }\n    },\n    \"learners/__all_modules__/num_module_steps_trained_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a00c219004a00a326004a008433004a006540004a00464d00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a00e10c004a00c219004a00a326004a008433004a006540004a00464d00652e\"\n      }\n    },\n    \"learners/__all_modules__/learner_connector_sum_episodes_length_out\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059552000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284da00f4740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      }\n    },\n    \"learners/__all_modules__/num_env_steps_trained_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a402a13004a60bf1c004a805426004aa0e92f004ac07e3900652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a209509004a402a13004a60bf1c004a805426004aa0e92f004ac07e3900652e\"\n      }\n    },\n    \"learners/__all_modules__/num_trainable_parameters\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284ac944c9004ac944c9004ac944c9004ac944c9004ac944c900652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284ac944c9004ac944c9004ac944c9004ac944c9004ac944c9004ac944c900652e\"\n      }\n    },\n    \"learners/__all_modules__/num_env_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a209509004a209509004a209509004a209509004a20950900652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a209509004a209509004a209509004a209509004a209509004a20950900652e\"\n      }\n    },\n    \"learners/__all_modules__/learner_connector_sum_episodes_length_in\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059552000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284da00f4740af4000000000004740af4000000000004740af4000000000004740af4000000000004740af400000000000652e\"\n      }\n    },\n    \"learners/__all_modules__/num_module_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a00e10c004a00e10c004a00e10c004a00e10c004a00e10c00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a00e10c004a00e10c004a00e10c004a00e10c004a00e10c004a00e10c00652e\"\n      }\n    },\n    \"learners/__all_modules__/num_env_steps_trained_lifetime_throughput\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428477ff80000000000004740d8556ecc185fcf4740d8551fffc9e3434740d84e4fba401ed74740d84a353e8e3dc4652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428477ff8000000000000477ff80000000000004740d8556ecc185fcf4740d8551fffc9e3434740d84e4fba401ed74740d84a353e8e3dc4652e\"\n      }\n    },\n    \"learners/__all_modules__/num_module_steps_trained_throughput\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428477ff8000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428477ff8000000000000477ff8000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    },\n    \"learners/__all_modules__/num_module_steps_trained_lifetime_throughput\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428477ff80000000000004740e05a308a87e7514740e059fb7fff7d164740e055672a2528a64740e052a4fb27f9ed652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428477ff8000000000000477ff80000000000004740e05a308a87e7514740e059fb7fff7d164740e055672a2528a64740e052a4fb27f9ed652e\"\n      }\n    },\n    \"learners/agent_13/module_train_batch_size_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000652e\"\n      }\n    },\n    \"learners/agent_13/entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040a5ac44094869452946807680d4304822dc44094869452946807680d43040efac34094869452946807680d430406c9c34094869452946807680d430426dac3409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243047aa8c44094869452946807680d43040a5ac44094869452946807680d4304822dc44094869452946807680d43040efac34094869452946807680d430406c9c34094869452946807680d430426dac3409486945294652e\"\n      }\n    },\n    \"learners/agent_13/weights_seq_no\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474000000000000000474008000000000000474010000000000000474014000000000000474018000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473ff0000000000000474000000000000000474008000000000000474010000000000000474014000000000000474018000000000000652e\"\n      }\n    },\n    \"learners/agent_13/total_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243046774703b94869452946807680d4304f747c0bd94869452946807680d4304e53b9bbd94869452946807680d43049e4d2abe94869452946807680d4304842ff2bd9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304193dcebd94869452946807680d43046774703b94869452946807680d4304f747c0bd94869452946807680d4304e53b9bbd94869452946807680d43049e4d2abe94869452946807680d4304842ff2bd9486945294652e\"\n      }\n    },\n    \"learners/agent_13/vf_explained_var\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304753b6b3f94869452946807680d430414396b3f94869452946807680d43048403693f94869452946807680d4304214d6b3f94869452946807680d43044a6d573f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ddf56e3f94869452946807680d4304753b6b3f94869452946807680d430414396b3f94869452946807680d43048403693f94869452946807680d4304214d6b3f94869452946807680d43044a6d573f9486945294652e\"\n      }\n    },\n    \"learners/agent_13/num_module_steps_trained_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a003a01004a00d701004a007402004a001103004a00ae0300652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953e000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d009d4a003a01004a00d701004a007402004a001103004a00ae0300652e\"\n      }\n    },\n    \"learners/agent_13/curr_kl_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000652e\"\n      }\n    },\n    \"learners/agent_13/mean_kl_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430434dc2b3c94869452946807680d43041dec2a3c94869452946807680d43040e7e153c94869452946807680d43048f02113c94869452946807680d43044d97093c9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243049897143c94869452946807680d430434dc2b3c94869452946807680d43041dec2a3c94869452946807680d43040e7e153c94869452946807680d43048f02113c94869452946807680d43044d97093c9486945294652e\"\n      }\n    },\n    \"learners/agent_13/num_module_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d009d4d009d4d009d4d009d4d009d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d009d4d009d4d009d4d009d4d009d4d009d652e\"\n      }\n    },\n    \"learners/agent_13/vf_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304de6e0d3a94869452946807680d43046e37b53994869452946807680d430480742d3a94869452946807680d43046d6f3e3a94869452946807680d4304abb2a33a9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304b4d6c73994869452946807680d4304de6e0d3a94869452946807680d43046e37b53994869452946807680d430480742d3a94869452946807680d43046d6f3e3a94869452946807680d4304abb2a33a9486945294652e\"\n      }\n    },\n    \"learners/agent_13/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f9486945294652e\"\n      }\n    },\n    \"learners/agent_13/vf_loss_unclipped\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304de6e0d3a94869452946807680d43046e37b53994869452946807680d430480742d3a94869452946807680d43046d6f3e3a94869452946807680d4304abb2a33a9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304b4d6c73994869452946807680d4304de6e0d3a94869452946807680d43046e37b53994869452946807680d430480742d3a94869452946807680d43046d6f3e3a94869452946807680d4304abb2a33a9486945294652e\"\n      }\n    },\n    \"learners/agent_13/curr_entropy_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    },\n    \"learners/agent_13/num_trainable_parameters\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b00652e\"\n      }\n    },\n    \"learners/agent_13/policy_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243048037873a94869452946807680d43041543c5bd94869452946807680d43048e53a0bd94869452946807680d430416dc2cbe94869452946807680d4304e62ef8bd9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304eebbd2bd94869452946807680d43048037873a94869452946807680d43041543c5bd94869452946807680d43048e53a0bd94869452946807680d430416dc2cbe94869452946807680d4304e62ef8bd9486945294652e\"\n      }\n    },\n    \"learners/agent_13/default_optimizer_learning_rate\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d652e\"\n      }\n    },\n    \"learners/agent_13/num_module_steps_trained_lifetime_throughput\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428477ff8000000000000474098eaf3d9e3c580474098eaa3144fe9d2474098e3a8ad295397474098df74a9866415652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428477ff8000000000000477ff8000000000000474098eaf3d9e3c580474098eaa3144fe9d2474098e3a8ad295397474098df74a9866415652e\"\n      }\n    },\n    \"learners/agent_8/total_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430408b285bd94869452946807680d4304fb8d76bd94869452946807680d4304f589f8bd94869452946807680d43046611f6bc94869452946807680d4304cb14a4bd9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243046b51b63d94869452946807680d430408b285bd94869452946807680d4304fb8d76bd94869452946807680d4304f589f8bd94869452946807680d43046611f6bc94869452946807680d4304cb14a4bd9486945294652e\"\n      }\n    },\n    \"learners/agent_8/vf_explained_var\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304e7c86f3f94869452946807680d4304bdd66f3f94869452946807680d430465fd653f94869452946807680d43049603703f94869452946807680d430499415f3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430450d7773f94869452946807680d4304e7c86f3f94869452946807680d4304bdd66f3f94869452946807680d430465fd653f94869452946807680d43049603703f94869452946807680d430499415f3f9486945294652e\"\n      }\n    },\n    \"learners/agent_8/num_module_steps_trained_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a003a01004a00d701004a007402004a001103004a00ae0300652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953e000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d009d4a003a01004a00d701004a007402004a001103004a00ae0300652e\"\n      }\n    },\n    \"learners/agent_8/curr_kl_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000652e\"\n      }\n    },\n    \"learners/agent_8/mean_kl_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243043527163c94869452946807680d43044d650e3c94869452946807680d43049a6f153c94869452946807680d43045ece0e3c94869452946807680d43048f7dfd3b9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304494c093c94869452946807680d43043527163c94869452946807680d43044d650e3c94869452946807680d43049a6f153c94869452946807680d43045ece0e3c94869452946807680d43048f7dfd3b9486945294652e\"\n      }\n    },\n    \"learners/agent_8/num_module_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d009d4d009d4d009d4d009d4d009d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d009d4d009d4d009d4d009d4d009d4d009d652e\"\n      }\n    },\n    \"learners/agent_8/vf_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430413ac833a94869452946807680d4304a39b883a94869452946807680d43040dfc6c3a94869452946807680d4304fecc113a94869452946807680d43049eb16e3a9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ce58543a94869452946807680d430413ac833a94869452946807680d4304a39b883a94869452946807680d43040dfc6c3a94869452946807680d4304fecc113a94869452946807680d43049eb16e3a9486945294652e\"\n      }\n    },\n    \"learners/agent_8/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f9486945294652e\"\n      }\n    },\n    \"learners/agent_8/curr_entropy_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    },\n    \"learners/agent_8/policy_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304b3818bbd94869452946807680d4304c1f880bd94869452946807680d43045220febd94869452946807680d4304d37304bd94869452946807680d43045a1da9bd9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304043ab13d94869452946807680d4304b3818bbd94869452946807680d4304c1f880bd94869452946807680d43045220febd94869452946807680d4304d37304bd94869452946807680d43045a1da9bd9486945294652e\"\n      }\n    },\n    \"learners/agent_8/vf_loss_unclipped\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430413ac833a94869452946807680d4304a39b883a94869452946807680d43040dfc6c3a94869452946807680d4304fecc113a94869452946807680d43049eb16e3a9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ce58543a94869452946807680d430413ac833a94869452946807680d4304a39b883a94869452946807680d43040dfc6c3a94869452946807680d4304fecc113a94869452946807680d43049eb16e3a9486945294652e\"\n      }\n    },\n    \"learners/agent_8/default_optimizer_learning_rate\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d652e\"\n      }\n    },\n    \"learners/agent_8/num_trainable_parameters\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b00652e\"\n      }\n    },\n    \"learners/agent_8/module_train_batch_size_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000652e\"\n      }\n    },\n    \"learners/agent_8/entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304d98cc44094869452946807680d4304ec7bc44094869452946807680d4304014cc44094869452946807680d43049b2fc44094869452946807680d43048218c4409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430417c3c44094869452946807680d4304d98cc44094869452946807680d4304ec7bc44094869452946807680d4304014cc44094869452946807680d43049b2fc44094869452946807680d43048218c4409486945294652e\"\n      }\n    },\n    \"learners/agent_8/weights_seq_no\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474000000000000000474008000000000000474010000000000000474014000000000000474018000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473ff0000000000000474000000000000000474008000000000000474010000000000000474014000000000000474018000000000000652e\"\n      }\n    },\n    \"learners/agent_8/num_module_steps_trained_lifetime_throughput\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428477ff8000000000000474098eaf5f4aad6a9474098eaa50d3daff4474098e3aaae903198474098df76665bf262652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428477ff8000000000000477ff8000000000000474098eaf5f4aad6a9474098eaa50d3daff4474098e3aaae903198474098df76665bf262652e\"\n      }\n    },\n    \"learners/agent_9/curr_entropy_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    },\n    \"learners/agent_9/policy_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304aea05fbe94869452946807680d4304588959bd94869452946807680d430407fce3bd94869452946807680d4304810593bd94869452946807680d43044d4317bd9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304062a13be94869452946807680d4304aea05fbe94869452946807680d4304588959bd94869452946807680d430407fce3bd94869452946807680d4304810593bd94869452946807680d43044d4317bd9486945294652e\"\n      }\n    },\n    \"learners/agent_9/vf_loss_unclipped\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430450eb7d3a94869452946807680d4304ca29013a94869452946807680d4304a2272a3a94869452946807680d430493e8933a94869452946807680d43049bfd173a9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243044ae6013b94869452946807680d430450eb7d3a94869452946807680d4304ca29013a94869452946807680d4304a2272a3a94869452946807680d430493e8933a94869452946807680d43049bfd173a9486945294652e\"\n      }\n    },\n    \"learners/agent_9/default_optimizer_learning_rate\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d652e\"\n      }\n    },\n    \"learners/agent_9/module_train_batch_size_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000652e\"\n      }\n    },\n    \"learners/agent_9/num_trainable_parameters\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b00652e\"\n      }\n    },\n    \"learners/agent_9/entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304e86ec44094869452946807680d43044962c44094869452946807680d43047f43c44094869452946807680d4304efffc34094869452946807680d43042fccc3409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304eaa6c44094869452946807680d4304e86ec44094869452946807680d43044962c44094869452946807680d43047f43c44094869452946807680d4304efffc34094869452946807680d43042fccc3409486945294652e\"\n      }\n    },\n    \"learners/agent_9/weights_seq_no\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474000000000000000474008000000000000474010000000000000474014000000000000474018000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473ff0000000000000474000000000000000474008000000000000474010000000000000474014000000000000474018000000000000652e\"\n      }\n    },\n    \"learners/agent_9/total_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304f4b75cbe94869452946807680d430404ba4fbd94869452946807680d43044caddebd94869452946807680d430416418dbd94869452946807680d4304e03a0dbd9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430407330fbe94869452946807680d4304f4b75cbe94869452946807680d430404ba4fbd94869452946807680d43044caddebd94869452946807680d430416418dbd94869452946807680d4304e03a0dbd9486945294652e\"\n      }\n    },\n    \"learners/agent_9/vf_explained_var\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430430ef6f3f94869452946807680d4304aa23713f94869452946807680d43045f6c703f94869452946807680d4304e761643f94869452946807680d4304328e703f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304c078693f94869452946807680d430430ef6f3f94869452946807680d4304aa23713f94869452946807680d43045f6c703f94869452946807680d4304e761643f94869452946807680d4304328e703f9486945294652e\"\n      }\n    },\n    \"learners/agent_9/num_module_steps_trained_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a003a01004a00d701004a007402004a001103004a00ae0300652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953e000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d009d4a003a01004a00d701004a007402004a001103004a00ae0300652e\"\n      }\n    },\n    \"learners/agent_9/curr_kl_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000652e\"\n      }\n    },\n    \"learners/agent_9/mean_kl_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243048260193c94869452946807680d4304c6d51b3c94869452946807680d4304ce201f3c94869452946807680d4304643f0a3c94869452946807680d43046229193c9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430421d01a3c94869452946807680d43048260193c94869452946807680d4304c6d51b3c94869452946807680d4304ce201f3c94869452946807680d4304643f0a3c94869452946807680d43046229193c9486945294652e\"\n      }\n    },\n    \"learners/agent_9/num_module_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d009d4d009d4d009d4d009d4d009d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d009d4d009d4d009d4d009d4d009d4d009d652e\"\n      }\n    },\n    \"learners/agent_9/vf_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430450eb7d3a94869452946807680d4304ca29013a94869452946807680d4304a2272a3a94869452946807680d430493e8933a94869452946807680d43049bfd173a9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243044ae6013b94869452946807680d430450eb7d3a94869452946807680d4304ca29013a94869452946807680d4304a2272a3a94869452946807680d430493e8933a94869452946807680d43049bfd173a9486945294652e\"\n      }\n    },\n    \"learners/agent_9/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f9486945294652e\"\n      }\n    },\n    \"learners/agent_9/num_module_steps_trained_lifetime_throughput\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428477ff8000000000000474098eaeee7473f78474098ea9e452be8d6474098e3a43e941f4c474098df70b63d0013652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428477ff8000000000000477ff8000000000000474098eaeee7473f78474098ea9e452be8d6474098e3a43e941f4c474098df70b63d0013652e\"\n      }\n    },\n    \"learners/agent_1/module_train_batch_size_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000652e\"\n      }\n    },\n    \"learners/agent_1/entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243041882c44094869452946807680d43046877c44094869452946807680d4304b85bc44094869452946807680d43045731c44094869452946807680d43041523c4409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243049eadc44094869452946807680d43041882c44094869452946807680d43046877c44094869452946807680d4304b85bc44094869452946807680d43045731c44094869452946807680d43041523c4409486945294652e\"\n      }\n    },\n    \"learners/agent_1/weights_seq_no\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474000000000000000474008000000000000474010000000000000474014000000000000474018000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473ff0000000000000474000000000000000474008000000000000474010000000000000474014000000000000474018000000000000652e\"\n      }\n    },\n    \"learners/agent_1/total_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304261c28be94869452946807680d4304f37cd5bd94869452946807680d4304c9a42fbe94869452946807680d4304d43680bd94869452946807680d430402a3b9bd9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430496b0ccbd94869452946807680d4304261c28be94869452946807680d4304f37cd5bd94869452946807680d4304c9a42fbe94869452946807680d4304d43680bd94869452946807680d430402a3b9bd9486945294652e\"\n      }\n    },\n    \"learners/agent_1/vf_explained_var\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243041e8d403f94869452946807680d430427d56b3f94869452946807680d430483df493f94869452946807680d4304c0c4583f94869452946807680d43044020623f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243042f0e623f94869452946807680d43041e8d403f94869452946807680d430427d56b3f94869452946807680d430483df493f94869452946807680d4304c0c4583f94869452946807680d43044020623f9486945294652e\"\n      }\n    },\n    \"learners/agent_1/num_module_steps_trained_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a003a01004a00d701004a007402004a001103004a00ae0300652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953e000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d009d4a003a01004a00d701004a007402004a001103004a00ae0300652e\"\n      }\n    },\n    \"learners/agent_1/curr_kl_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000652e\"\n      }\n    },\n    \"learners/agent_1/mean_kl_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304b2ec193c94869452946807680d43049f2e043c94869452946807680d430441ad013c94869452946807680d4304ee49023c94869452946807680d430400620c3c9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304bed2133c94869452946807680d4304b2ec193c94869452946807680d43049f2e043c94869452946807680d430441ad013c94869452946807680d4304ee49023c94869452946807680d430400620c3c9486945294652e\"\n      }\n    },\n    \"learners/agent_1/num_module_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d009d4d009d4d009d4d009d4d009d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d009d4d009d4d009d4d009d4d009d4d009d652e\"\n      }\n    },\n    \"learners/agent_1/vf_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304426a063c94869452946807680d430423dba23a94869452946807680d4304187d253b94869452946807680d4304c85aa43a94869452946807680d4304ac092d3a9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243048cce2b3b94869452946807680d4304426a063c94869452946807680d430423dba23a94869452946807680d4304187d253b94869452946807680d4304c85aa43a94869452946807680d4304ac092d3a9486945294652e\"\n      }\n    },\n    \"learners/agent_1/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f9486945294652e\"\n      }\n    },\n    \"learners/agent_1/vf_loss_unclipped\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304426a063c94869452946807680d430423dba23a94869452946807680d4304187d253b94869452946807680d4304c85aa43a94869452946807680d4304ac092d3a9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243048cce2b3b94869452946807680d4304426a063c94869452946807680d430423dba23a94869452946807680d4304187d253b94869452946807680d4304c85aa43a94869452946807680d4304ac092d3a9486945294652e\"\n      }\n    },\n    \"learners/agent_1/curr_entropy_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    },\n    \"learners/agent_1/num_trainable_parameters\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b00652e\"\n      }\n    },\n    \"learners/agent_1/policy_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304596f32be94869452946807680d43045656dbbd94869452946807680d4304b4d933be94869452946807680d4304180a86bd94869452946807680d4304887fbebd9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243041dc1d5bd94869452946807680d4304596f32be94869452946807680d43045656dbbd94869452946807680d4304b4d933be94869452946807680d4304180a86bd94869452946807680d4304887fbebd9486945294652e\"\n      }\n    },\n    \"learners/agent_1/default_optimizer_learning_rate\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d652e\"\n      }\n    },\n    \"learners/agent_1/num_module_steps_trained_lifetime_throughput\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428477ff8000000000000474098eaf39df15ca5474098eaa2d865ce10474098e3a87502bb7a474098df74737ec729652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428477ff8000000000000477ff8000000000000474098eaf39df15ca5474098eaa2d865ce10474098e3a87502bb7a474098df74737ec729652e\"\n      }\n    },\n    \"learners/agent_19/vf_explained_var\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304e317653f94869452946807680d4304a30c633f94869452946807680d4304b59c5e3f94869452946807680d4304026c4e3f94869452946807680d430428114f3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430408be5f3f94869452946807680d4304e317653f94869452946807680d4304a30c633f94869452946807680d4304b59c5e3f94869452946807680d4304026c4e3f94869452946807680d430428114f3f9486945294652e\"\n      }\n    },\n    \"learners/agent_19/num_module_steps_trained_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a003a01004a00d701004a007402004a001103004a00ae0300652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953e000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d009d4a003a01004a00d701004a007402004a001103004a00ae0300652e\"\n      }\n    },\n    \"learners/agent_19/curr_kl_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000652e\"\n      }\n    },\n    \"learners/agent_19/mean_kl_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304fcc6023c94869452946807680d4304015cf73b94869452946807680d4304c5c3fd3b94869452946807680d4304fab1f13b94869452946807680d4304491b003c9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243041fd9fe3b94869452946807680d4304fcc6023c94869452946807680d4304015cf73b94869452946807680d4304c5c3fd3b94869452946807680d4304fab1f13b94869452946807680d4304491b003c9486945294652e\"\n      }\n    },\n    \"learners/agent_19/num_module_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d009d4d009d4d009d4d009d4d009d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d009d4d009d4d009d4d009d4d009d4d009d652e\"\n      }\n    },\n    \"learners/agent_19/vf_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304c3cfd83a94869452946807680d4304ac0d933a94869452946807680d43046f019a3a94869452946807680d430462c0013b94869452946807680d43049c4ce93a9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243042900f73a94869452946807680d4304c3cfd83a94869452946807680d4304ac0d933a94869452946807680d43046f019a3a94869452946807680d430462c0013b94869452946807680d43049c4ce93a9486945294652e\"\n      }\n    },\n    \"learners/agent_19/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f9486945294652e\"\n      }\n    },\n    \"learners/agent_19/curr_entropy_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    },\n    \"learners/agent_19/policy_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304d4bc07be94869452946807680d4304dd6f24be94869452946807680d43048efa93bd94869452946807680d4304b7cca1bd94869452946807680d43047d0ad5bd9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304e52437bd94869452946807680d4304d4bc07be94869452946807680d4304dd6f24be94869452946807680d43048efa93bd94869452946807680d4304b7cca1bd94869452946807680d43047d0ad5bd9486945294652e\"\n      }\n    },\n    \"learners/agent_19/vf_loss_unclipped\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304c3cfd83a94869452946807680d4304ac0d933a94869452946807680d43046f019a3a94869452946807680d430462c0013b94869452946807680d43049c4ce93a9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243042900f73a94869452946807680d4304c3cfd83a94869452946807680d4304ac0d933a94869452946807680d43046f019a3a94869452946807680d430462c0013b94869452946807680d43049c4ce93a9486945294652e\"\n      }\n    },\n    \"learners/agent_19/default_optimizer_learning_rate\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d652e\"\n      }\n    },\n    \"learners/agent_19/module_train_batch_size_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000652e\"\n      }\n    },\n    \"learners/agent_19/num_trainable_parameters\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284ae5e604004ae5e604004ae5e604004ae5e604004ae5e60400652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284ae5e604004ae5e604004ae5e604004ae5e604004ae5e604004ae5e60400652e\"\n      }\n    },\n    \"learners/agent_19/entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040a3ac44094869452946807680d4304b80ac44094869452946807680d430401e3c34094869452946807680d43040eb6c34094869452946807680d43046385c3409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304a87bc44094869452946807680d43040a3ac44094869452946807680d4304b80ac44094869452946807680d430401e3c34094869452946807680d43040eb6c34094869452946807680d43046385c3409486945294652e\"\n      }\n    },\n    \"learners/agent_19/weights_seq_no\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474000000000000000474008000000000000474010000000000000474014000000000000474018000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473ff0000000000000474000000000000000474008000000000000474010000000000000474014000000000000474018000000000000652e\"\n      }\n    },\n    \"learners/agent_19/total_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304b76804be94869452946807680d4304fcbd21be94869452946807680d43047c668ebd94869452946807680d430446b99abd94869452946807680d43046a31cebd9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304de0d29bd94869452946807680d4304b76804be94869452946807680d4304fcbd21be94869452946807680d43047c668ebd94869452946807680d430446b99abd94869452946807680d43046a31cebd9486945294652e\"\n      }\n    },\n    \"learners/agent_19/num_module_steps_trained_lifetime_throughput\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428477ff8000000000000474098eaf69f4daabd474098eaa5a6ae011d474098e3ab45d36dea474098df76ecad8502652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428477ff8000000000000477ff8000000000000474098eaf69f4daabd474098eaa5a6ae011d474098e3ab45d36dea474098df76ecad8502652e\"\n      }\n    },\n    \"learners/agent_17/vf_explained_var\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ef9a6b3f94869452946807680d4304b3325d3f94869452946807680d4304437a643f94869452946807680d430414396c3f94869452946807680d4304f9254e3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430414e6523f94869452946807680d4304ef9a6b3f94869452946807680d4304b3325d3f94869452946807680d4304437a643f94869452946807680d430414396c3f94869452946807680d4304f9254e3f9486945294652e\"\n      }\n    },\n    \"learners/agent_17/num_module_steps_trained_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a003a01004a00d701004a007402004a001103004a00ae0300652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953e000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d009d4a003a01004a00d701004a007402004a001103004a00ae0300652e\"\n      }\n    },\n    \"learners/agent_17/curr_kl_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000652e\"\n      }\n    },\n    \"learners/agent_17/mean_kl_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430411c6f33b94869452946807680d4304dc3ef43b94869452946807680d4304ba9fec3b94869452946807680d43049803ef3b94869452946807680d4304d0c4f13b9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304af4ceb3b94869452946807680d430411c6f33b94869452946807680d4304dc3ef43b94869452946807680d4304ba9fec3b94869452946807680d43049803ef3b94869452946807680d4304d0c4f13b9486945294652e\"\n      }\n    },\n    \"learners/agent_17/vf_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243047021ef3a94869452946807680d4304164fb23a94869452946807680d43040dbcbc3a94869452946807680d4304e69a923a94869452946807680d4304d675983a9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040adc4b3b94869452946807680d43047021ef3a94869452946807680d4304164fb23a94869452946807680d43040dbcbc3a94869452946807680d4304e69a923a94869452946807680d4304d675983a9486945294652e\"\n      }\n    },\n    \"learners/agent_17/vf_loss_unclipped\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243047021ef3a94869452946807680d4304164fb23a94869452946807680d43040dbcbc3a94869452946807680d4304e69a923a94869452946807680d4304d675983a9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040adc4b3b94869452946807680d43047021ef3a94869452946807680d4304164fb23a94869452946807680d43040dbcbc3a94869452946807680d4304e69a923a94869452946807680d4304d675983a9486945294652e\"\n      }\n    },\n    \"learners/agent_17/default_optimizer_learning_rate\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d652e\"\n      }\n    },\n    \"learners/agent_17/curr_entropy_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    },\n    \"learners/agent_17/num_trainable_parameters\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284ae5e604004ae5e604004ae5e604004ae5e604004ae5e60400652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284ae5e604004ae5e604004ae5e604004ae5e604004ae5e604004ae5e60400652e\"\n      }\n    },\n    \"learners/agent_17/policy_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243042638f2bd94869452946807680d4304f995a33c94869452946807680d4304ccd516bd94869452946807680d4304fe4b31be94869452946807680d430470418abd9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304e85cc0bd94869452946807680d43042638f2bd94869452946807680d4304f995a33c94869452946807680d4304ccd516bd94869452946807680d4304fe4b31be94869452946807680d430470418abd9486945294652e\"\n      }\n    },\n    \"learners/agent_17/weights_seq_no\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474000000000000000474008000000000000474010000000000000474014000000000000474018000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473ff0000000000000474000000000000000474008000000000000474010000000000000474014000000000000474018000000000000652e\"\n      }\n    },\n    \"learners/agent_17/total_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243048d6febbd94869452946807680d430441f1ba3c94869452946807680d430488050bbd94869452946807680d43045da82ebe94869452946807680d4304efd984bd9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304130db7bd94869452946807680d43048d6febbd94869452946807680d430441f1ba3c94869452946807680d430488050bbd94869452946807680d43045da82ebe94869452946807680d4304efd984bd9486945294652e\"\n      }\n    },\n    \"learners/agent_17/module_train_batch_size_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000652e\"\n      }\n    },\n    \"learners/agent_17/num_module_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d009d4d009d4d009d4d009d4d009d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d009d4d009d4d009d4d009d4d009d4d009d652e\"\n      }\n    },\n    \"learners/agent_17/entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243049938c44094869452946807680d43049a18c44094869452946807680d4304e7eec34094869452946807680d4304d2d5c34094869452946807680d4304b8acc3409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304de5bc44094869452946807680d43049938c44094869452946807680d43049a18c44094869452946807680d4304e7eec34094869452946807680d4304d2d5c34094869452946807680d4304b8acc3409486945294652e\"\n      }\n    },\n    \"learners/agent_17/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f9486945294652e\"\n      }\n    },\n    \"learners/agent_17/num_module_steps_trained_lifetime_throughput\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428477ff8000000000000474098eaf68c648a7f474098eaa594ad9c30474098e3ab34a7cab8474098df76dc1858da652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428477ff8000000000000477ff8000000000000474098eaf68c648a7f474098eaa594ad9c30474098e3ab34a7cab8474098df76dc1858da652e\"\n      }\n    },\n    \"learners/agent_3/curr_kl_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000652e\"\n      }\n    },\n    \"learners/agent_3/vf_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243041e8cd83994869452946807680d4304cf7fdc3994869452946807680d4304e2a1bc3994869452946807680d430493372b3a94869452946807680d4304ad251c3a9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304d947003a94869452946807680d43041e8cd83994869452946807680d4304cf7fdc3994869452946807680d4304e2a1bc3994869452946807680d430493372b3a94869452946807680d4304ad251c3a9486945294652e\"\n      }\n    },\n    \"learners/agent_3/vf_loss_unclipped\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243041e8cd83994869452946807680d4304cf7fdc3994869452946807680d4304e2a1bc3994869452946807680d430493372b3a94869452946807680d4304ad251c3a9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304d947003a94869452946807680d43041e8cd83994869452946807680d4304cf7fdc3994869452946807680d4304e2a1bc3994869452946807680d430493372b3a94869452946807680d4304ad251c3a9486945294652e\"\n      }\n    },\n    \"learners/agent_3/default_optimizer_learning_rate\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d652e\"\n      }\n    },\n    \"learners/agent_3/curr_entropy_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    },\n    \"learners/agent_3/num_trainable_parameters\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b00652e\"\n      }\n    },\n    \"learners/agent_3/policy_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430435341fbe94869452946807680d430410dccfbd94869452946807680d43044cf996bd94869452946807680d430466f5dcbd94869452946807680d4304117a23bd9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243045f1f2dbe94869452946807680d430435341fbe94869452946807680d430410dccfbd94869452946807680d43044cf996bd94869452946807680d430466f5dcbd94869452946807680d4304117a23bd9486945294652e\"\n      }\n    },\n    \"learners/agent_3/entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243044c61c44094869452946807680d43047a38c44094869452946807680d4304870ec44094869452946807680d43040ce3c34094869452946807680d430460c5c3409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243045e8ec44094869452946807680d43044c61c44094869452946807680d43047a38c44094869452946807680d4304870ec44094869452946807680d43040ce3c34094869452946807680d430460c5c3409486945294652e\"\n      }\n    },\n    \"learners/agent_3/weights_seq_no\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474000000000000000474008000000000000474010000000000000474014000000000000474018000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473ff0000000000000474000000000000000474008000000000000474010000000000000474014000000000000474018000000000000652e\"\n      }\n    },\n    \"learners/agent_3/total_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304f7e31cbe94869452946807680d43047f58cbbd94869452946807680d43049c7392bd94869452946807680d4304990dd8bd94869452946807680d43043ce118bd9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430467c02abe94869452946807680d4304f7e31cbe94869452946807680d43047f58cbbd94869452946807680d43049c7392bd94869452946807680d4304990dd8bd94869452946807680d43043ce118bd9486945294652e\"\n      }\n    },\n    \"learners/agent_3/num_module_steps_trained_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a003a01004a00d701004a007402004a001103004a00ae0300652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953e000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d009d4a003a01004a00d701004a007402004a001103004a00ae0300652e\"\n      }\n    },\n    \"learners/agent_3/module_train_batch_size_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000652e\"\n      }\n    },\n    \"learners/agent_3/mean_kl_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243047e3d173c94869452946807680d4304961a123c94869452946807680d4304616a173c94869452946807680d4304adb60e3c94869452946807680d4304fe24233c9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304e796153c94869452946807680d43047e3d173c94869452946807680d4304961a123c94869452946807680d4304616a173c94869452946807680d4304adb60e3c94869452946807680d4304fe24233c9486945294652e\"\n      }\n    },\n    \"learners/agent_3/num_module_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d009d4d009d4d009d4d009d4d009d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d009d4d009d4d009d4d009d4d009d4d009d652e\"\n      }\n    },\n    \"learners/agent_3/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f9486945294652e\"\n      }\n    },\n    \"learners/agent_3/vf_explained_var\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243044e0b753f94869452946807680d4304029c713f94869452946807680d43041547713f94869452946807680d4304dc1f6a3f94869452946807680d4304af776f3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243048bef753f94869452946807680d43044e0b753f94869452946807680d4304029c713f94869452946807680d43041547713f94869452946807680d4304dc1f6a3f94869452946807680d4304af776f3f9486945294652e\"\n      }\n    },\n    \"learners/agent_3/num_module_steps_trained_lifetime_throughput\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428477ff8000000000000474098eaefc7ebaf7c474098ea9f1b4833a3474098e3a504dfc305474098df7160d354d9652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428477ff8000000000000477ff8000000000000474098eaefc7ebaf7c474098ea9f1b4833a3474098e3a504dfc305474098df7160d354d9652e\"\n      }\n    },\n    \"learners/agent_15/total_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304dc51673d94869452946807680d4304524d3fbe94869452946807680d43040ecd6dbd94869452946807680d4304ede09abd94869452946807680d43041c7dc6bd9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243042c408b3d94869452946807680d4304dc51673d94869452946807680d4304524d3fbe94869452946807680d43040ecd6dbd94869452946807680d4304ede09abd94869452946807680d43041c7dc6bd9486945294652e\"\n      }\n    },\n    \"learners/agent_15/vf_explained_var\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304d66d623f94869452946807680d43048c685f3f94869452946807680d430446d94d3f94869452946807680d43048101603f94869452946807680d43045cc9603f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243047a81673f94869452946807680d4304d66d623f94869452946807680d43048c685f3f94869452946807680d430446d94d3f94869452946807680d43048101603f94869452946807680d43045cc9603f9486945294652e\"\n      }\n    },\n    \"learners/agent_15/num_module_steps_trained_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a003a01004a00d701004a007402004a001103004a00ae0300652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953e000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d009d4a003a01004a00d701004a007402004a001103004a00ae0300652e\"\n      }\n    },\n    \"learners/agent_15/curr_kl_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000652e\"\n      }\n    },\n    \"learners/agent_15/mean_kl_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304b694f13b94869452946807680d43048f45f33b94869452946807680d43048d1df23b94869452946807680d43046e2fee3b94869452946807680d4304e4daef3b9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430456daf33b94869452946807680d4304b694f13b94869452946807680d43048f45f33b94869452946807680d43048d1df23b94869452946807680d43046e2fee3b94869452946807680d4304e4daef3b9486945294652e\"\n      }\n    },\n    \"learners/agent_15/num_module_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d009d4d009d4d009d4d009d4d009d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d009d4d009d4d009d4d009d4d009d4d009d652e\"\n      }\n    },\n    \"learners/agent_15/vf_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ccefc73a94869452946807680d43040ea7003b94869452946807680d4304c018033b94869452946807680d430427df063b94869452946807680d430402e7c13a9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430476cfc63a94869452946807680d4304ccefc73a94869452946807680d43040ea7003b94869452946807680d4304c018033b94869452946807680d430427df063b94869452946807680d430402e7c13a9486945294652e\"\n      }\n    },\n    \"learners/agent_15/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f9486945294652e\"\n      }\n    },\n    \"learners/agent_15/vf_loss_unclipped\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ccefc73a94869452946807680d43040ea7003b94869452946807680d4304c018033b94869452946807680d430427df063b94869452946807680d430402e7c13a9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430476cfc63a94869452946807680d4304ccefc73a94869452946807680d43040ea7003b94869452946807680d4304c018033b94869452946807680d430427df063b94869452946807680d430402e7c13a9486945294652e\"\n      }\n    },\n    \"learners/agent_15/curr_entropy_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    },\n    \"learners/agent_15/num_trainable_parameters\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284ae5e604004ae5e604004ae5e604004ae5e604004ae5e60400652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284ae5e604004ae5e604004ae5e604004ae5e604004ae5e604004ae5e60400652e\"\n      }\n    },\n    \"learners/agent_15/policy_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243043e085b3d94869452946807680d43042ad542be94869452946807680d4304210c7cbd94869452946807680d43041612a2bd94869452946807680d43043f84ccbd9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243049a18853d94869452946807680d43043e085b3d94869452946807680d43042ad542be94869452946807680d4304210c7cbd94869452946807680d43041612a2bd94869452946807680d43043f84ccbd9486945294652e\"\n      }\n    },\n    \"learners/agent_15/default_optimizer_learning_rate\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d652e\"\n      }\n    },\n    \"learners/agent_15/module_train_batch_size_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000652e\"\n      }\n    },\n    \"learners/agent_15/entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304875cc44094869452946807680d43046b44c44094869452946807680d4304bd1ec44094869452946807680d430494e8c34094869452946807680d430448d1c3409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304b974c44094869452946807680d4304875cc44094869452946807680d43046b44c44094869452946807680d4304bd1ec44094869452946807680d430494e8c34094869452946807680d430448d1c3409486945294652e\"\n      }\n    },\n    \"learners/agent_15/weights_seq_no\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474000000000000000474008000000000000474010000000000000474014000000000000474018000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473ff0000000000000474000000000000000474008000000000000474010000000000000474014000000000000474018000000000000652e\"\n      }\n    },\n    \"learners/agent_15/num_module_steps_trained_lifetime_throughput\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428477ff8000000000000474098eaf5af61bca5474098eaa4ca713177474098e3aa6ff16612474098df7629da60b9652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428477ff8000000000000477ff8000000000000474098eaf5af61bca5474098eaa4ca713177474098e3aa6ff16612474098df7629da60b9652e\"\n      }\n    },\n    \"learners/agent_12/total_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304c9a4043d94869452946807680d43048593aebd94869452946807680d4304b87ce2bd94869452946807680d430431b6a2bd94869452946807680d4304d9e4abbd9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304353528be94869452946807680d4304c9a4043d94869452946807680d43048593aebd94869452946807680d4304b87ce2bd94869452946807680d430431b6a2bd94869452946807680d4304d9e4abbd9486945294652e\"\n      }\n    },\n    \"learners/agent_12/num_module_steps_trained_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a003a01004a00d701004a007402004a001103004a00ae0300652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953e000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d009d4a003a01004a00d701004a007402004a001103004a00ae0300652e\"\n      }\n    },\n    \"learners/agent_12/module_train_batch_size_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000652e\"\n      }\n    },\n    \"learners/agent_12/num_module_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d009d4d009d4d009d4d009d4d009d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d009d4d009d4d009d4d009d4d009d4d009d652e\"\n      }\n    },\n    \"learners/agent_12/entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243049e83c44094869452946807680d43045c70c44094869452946807680d43040043c44094869452946807680d43046822c44094869452946807680d43045209c4409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430490a5c44094869452946807680d43049e83c44094869452946807680d43045c70c44094869452946807680d43040043c44094869452946807680d43046822c44094869452946807680d43045209c4409486945294652e\"\n      }\n    },\n    \"learners/agent_12/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f9486945294652e\"\n      }\n    },\n    \"learners/agent_12/vf_explained_var\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040263673f94869452946807680d430409666e3f94869452946807680d4304bce2703f94869452946807680d430400af6a3f94869452946807680d430421406d3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040040733f94869452946807680d43040263673f94869452946807680d430409666e3f94869452946807680d4304bce2703f94869452946807680d430400af6a3f94869452946807680d430421406d3f9486945294652e\"\n      }\n    },\n    \"learners/agent_12/curr_kl_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000652e\"\n      }\n    },\n    \"learners/agent_12/mean_kl_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304d4f5193c94869452946807680d430464c90f3c94869452946807680d43048631113c94869452946807680d43043ba3033c94869452946807680d4304b175163c9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243047a7c1f3c94869452946807680d4304d4f5193c94869452946807680d430464c90f3c94869452946807680d43048631113c94869452946807680d43043ba3033c94869452946807680d4304b175163c9486945294652e\"\n      }\n    },\n    \"learners/agent_12/vf_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243049e1e393a94869452946807680d4304157d223a94869452946807680d4304887b393a94869452946807680d43042ee8113a94869452946807680d4304c025e9399486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430442e0283a94869452946807680d43049e1e393a94869452946807680d4304157d223a94869452946807680d4304887b393a94869452946807680d43042ee8113a94869452946807680d4304c025e9399486945294652e\"\n      }\n    },\n    \"learners/agent_12/vf_loss_unclipped\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243049e1e393a94869452946807680d4304157d223a94869452946807680d4304887b393a94869452946807680d43042ee8113a94869452946807680d4304c025e9399486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430442e0283a94869452946807680d43049e1e393a94869452946807680d4304157d223a94869452946807680d4304887b393a94869452946807680d43042ee8113a94869452946807680d4304c025e9399486945294652e\"\n      }\n    },\n    \"learners/agent_12/default_optimizer_learning_rate\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d652e\"\n      }\n    },\n    \"learners/agent_12/curr_entropy_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    },\n    \"learners/agent_12/num_trainable_parameters\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b00652e\"\n      }\n    },\n    \"learners/agent_12/policy_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243043b1bf43c94869452946807680d4304ba70b3bd94869452946807680d4304ed90e7bd94869452946807680d43047e24a7bd94869452946807680d4304f090b0bd9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430470dc2abe94869452946807680d43043b1bf43c94869452946807680d4304ba70b3bd94869452946807680d4304ed90e7bd94869452946807680d43047e24a7bd94869452946807680d4304f090b0bd9486945294652e\"\n      }\n    },\n    \"learners/agent_12/weights_seq_no\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474000000000000000474008000000000000474010000000000000474014000000000000474018000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473ff0000000000000474000000000000000474008000000000000474010000000000000474014000000000000474018000000000000652e\"\n      }\n    },\n    \"learners/agent_12/num_module_steps_trained_lifetime_throughput\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428477ff8000000000000474098eaf568b3b964474098eaa4889c9752474098e3aa28b31ba4474098df75f0d1c7cb652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428477ff8000000000000477ff8000000000000474098eaf568b3b964474098eaa4889c9752474098e3aa28b31ba4474098df75f0d1c7cb652e\"\n      }\n    },\n    \"learners/agent_18/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f9486945294652e\"\n      }\n    },\n    \"learners/agent_18/vf_explained_var\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304c2b7623f94869452946807680d430400a45c3f94869452946807680d43041c5e663f94869452946807680d430499bc403f94869452946807680d4304de69413f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304d609723f94869452946807680d4304c2b7623f94869452946807680d430400a45c3f94869452946807680d43041c5e663f94869452946807680d430499bc403f94869452946807680d4304de69413f9486945294652e\"\n      }\n    },\n    \"learners/agent_18/num_module_steps_trained_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a003a01004a00d701004a007402004a001103004a00ae0300652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953e000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d009d4a003a01004a00d701004a007402004a001103004a00ae0300652e\"\n      }\n    },\n    \"learners/agent_18/curr_kl_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000652e\"\n      }\n    },\n    \"learners/agent_18/mean_kl_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243046ec0fa3b94869452946807680d4304f244f63b94869452946807680d4304104cf53b94869452946807680d4304fb47f73b94869452946807680d430464be013c9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304e8cdf93b94869452946807680d43046ec0fa3b94869452946807680d4304f244f63b94869452946807680d4304104cf53b94869452946807680d4304fb47f73b94869452946807680d430464be013c9486945294652e\"\n      }\n    },\n    \"learners/agent_18/vf_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304cae4903a94869452946807680d4304dddaa43a94869452946807680d43046205813a94869452946807680d4304883e103b94869452946807680d43040a680d3b9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430484b1963a94869452946807680d4304cae4903a94869452946807680d4304dddaa43a94869452946807680d43046205813a94869452946807680d4304883e103b94869452946807680d43040a680d3b9486945294652e\"\n      }\n    },\n    \"learners/agent_18/vf_loss_unclipped\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304cae4903a94869452946807680d4304dddaa43a94869452946807680d43046205813a94869452946807680d4304883e103b94869452946807680d43040a680d3b9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430484b1963a94869452946807680d4304cae4903a94869452946807680d4304dddaa43a94869452946807680d43046205813a94869452946807680d4304883e103b94869452946807680d43040a680d3b9486945294652e\"\n      }\n    },\n    \"learners/agent_18/default_optimizer_learning_rate\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d652e\"\n      }\n    },\n    \"learners/agent_18/curr_entropy_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    },\n    \"learners/agent_18/num_trainable_parameters\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284ae5e604004ae5e604004ae5e604004ae5e604004ae5e60400652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284ae5e604004ae5e604004ae5e604004ae5e604004ae5e604004ae5e60400652e\"\n      }\n    },\n    \"learners/agent_18/policy_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ca4b14be94869452946807680d4304f8c631bc94869452946807680d4304b72ee83b94869452946807680d4304f4c7b1bb94869452946807680d4304f50287bd9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430467c80bbd94869452946807680d4304ca4b14be94869452946807680d4304f8c631bc94869452946807680d4304b72ee83b94869452946807680d4304f4c7b1bb94869452946807680d4304f50287bd9486945294652e\"\n      }\n    },\n    \"learners/agent_18/weights_seq_no\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474000000000000000474008000000000000474010000000000000474014000000000000474018000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473ff0000000000000474000000000000000474008000000000000474010000000000000474014000000000000474018000000000000652e\"\n      }\n    },\n    \"learners/agent_18/total_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304cc9811be94869452946807680d43041f8b04bc94869452946807680d43049fbf1c3c94869452946807680d430411d0e0ba94869452946807680d4304b0b27ebd9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430419d400bd94869452946807680d4304cc9811be94869452946807680d43041f8b04bc94869452946807680d43049fbf1c3c94869452946807680d430411d0e0ba94869452946807680d4304b0b27ebd9486945294652e\"\n      }\n    },\n    \"learners/agent_18/module_train_batch_size_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000652e\"\n      }\n    },\n    \"learners/agent_18/num_module_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d009d4d009d4d009d4d009d4d009d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d009d4d009d4d009d4d009d4d009d4d009d652e\"\n      }\n    },\n    \"learners/agent_18/entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243047d4dc44094869452946807680d4304042bc44094869452946807680d43049512c44094869452946807680d4304e4f6c34094869452946807680d430472b3c3409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243048794c44094869452946807680d43047d4dc44094869452946807680d4304042bc44094869452946807680d43049512c44094869452946807680d4304e4f6c34094869452946807680d430472b3c3409486945294652e\"\n      }\n    },\n    \"learners/agent_18/num_module_steps_trained_lifetime_throughput\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428477ff8000000000000474098eaf589dc5e00474098eaa4a7bb88eb474098e3aa4811ca27474098df760a69f072652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428477ff8000000000000477ff8000000000000474098eaf589dc5e00474098eaa4a7bb88eb474098e3aa4811ca27474098df760a69f072652e\"\n      }\n    },\n    \"learners/agent_7/num_module_steps_trained_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a003a01004a00d701004a007402004a001103004a00ae0300652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953e000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d009d4a003a01004a00d701004a007402004a001103004a00ae0300652e\"\n      }\n    },\n    \"learners/agent_7/curr_kl_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000652e\"\n      }\n    },\n    \"learners/agent_7/mean_kl_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304d52a103c94869452946807680d4304b215223c94869452946807680d4304c4e9043c94869452946807680d430408a10d3c94869452946807680d430496db203c9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243041bf5233c94869452946807680d4304d52a103c94869452946807680d4304b215223c94869452946807680d4304c4e9043c94869452946807680d430408a10d3c94869452946807680d430496db203c9486945294652e\"\n      }\n    },\n    \"learners/agent_7/num_module_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d009d4d009d4d009d4d009d4d009d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d009d4d009d4d009d4d009d4d009d4d009d652e\"\n      }\n    },\n    \"learners/agent_7/vf_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304dbbb183b94869452946807680d43042c410f3a94869452946807680d430475fe0f3a94869452946807680d4304158ce03994869452946807680d43044f8f433a9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243042557863a94869452946807680d4304dbbb183b94869452946807680d43042c410f3a94869452946807680d430475fe0f3a94869452946807680d4304158ce03994869452946807680d43044f8f433a9486945294652e\"\n      }\n    },\n    \"learners/agent_7/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f9486945294652e\"\n      }\n    },\n    \"learners/agent_7/vf_loss_unclipped\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304dbbb183b94869452946807680d43042c410f3a94869452946807680d430475fe0f3a94869452946807680d4304158ce03994869452946807680d43044f8f433a9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243042557863a94869452946807680d4304dbbb183b94869452946807680d43042c410f3a94869452946807680d430475fe0f3a94869452946807680d4304158ce03994869452946807680d43044f8f433a9486945294652e\"\n      }\n    },\n    \"learners/agent_7/curr_entropy_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    },\n    \"learners/agent_7/num_trainable_parameters\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b00652e\"\n      }\n    },\n    \"learners/agent_7/policy_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040a7a38be94869452946807680d430493a6ccbd94869452946807680d43047f93aabd94869452946807680d43048eab71bd94869452946807680d43043d29c1bd9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304bf7327be94869452946807680d43040a7a38be94869452946807680d430493a6ccbd94869452946807680d43047f93aabd94869452946807680d43048eab71bd94869452946807680d43043d29c1bd9486945294652e\"\n      }\n    },\n    \"learners/agent_7/default_optimizer_learning_rate\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d652e\"\n      }\n    },\n    \"learners/agent_7/module_train_batch_size_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000652e\"\n      }\n    },\n    \"learners/agent_7/entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243043b87c44094869452946807680d4304e865c44094869452946807680d43049b5fc44094869452946807680d4304d427c44094869452946807680d430415f2c3409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304e3abc44094869452946807680d43043b87c44094869452946807680d4304e865c44094869452946807680d43049b5fc44094869452946807680d4304d427c44094869452946807680d430415f2c3409486945294652e\"\n      }\n    },\n    \"learners/agent_7/weights_seq_no\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474000000000000000474008000000000000474010000000000000474014000000000000474018000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473ff0000000000000474000000000000000474008000000000000474010000000000000474014000000000000474018000000000000652e\"\n      }\n    },\n    \"learners/agent_7/total_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304c54934be94869452946807680d4304ba7ac7bd94869452946807680d4304dd20a6bd94869452946807680d43049ad568bd94869452946807680d4304a19cbbbd9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304675a24be94869452946807680d4304c54934be94869452946807680d4304ba7ac7bd94869452946807680d4304dd20a6bd94869452946807680d43049ad568bd94869452946807680d4304a19cbbbd9486945294652e\"\n      }\n    },\n    \"learners/agent_7/vf_explained_var\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430451e15f3f94869452946807680d43040d2e783f94869452946807680d43042613673f94869452946807680d430473596f3f94869452946807680d430434b8683f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243048a95663f94869452946807680d430451e15f3f94869452946807680d43040d2e783f94869452946807680d43042613673f94869452946807680d430473596f3f94869452946807680d430434b8683f9486945294652e\"\n      }\n    },\n    \"learners/agent_7/num_module_steps_trained_lifetime_throughput\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428477ff8000000000000474098eaf786ea0074474098eaa685978d00474098e3ac32658e9c474098df77e4f8474b652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428477ff8000000000000477ff8000000000000474098eaf786ea0074474098eaa685978d00474098e3ac32658e9c474098df77e4f8474b652e\"\n      }\n    },\n    \"learners/agent_14/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f9486945294652e\"\n      }\n    },\n    \"learners/agent_14/curr_entropy_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    },\n    \"learners/agent_14/policy_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243041008a7bd94869452946807680d4304f89803be94869452946807680d43047c29cebd94869452946807680d43045caa00be94869452946807680d430454c6c0bd9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243048e7bb5bd94869452946807680d43041008a7bd94869452946807680d4304f89803be94869452946807680d43047c29cebd94869452946807680d43045caa00be94869452946807680d430454c6c0bd9486945294652e\"\n      }\n    },\n    \"learners/agent_14/vf_loss_unclipped\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304d888a43a94869452946807680d4304f268953a94869452946807680d43042efd913a94869452946807680d4304fc21b93a94869452946807680d4304d6d1b33a9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243047b71f53a94869452946807680d4304d888a43a94869452946807680d4304f268953a94869452946807680d43042efd913a94869452946807680d4304fc21b93a94869452946807680d4304d6d1b33a9486945294652e\"\n      }\n    },\n    \"learners/agent_14/default_optimizer_learning_rate\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d652e\"\n      }\n    },\n    \"learners/agent_14/module_train_batch_size_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000652e\"\n      }\n    },\n    \"learners/agent_14/num_trainable_parameters\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284ae5e604004ae5e604004ae5e604004ae5e604004ae5e60400652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284ae5e604004ae5e604004ae5e604004ae5e604004ae5e604004ae5e60400652e\"\n      }\n    },\n    \"learners/agent_14/entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ee3bc44094869452946807680d4304eb0cc44094869452946807680d4304a40fc44094869452946807680d4304a4bbc34094869452946807680d43040090c3409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ad7ac44094869452946807680d4304ee3bc44094869452946807680d4304eb0cc44094869452946807680d4304a40fc44094869452946807680d4304a4bbc34094869452946807680d43040090c3409486945294652e\"\n      }\n    },\n    \"learners/agent_14/weights_seq_no\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474000000000000000474008000000000000474010000000000000474014000000000000474018000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473ff0000000000000474000000000000000474008000000000000474010000000000000474014000000000000474018000000000000652e\"\n      }\n    },\n    \"learners/agent_14/total_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ce2ba1bd94869452946807680d4304a5ae00be94869452946807680d4304e9a2c8bd94869452946807680d4304584cfbbd94869452946807680d4304c34bbabd9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243049d23aebd94869452946807680d4304ce2ba1bd94869452946807680d4304a5ae00be94869452946807680d4304e9a2c8bd94869452946807680d4304584cfbbd94869452946807680d4304c34bbabd9486945294652e\"\n      }\n    },\n    \"learners/agent_14/vf_explained_var\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243042324643f94869452946807680d43045767543f94869452946807680d43047685573f94869452946807680d4304af4e5b3f94869452946807680d4304dbc9603f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304b7694f3f94869452946807680d43042324643f94869452946807680d43045767543f94869452946807680d43047685573f94869452946807680d4304af4e5b3f94869452946807680d4304dbc9603f9486945294652e\"\n      }\n    },\n    \"learners/agent_14/num_module_steps_trained_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a003a01004a00d701004a007402004a001103004a00ae0300652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953e000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d009d4a003a01004a00d701004a007402004a001103004a00ae0300652e\"\n      }\n    },\n    \"learners/agent_14/curr_kl_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000652e\"\n      }\n    },\n    \"learners/agent_14/mean_kl_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304e394033c94869452946807680d43040ed80b3c94869452946807680d4304b3c8013c94869452946807680d4304b132fb3b94869452946807680d430499c3123c9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304c4560c3c94869452946807680d4304e394033c94869452946807680d43040ed80b3c94869452946807680d4304b3c8013c94869452946807680d4304b132fb3b94869452946807680d430499c3123c9486945294652e\"\n      }\n    },\n    \"learners/agent_14/num_module_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d009d4d009d4d009d4d009d4d009d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d009d4d009d4d009d4d009d4d009d4d009d652e\"\n      }\n    },\n    \"learners/agent_14/vf_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304d888a43a94869452946807680d4304f268953a94869452946807680d43042efd913a94869452946807680d4304fc21b93a94869452946807680d4304d6d1b33a9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243047b71f53a94869452946807680d4304d888a43a94869452946807680d4304f268953a94869452946807680d43042efd913a94869452946807680d4304fc21b93a94869452946807680d4304d6d1b33a9486945294652e\"\n      }\n    },\n    \"learners/agent_14/num_module_steps_trained_lifetime_throughput\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428477ff8000000000000474098eaebb5e7d447474098ea9b42f73751474098e3a165870644474098df6e08145c69652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428477ff8000000000000477ff8000000000000474098eaebb5e7d447474098ea9b42f73751474098e3a165870644474098df6e08145c69652e\"\n      }\n    },\n    \"learners/agent_0/num_trainable_parameters\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b00652e\"\n      }\n    },\n    \"learners/agent_0/entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243049b74c44094869452946807680d4304a742c44094869452946807680d4304cd19c44094869452946807680d43044ffbc34094869452946807680d4304b6c3c3409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304f0a8c44094869452946807680d43049b74c44094869452946807680d4304a742c44094869452946807680d4304cd19c44094869452946807680d43044ffbc34094869452946807680d4304b6c3c3409486945294652e\"\n      }\n    },\n    \"learners/agent_0/weights_seq_no\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474000000000000000474008000000000000474010000000000000474014000000000000474018000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473ff0000000000000474000000000000000474008000000000000474010000000000000474014000000000000474018000000000000652e\"\n      }\n    },\n    \"learners/agent_0/total_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304a869a8bd94869452946807680d4304cb60a2bd94869452946807680d430432e054be94869452946807680d43043f9588bd94869452946807680d4304699c983c9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304c94178bc94869452946807680d4304a869a8bd94869452946807680d4304cb60a2bd94869452946807680d430432e054be94869452946807680d43043f9588bd94869452946807680d4304699c983c9486945294652e\"\n      }\n    },\n    \"learners/agent_0/vf_explained_var\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243046bd8753f94869452946807680d4304442d703f94869452946807680d430443bf6d3f94869452946807680d4304c1276e3f94869452946807680d43045aeb693f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243045561763f94869452946807680d43046bd8753f94869452946807680d4304442d703f94869452946807680d430443bf6d3f94869452946807680d4304c1276e3f94869452946807680d43045aeb693f9486945294652e\"\n      }\n    },\n    \"learners/agent_0/num_module_steps_trained_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a003a01004a00d701004a007402004a001103004a00ae0300652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953e000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d009d4a003a01004a00d701004a007402004a001103004a00ae0300652e\"\n      }\n    },\n    \"learners/agent_0/curr_kl_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000652e\"\n      }\n    },\n    \"learners/agent_0/module_train_batch_size_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000652e\"\n      }\n    },\n    \"learners/agent_0/mean_kl_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243047a44173c94869452946807680d43043a00163c94869452946807680d43044e2a093c94869452946807680d4304c8c10f3c94869452946807680d4304046d0a3c9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304b04f1c3c94869452946807680d43047a44173c94869452946807680d43043a00163c94869452946807680d43044e2a093c94869452946807680d4304c8c10f3c94869452946807680d4304046d0a3c9486945294652e\"\n      }\n    },\n    \"learners/agent_0/num_module_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d009d4d009d4d009d4d009d4d009d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d009d4d009d4d009d4d009d4d009d4d009d652e\"\n      }\n    },\n    \"learners/agent_0/vf_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430465031b3a94869452946807680d43049e403f3a94869452946807680d4304a255913a94869452946807680d430445f52c3a94869452946807680d430440f6fa399486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243046a811c3a94869452946807680d430465031b3a94869452946807680d43049e403f3a94869452946807680d4304a255913a94869452946807680d430445f52c3a94869452946807680d430440f6fa399486945294652e\"\n      }\n    },\n    \"learners/agent_0/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f9486945294652e\"\n      }\n    },\n    \"learners/agent_0/curr_entropy_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    },\n    \"learners/agent_0/policy_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304cb67adbd94869452946807680d43044e9fa7bd94869452946807680d4304ccb957be94869452946807680d430435878dbd94869452946807680d4304ddd8863c9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243047ca690bc94869452946807680d4304cb67adbd94869452946807680d43044e9fa7bd94869452946807680d4304ccb957be94869452946807680d430435878dbd94869452946807680d4304ddd8863c9486945294652e\"\n      }\n    },\n    \"learners/agent_0/vf_loss_unclipped\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430465031b3a94869452946807680d43049e403f3a94869452946807680d4304a255913a94869452946807680d430445f52c3a94869452946807680d430440f6fa399486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243046a811c3a94869452946807680d430465031b3a94869452946807680d43049e403f3a94869452946807680d4304a255913a94869452946807680d430445f52c3a94869452946807680d430440f6fa399486945294652e\"\n      }\n    },\n    \"learners/agent_0/default_optimizer_learning_rate\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d652e\"\n      }\n    },\n    \"learners/agent_0/num_module_steps_trained_lifetime_throughput\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428477ff8000000000000474098eaf2dedf8d9f474098eaa217e0e676474098e3a7c4574762474098df73d7f34d56652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428477ff8000000000000477ff8000000000000474098eaf2dedf8d9f474098eaa217e0e676474098e3a7c4574762474098df73d7f34d56652e\"\n      }\n    },\n    \"learners/agent_2/num_trainable_parameters\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b00652e\"\n      }\n    },\n    \"learners/agent_2/policy_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304887fbbbd94869452946807680d43041e02b5bd94869452946807680d430420afbabd94869452946807680d43041ec7fdbd94869452946807680d43041aea37bd9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430457ac9bbd94869452946807680d4304887fbbbd94869452946807680d43041e02b5bd94869452946807680d430420afbabd94869452946807680d43041ec7fdbd94869452946807680d43041aea37bd9486945294652e\"\n      }\n    },\n    \"learners/agent_2/default_optimizer_learning_rate\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d652e\"\n      }\n    },\n    \"learners/agent_2/module_train_batch_size_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000652e\"\n      }\n    },\n    \"learners/agent_2/entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304b659c44094869452946807680d43045a63c44094869452946807680d4304c14ac44094869452946807680d4304562ac44094869452946807680d43049bf6c3409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ee93c44094869452946807680d4304b659c44094869452946807680d43045a63c44094869452946807680d4304c14ac44094869452946807680d4304562ac44094869452946807680d43049bf6c3409486945294652e\"\n      }\n    },\n    \"learners/agent_2/weights_seq_no\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474000000000000000474008000000000000474010000000000000474014000000000000474018000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473ff0000000000000474000000000000000474008000000000000474010000000000000474014000000000000474018000000000000652e\"\n      }\n    },\n    \"learners/agent_2/total_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243048416b6bd94869452946807680d43045e52b0bd94869452946807680d4304265bb6bd94869452946807680d43041cabf9bd94869452946807680d430406252ebd9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304842e95bd94869452946807680d43048416b6bd94869452946807680d43045e52b0bd94869452946807680d4304265bb6bd94869452946807680d43041cabf9bd94869452946807680d430406252ebd9486945294652e\"\n      }\n    },\n    \"learners/agent_2/vf_explained_var\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304eb1a703f94869452946807680d430478ea713f94869452946807680d4304a9c8743f94869452946807680d43046ae6723f94869452946807680d43049fba6c3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430415d4703f94869452946807680d4304eb1a703f94869452946807680d430478ea713f94869452946807680d4304a9c8743f94869452946807680d43046ae6723f94869452946807680d43049fba6c3f9486945294652e\"\n      }\n    },\n    \"learners/agent_2/num_module_steps_trained_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a003a01004a00d701004a007402004a001103004a00ae0300652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953e000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d009d4a003a01004a00d701004a007402004a001103004a00ae0300652e\"\n      }\n    },\n    \"learners/agent_2/curr_kl_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000652e\"\n      }\n    },\n    \"learners/agent_2/mean_kl_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304961d123c94869452946807680d430484e1123c94869452946807680d430486900b3c94869452946807680d43041268033c94869452946807680d4304bb67153c9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304e0bf1e3c94869452946807680d4304961d123c94869452946807680d430484e1123c94869452946807680d430486900b3c94869452946807680d43041268033c94869452946807680d4304bb67153c9486945294652e\"\n      }\n    },\n    \"learners/agent_2/num_module_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d009d4d009d4d009d4d009d4d009d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d009d4d009d4d009d4d009d4d009d4d009d652e\"\n      }\n    },\n    \"learners/agent_2/vf_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430412ef603a94869452946807680d4304d5da013a94869452946807680d430404c3d63994869452946807680d43042c00d33994869452946807680d4304502c133a9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243045375a13a94869452946807680d430412ef603a94869452946807680d4304d5da013a94869452946807680d430404c3d63994869452946807680d43042c00d33994869452946807680d4304502c133a9486945294652e\"\n      }\n    },\n    \"learners/agent_2/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f9486945294652e\"\n      }\n    },\n    \"learners/agent_2/vf_loss_unclipped\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430412ef603a94869452946807680d4304d5da013a94869452946807680d430404c3d63994869452946807680d43042c00d33994869452946807680d4304502c133a9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243045375a13a94869452946807680d430412ef603a94869452946807680d4304d5da013a94869452946807680d430404c3d63994869452946807680d43042c00d33994869452946807680d4304502c133a9486945294652e\"\n      }\n    },\n    \"learners/agent_2/curr_entropy_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    },\n    \"learners/agent_2/num_module_steps_trained_lifetime_throughput\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428477ff8000000000000474098eaef594866a1474098ea9eb2016e4e474098e3a4a2409709474098df7106dd2fc8652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428477ff8000000000000477ff8000000000000474098eaef594866a1474098ea9eb2016e4e474098e3a4a2409709474098df7106dd2fc8652e\"\n      }\n    },\n    \"learners/agent_4/num_module_steps_trained_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a003a01004a00d701004a007402004a001103004a00ae0300652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953e000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d009d4a003a01004a00d701004a007402004a001103004a00ae0300652e\"\n      }\n    },\n    \"learners/agent_4/curr_kl_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000473fc99999a0000000652e\"\n      }\n    },\n    \"learners/agent_4/module_train_batch_size_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000474070000000000000652e\"\n      }\n    },\n    \"learners/agent_4/mean_kl_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430414ec163c94869452946807680d430430d11c3c94869452946807680d430456c8153c94869452946807680d430498c5173c94869452946807680d4304be10153c9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243043f4a183c94869452946807680d430414ec163c94869452946807680d430430d11c3c94869452946807680d430456c8153c94869452946807680d430498c5173c94869452946807680d4304be10153c9486945294652e\"\n      }\n    },\n    \"learners/agent_4/num_module_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d009d4d009d4d009d4d009d4d009d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d009d4d009d4d009d4d009d4d009d4d009d652e\"\n      }\n    },\n    \"learners/agent_4/vf_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304e7f3ea3994869452946807680d4304b71d043a94869452946807680d4304a9c8b53994869452946807680d4304797dbf3994869452946807680d43046b6bb63a9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304c6d6963a94869452946807680d4304e7f3ea3994869452946807680d4304b71d043a94869452946807680d4304a9c8b53994869452946807680d4304797dbf3994869452946807680d43046b6bb63a9486945294652e\"\n      }\n    },\n    \"learners/agent_4/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f94869452946807680d43040000803f9486945294652e\"\n      }\n    },\n    \"learners/agent_4/vf_explained_var\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430417d76f3f94869452946807680d4304a1fa763f94869452946807680d4304e746703f94869452946807680d43040248783f94869452946807680d4304c641663f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430449bd683f94869452946807680d430417d76f3f94869452946807680d4304a1fa763f94869452946807680d4304e746703f94869452946807680d43040248783f94869452946807680d4304c641663f9486945294652e\"\n      }\n    },\n    \"learners/agent_4/policy_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243044ca6ff3c94869452946807680d43041f8178bd94869452946807680d4304e0c1f6bd94869452946807680d4304d0ad19bc94869452946807680d43049815b4bd9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430491420fbe94869452946807680d43044ca6ff3c94869452946807680d43041f8178bd94869452946807680d4304e0c1f6bd94869452946807680d4304d0ad19bc94869452946807680d43049815b4bd9486945294652e\"\n      }\n    },\n    \"learners/agent_4/vf_loss_unclipped\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304e7f3ea3994869452946807680d4304b71d043a94869452946807680d4304a9c8b53994869452946807680d4304797dbf3994869452946807680d43046b6bb63a9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304c6d6963a94869452946807680d4304e7f3ea3994869452946807680d4304b71d043a94869452946807680d4304a9c8b53994869452946807680d4304797dbf3994869452946807680d43046b6bb63a9486945294652e\"\n      }\n    },\n    \"learners/agent_4/default_optimizer_learning_rate\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d473f0a36e2eb1c432d652e\"\n      }\n    },\n    \"learners/agent_4/curr_entropy_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    },\n    \"learners/agent_4/num_trainable_parameters\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b004ae5ec0b00652e\"\n      }\n    },\n    \"learners/agent_4/entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243048043c44094869452946807680d43042c30c44094869452946807680d43045c1ec44094869452946807680d4304bce9c34094869452946807680d430466aac3409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243042898c44094869452946807680d43048043c44094869452946807680d43042c30c44094869452946807680d43045c1ec44094869452946807680d4304bce9c34094869452946807680d430466aac3409486945294652e\"\n      }\n    },\n    \"learners/agent_4/weights_seq_no\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474000000000000000474008000000000000474010000000000000474014000000000000474018000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473ff0000000000000474000000000000000474008000000000000474010000000000000474014000000000000474018000000000000652e\"\n      }\n    },\n    \"learners/agent_4/total_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304da34093d94869452946807680d430465996ebd94869452946807680d43047a4df2bd94869452946807680d430460aeeabb94869452946807680d4304e481adbd9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243048f2d0cbe94869452946807680d4304da34093d94869452946807680d430465996ebd94869452946807680d43047a4df2bd94869452946807680d430460aeeabb94869452946807680d4304e481adbd9486945294652e\"\n      }\n    },\n    \"learners/agent_4/num_module_steps_trained_lifetime_throughput\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428477ff8000000000000474098eaf6d4d8e1f6474098eaa5da2c43c9474098e3ab76d21583474098df771ca1d179652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428477ff8000000000000477ff8000000000000474098eaf6d4d8e1f6474098eaa5da2c43c9474098e3ab76d21583474098df771ca1d179652e\"\n      }\n    },\n    \"env_runners/timers/connectors/add_time_dim_to_batch_and_zero_pad\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308abaaaaaa0c08083f94869452946807680d4308abaaaaaa0c08083f94869452946807680d4308abaaaaaa0c08083f94869452946807680d4308abaaaaaa0c08083f94869452946807680d4308abaaaaaa0c08083f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595e9000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308abaaaaaa0c08083f94869452946807680d4308abaaaaaa0c08083f94869452946807680d4308abaaaaaa0c08083f94869452946807680d4308abaaaaaa0c08083f94869452946807680d4308abaaaaaa0c08083f94869452946807680d4308abaaaaaa0c08083f9486945294652e\"\n      }\n    },\n    \"env_runners/timers/connectors/numpy_to_tensor\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000800dd1273f94869452946807680d4308000000800dd1273f94869452946807680d4308000000800dd1273f94869452946807680d4308000000800dd1273f94869452946807680d4308000000800dd1273f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595e9000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000800dd1273f94869452946807680d4308000000800dd1273f94869452946807680d4308000000800dd1273f94869452946807680d4308000000800dd1273f94869452946807680d4308000000800dd1273f94869452946807680d4308000000800dd1273f9486945294652e\"\n      }\n    },\n    \"env_runners/timers/connectors/agent_to_module_mapping\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000040afe73e94869452946807680d43080000000040afe73e94869452946807680d43080000000040afe73e94869452946807680d43080000000040afe73e94869452946807680d43080000000040afe73e9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595e9000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000040afe73e94869452946807680d43080000000040afe73e94869452946807680d43080000000040afe73e94869452946807680d43080000000040afe73e94869452946807680d43080000000040afe73e94869452946807680d43080000000040afe73e9486945294652e\"\n      }\n    },\n    \"env_runners/timers/connectors/add_states_from_episodes_to_batch\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308abaaaaaae652f83e94869452946807680d4308abaaaaaae652f83e94869452946807680d4308abaaaaaae652f83e94869452946807680d4308abaaaaaae652f83e94869452946807680d4308abaaaaaae652f83e9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595e9000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308abaaaaaae652f83e94869452946807680d4308abaaaaaae652f83e94869452946807680d4308abaaaaaae652f83e94869452946807680d4308abaaaaaae652f83e94869452946807680d4308abaaaaaae652f83e94869452946807680d4308abaaaaaae652f83e9486945294652e\"\n      }\n    },\n    \"env_runners/timers/connectors/batch_individual_items\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308555555557c201e3f94869452946807680d4308555555557c201e3f94869452946807680d4308555555557c201e3f94869452946807680d4308555555557c201e3f94869452946807680d4308555555557c201e3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595e9000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308555555557c201e3f94869452946807680d4308555555557c201e3f94869452946807680d4308555555557c201e3f94869452946807680d4308555555557c201e3f94869452946807680d4308555555557c201e3f94869452946807680d4308555555557c201e3f9486945294652e\"\n      }\n    },\n    \"env_runners/timers/connectors/add_observations_from_episodes_to_batch\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000f493153f94869452946807680d430800000000f493153f94869452946807680d430800000000f493153f94869452946807680d430800000000f493153f94869452946807680d430800000000f493153f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595e9000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000f493153f94869452946807680d430800000000f493153f94869452946807680d430800000000f493153f94869452946807680d430800000000f493153f94869452946807680d430800000000f493153f94869452946807680d430800000000f493153f9486945294652e\"\n      }\n    },\n    \"learners/__all_modules__/learner_connector/connector_pipeline_timer\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847400051cf9a9c47ae4740004efd81b78ea447400049868060d7744740004762dc501cfa4740004275f951ac0c652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740005716f010000047400051cf9a9c47ae4740004efd81b78ea447400049868060d7744740004762dc501cfa4740004275f951ac0c652e\"\n      }\n    },\n    \"env_runners/module_to_env_connector/timers/connectors/module_to_agent_unmapping\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243081fd0a8178bcae33e94869452946807680d43080f59daeb0ef9e43e94869452946807680d43088b3b95119b39e63e94869452946807680d4308c592f2e105d9e53e94869452946807680d4308e7258c0e0906e53e9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595e9000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308b49219a78c3ee43e94869452946807680d43081fd0a8178bcae33e94869452946807680d43080f59daeb0ef9e43e94869452946807680d43088b3b95119b39e63e94869452946807680d4308c592f2e105d9e53e94869452946807680d4308e7258c0e0906e53e9486945294652e\"\n      }\n    },\n    \"env_runners/module_to_env_connector/timers/connectors/remove_single_ts_time_rank_from_batch\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083458289ef3f4b53e94869452946807680d4308695b988d2d31b73e94869452946807680d43080d545541e125b93e94869452946807680d43082b2d6710703fb83e94869452946807680d43088b04216000a5b73e9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595e9000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089f1652ea2f79b53e94869452946807680d43083458289ef3f4b53e94869452946807680d4308695b988d2d31b73e94869452946807680d43080d545541e125b93e94869452946807680d43082b2d6710703fb83e94869452946807680d43088b04216000a5b73e9486945294652e\"\n      }\n    },\n    \"env_runners/module_to_env_connector/timers/connectors/un_batch_to_individual_items\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243087537f0122bfa263f94869452946807680d4308bd2a606aa728283f94869452946807680d43083074a1aa31062a3f94869452946807680d4308b8e14c8ec377293f94869452946807680d4308f3cfc8b264b2283f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595e9000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f724f6bcb4bc263f94869452946807680d43087537f0122bfa263f94869452946807680d4308bd2a606aa728283f94869452946807680d43083074a1aa31062a3f94869452946807680d4308b8e14c8ec377293f94869452946807680d4308f3cfc8b264b2283f9486945294652e\"\n      }\n    },\n    \"env_runners/module_to_env_connector/timers/connectors/listify_data_for_vector_env\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308fc0e47c4db2f003f94869452946807680d430841a9e76c6b19013f94869452946807680d43086f454213e71e023f94869452946807680d4308f3e1fc22cfe8013f94869452946807680d43086cecd3910f15013f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595e9000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308154a2b5c073b003f94869452946807680d4308fc0e47c4db2f003f94869452946807680d430841a9e76c6b19013f94869452946807680d43086f454213e71e023f94869452946807680d4308f3e1fc22cfe8013f94869452946807680d43086cecd3910f15013f9486945294652e\"\n      }\n    },\n    \"env_runners/module_to_env_connector/timers/connectors/normalize_and_clip_actions\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243087df2de94c8151d3f94869452946807680d430899e46d37da9b1e3f94869452946807680d4308dbd23ab9d147203f94869452946807680d43081421256c550b203f94869452946807680d4308b514e0d010c61e3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595e9000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308b3db923ae93f1d3f94869452946807680d43087df2de94c8151d3f94869452946807680d430899e46d37da9b1e3f94869452946807680d4308dbd23ab9d147203f94869452946807680d43081421256c550b203f94869452946807680d4308b514e0d010c61e3f9486945294652e\"\n      }\n    },\n    \"env_runners/module_to_env_connector/timers/connectors/tensor_to_numpy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e367d2274e16303f94869452946807680d4308e3b19ff15bd9303f94869452946807680d430852f35b9d06e9313f94869452946807680d4308730eda6213c5313f94869452946807680d43086a7df23fddfd303f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595e9000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082797ff09bb28303f94869452946807680d4308e367d2274e16303f94869452946807680d4308e3b19ff15bd9303f94869452946807680d430852f35b9d06e9313f94869452946807680d4308730eda6213c5313f94869452946807680d43086a7df23fddfd303f9486945294652e\"\n      }\n    },\n    \"env_runners/module_to_env_connector/timers/connectors/get_actions\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430884f5f2f6656d523f94869452946807680d4308e3cf1b955765533f94869452946807680d430890ddc02ea5a6543f94869452946807680d430815b8aae9315d543f94869452946807680d4308f7fe4551a38a533f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595e9000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080416366d1e9b523f94869452946807680d430884f5f2f6656d523f94869452946807680d4308e3cf1b955765533f94869452946807680d430890ddc02ea5a6543f94869452946807680d430815b8aae9315d543f94869452946807680d4308f7fe4551a38a533f9486945294652e\"\n      }\n    },\n    \"env_runners/env_to_module_connector/timers/connectors/add_states_from_episodes_to_batch\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308602a84d6a71ff73e94869452946807680d4308ef88f51013cdf83e94869452946807680d4308575470ba89cdf93e94869452946807680d43080dfbe39ac96af93e94869452946807680d4308c7a332ca388ff83e9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595e9000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082debcbabe304f73e94869452946807680d4308602a84d6a71ff73e94869452946807680d4308ef88f51013cdf83e94869452946807680d4308575470ba89cdf93e94869452946807680d43080dfbe39ac96af93e94869452946807680d4308c7a332ca388ff83e9486945294652e\"\n      }\n    },\n    \"env_runners/env_to_module_connector/timers/connectors/batch_individual_items\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243081c97db1ffa48193f94869452946807680d43089860ada00f0f1a3f94869452946807680d4308e055a17fe8d01b3f94869452946807680d4308408d435ca3791b3f94869452946807680d4308e45b69ba5c7a1a3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595e9000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e3a8c4c9fefe183f94869452946807680d43081c97db1ffa48193f94869452946807680d43089860ada00f0f1a3f94869452946807680d4308e055a17fe8d01b3f94869452946807680d4308408d435ca3791b3f94869452946807680d4308e45b69ba5c7a1a3f9486945294652e\"\n      }\n    },\n    \"env_runners/env_to_module_connector/timers/connectors/add_observations_from_episodes_to_batch\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082f123b190206123f94869452946807680d43086bbe80257c20133f94869452946807680d430871eabc75216f143f94869452946807680d4308d520d84a1de7133f94869452946807680d4308317801349f83133f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595e9000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308130d2aeeba09123f94869452946807680d43082f123b190206123f94869452946807680d43086bbe80257c20133f94869452946807680d430871eabc75216f143f94869452946807680d4308d520d84a1de7133f94869452946807680d4308317801349f83133f9486945294652e\"\n      }\n    },\n    \"env_runners/env_to_module_connector/timers/connectors/add_time_dim_to_batch_and_zero_pad\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243081dbe4f086504ff3e94869452946807680d43087c2f915d4169003f94869452946807680d4308a2fc226bb0d4013f94869452946807680d4308717f1e79733f013f94869452946807680d4308cf95bf84b0b1003f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595e9000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430865319502920eff3e94869452946807680d43081dbe4f086504ff3e94869452946807680d43087c2f915d4169003f94869452946807680d4308a2fc226bb0d4013f94869452946807680d4308717f1e79733f013f94869452946807680d4308cf95bf84b0b1003f9486945294652e\"\n      }\n    },\n    \"env_runners/env_to_module_connector/timers/connectors/numpy_to_tensor\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243087f588987b70d233f94869452946807680d4308e726a387d40e243f94869452946807680d4308b37e2449ff76253f94869452946807680d43089d78da293ccf243f94869452946807680d43081bf6ba642a53243f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595e9000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a3d72ad0660a233f94869452946807680d43087f588987b70d233f94869452946807680d4308e726a387d40e243f94869452946807680d4308b37e2449ff76253f94869452946807680d43089d78da293ccf243f94869452946807680d43081bf6ba642a53243f9486945294652e\"\n      }\n    },\n    \"env_runners/env_to_module_connector/timers/connectors/agent_to_module_mapping\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308c48a167e2721e63e94869452946807680d430883bc0b2fa54ee73e94869452946807680d43082caecfbbb514e93e94869452946807680d430858dbea9dbb48e83e94869452946807680d430880c4fb05cf84e73e9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595e9000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ec8bce93cd32e63e94869452946807680d4308c48a167e2721e63e94869452946807680d430883bc0b2fa54ee73e94869452946807680d43082caecfbbb514e93e94869452946807680d430858dbea9dbb48e83e94869452946807680d430880c4fb05cf84e73e9486945294652e\"\n      }\n    },\n    \"learners/__all_modules__/learner_connector/timers/connectors/add_columns_from_episodes_to_train_batch\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe591e38e4a147b473fe58fb5ec8af06f473fe58df869a43097473fe58d1b6b58f2aa473fe58c221c6a37eb652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe592d307e80000473fe591e38e4a147b473fe58fb5ec8af06f473fe58df869a43097473fe58d1b6b58f2aa473fe58c221c6a37eb652e\"\n      }\n    },\n    \"learners/__all_modules__/learner_connector/timers/connectors/general_advantage_estimation\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fbaac60ad37ae14473fba8ecad230b923473fba719f8fec655e473fba550f465f26ea473fba396a2e9a5c49652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fbac9ca27c00000473fbaac60ad37ae14473fba8ecad230b923473fba719f8fec655e473fba550f465f26ea473fba396a2e9a5c49652e\"\n      }\n    },\n    \"learners/__all_modules__/learner_connector/timers/connectors/batch_individual_items\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473ff0a16b5aa63d71473ff0a20ae76c0ebf473ff09d0c3b202314473ff09e263b45d0ce473ff099a2a77deae1652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473ff0a67369f40000473ff0a16b5aa63d71473ff0a20ae76c0ebf473ff09d0c3b202314473ff09e263b45d0ce473ff099a2a77deae1652e\"\n      }\n    },\n    \"learners/__all_modules__/learner_connector/timers/connectors/add_observations_from_episodes_to_batch\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f5528ad2fae147b473f551e2d3052bd3c473f55171184f5c077473f55172c044536dc473f550e12f6c9a464652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f552ae810000000473f5528ad2fae147b473f551e2d3052bd3c473f55171184f5c077473f55172c044536dc473f550e12f6c9a464652e\"\n      }\n    },\n    \"learners/__all_modules__/learner_connector/timers/connectors/numpy_to_tensor\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fa15ab96c3eb852473fa15ac697670d84473fa15a4ec7ab246b473fa15a2d5034f36a473fa15c42e59ad242652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fa15c8dca800000473fa15ab96c3eb852473fa15ac697670d84473fa15a4ec7ab246b473fa15a2d5034f36a473fa15c42e59ad242652e\"\n      }\n    },\n    \"learners/__all_modules__/learner_connector/timers/connectors/agent_to_module_mapping\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fa37fb493147ae1473fa37efb7eec985f473fa37d36e9a3d449473fa37cfc2f356415473fa37c5cdf59fa1f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fa37d30ad800000473fa37fb493147ae1473fa37efb7eec985f473fa37d36e9a3d449473fa37cfc2f356415473fa37c5cdf59fa1f652e\"\n      }\n    },\n    \"learners/__all_modules__/learner_connector/timers/connectors/add_states_from_episodes_to_batch\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473ef8c5fd7ae147ae473ef8c3e7b487fcb9473f0106837e7ba238473f00fa72bd37d65b473f00ef0108203d2c652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473ef8c94800000000473ef8c5fd7ae147ae473ef8c3e7b487fcb9473f0106837e7ba238473f00fa72bd37d65b473f00ef0108203d2c652e\"\n      }\n    },\n    \"learners/__all_modules__/learner_connector/timers/connectors/add_time_dim_to_batch_and_zero_pad\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f0ec92700000000473f0ec81830a3d70a473f0ec14435460aa6473f0ebcb8a561804d473f0ebd69145df757652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f0ecbd000000000473f0ec92700000000473f0ec81830a3d70a473f0ec14435460aa6473f0ebcb8a561804d473f0ebd69145df757652e\"\n      }\n    },\n    \"learners/__all_modules__/learner_connector/timers/connectors/add_one_ts_to_episodes_and_truncate\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fc2ff8d014e147b473fc2e546d56ca8c1473fc2cbbfffd29cd4473fc2b29e7756e80f473fc2996dbc9a328a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fc3196113e00000473fc2ff8d014e147b473fc2e546d56ca8c1473fc2cbbfffd29cd4473fc2b29e7756e80f473fc2996dbc9a328a652e\"\n      }\n    },\n    \"timers/synch_env_connectors\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f5c606560000000473f5c6a3f9b0a3d71473f5c6b2a508793de473f5c87b8aa48c826473f5c8357b0bdd063652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f5c606560000000473f5c6a3f9b0a3d71473f5c6b2a508793de473f5c87b8aa48c826473f5c8357b0bdd063652e\"\n      }\n    },\n    \"env_runners/time_between_sampling\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000de9453ed2c4094869452946807680d430822028b585cea2c4094869452946807680d4308453e7992bae82c4094869452946807680d430847b192cecce52c4094869452946807680d43085bb01f3487e32c409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000de9453ed2c4094869452946807680d430822028b585cea2c4094869452946807680d4308453e7992bae82c4094869452946807680d430847b192cecce52c4094869452946807680d43085bb01f3487e32c409486945294652e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b0a8c11636865636b706f696e745f61745f656e6494888c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"]], "runner_data": {"_earliest_stopping_actor": Infinity, "_actor_cleanup_timeout": 600, "_actor_force_cleanup_timeout": 10, "_reuse_actors": false, "_buffer_length": 1, "_buffer_min_time_s": 0.0, "_buffer_max_time_s": 100.0, "_max_pending_trials": 200, "_metric": null, "_total_time": 151.17440128326416, "_iteration": 1803, "_has_errored": false, "_fail_fast": false, "_print_trial_errors": true, "_cached_trial_decisions": {}, "_queued_trial_decisions": {}, "_should_stop_experiment": false, "_stopper": {"_type": "CLOUDPICKLE_FALLBACK", "value": "8005952c000000000000008c157261792e74756e652e73746f707065722e6e6f6f70948c0b4e6f6f7053746f707065729493942981942e"}, "_start_time": 1761037183.9745474, "_session_str": "2025-10-21_10-59-43", "_checkpoint_period": "auto", "_trial_checkpoint_config": {"_type": "CLOUDPICKLE_FALLBACK", "value": "800595f1000000000000008c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b0a8c11636865636b706f696e745f61745f656e6494888c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394680c75622e"}, "_resumed": false}, "stats": {"start_time": 1761037183.9745474}}