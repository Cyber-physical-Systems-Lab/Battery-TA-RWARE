{"trial_data": [["{\n  \"stub\": false,\n  \"trainable_name\": \"PPO\",\n  \"trial_id\": \"937c9_00000\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595ca020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1750504f5f323032352d31302d32315f31312d30382d3537948c0e747269616c5f6469725f6e616d65948c3c50504f5f57617265686f7573654d756c74694167656e74456e765f39333763395f30303030305f305f323032352d31302d32315f31312d30382d3537948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e74948875628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c362f686f6d652f7875657a68692f7461736b2d61737369676e6d656e742d726f626f7469632d77617265686f7573652f726573756c7473948c0673796e6365729468008c115f46696c6573797374656d53796e6365729493942981947d94286815681b68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032352d31302d32315f31312d30382d35379475622e\"\n  },\n  \"config\": {\n    \"exploration_config\": {\n      \"type\": \"StochasticSampling\"\n    },\n    \"extra_python_environs_for_driver\": {},\n    \"extra_python_environs_for_worker\": {},\n    \"placement_strategy\": \"PACK\",\n    \"num_gpus\": 1,\n    \"_fake_gpus\": false,\n    \"num_cpus_for_main_process\": 1,\n    \"eager_tracing\": true,\n    \"eager_max_retraces\": 20,\n    \"tf_session_args\": {\n      \"intra_op_parallelism_threads\": 2,\n      \"inter_op_parallelism_threads\": 2,\n      \"gpu_options\": {\n        \"allow_growth\": true\n      },\n      \"log_device_placement\": false,\n      \"device_count\": {\n        \"CPU\": 1\n      },\n      \"allow_soft_placement\": true\n    },\n    \"local_tf_session_args\": {\n      \"intra_op_parallelism_threads\": 8,\n      \"inter_op_parallelism_threads\": 8\n    },\n    \"torch_compile_learner\": false,\n    \"torch_compile_learner_what_to_compile\": \"forward_train\",\n    \"torch_compile_learner_dynamo_backend\": \"inductor\",\n    \"torch_compile_learner_dynamo_mode\": null,\n    \"torch_compile_worker\": false,\n    \"torch_compile_worker_dynamo_backend\": \"onnxrt\",\n    \"torch_compile_worker_dynamo_mode\": null,\n    \"torch_ddp_kwargs\": {},\n    \"torch_skip_nan_gradients\": false,\n    \"env\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005952a000000000000008c0b747261696e5f7574696c73948c1657617265686f7573654d756c74694167656e74456e769493942e\"\n    },\n    \"env_config\": {\n      \"env_id\": \"tarware-extralarge-14agvs-7pickers-partialobs-chg-v1\"\n    },\n    \"observation_space\": null,\n    \"action_space\": null,\n    \"clip_rewards\": null,\n    \"normalize_actions\": true,\n    \"clip_actions\": false,\n    \"_is_atari\": null,\n    \"disable_env_checking\": false,\n    \"render_env\": true,\n    \"action_mask_key\": \"action_mask\",\n    \"env_runner_cls\": null,\n    \"num_env_runners\": 3,\n    \"create_local_env_runner\": true,\n    \"num_envs_per_env_runner\": 1,\n    \"gym_env_vectorize_mode\": \"SYNC\",\n    \"num_cpus_per_env_runner\": 1,\n    \"num_gpus_per_env_runner\": 0,\n    \"custom_resources_per_env_runner\": {},\n    \"validate_env_runners_after_construction\": true,\n    \"episodes_to_numpy\": true,\n    \"max_requests_in_flight_per_env_runner\": 1,\n    \"sample_timeout_s\": 60.0,\n    \"_env_to_module_connector\": null,\n    \"add_default_connectors_to_env_to_module_pipeline\": true,\n    \"_module_to_env_connector\": null,\n    \"add_default_connectors_to_module_to_env_pipeline\": true,\n    \"merge_env_runner_states\": \"training_only\",\n    \"broadcast_env_runner_states\": true,\n    \"episode_lookback_horizon\": 1,\n    \"rollout_fragment_length\": \"auto\",\n    \"batch_mode\": \"truncate_episodes\",\n    \"compress_observations\": false,\n    \"remote_worker_envs\": false,\n    \"remote_env_batch_wait_ms\": 0,\n    \"enable_tf1_exec_eagerly\": false,\n    \"sample_collector\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059551000000000000008c357261792e726c6c69622e6576616c756174696f6e2e636f6c6c6563746f72732e73696d706c655f6c6973745f636f6c6c6563746f72948c1353696d706c654c697374436f6c6c6563746f729493942e\"\n    },\n    \"preprocessor_pref\": \"deepmind\",\n    \"observation_filter\": \"NoFilter\",\n    \"update_worker_filter_stats\": true,\n    \"use_worker_filter_stats\": true,\n    \"sampler_perf_stats_ema_coef\": null,\n    \"_is_online\": true,\n    \"num_learners\": 0,\n    \"num_gpus_per_learner\": 1,\n    \"num_cpus_per_learner\": \"auto\",\n    \"num_aggregator_actors_per_learner\": 0,\n    \"max_requests_in_flight_per_aggregator_actor\": 3,\n    \"local_gpu_idx\": 0,\n    \"max_requests_in_flight_per_learner\": 3,\n    \"gamma\": 0.99,\n    \"lr\": 5e-05,\n    \"grad_clip\": null,\n    \"grad_clip_by\": \"global_norm\",\n    \"_train_batch_size_per_learner\": null,\n    \"train_batch_size\": 4000,\n    \"num_epochs\": 10,\n    \"minibatch_size\": 256,\n    \"shuffle_batch_per_epoch\": true,\n    \"model\": {\n      \"fcnet_hiddens\": [\n        256,\n        256\n      ],\n      \"fcnet_activation\": \"tanh\",\n      \"fcnet_weights_initializer\": null,\n      \"fcnet_weights_initializer_config\": null,\n      \"fcnet_bias_initializer\": null,\n      \"fcnet_bias_initializer_config\": null,\n      \"conv_filters\": null,\n      \"conv_activation\": \"relu\",\n      \"conv_kernel_initializer\": null,\n      \"conv_kernel_initializer_config\": null,\n      \"conv_bias_initializer\": null,\n      \"conv_bias_initializer_config\": null,\n      \"conv_transpose_kernel_initializer\": null,\n      \"conv_transpose_kernel_initializer_config\": null,\n      \"conv_transpose_bias_initializer\": null,\n      \"conv_transpose_bias_initializer_config\": null,\n      \"post_fcnet_hiddens\": [],\n      \"post_fcnet_activation\": \"relu\",\n      \"post_fcnet_weights_initializer\": null,\n      \"post_fcnet_weights_initializer_config\": null,\n      \"post_fcnet_bias_initializer\": null,\n      \"post_fcnet_bias_initializer_config\": null,\n      \"free_log_std\": false,\n      \"log_std_clip_param\": 20.0,\n      \"no_final_linear\": false,\n      \"vf_share_layers\": false,\n      \"use_lstm\": false,\n      \"max_seq_len\": 20,\n      \"lstm_cell_size\": 256,\n      \"lstm_use_prev_action\": false,\n      \"lstm_use_prev_reward\": false,\n      \"lstm_weights_initializer\": null,\n      \"lstm_weights_initializer_config\": null,\n      \"lstm_bias_initializer\": null,\n      \"lstm_bias_initializer_config\": null,\n      \"_time_major\": false,\n      \"use_attention\": false,\n      \"attention_num_transformer_units\": 1,\n      \"attention_dim\": 64,\n      \"attention_num_heads\": 1,\n      \"attention_head_dim\": 32,\n      \"attention_memory_inference\": 50,\n      \"attention_memory_training\": 50,\n      \"attention_position_wise_mlp_dim\": 32,\n      \"attention_init_gru_gate_bias\": 2.0,\n      \"attention_use_n_prev_actions\": 0,\n      \"attention_use_n_prev_rewards\": 0,\n      \"framestack\": true,\n      \"dim\": 84,\n      \"grayscale\": false,\n      \"zero_mean\": true,\n      \"custom_model\": null,\n      \"custom_model_config\": {},\n      \"custom_action_dist\": null,\n      \"custom_preprocessor\": null,\n      \"encoder_latent_dim\": null,\n      \"always_check_shapes\": false,\n      \"lstm_use_prev_action_reward\": -1,\n      \"_use_default_native_models\": -1,\n      \"_disable_preprocessor_api\": false,\n      \"_disable_action_flattening\": false\n    },\n    \"_learner_connector\": null,\n    \"add_default_connectors_to_learner_pipeline\": true,\n    \"learner_config_dict\": {},\n    \"optimizer\": {},\n    \"_learner_class\": null,\n    \"callbacks_on_algorithm_init\": null,\n    \"callbacks_on_env_runners_recreated\": null,\n    \"callbacks_on_offline_eval_runners_recreated\": null,\n    \"callbacks_on_checkpoint_loaded\": null,\n    \"callbacks_on_environment_created\": null,\n    \"callbacks_on_episode_created\": null,\n    \"callbacks_on_episode_start\": null,\n    \"callbacks_on_episode_step\": null,\n    \"callbacks_on_episode_end\": null,\n    \"callbacks_on_evaluate_start\": null,\n    \"callbacks_on_evaluate_end\": null,\n    \"callbacks_on_evaluate_offline_start\": null,\n    \"callbacks_on_evaluate_offline_end\": null,\n    \"callbacks_on_sample_end\": null,\n    \"callbacks_on_train_result\": null,\n    \"explore\": true,\n    \"enable_rl_module_and_learner\": false,\n    \"enable_env_runner_and_connector_v2\": false,\n    \"_prior_exploration_config\": null,\n    \"count_steps_by\": \"env_steps\",\n    \"policy_map_capacity\": 100,\n    \"policy_mapping_fn\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059512020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b034b004b004b044b014b5b43047c005300944e859429288c086167656e745f6964948c07657069736f6465948c06776f726b6572948c066b77617267739474948c432f686f6d652f7875657a68692f7461736b2d61737369676e6d656e742d726f626f7469632d77617265686f7573652f736372697074732f747261696e5f70706f2e7079948c083c6c616d6264613e944b1e43020400942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f948c17747261696e2e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f9468098c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n    },\n    \"policies_to_train\": null,\n    \"policy_states_are_swappable\": false,\n    \"observation_fn\": null,\n    \"offline_data_class\": null,\n    \"input_read_method\": \"read_parquet\",\n    \"input_read_method_kwargs\": {},\n    \"input_read_schema\": {},\n    \"input_read_episodes\": false,\n    \"input_read_sample_batches\": false,\n    \"input_read_batch_size\": null,\n    \"input_filesystem\": null,\n    \"input_filesystem_kwargs\": {},\n    \"input_compress_columns\": [\n      \"obs\",\n      \"new_obs\"\n    ],\n    \"input_spaces_jsonable\": true,\n    \"materialize_data\": false,\n    \"materialize_mapped_data\": true,\n    \"map_batches_kwargs\": {},\n    \"iter_batches_kwargs\": {},\n    \"ignore_final_observation\": false,\n    \"prelearner_class\": null,\n    \"prelearner_buffer_class\": null,\n    \"prelearner_buffer_kwargs\": {},\n    \"prelearner_module_synch_period\": 10,\n    \"dataset_num_iters_per_learner\": null,\n    \"input_config\": {},\n    \"actions_in_input_normalized\": false,\n    \"postprocess_inputs\": false,\n    \"shuffle_buffer_size\": 0,\n    \"output\": null,\n    \"output_config\": {},\n    \"output_compress_columns\": [\n      \"obs\",\n      \"new_obs\"\n    ],\n    \"output_max_file_size\": 67108864,\n    \"output_max_rows_per_file\": null,\n    \"output_write_remaining_data\": false,\n    \"output_write_method\": \"write_parquet\",\n    \"output_write_method_kwargs\": {},\n    \"output_filesystem\": null,\n    \"output_filesystem_kwargs\": {},\n    \"output_write_episodes\": true,\n    \"offline_sampling\": false,\n    \"evaluation_interval\": 10,\n    \"evaluation_duration\": 5,\n    \"evaluation_duration_unit\": \"episodes\",\n    \"evaluation_sample_timeout_s\": 120.0,\n    \"evaluation_auto_duration_min_env_steps_per_sample\": 100,\n    \"evaluation_auto_duration_max_env_steps_per_sample\": 2000,\n    \"evaluation_parallel_to_training\": false,\n    \"evaluation_force_reset_envs_before_iteration\": true,\n    \"evaluation_config\": {\n      \"explore\": false\n    },\n    \"off_policy_estimation_methods\": {},\n    \"ope_split_batch_by_episode\": true,\n    \"evaluation_num_env_runners\": 0,\n    \"in_evaluation\": false,\n    \"sync_filters_on_rollout_workers_timeout_s\": 10.0,\n    \"offline_evaluation_interval\": null,\n    \"num_offline_eval_runners\": 0,\n    \"offline_evaluation_type\": null,\n    \"offline_eval_runner_class\": null,\n    \"offline_loss_for_module_fn\": null,\n    \"offline_evaluation_duration\": 1,\n    \"offline_evaluation_parallel_to_training\": false,\n    \"offline_evaluation_timeout_s\": 120.0,\n    \"num_cpus_per_offline_eval_runner\": 1,\n    \"num_gpus_per_offline_eval_runner\": 0,\n    \"custom_resources_per_offline_eval_runner\": {},\n    \"restart_failed_offline_eval_runners\": true,\n    \"ignore_offline_eval_runner_failures\": false,\n    \"max_num_offline_eval_runner_restarts\": 1000,\n    \"offline_eval_runner_restore_timeout_s\": 1800.0,\n    \"max_requests_in_flight_per_offline_eval_runner\": 1,\n    \"validate_offline_eval_runners_after_construction\": true,\n    \"offline_eval_runner_health_probe_timeout_s\": 30.0,\n    \"offline_eval_rl_module_inference_only\": false,\n    \"broadcast_offline_eval_runner_states\": false,\n    \"offline_eval_batch_size_per_runner\": 256,\n    \"dataset_num_iters_per_eval_runner\": 1,\n    \"keep_per_episode_custom_metrics\": false,\n    \"metrics_episode_collection_timeout_s\": 60.0,\n    \"metrics_num_episodes_for_smoothing\": 100,\n    \"min_time_s_per_iteration\": null,\n    \"min_train_timesteps_per_iteration\": 0,\n    \"min_sample_timesteps_per_iteration\": 0,\n    \"log_gradients\": false,\n    \"export_native_model_files\": false,\n    \"checkpoint_trainable_policies_only\": false,\n    \"logger_creator\": null,\n    \"logger_config\": null,\n    \"log_level\": \"WARN\",\n    \"log_sys_usage\": true,\n    \"fake_sampler\": false,\n    \"seed\": null,\n    \"restart_failed_env_runners\": true,\n    \"ignore_env_runner_failures\": false,\n    \"max_num_env_runner_restarts\": 1000,\n    \"delay_between_env_runner_restarts_s\": 60.0,\n    \"restart_failed_sub_environments\": false,\n    \"num_consecutive_env_runner_failures_tolerance\": 100,\n    \"env_runner_health_probe_timeout_s\": 30.0,\n    \"env_runner_restore_timeout_s\": 1800.0,\n    \"_model_config\": {},\n    \"_rl_module_spec\": null,\n    \"algorithm_config_overrides_per_module\": {},\n    \"_per_module_overrides\": {},\n    \"_validate_config\": true,\n    \"_use_msgpack_checkpoints\": false,\n    \"_torch_grad_scaler_class\": null,\n    \"_torch_lr_scheduler_classes\": null,\n    \"_tf_policy_handles_more_than_one_loss\": false,\n    \"_disable_preprocessor_api\": false,\n    \"_disable_action_flattening\": false,\n    \"_disable_initialize_loss_from_dummy_batch\": false,\n    \"_dont_auto_sync_env_runner_states\": false,\n    \"env_task_fn\": -1,\n    \"enable_connectors\": -1,\n    \"simple_optimizer\": -1,\n    \"policy_map_cache\": -1,\n    \"worker_cls\": -1,\n    \"synchronize_filters\": -1,\n    \"enable_async_evaluation\": -1,\n    \"custom_async_evaluation_function\": -1,\n    \"_enable_rl_module_api\": -1,\n    \"auto_wrap_old_gym_envs\": -1,\n    \"always_attach_evaluation_results\": -1,\n    \"replay_sequence_length\": null,\n    \"_disable_execution_plan_api\": -1,\n    \"use_critic\": true,\n    \"use_gae\": true,\n    \"use_kl_loss\": true,\n    \"kl_coeff\": 0.2,\n    \"kl_target\": 0.01,\n    \"vf_loss_coeff\": 1.0,\n    \"entropy_coeff\": 0.0,\n    \"clip_param\": 0.2,\n    \"vf_clip_param\": 10.0,\n    \"entropy_coeff_schedule\": null,\n    \"lr_schedule\": null,\n    \"sgd_minibatch_size\": -1,\n    \"vf_share_layers\": -1,\n    \"lambda\": 0.95,\n    \"input\": \"sampler\",\n    \"policies\": {\n      \"agent_0\": [\n        null,\n        null,\n        null,\n        {}\n      ],\n      \"agent_1\": [\n        null,\n        null,\n        null,\n        {}\n      ],\n      \"agent_2\": [\n        null,\n        null,\n        null,\n        {}\n      ],\n      \"agent_3\": [\n        null,\n        null,\n        null,\n        {}\n      ],\n      \"agent_4\": [\n        null,\n        null,\n        null,\n        {}\n      ],\n      \"agent_5\": [\n        null,\n        null,\n        null,\n        {}\n      ],\n      \"agent_6\": [\n        null,\n        null,\n        null,\n        {}\n      ],\n      \"agent_7\": [\n        null,\n        null,\n        null,\n        {}\n      ],\n      \"agent_8\": [\n        null,\n        null,\n        null,\n        {}\n      ],\n      \"agent_9\": [\n        null,\n        null,\n        null,\n        {}\n      ],\n      \"agent_10\": [\n        null,\n        null,\n        null,\n        {}\n      ],\n      \"agent_11\": [\n        null,\n        null,\n        null,\n        {}\n      ],\n      \"agent_12\": [\n        null,\n        null,\n        null,\n        {}\n      ],\n      \"agent_13\": [\n        null,\n        null,\n        null,\n        {}\n      ],\n      \"agent_14\": [\n        null,\n        null,\n        null,\n        {}\n      ],\n      \"agent_15\": [\n        null,\n        null,\n        null,\n        {}\n      ],\n      \"agent_16\": [\n        null,\n        null,\n        null,\n        {}\n      ],\n      \"agent_17\": [\n        null,\n        null,\n        null,\n        {}\n      ],\n      \"agent_18\": [\n        null,\n        null,\n        null,\n        {}\n      ],\n      \"agent_19\": [\n        null,\n        null,\n        null,\n        {}\n      ],\n      \"agent_20\": [\n        null,\n        null,\n        null,\n        {}\n      ]\n    },\n    \"callbacks\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059533000000000000008c1d7261792e726c6c69622e63616c6c6261636b732e63616c6c6261636b73948c0d524c6c696243616c6c6261636b9493942e\"\n    },\n    \"create_env_on_driver\": false,\n    \"custom_eval_function\": null,\n    \"framework\": \"torch\"\n  },\n  \"_Trial__unresolved_config\": {\n    \"exploration_config\": {\n      \"type\": \"StochasticSampling\"\n    },\n    \"extra_python_environs_for_driver\": {},\n    \"extra_python_environs_for_worker\": {},\n    \"placement_strategy\": \"PACK\",\n    \"num_gpus\": 1,\n    \"_fake_gpus\": false,\n    \"num_cpus_for_main_process\": 1,\n    \"eager_tracing\": true,\n    \"eager_max_retraces\": 20,\n    \"tf_session_args\": {\n      \"intra_op_parallelism_threads\": 2,\n      \"inter_op_parallelism_threads\": 2,\n      \"gpu_options\": {\n        \"allow_growth\": true\n      },\n      \"log_device_placement\": false,\n      \"device_count\": {\n        \"CPU\": 1\n      },\n      \"allow_soft_placement\": true\n    },\n    \"local_tf_session_args\": {\n      \"intra_op_parallelism_threads\": 8,\n      \"inter_op_parallelism_threads\": 8\n    },\n    \"torch_compile_learner\": false,\n    \"torch_compile_learner_what_to_compile\": \"forward_train\",\n    \"torch_compile_learner_dynamo_backend\": \"inductor\",\n    \"torch_compile_learner_dynamo_mode\": null,\n    \"torch_compile_worker\": false,\n    \"torch_compile_worker_dynamo_backend\": \"onnxrt\",\n    \"torch_compile_worker_dynamo_mode\": null,\n    \"torch_ddp_kwargs\": {},\n    \"torch_skip_nan_gradients\": false,\n    \"env\": [\n      \"__ref_ph\",\n      \"1181ad55\"\n    ],\n    \"env_config\": {\n      \"env_id\": \"tarware-extralarge-14agvs-7pickers-partialobs-chg-v1\"\n    },\n    \"observation_space\": null,\n    \"action_space\": null,\n    \"clip_rewards\": null,\n    \"normalize_actions\": true,\n    \"clip_actions\": false,\n    \"_is_atari\": null,\n    \"disable_env_checking\": false,\n    \"render_env\": true,\n    \"action_mask_key\": \"action_mask\",\n    \"env_runner_cls\": null,\n    \"num_env_runners\": 3,\n    \"create_local_env_runner\": true,\n    \"num_envs_per_env_runner\": 1,\n    \"gym_env_vectorize_mode\": \"SYNC\",\n    \"num_cpus_per_env_runner\": 1,\n    \"num_gpus_per_env_runner\": 0,\n    \"custom_resources_per_env_runner\": {},\n    \"validate_env_runners_after_construction\": true,\n    \"episodes_to_numpy\": true,\n    \"max_requests_in_flight_per_env_runner\": 1,\n    \"sample_timeout_s\": 60.0,\n    \"_env_to_module_connector\": null,\n    \"add_default_connectors_to_env_to_module_pipeline\": true,\n    \"_module_to_env_connector\": null,\n    \"add_default_connectors_to_module_to_env_pipeline\": true,\n    \"merge_env_runner_states\": \"training_only\",\n    \"broadcast_env_runner_states\": true,\n    \"episode_lookback_horizon\": 1,\n    \"rollout_fragment_length\": \"auto\",\n    \"batch_mode\": \"truncate_episodes\",\n    \"compress_observations\": false,\n    \"remote_worker_envs\": false,\n    \"remote_env_batch_wait_ms\": 0,\n    \"enable_tf1_exec_eagerly\": false,\n    \"sample_collector\": [\n      \"__ref_ph\",\n      \"f176708f\"\n    ],\n    \"preprocessor_pref\": \"deepmind\",\n    \"observation_filter\": \"NoFilter\",\n    \"update_worker_filter_stats\": true,\n    \"use_worker_filter_stats\": true,\n    \"sampler_perf_stats_ema_coef\": null,\n    \"_is_online\": true,\n    \"num_learners\": 0,\n    \"num_gpus_per_learner\": 1,\n    \"num_cpus_per_learner\": \"auto\",\n    \"num_aggregator_actors_per_learner\": 0,\n    \"max_requests_in_flight_per_aggregator_actor\": 3,\n    \"local_gpu_idx\": 0,\n    \"max_requests_in_flight_per_learner\": 3,\n    \"gamma\": 0.99,\n    \"lr\": 5e-05,\n    \"grad_clip\": null,\n    \"grad_clip_by\": \"global_norm\",\n    \"_train_batch_size_per_learner\": null,\n    \"train_batch_size\": 4000,\n    \"num_epochs\": 10,\n    \"minibatch_size\": 256,\n    \"shuffle_batch_per_epoch\": true,\n    \"model\": {\n      \"fcnet_hiddens\": [\n        256,\n        256\n      ],\n      \"fcnet_activation\": \"tanh\",\n      \"fcnet_weights_initializer\": null,\n      \"fcnet_weights_initializer_config\": null,\n      \"fcnet_bias_initializer\": null,\n      \"fcnet_bias_initializer_config\": null,\n      \"conv_filters\": null,\n      \"conv_activation\": \"relu\",\n      \"conv_kernel_initializer\": null,\n      \"conv_kernel_initializer_config\": null,\n      \"conv_bias_initializer\": null,\n      \"conv_bias_initializer_config\": null,\n      \"conv_transpose_kernel_initializer\": null,\n      \"conv_transpose_kernel_initializer_config\": null,\n      \"conv_transpose_bias_initializer\": null,\n      \"conv_transpose_bias_initializer_config\": null,\n      \"post_fcnet_hiddens\": [],\n      \"post_fcnet_activation\": \"relu\",\n      \"post_fcnet_weights_initializer\": null,\n      \"post_fcnet_weights_initializer_config\": null,\n      \"post_fcnet_bias_initializer\": null,\n      \"post_fcnet_bias_initializer_config\": null,\n      \"free_log_std\": false,\n      \"log_std_clip_param\": 20.0,\n      \"no_final_linear\": false,\n      \"vf_share_layers\": false,\n      \"use_lstm\": false,\n      \"max_seq_len\": 20,\n      \"lstm_cell_size\": 256,\n      \"lstm_use_prev_action\": false,\n      \"lstm_use_prev_reward\": false,\n      \"lstm_weights_initializer\": null,\n      \"lstm_weights_initializer_config\": null,\n      \"lstm_bias_initializer\": null,\n      \"lstm_bias_initializer_config\": null,\n      \"_time_major\": false,\n      \"use_attention\": false,\n      \"attention_num_transformer_units\": 1,\n      \"attention_dim\": 64,\n      \"attention_num_heads\": 1,\n      \"attention_head_dim\": 32,\n      \"attention_memory_inference\": 50,\n      \"attention_memory_training\": 50,\n      \"attention_position_wise_mlp_dim\": 32,\n      \"attention_init_gru_gate_bias\": 2.0,\n      \"attention_use_n_prev_actions\": 0,\n      \"attention_use_n_prev_rewards\": 0,\n      \"framestack\": true,\n      \"dim\": 84,\n      \"grayscale\": false,\n      \"zero_mean\": true,\n      \"custom_model\": null,\n      \"custom_model_config\": {},\n      \"custom_action_dist\": null,\n      \"custom_preprocessor\": null,\n      \"encoder_latent_dim\": null,\n      \"always_check_shapes\": false,\n      \"lstm_use_prev_action_reward\": -1,\n      \"_use_default_native_models\": -1,\n      \"_disable_preprocessor_api\": false,\n      \"_disable_action_flattening\": false\n    },\n    \"_learner_connector\": null,\n    \"add_default_connectors_to_learner_pipeline\": true,\n    \"learner_config_dict\": {},\n    \"optimizer\": {},\n    \"_learner_class\": null,\n    \"callbacks_on_algorithm_init\": null,\n    \"callbacks_on_env_runners_recreated\": null,\n    \"callbacks_on_offline_eval_runners_recreated\": null,\n    \"callbacks_on_checkpoint_loaded\": null,\n    \"callbacks_on_environment_created\": null,\n    \"callbacks_on_episode_created\": null,\n    \"callbacks_on_episode_start\": null,\n    \"callbacks_on_episode_step\": null,\n    \"callbacks_on_episode_end\": null,\n    \"callbacks_on_evaluate_start\": null,\n    \"callbacks_on_evaluate_end\": null,\n    \"callbacks_on_evaluate_offline_start\": null,\n    \"callbacks_on_evaluate_offline_end\": null,\n    \"callbacks_on_sample_end\": null,\n    \"callbacks_on_train_result\": null,\n    \"explore\": true,\n    \"enable_rl_module_and_learner\": false,\n    \"enable_env_runner_and_connector_v2\": false,\n    \"_prior_exploration_config\": null,\n    \"count_steps_by\": \"env_steps\",\n    \"policy_map_capacity\": 100,\n    \"policy_mapping_fn\": [\n      \"__ref_ph\",\n      \"cdf20c8b\"\n    ],\n    \"policies_to_train\": null,\n    \"policy_states_are_swappable\": false,\n    \"observation_fn\": null,\n    \"offline_data_class\": null,\n    \"input_read_method\": \"read_parquet\",\n    \"input_read_method_kwargs\": {},\n    \"input_read_schema\": {},\n    \"input_read_episodes\": false,\n    \"input_read_sample_batches\": false,\n    \"input_read_batch_size\": null,\n    \"input_filesystem\": null,\n    \"input_filesystem_kwargs\": {},\n    \"input_compress_columns\": [\n      \"obs\",\n      \"new_obs\"\n    ],\n    \"input_spaces_jsonable\": true,\n    \"materialize_data\": false,\n    \"materialize_mapped_data\": true,\n    \"map_batches_kwargs\": {},\n    \"iter_batches_kwargs\": {},\n    \"ignore_final_observation\": false,\n    \"prelearner_class\": null,\n    \"prelearner_buffer_class\": null,\n    \"prelearner_buffer_kwargs\": {},\n    \"prelearner_module_synch_period\": 10,\n    \"dataset_num_iters_per_learner\": null,\n    \"input_config\": {},\n    \"actions_in_input_normalized\": false,\n    \"postprocess_inputs\": false,\n    \"shuffle_buffer_size\": 0,\n    \"output\": null,\n    \"output_config\": {},\n    \"output_compress_columns\": [\n      \"obs\",\n      \"new_obs\"\n    ],\n    \"output_max_file_size\": 67108864,\n    \"output_max_rows_per_file\": null,\n    \"output_write_remaining_data\": false,\n    \"output_write_method\": \"write_parquet\",\n    \"output_write_method_kwargs\": {},\n    \"output_filesystem\": null,\n    \"output_filesystem_kwargs\": {},\n    \"output_write_episodes\": true,\n    \"offline_sampling\": false,\n    \"evaluation_interval\": 10,\n    \"evaluation_duration\": 5,\n    \"evaluation_duration_unit\": \"episodes\",\n    \"evaluation_sample_timeout_s\": 120.0,\n    \"evaluation_auto_duration_min_env_steps_per_sample\": 100,\n    \"evaluation_auto_duration_max_env_steps_per_sample\": 2000,\n    \"evaluation_parallel_to_training\": false,\n    \"evaluation_force_reset_envs_before_iteration\": true,\n    \"evaluation_config\": {\n      \"explore\": false\n    },\n    \"off_policy_estimation_methods\": {},\n    \"ope_split_batch_by_episode\": true,\n    \"evaluation_num_env_runners\": 0,\n    \"in_evaluation\": false,\n    \"sync_filters_on_rollout_workers_timeout_s\": 10.0,\n    \"offline_evaluation_interval\": null,\n    \"num_offline_eval_runners\": 0,\n    \"offline_evaluation_type\": null,\n    \"offline_eval_runner_class\": null,\n    \"offline_loss_for_module_fn\": null,\n    \"offline_evaluation_duration\": 1,\n    \"offline_evaluation_parallel_to_training\": false,\n    \"offline_evaluation_timeout_s\": 120.0,\n    \"num_cpus_per_offline_eval_runner\": 1,\n    \"num_gpus_per_offline_eval_runner\": 0,\n    \"custom_resources_per_offline_eval_runner\": {},\n    \"restart_failed_offline_eval_runners\": true,\n    \"ignore_offline_eval_runner_failures\": false,\n    \"max_num_offline_eval_runner_restarts\": 1000,\n    \"offline_eval_runner_restore_timeout_s\": 1800.0,\n    \"max_requests_in_flight_per_offline_eval_runner\": 1,\n    \"validate_offline_eval_runners_after_construction\": true,\n    \"offline_eval_runner_health_probe_timeout_s\": 30.0,\n    \"offline_eval_rl_module_inference_only\": false,\n    \"broadcast_offline_eval_runner_states\": false,\n    \"offline_eval_batch_size_per_runner\": 256,\n    \"dataset_num_iters_per_eval_runner\": 1,\n    \"keep_per_episode_custom_metrics\": false,\n    \"metrics_episode_collection_timeout_s\": 60.0,\n    \"metrics_num_episodes_for_smoothing\": 100,\n    \"min_time_s_per_iteration\": null,\n    \"min_train_timesteps_per_iteration\": 0,\n    \"min_sample_timesteps_per_iteration\": 0,\n    \"log_gradients\": false,\n    \"export_native_model_files\": false,\n    \"checkpoint_trainable_policies_only\": false,\n    \"logger_creator\": null,\n    \"logger_config\": null,\n    \"log_level\": \"WARN\",\n    \"log_sys_usage\": true,\n    \"fake_sampler\": false,\n    \"seed\": null,\n    \"restart_failed_env_runners\": true,\n    \"ignore_env_runner_failures\": false,\n    \"max_num_env_runner_restarts\": 1000,\n    \"delay_between_env_runner_restarts_s\": 60.0,\n    \"restart_failed_sub_environments\": false,\n    \"num_consecutive_env_runner_failures_tolerance\": 100,\n    \"env_runner_health_probe_timeout_s\": 30.0,\n    \"env_runner_restore_timeout_s\": 1800.0,\n    \"_model_config\": {},\n    \"_rl_module_spec\": null,\n    \"algorithm_config_overrides_per_module\": {},\n    \"_per_module_overrides\": {},\n    \"_validate_config\": true,\n    \"_use_msgpack_checkpoints\": false,\n    \"_torch_grad_scaler_class\": null,\n    \"_torch_lr_scheduler_classes\": null,\n    \"_tf_policy_handles_more_than_one_loss\": false,\n    \"_disable_preprocessor_api\": false,\n    \"_disable_action_flattening\": false,\n    \"_disable_initialize_loss_from_dummy_batch\": false,\n    \"_dont_auto_sync_env_runner_states\": false,\n    \"env_task_fn\": -1,\n    \"enable_connectors\": -1,\n    \"simple_optimizer\": -1,\n    \"policy_map_cache\": -1,\n    \"worker_cls\": -1,\n    \"synchronize_filters\": -1,\n    \"enable_async_evaluation\": -1,\n    \"custom_async_evaluation_function\": -1,\n    \"_enable_rl_module_api\": -1,\n    \"auto_wrap_old_gym_envs\": -1,\n    \"always_attach_evaluation_results\": -1,\n    \"replay_sequence_length\": null,\n    \"_disable_execution_plan_api\": -1,\n    \"use_critic\": true,\n    \"use_gae\": true,\n    \"use_kl_loss\": true,\n    \"kl_coeff\": 0.2,\n    \"kl_target\": 0.01,\n    \"vf_loss_coeff\": 1.0,\n    \"entropy_coeff\": 0.0,\n    \"clip_param\": 0.2,\n    \"vf_clip_param\": 10.0,\n    \"entropy_coeff_schedule\": null,\n    \"lr_schedule\": null,\n    \"sgd_minibatch_size\": -1,\n    \"vf_share_layers\": -1,\n    \"lambda\": 0.95,\n    \"input\": \"sampler\",\n    \"policies\": {\n      \"agent_0\": [\n        null,\n        null,\n        null,\n        {}\n      ],\n      \"agent_1\": [\n        null,\n        null,\n        null,\n        {}\n      ],\n      \"agent_2\": [\n        null,\n        null,\n        null,\n        {}\n      ],\n      \"agent_3\": [\n        null,\n        null,\n        null,\n        {}\n      ],\n      \"agent_4\": [\n        null,\n        null,\n        null,\n        {}\n      ],\n      \"agent_5\": [\n        null,\n        null,\n        null,\n        {}\n      ],\n      \"agent_6\": [\n        null,\n        null,\n        null,\n        {}\n      ],\n      \"agent_7\": [\n        null,\n        null,\n        null,\n        {}\n      ],\n      \"agent_8\": [\n        null,\n        null,\n        null,\n        {}\n      ],\n      \"agent_9\": [\n        null,\n        null,\n        null,\n        {}\n      ],\n      \"agent_10\": [\n        null,\n        null,\n        null,\n        {}\n      ],\n      \"agent_11\": [\n        null,\n        null,\n        null,\n        {}\n      ],\n      \"agent_12\": [\n        null,\n        null,\n        null,\n        {}\n      ],\n      \"agent_13\": [\n        null,\n        null,\n        null,\n        {}\n      ],\n      \"agent_14\": [\n        null,\n        null,\n        null,\n        {}\n      ],\n      \"agent_15\": [\n        null,\n        null,\n        null,\n        {}\n      ],\n      \"agent_16\": [\n        null,\n        null,\n        null,\n        {}\n      ],\n      \"agent_17\": [\n        null,\n        null,\n        null,\n        {}\n      ],\n      \"agent_18\": [\n        null,\n        null,\n        null,\n        {}\n      ],\n      \"agent_19\": [\n        null,\n        null,\n        null,\n        {}\n      ],\n      \"agent_20\": [\n        null,\n        null,\n        null,\n        {}\n      ]\n    },\n    \"callbacks\": [\n      \"__ref_ph\",\n      \"8913b504\"\n    ],\n    \"create_env_on_driver\": false,\n    \"custom_eval_function\": null,\n    \"framework\": \"torch\"\n  },\n  \"evaluated_params\": {},\n  \"experiment_tag\": \"0\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 10\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595e5000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d94287d94288c0343505594473ff00000000000008c0347505594473ff0000000000000757d946808473ff0000000000000737d946808473ff0000000000000737d946808473ff000000000000073658c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"RUNNING\",\n  \"relative_logdir\": \"PPO_WarehouseMultiAgentEnv_937c9_00000_0_2025-10-21_11-08-57\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1761037746.1603377,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"custom_metrics\": {},\n    \"episode_media\": {},\n    \"info\": {\n      \"learner\": {\n        \"agent_5\": {\n          \"learner_stats\": {\n            \"allreduce_latency\": 0.0,\n            \"grad_gnorm\": 0.6628228642046452,\n            \"cur_kl_coeff\": 0.19999999999999998,\n            \"cur_lr\": 5.000000000000001e-05,\n            \"total_loss\": -0.04359709990203555,\n            \"policy_loss\": -0.04675849936320446,\n            \"vf_loss\": 0.0019867469956807325,\n            \"vf_explained_var\": 0.6375932186841965,\n            \"kl\": 0.005873261537294639,\n            \"entropy\": 6.176175844669342,\n            \"entropy_coeff\": 0.0\n          },\n          \"model\": {},\n          \"custom_metrics\": {},\n          \"num_agent_steps_trained\": 250.0,\n          \"num_grad_updates_lifetime\": 80.5,\n          \"diff_num_grad_updates_vs_sampler_policy\": 79.5\n        },\n        \"agent_4\": {\n          \"learner_stats\": {\n            \"allreduce_latency\": 0.0,\n            \"grad_gnorm\": 0.3928613349795341,\n            \"cur_kl_coeff\": 0.19999999999999998,\n            \"cur_lr\": 5.000000000000001e-05,\n            \"total_loss\": -0.03879295451552025,\n            \"policy_loss\": -0.04008008027740288,\n            \"vf_loss\": 0.00022955927232146678,\n            \"vf_explained_var\": 0.8434331394731999,\n            \"kl\": 0.005287830300358109,\n            \"entropy\": 6.17685629427433,\n            \"entropy_coeff\": 0.0\n          },\n          \"model\": {},\n          \"custom_metrics\": {},\n          \"num_agent_steps_trained\": 250.0,\n          \"num_grad_updates_lifetime\": 80.5,\n          \"diff_num_grad_updates_vs_sampler_policy\": 79.5\n        },\n        \"agent_13\": {\n          \"learner_stats\": {\n            \"allreduce_latency\": 0.0,\n            \"grad_gnorm\": 0.6848604042083025,\n            \"cur_kl_coeff\": 0.19999999999999998,\n            \"cur_lr\": 5.000000000000001e-05,\n            \"total_loss\": -0.04350265678258438,\n            \"policy_loss\": -0.0463587378297234,\n            \"vf_loss\": 0.0018354731666477165,\n            \"vf_explained_var\": 0.7413824584335089,\n            \"kl\": 0.005103038757056311,\n            \"entropy\": 6.1769769310951235,\n            \"entropy_coeff\": 0.0\n          },\n          \"model\": {},\n          \"custom_metrics\": {},\n          \"num_agent_steps_trained\": 250.0,\n          \"num_grad_updates_lifetime\": 80.5,\n          \"diff_num_grad_updates_vs_sampler_policy\": 79.5\n        },\n        \"agent_0\": {\n          \"learner_stats\": {\n            \"allreduce_latency\": 0.0,\n            \"grad_gnorm\": 0.6007273502647876,\n            \"cur_kl_coeff\": 0.19999999999999998,\n            \"cur_lr\": 5.000000000000001e-05,\n            \"total_loss\": -0.04672154011859675,\n            \"policy_loss\": -0.048813783389050514,\n            \"vf_loss\": 0.0009674807578448963,\n            \"vf_explained_var\": 0.7767446111887694,\n            \"kl\": 0.005623814247610426,\n            \"entropy\": 6.176413765549659,\n            \"entropy_coeff\": 0.0\n          },\n          \"model\": {},\n          \"custom_metrics\": {},\n          \"num_agent_steps_trained\": 250.0,\n          \"num_grad_updates_lifetime\": 80.5,\n          \"diff_num_grad_updates_vs_sampler_policy\": 79.5\n        },\n        \"agent_15\": {\n          \"learner_stats\": {\n            \"allreduce_latency\": 0.0,\n            \"grad_gnorm\": 0.7731216736137867,\n            \"cur_kl_coeff\": 0.19999999999999998,\n            \"cur_lr\": 5.000000000000001e-05,\n            \"total_loss\": -0.04177166289955494,\n            \"policy_loss\": -0.04610337391786743,\n            \"vf_loss\": 0.0033900260561495086,\n            \"vf_explained_var\": 0.24210648238658905,\n            \"kl\": 0.004708427456148456,\n            \"entropy\": 6.177436506748199,\n            \"entropy_coeff\": 0.0\n          },\n          \"model\": {},\n          \"custom_metrics\": {},\n          \"num_agent_steps_trained\": 250.0,\n          \"num_grad_updates_lifetime\": 80.5,\n          \"diff_num_grad_updates_vs_sampler_policy\": 79.5\n        },\n        \"agent_19\": {\n          \"learner_stats\": {\n            \"allreduce_latency\": 0.0,\n            \"grad_gnorm\": 0.7953502051532269,\n            \"cur_kl_coeff\": 0.19999999999999998,\n            \"cur_lr\": 5.000000000000001e-05,\n            \"total_loss\": -0.04062979888840346,\n            \"policy_loss\": -0.045478487486252564,\n            \"vf_loss\": 0.0038975650291831697,\n            \"vf_explained_var\": 0.26418117992579937,\n            \"kl\": 0.004755612317012492,\n            \"entropy\": 6.177408641576767,\n            \"entropy_coeff\": 0.0\n          },\n          \"model\": {},\n          \"custom_metrics\": {},\n          \"num_agent_steps_trained\": 250.0,\n          \"num_grad_updates_lifetime\": 80.5,\n          \"diff_num_grad_updates_vs_sampler_policy\": 79.5\n        },\n        \"agent_3\": {\n          \"learner_stats\": {\n            \"allreduce_latency\": 0.0,\n            \"grad_gnorm\": 0.6569609351456165,\n            \"cur_kl_coeff\": 0.19999999999999998,\n            \"cur_lr\": 5.000000000000001e-05,\n            \"total_loss\": -0.04531698364662588,\n            \"policy_loss\": -0.047864361766914956,\n            \"vf_loss\": 0.001497053426965067,\n            \"vf_explained_var\": 0.7605365939438343,\n            \"kl\": 0.005251618787201551,\n            \"entropy\": 6.1768194258213045,\n            \"entropy_coeff\": 0.0\n          },\n          \"model\": {},\n          \"custom_metrics\": {},\n          \"num_agent_steps_trained\": 250.0,\n          \"num_grad_updates_lifetime\": 80.5,\n          \"diff_num_grad_updates_vs_sampler_policy\": 79.5\n        },\n        \"agent_20\": {\n          \"learner_stats\": {\n            \"allreduce_latency\": 0.0,\n            \"grad_gnorm\": 0.7734985277056694,\n            \"cur_kl_coeff\": 0.19999999999999998,\n            \"cur_lr\": 5.000000000000001e-05,\n            \"total_loss\": -0.039919372356234814,\n            \"policy_loss\": -0.04478425519773736,\n            \"vf_loss\": 0.0038360671256668865,\n            \"vf_explained_var\": 0.24774767979979515,\n            \"kl\": 0.0051440823540133355,\n            \"entropy\": 6.177019014954567,\n            \"entropy_coeff\": 0.0\n          },\n          \"model\": {},\n          \"custom_metrics\": {},\n          \"num_agent_steps_trained\": 250.0,\n          \"num_grad_updates_lifetime\": 80.5,\n          \"diff_num_grad_updates_vs_sampler_policy\": 79.5\n        },\n        \"agent_2\": {\n          \"learner_stats\": {\n            \"allreduce_latency\": 0.0,\n            \"grad_gnorm\": 0.5963431052863598,\n            \"cur_kl_coeff\": 0.19999999999999998,\n            \"cur_lr\": 5.000000000000001e-05,\n            \"total_loss\": -0.03828517465663026,\n            \"policy_loss\": -0.03931753882789053,\n            \"vf_loss\": 1.7230370237086844e-05,\n            \"vf_explained_var\": 0.6368009079247713,\n            \"kl\": 0.005075663798538699,\n            \"entropy\": 6.177039608359337,\n            \"entropy_coeff\": 0.0\n          },\n          \"model\": {},\n          \"custom_metrics\": {},\n          \"num_agent_steps_trained\": 250.0,\n          \"num_grad_updates_lifetime\": 80.5,\n          \"diff_num_grad_updates_vs_sampler_policy\": 79.5\n        },\n        \"agent_7\": {\n          \"learner_stats\": {\n            \"allreduce_latency\": 0.0,\n            \"grad_gnorm\": 0.4248142417520285,\n            \"cur_kl_coeff\": 0.19999999999999998,\n            \"cur_lr\": 5.000000000000001e-05,\n            \"total_loss\": -0.04500943329912843,\n            \"policy_loss\": -0.04642385820334312,\n            \"vf_loss\": 0.00037911689840939287,\n            \"vf_explained_var\": 0.8246649790555238,\n            \"kl\": 0.005176538858677304,\n            \"entropy\": 6.176957020163536,\n            \"entropy_coeff\": 0.0\n          },\n          \"model\": {},\n          \"custom_metrics\": {},\n          \"num_agent_steps_trained\": 250.0,\n          \"num_grad_updates_lifetime\": 80.5,\n          \"diff_num_grad_updates_vs_sampler_policy\": 79.5\n        },\n        \"agent_10\": {\n          \"learner_stats\": {\n            \"allreduce_latency\": 0.0,\n            \"grad_gnorm\": 0.7114672303199768,\n            \"cur_kl_coeff\": 0.19999999999999998,\n            \"cur_lr\": 5.000000000000001e-05,\n            \"total_loss\": -0.04261054965400035,\n            \"policy_loss\": -0.04558037797396537,\n            \"vf_loss\": 0.0021062425913441984,\n            \"vf_explained_var\": 0.7238317221403122,\n            \"kl\": 0.004317931410400888,\n            \"entropy\": 6.177790689468384,\n            \"entropy_coeff\": 0.0\n          },\n          \"model\": {},\n          \"custom_metrics\": {},\n          \"num_agent_steps_trained\": 250.0,\n          \"num_grad_updates_lifetime\": 80.5,\n          \"diff_num_grad_updates_vs_sampler_policy\": 79.5\n        },\n        \"agent_8\": {\n          \"learner_stats\": {\n            \"allreduce_latency\": 0.0,\n            \"grad_gnorm\": 0.38750932244583963,\n            \"cur_kl_coeff\": 0.19999999999999998,\n            \"cur_lr\": 5.000000000000001e-05,\n            \"total_loss\": -0.04238021403034509,\n            \"policy_loss\": -0.043361809103225825,\n            \"vf_loss\": 0.00023282966037072584,\n            \"vf_explained_var\": 0.8575464218854905,\n            \"kl\": 0.003743829339146032,\n            \"entropy\": 6.178380465507507,\n            \"entropy_coeff\": 0.0\n          },\n          \"model\": {},\n          \"custom_metrics\": {},\n          \"num_agent_steps_trained\": 250.0,\n          \"num_grad_updates_lifetime\": 80.5,\n          \"diff_num_grad_updates_vs_sampler_policy\": 79.5\n        },\n        \"agent_9\": {\n          \"learner_stats\": {\n            \"allreduce_latency\": 0.0,\n            \"grad_gnorm\": 0.620915948972106,\n            \"cur_kl_coeff\": 0.19999999999999998,\n            \"cur_lr\": 5.000000000000001e-05,\n            \"total_loss\": -0.03920738640881609,\n            \"policy_loss\": -0.04024473679164657,\n            \"vf_loss\": 9.855738909436695e-06,\n            \"vf_explained_var\": 0.7513076294213533,\n            \"kl\": 0.005137474206799197,\n            \"entropy\": 6.176993077993393,\n            \"entropy_coeff\": 0.0\n          },\n          \"model\": {},\n          \"custom_metrics\": {},\n          \"num_agent_steps_trained\": 250.0,\n          \"num_grad_updates_lifetime\": 80.5,\n          \"diff_num_grad_updates_vs_sampler_policy\": 79.5\n        },\n        \"agent_11\": {\n          \"learner_stats\": {\n            \"allreduce_latency\": 0.0,\n            \"grad_gnorm\": 0.6695550084114075,\n            \"cur_kl_coeff\": 0.19999999999999998,\n            \"cur_lr\": 5.000000000000001e-05,\n            \"total_loss\": -0.0433435093404114,\n            \"policy_loss\": -0.04586449110647663,\n            \"vf_loss\": 0.0013849644300535147,\n            \"vf_explained_var\": 0.7541764177381992,\n            \"kl\": 0.005680086939082685,\n            \"entropy\": 6.176377484202385,\n            \"entropy_coeff\": 0.0\n          },\n          \"model\": {},\n          \"custom_metrics\": {},\n          \"num_agent_steps_trained\": 250.0,\n          \"num_grad_updates_lifetime\": 80.5,\n          \"diff_num_grad_updates_vs_sampler_policy\": 79.5\n        },\n        \"agent_6\": {\n          \"learner_stats\": {\n            \"allreduce_latency\": 0.0,\n            \"grad_gnorm\": 0.5933342272415757,\n            \"cur_kl_coeff\": 0.19999999999999998,\n            \"cur_lr\": 5.000000000000001e-05,\n            \"total_loss\": -0.04571261985984165,\n            \"policy_loss\": -0.04761210111209948,\n            \"vf_loss\": 0.000872174321852981,\n            \"vf_explained_var\": 0.7932753082364797,\n            \"kl\": 0.005136534875055077,\n            \"entropy\": 6.176899519562721,\n            \"entropy_coeff\": 0.0\n          },\n          \"model\": {},\n          \"custom_metrics\": {},\n          \"num_agent_steps_trained\": 250.0,\n          \"num_grad_updates_lifetime\": 80.5,\n          \"diff_num_grad_updates_vs_sampler_policy\": 79.5\n        },\n        \"agent_16\": {\n          \"learner_stats\": {\n            \"allreduce_latency\": 0.0,\n            \"grad_gnorm\": 0.7869379967451096,\n            \"cur_kl_coeff\": 0.19999999999999998,\n            \"cur_lr\": 5.000000000000001e-05,\n            \"total_loss\": -0.04269255140898167,\n            \"policy_loss\": -0.04759652213833761,\n            \"vf_loss\": 0.0038235232066654136,\n            \"vf_explained_var\": 0.27241815663874147,\n            \"kl\": 0.005402238416832006,\n            \"entropy\": 6.176775121688843,\n            \"entropy_coeff\": 0.0\n          },\n          \"model\": {},\n          \"custom_metrics\": {},\n          \"num_agent_steps_trained\": 250.0,\n          \"num_grad_updates_lifetime\": 80.5,\n          \"diff_num_grad_updates_vs_sampler_policy\": 79.5\n        },\n        \"agent_1\": {\n          \"learner_stats\": {\n            \"allreduce_latency\": 0.0,\n            \"grad_gnorm\": 0.7498519621789456,\n            \"cur_kl_coeff\": 0.19999999999999998,\n            \"cur_lr\": 5.000000000000001e-05,\n            \"total_loss\": -0.04078422211532597,\n            \"policy_loss\": -0.044464020896703,\n            \"vf_loss\": 0.0027592750334861195,\n            \"vf_explained_var\": 0.6717534307390451,\n            \"kl\": 0.004602619858746948,\n            \"entropy\": 6.177507683634758,\n            \"entropy_coeff\": 0.0\n          },\n          \"model\": {},\n          \"custom_metrics\": {},\n          \"num_agent_steps_trained\": 250.0,\n          \"num_grad_updates_lifetime\": 80.5,\n          \"diff_num_grad_updates_vs_sampler_policy\": 79.5\n        },\n        \"agent_12\": {\n          \"learner_stats\": {\n            \"allreduce_latency\": 0.0,\n            \"grad_gnorm\": 0.6966248460114002,\n            \"cur_kl_coeff\": 0.19999999999999998,\n            \"cur_lr\": 5.000000000000001e-05,\n            \"total_loss\": -0.04409215200175822,\n            \"policy_loss\": -0.04699938178237062,\n            \"vf_loss\": 0.0020329539838712662,\n            \"vf_explained_var\": 0.7333294101059437,\n            \"kl\": 0.004371380647398837,\n            \"entropy\": 6.177722862362861,\n            \"entropy_coeff\": 0.0\n          },\n          \"model\": {},\n          \"custom_metrics\": {},\n          \"num_agent_steps_trained\": 250.0,\n          \"num_grad_updates_lifetime\": 80.5,\n          \"diff_num_grad_updates_vs_sampler_policy\": 79.5\n        },\n        \"agent_14\": {\n          \"learner_stats\": {\n            \"allreduce_latency\": 0.0,\n            \"grad_gnorm\": 0.7747931212186814,\n            \"cur_kl_coeff\": 0.19999999999999998,\n            \"cur_lr\": 5.000000000000001e-05,\n            \"total_loss\": -0.04396464388810273,\n            \"policy_loss\": -0.049254749249666926,\n            \"vf_loss\": 0.004284306976478547,\n            \"vf_explained_var\": 0.27437673695385456,\n            \"kl\": 0.0050289939891399625,\n            \"entropy\": 6.177122569084167,\n            \"entropy_coeff\": 0.0\n          },\n          \"model\": {},\n          \"custom_metrics\": {},\n          \"num_agent_steps_trained\": 250.0,\n          \"num_grad_updates_lifetime\": 80.5,\n          \"diff_num_grad_updates_vs_sampler_policy\": 79.5\n        },\n        \"agent_17\": {\n          \"learner_stats\": {\n            \"allreduce_latency\": 0.0,\n            \"grad_gnorm\": 0.7749452617019414,\n            \"cur_kl_coeff\": 0.19999999999999998,\n            \"cur_lr\": 5.000000000000001e-05,\n            \"total_loss\": -0.044516423007007686,\n            \"policy_loss\": -0.0490830973663833,\n            \"vf_loss\": 0.003491356852464378,\n            \"vf_explained_var\": 0.280439143627882,\n            \"kl\": 0.005376582742837854,\n            \"entropy\": 6.176796442270279,\n            \"entropy_coeff\": 0.0\n          },\n          \"model\": {},\n          \"custom_metrics\": {},\n          \"num_agent_steps_trained\": 250.0,\n          \"num_grad_updates_lifetime\": 80.5,\n          \"diff_num_grad_updates_vs_sampler_policy\": 79.5\n        },\n        \"agent_18\": {\n          \"learner_stats\": {\n            \"allreduce_latency\": 0.0,\n            \"grad_gnorm\": 0.7722561895847321,\n            \"cur_kl_coeff\": 0.19999999999999998,\n            \"cur_lr\": 5.000000000000001e-05,\n            \"total_loss\": -0.040038841503701406,\n            \"policy_loss\": -0.045286459196358916,\n            \"vf_loss\": 0.004272990216122707,\n            \"vf_explained_var\": 0.3040101286023855,\n            \"kl\": 0.0048731343600820765,\n            \"entropy\": 6.177304804325104,\n            \"entropy_coeff\": 0.0\n          },\n          \"model\": {},\n          \"custom_metrics\": {},\n          \"num_agent_steps_trained\": 250.0,\n          \"num_grad_updates_lifetime\": 80.5,\n          \"diff_num_grad_updates_vs_sampler_policy\": 79.5\n        }\n      },\n      \"num_env_steps_sampled\": 4000,\n      \"num_env_steps_trained\": 4000,\n      \"num_agent_steps_sampled\": 84000,\n      \"num_agent_steps_trained\": 84000\n    },\n    \"env_runners\": {\n      \"episode_reward_max\": -43.929999999999694,\n      \"episode_reward_min\": -61.56000000000211,\n      \"episode_reward_mean\": -54.30500000000122,\n      \"episode_len_mean\": 500.0,\n      \"episode_media\": {},\n      \"episodes_timesteps_total\": 3000,\n      \"policy_reward_min\": {\n        \"agent_0\": -5.190000000000026,\n        \"agent_1\": -5.260000000000027,\n        \"agent_2\": -0.5000000000000003,\n        \"agent_3\": -5.320000000000028,\n        \"agent_4\": -0.5000000000000003,\n        \"agent_5\": -4.0700000000000145,\n        \"agent_6\": -5.130000000000026,\n        \"agent_7\": -0.5000000000000003,\n        \"agent_8\": -0.5000000000000003,\n        \"agent_9\": -0.5000000000000003,\n        \"agent_10\": -5.290000000000028,\n        \"agent_11\": -5.330000000000028,\n        \"agent_12\": -5.290000000000028,\n        \"agent_13\": -5.080000000000025,\n        \"agent_14\": -4.880000000000023,\n        \"agent_15\": -5.230000000000027,\n        \"agent_16\": -5.100000000000026,\n        \"agent_17\": -5.330000000000028,\n        \"agent_18\": -4.630000000000019,\n        \"agent_19\": -4.910000000000023,\n        \"agent_20\": -4.980000000000024\n      },\n      \"policy_reward_max\": {\n        \"agent_0\": -0.5000000000000003,\n        \"agent_1\": -0.5000000000000003,\n        \"agent_2\": -0.5000000000000003,\n        \"agent_3\": -0.5000000000000003,\n        \"agent_4\": -0.5000000000000003,\n        \"agent_5\": -0.5000000000000003,\n        \"agent_6\": -0.5000000000000003,\n        \"agent_7\": -0.5000000000000003,\n        \"agent_8\": -0.5000000000000003,\n        \"agent_9\": -0.5000000000000003,\n        \"agent_10\": -0.5000000000000003,\n        \"agent_11\": -0.5000000000000003,\n        \"agent_12\": -0.5000000000000003,\n        \"agent_13\": -0.5000000000000003,\n        \"agent_14\": -3.68000000000001,\n        \"agent_15\": -4.090000000000013,\n        \"agent_16\": -3.940000000000013,\n        \"agent_17\": -3.950000000000013,\n        \"agent_18\": -3.6700000000000097,\n        \"agent_19\": -4.220000000000016,\n        \"agent_20\": -4.140000000000015\n      },\n      \"policy_reward_mean\": {\n        \"agent_0\": -1.3300000000000047,\n        \"agent_1\": -2.823333333333346,\n        \"agent_2\": -0.5000000000000003,\n        \"agent_3\": -2.491666666666676,\n        \"agent_4\": -0.5000000000000003,\n        \"agent_5\": -1.8083333333333353,\n        \"agent_6\": -1.321666666666671,\n        \"agent_7\": -0.5000000000000003,\n        \"agent_8\": -0.5000000000000003,\n        \"agent_9\": -0.5000000000000003,\n        \"agent_10\": -2.8700000000000134,\n        \"agent_11\": -1.7183333333333384,\n        \"agent_12\": -2.7466666666666786,\n        \"agent_13\": -3.065000000000012,\n        \"agent_14\": -4.31833333333335,\n        \"agent_15\": -4.810000000000023,\n        \"agent_16\": -4.563333333333353,\n        \"agent_17\": -4.7816666666666885,\n        \"agent_18\": -4.063333333333348,\n        \"agent_19\": -4.61000000000002,\n        \"agent_20\": -4.483333333333352\n      },\n      \"custom_metrics\": {},\n      \"hist_stats\": {\n        \"episode_reward\": [\n          -57.960000000001976,\n          -51.160000000000316,\n          -50.4900000000012,\n          -60.730000000002065,\n          -61.56000000000211,\n          -43.929999999999694\n        ],\n        \"episode_lengths\": [\n          500,\n          500,\n          500,\n          500,\n          500,\n          500\n        ],\n        \"policy_agent_0_reward\": [\n          -0.5000000000000003,\n          -0.5000000000000003,\n          -0.7900000000000006,\n          -0.5000000000000003,\n          -5.190000000000026,\n          -0.5000000000000003\n        ],\n        \"policy_agent_1_reward\": [\n          -5.020000000000024,\n          -0.5000000000000003,\n          -5.260000000000027,\n          -5.160000000000026,\n          -0.5000000000000003,\n          -0.5000000000000003\n        ],\n        \"policy_agent_2_reward\": [\n          -0.5000000000000003,\n          -0.5000000000000003,\n          -0.5000000000000003,\n          -0.5000000000000003,\n          -0.5000000000000003,\n          -0.5000000000000003\n        ],\n        \"policy_agent_3_reward\": [\n          -5.190000000000026,\n          -0.5000000000000003,\n          -2.9400000000000017,\n          -0.5000000000000003,\n          -5.320000000000028,\n          -0.5000000000000003\n        ],\n        \"policy_agent_4_reward\": [\n          -0.5000000000000003,\n          -0.5000000000000003,\n          -0.5000000000000003,\n          -0.5000000000000003,\n          -0.5000000000000003,\n          -0.5000000000000003\n        ],\n        \"policy_agent_5_reward\": [\n          -1.949999999999992,\n          -4.0700000000000145,\n          -0.5000000000000003,\n          -3.3300000000000063,\n          -0.5000000000000003,\n          -0.5000000000000003\n        ],\n        \"policy_agent_6_reward\": [\n          -0.8000000000000006,\n          -0.5000000000000003,\n          -0.5000000000000003,\n          -5.130000000000026,\n          -0.5000000000000003,\n          -0.5000000000000003\n        ],\n        \"policy_agent_7_reward\": [\n          -0.5000000000000003,\n          -0.5000000000000003,\n          -0.5000000000000003,\n          -0.5000000000000003,\n          -0.5000000000000003,\n          -0.5000000000000003\n        ],\n        \"policy_agent_8_reward\": [\n          -0.5000000000000003,\n          -0.5000000000000003,\n          -0.5000000000000003,\n          -0.5000000000000003,\n          -0.5000000000000003,\n          -0.5000000000000003\n        ],\n        \"policy_agent_9_reward\": [\n          -0.5000000000000003,\n          -0.5000000000000003,\n          -0.5000000000000003,\n          -0.5000000000000003,\n          -0.5000000000000003,\n          -0.5000000000000003\n        ],\n        \"policy_agent_10_reward\": [\n          -5.240000000000027,\n          -5.290000000000028,\n          -0.5000000000000003,\n          -0.5000000000000003,\n          -5.190000000000026,\n          -0.5000000000000003\n        ],\n        \"policy_agent_11_reward\": [\n          -0.5000000000000003,\n          -5.330000000000028,\n          -2.980000000000002,\n          -0.5000000000000003,\n          -0.5000000000000003,\n          -0.5000000000000003\n        ],\n        \"policy_agent_12_reward\": [\n          -5.290000000000028,\n          -0.5000000000000003,\n          -0.5000000000000003,\n          -4.8600000000000225,\n          -4.830000000000022,\n          -0.5000000000000003\n        ],\n        \"policy_agent_13_reward\": [\n          -0.5000000000000003,\n          -0.5000000000000003,\n          -2.299999999999995,\n          -5.080000000000025,\n          -5.000000000000024,\n          -5.010000000000025\n        ],\n        \"policy_agent_14_reward\": [\n          -4.450000000000019,\n          -3.68000000000001,\n          -3.9700000000000117,\n          -4.680000000000021,\n          -4.250000000000016,\n          -4.880000000000023\n        ],\n        \"policy_agent_15_reward\": [\n          -4.430000000000018,\n          -5.230000000000027,\n          -4.090000000000013,\n          -5.080000000000025,\n          -4.970000000000024,\n          -5.060000000000025\n        ],\n        \"policy_agent_16_reward\": [\n          -4.320000000000016,\n          -4.950000000000024,\n          -5.100000000000026,\n          -4.730000000000022,\n          -3.940000000000013,\n          -4.340000000000017\n        ],\n        \"policy_agent_17_reward\": [\n          -4.67000000000002,\n          -3.950000000000013,\n          -5.330000000000028,\n          -4.410000000000018,\n          -5.020000000000024,\n          -5.310000000000027\n        ],\n        \"policy_agent_18_reward\": [\n          -3.860000000000012,\n          -3.920000000000013,\n          -4.300000000000016,\n          -4.000000000000013,\n          -4.630000000000019,\n          -3.6700000000000097\n        ],\n        \"policy_agent_19_reward\": [\n          -4.60000000000002,\n          -4.590000000000019,\n          -4.220000000000016,\n          -4.790000000000021,\n          -4.550000000000019,\n          -4.910000000000023\n        ],\n        \"policy_agent_20_reward\": [\n          -4.140000000000015,\n          -4.650000000000021,\n          -4.710000000000021,\n          -4.980000000000024,\n          -4.170000000000015,\n          -4.250000000000016\n        ]\n      },\n      \"sampler_perf\": {\n        \"mean_raw_obs_processing_ms\": 1.860233524956411,\n        \"mean_inference_ms\": 9.928458898973238,\n        \"mean_action_processing_ms\": 0.6863239248299343,\n        \"mean_env_wait_ms\": 2.746555278078143,\n        \"mean_env_render_ms\": 0.0\n      },\n      \"num_faulty_episodes\": 0,\n      \"connector_metrics\": {\n        \"ObsPreprocessorConnector_ms\": 0.002566027262854198,\n        \"StateBufferConnector_ms\": 0.0014021283104306175,\n        \"ViewRequirementAgentConnector_ms\": 0.03029732477097284\n      },\n      \"num_episodes\": 6,\n      \"episode_return_max\": -43.929999999999694,\n      \"episode_return_min\": -61.56000000000211,\n      \"episode_return_mean\": -54.30500000000122,\n      \"episodes_this_iter\": 6\n    },\n    \"num_healthy_workers\": 3,\n    \"actor_manager_num_outstanding_async_reqs\": 0,\n    \"num_remote_worker_restarts\": 0,\n    \"num_agent_steps_sampled\": 84000,\n    \"num_agent_steps_trained\": 84000,\n    \"num_env_steps_sampled\": 4000,\n    \"num_env_steps_trained\": 4000,\n    \"num_env_steps_sampled_this_iter\": 4000,\n    \"num_env_steps_trained_this_iter\": 4000,\n    \"num_env_steps_sampled_throughput_per_sec\": 128.324312796662,\n    \"num_env_steps_trained_throughput_per_sec\": 128.324312796662,\n    \"timesteps_total\": 4000,\n    \"num_env_steps_sampled_lifetime\": 4000,\n    \"num_agent_steps_sampled_lifetime\": 84000,\n    \"num_steps_trained_this_iter\": 4000,\n    \"agent_timesteps_total\": 84000,\n    \"timers\": {\n      \"training_iteration_time_ms\": 31171.028,\n      \"restore_workers_time_ms\": 0.012,\n      \"training_step_time_ms\": 31170.99,\n      \"sample_time_ms\": 20658.006,\n      \"learn_time_ms\": 10486.003,\n      \"learn_throughput\": 381.461,\n      \"synch_weights_time_ms\": 25.959\n    },\n    \"counters\": {\n      \"num_env_steps_sampled\": 4000,\n      \"num_env_steps_trained\": 4000,\n      \"num_agent_steps_sampled\": 84000,\n      \"num_agent_steps_trained\": 84000\n    },\n    \"done\": false,\n    \"training_iteration\": 1,\n    \"trial_id\": \"937c9_00000\",\n    \"date\": \"2025-10-21_11-09-37\",\n    \"timestamp\": 1761037777,\n    \"time_this_iter_s\": 31.19081139564514,\n    \"time_total_s\": 31.19081139564514,\n    \"pid\": 3245221,\n    \"hostname\": \"xuezhi-Precision-3660\",\n    \"node_ip\": \"130.238.16.41\",\n    \"config\": {\n      \"exploration_config\": {\n        \"type\": \"StochasticSampling\"\n      },\n      \"extra_python_environs_for_driver\": {},\n      \"extra_python_environs_for_worker\": {},\n      \"placement_strategy\": \"PACK\",\n      \"num_gpus\": 1,\n      \"_fake_gpus\": false,\n      \"num_cpus_for_main_process\": 1,\n      \"eager_tracing\": true,\n      \"eager_max_retraces\": 20,\n      \"tf_session_args\": {\n        \"intra_op_parallelism_threads\": 2,\n        \"inter_op_parallelism_threads\": 2,\n        \"gpu_options\": {\n          \"allow_growth\": true\n        },\n        \"log_device_placement\": false,\n        \"device_count\": {\n          \"CPU\": 1\n        },\n        \"allow_soft_placement\": true\n      },\n      \"local_tf_session_args\": {\n        \"intra_op_parallelism_threads\": 8,\n        \"inter_op_parallelism_threads\": 8\n      },\n      \"torch_compile_learner\": false,\n      \"torch_compile_learner_what_to_compile\": \"forward_train\",\n      \"torch_compile_learner_dynamo_backend\": \"inductor\",\n      \"torch_compile_learner_dynamo_mode\": null,\n      \"torch_compile_worker\": false,\n      \"torch_compile_worker_dynamo_backend\": \"onnxrt\",\n      \"torch_compile_worker_dynamo_mode\": null,\n      \"torch_ddp_kwargs\": {},\n      \"torch_skip_nan_gradients\": false,\n      \"env\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b747261696e5f7574696c73948c1657617265686f7573654d756c74694167656e74456e769493942e\"\n      },\n      \"env_config\": {\n        \"env_id\": \"tarware-extralarge-14agvs-7pickers-partialobs-chg-v1\"\n      },\n      \"observation_space\": null,\n      \"action_space\": null,\n      \"clip_rewards\": null,\n      \"normalize_actions\": true,\n      \"clip_actions\": false,\n      \"_is_atari\": null,\n      \"disable_env_checking\": false,\n      \"render_env\": true,\n      \"action_mask_key\": \"action_mask\",\n      \"env_runner_cls\": null,\n      \"num_env_runners\": 3,\n      \"create_local_env_runner\": true,\n      \"num_envs_per_env_runner\": 1,\n      \"gym_env_vectorize_mode\": \"SYNC\",\n      \"num_cpus_per_env_runner\": 1,\n      \"num_gpus_per_env_runner\": 0,\n      \"custom_resources_per_env_runner\": {},\n      \"validate_env_runners_after_construction\": true,\n      \"episodes_to_numpy\": true,\n      \"max_requests_in_flight_per_env_runner\": 1,\n      \"sample_timeout_s\": 60.0,\n      \"_env_to_module_connector\": null,\n      \"add_default_connectors_to_env_to_module_pipeline\": true,\n      \"_module_to_env_connector\": null,\n      \"add_default_connectors_to_module_to_env_pipeline\": true,\n      \"merge_env_runner_states\": \"training_only\",\n      \"broadcast_env_runner_states\": true,\n      \"episode_lookback_horizon\": 1,\n      \"rollout_fragment_length\": \"auto\",\n      \"batch_mode\": \"truncate_episodes\",\n      \"compress_observations\": false,\n      \"remote_worker_envs\": false,\n      \"remote_env_batch_wait_ms\": 0,\n      \"enable_tf1_exec_eagerly\": false,\n      \"sample_collector\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059551000000000000008c357261792e726c6c69622e6576616c756174696f6e2e636f6c6c6563746f72732e73696d706c655f6c6973745f636f6c6c6563746f72948c1353696d706c654c697374436f6c6c6563746f729493942e\"\n      },\n      \"preprocessor_pref\": \"deepmind\",\n      \"observation_filter\": \"NoFilter\",\n      \"update_worker_filter_stats\": true,\n      \"use_worker_filter_stats\": true,\n      \"sampler_perf_stats_ema_coef\": null,\n      \"_is_online\": true,\n      \"num_learners\": 0,\n      \"num_gpus_per_learner\": 1,\n      \"num_cpus_per_learner\": \"auto\",\n      \"num_aggregator_actors_per_learner\": 0,\n      \"max_requests_in_flight_per_aggregator_actor\": 3,\n      \"local_gpu_idx\": 0,\n      \"max_requests_in_flight_per_learner\": 3,\n      \"gamma\": 0.99,\n      \"lr\": 5e-05,\n      \"grad_clip\": null,\n      \"grad_clip_by\": \"global_norm\",\n      \"_train_batch_size_per_learner\": null,\n      \"train_batch_size\": 4000,\n      \"num_epochs\": 10,\n      \"minibatch_size\": 256,\n      \"shuffle_batch_per_epoch\": true,\n      \"model\": {\n        \"fcnet_hiddens\": [\n          256,\n          256\n        ],\n        \"fcnet_activation\": \"tanh\",\n        \"fcnet_weights_initializer\": null,\n        \"fcnet_weights_initializer_config\": null,\n        \"fcnet_bias_initializer\": null,\n        \"fcnet_bias_initializer_config\": null,\n        \"conv_filters\": null,\n        \"conv_activation\": \"relu\",\n        \"conv_kernel_initializer\": null,\n        \"conv_kernel_initializer_config\": null,\n        \"conv_bias_initializer\": null,\n        \"conv_bias_initializer_config\": null,\n        \"conv_transpose_kernel_initializer\": null,\n        \"conv_transpose_kernel_initializer_config\": null,\n        \"conv_transpose_bias_initializer\": null,\n        \"conv_transpose_bias_initializer_config\": null,\n        \"post_fcnet_hiddens\": [],\n        \"post_fcnet_activation\": \"relu\",\n        \"post_fcnet_weights_initializer\": null,\n        \"post_fcnet_weights_initializer_config\": null,\n        \"post_fcnet_bias_initializer\": null,\n        \"post_fcnet_bias_initializer_config\": null,\n        \"free_log_std\": false,\n        \"log_std_clip_param\": 20.0,\n        \"no_final_linear\": false,\n        \"vf_share_layers\": false,\n        \"use_lstm\": false,\n        \"max_seq_len\": 20,\n        \"lstm_cell_size\": 256,\n        \"lstm_use_prev_action\": false,\n        \"lstm_use_prev_reward\": false,\n        \"lstm_weights_initializer\": null,\n        \"lstm_weights_initializer_config\": null,\n        \"lstm_bias_initializer\": null,\n        \"lstm_bias_initializer_config\": null,\n        \"_time_major\": false,\n        \"use_attention\": false,\n        \"attention_num_transformer_units\": 1,\n        \"attention_dim\": 64,\n        \"attention_num_heads\": 1,\n        \"attention_head_dim\": 32,\n        \"attention_memory_inference\": 50,\n        \"attention_memory_training\": 50,\n        \"attention_position_wise_mlp_dim\": 32,\n        \"attention_init_gru_gate_bias\": 2.0,\n        \"attention_use_n_prev_actions\": 0,\n        \"attention_use_n_prev_rewards\": 0,\n        \"framestack\": true,\n        \"dim\": 84,\n        \"grayscale\": false,\n        \"zero_mean\": true,\n        \"custom_model\": null,\n        \"custom_model_config\": {},\n        \"custom_action_dist\": null,\n        \"custom_preprocessor\": null,\n        \"encoder_latent_dim\": null,\n        \"always_check_shapes\": false,\n        \"lstm_use_prev_action_reward\": -1,\n        \"_use_default_native_models\": -1,\n        \"_disable_preprocessor_api\": false,\n        \"_disable_action_flattening\": false\n      },\n      \"_learner_connector\": null,\n      \"add_default_connectors_to_learner_pipeline\": true,\n      \"learner_config_dict\": {},\n      \"optimizer\": {},\n      \"_learner_class\": null,\n      \"callbacks_on_algorithm_init\": null,\n      \"callbacks_on_env_runners_recreated\": null,\n      \"callbacks_on_offline_eval_runners_recreated\": null,\n      \"callbacks_on_checkpoint_loaded\": null,\n      \"callbacks_on_environment_created\": null,\n      \"callbacks_on_episode_created\": null,\n      \"callbacks_on_episode_start\": null,\n      \"callbacks_on_episode_step\": null,\n      \"callbacks_on_episode_end\": null,\n      \"callbacks_on_evaluate_start\": null,\n      \"callbacks_on_evaluate_end\": null,\n      \"callbacks_on_evaluate_offline_start\": null,\n      \"callbacks_on_evaluate_offline_end\": null,\n      \"callbacks_on_sample_end\": null,\n      \"callbacks_on_train_result\": null,\n      \"explore\": true,\n      \"enable_rl_module_and_learner\": false,\n      \"enable_env_runner_and_connector_v2\": false,\n      \"_prior_exploration_config\": null,\n      \"count_steps_by\": \"env_steps\",\n      \"policy_map_capacity\": 100,\n      \"policy_mapping_fn\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059512020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b034b004b004b044b014b5b43047c005300944e859429288c086167656e745f6964948c07657069736f6465948c06776f726b6572948c066b77617267739474948c432f686f6d652f7875657a68692f7461736b2d61737369676e6d656e742d726f626f7469632d77617265686f7573652f736372697074732f747261696e5f70706f2e7079948c083c6c616d6264613e944b1e43020400942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680f754e4e4e7494529468008c125f66756e6374696f6e5f7365747374617465949394681a7d947d9428681668108c0c5f5f7175616c6e616d655f5f948c17747261696e2e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f9468098c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n      },\n      \"policies_to_train\": null,\n      \"policy_states_are_swappable\": false,\n      \"observation_fn\": null,\n      \"offline_data_class\": null,\n      \"input_read_method\": \"read_parquet\",\n      \"input_read_method_kwargs\": {},\n      \"input_read_schema\": {},\n      \"input_read_episodes\": false,\n      \"input_read_sample_batches\": false,\n      \"input_read_batch_size\": null,\n      \"input_filesystem\": null,\n      \"input_filesystem_kwargs\": {},\n      \"input_compress_columns\": [\n        \"obs\",\n        \"new_obs\"\n      ],\n      \"input_spaces_jsonable\": true,\n      \"materialize_data\": false,\n      \"materialize_mapped_data\": true,\n      \"map_batches_kwargs\": {},\n      \"iter_batches_kwargs\": {},\n      \"ignore_final_observation\": false,\n      \"prelearner_class\": null,\n      \"prelearner_buffer_class\": null,\n      \"prelearner_buffer_kwargs\": {},\n      \"prelearner_module_synch_period\": 10,\n      \"dataset_num_iters_per_learner\": null,\n      \"input_config\": {},\n      \"actions_in_input_normalized\": false,\n      \"postprocess_inputs\": false,\n      \"shuffle_buffer_size\": 0,\n      \"output\": null,\n      \"output_config\": {},\n      \"output_compress_columns\": [\n        \"obs\",\n        \"new_obs\"\n      ],\n      \"output_max_file_size\": 67108864,\n      \"output_max_rows_per_file\": null,\n      \"output_write_remaining_data\": false,\n      \"output_write_method\": \"write_parquet\",\n      \"output_write_method_kwargs\": {},\n      \"output_filesystem\": null,\n      \"output_filesystem_kwargs\": {},\n      \"output_write_episodes\": true,\n      \"offline_sampling\": false,\n      \"evaluation_interval\": 10,\n      \"evaluation_duration\": 5,\n      \"evaluation_duration_unit\": \"episodes\",\n      \"evaluation_sample_timeout_s\": 120.0,\n      \"evaluation_auto_duration_min_env_steps_per_sample\": 100,\n      \"evaluation_auto_duration_max_env_steps_per_sample\": 2000,\n      \"evaluation_parallel_to_training\": false,\n      \"evaluation_force_reset_envs_before_iteration\": true,\n      \"evaluation_config\": {\n        \"explore\": false\n      },\n      \"off_policy_estimation_methods\": {},\n      \"ope_split_batch_by_episode\": true,\n      \"evaluation_num_env_runners\": 0,\n      \"in_evaluation\": false,\n      \"sync_filters_on_rollout_workers_timeout_s\": 10.0,\n      \"offline_evaluation_interval\": null,\n      \"num_offline_eval_runners\": 0,\n      \"offline_evaluation_type\": null,\n      \"offline_eval_runner_class\": null,\n      \"offline_loss_for_module_fn\": null,\n      \"offline_evaluation_duration\": 1,\n      \"offline_evaluation_parallel_to_training\": false,\n      \"offline_evaluation_timeout_s\": 120.0,\n      \"num_cpus_per_offline_eval_runner\": 1,\n      \"num_gpus_per_offline_eval_runner\": 0,\n      \"custom_resources_per_offline_eval_runner\": {},\n      \"restart_failed_offline_eval_runners\": true,\n      \"ignore_offline_eval_runner_failures\": false,\n      \"max_num_offline_eval_runner_restarts\": 1000,\n      \"offline_eval_runner_restore_timeout_s\": 1800.0,\n      \"max_requests_in_flight_per_offline_eval_runner\": 1,\n      \"validate_offline_eval_runners_after_construction\": true,\n      \"offline_eval_runner_health_probe_timeout_s\": 30.0,\n      \"offline_eval_rl_module_inference_only\": false,\n      \"broadcast_offline_eval_runner_states\": false,\n      \"offline_eval_batch_size_per_runner\": 256,\n      \"dataset_num_iters_per_eval_runner\": 1,\n      \"keep_per_episode_custom_metrics\": false,\n      \"metrics_episode_collection_timeout_s\": 60.0,\n      \"metrics_num_episodes_for_smoothing\": 100,\n      \"min_time_s_per_iteration\": null,\n      \"min_train_timesteps_per_iteration\": 0,\n      \"min_sample_timesteps_per_iteration\": 0,\n      \"log_gradients\": false,\n      \"export_native_model_files\": false,\n      \"checkpoint_trainable_policies_only\": false,\n      \"logger_creator\": null,\n      \"logger_config\": null,\n      \"log_level\": \"WARN\",\n      \"log_sys_usage\": true,\n      \"fake_sampler\": false,\n      \"seed\": null,\n      \"restart_failed_env_runners\": true,\n      \"ignore_env_runner_failures\": false,\n      \"max_num_env_runner_restarts\": 1000,\n      \"delay_between_env_runner_restarts_s\": 60.0,\n      \"restart_failed_sub_environments\": false,\n      \"num_consecutive_env_runner_failures_tolerance\": 100,\n      \"env_runner_health_probe_timeout_s\": 30.0,\n      \"env_runner_restore_timeout_s\": 1800.0,\n      \"_model_config\": {},\n      \"_rl_module_spec\": null,\n      \"algorithm_config_overrides_per_module\": {},\n      \"_per_module_overrides\": {},\n      \"_validate_config\": true,\n      \"_use_msgpack_checkpoints\": false,\n      \"_torch_grad_scaler_class\": null,\n      \"_torch_lr_scheduler_classes\": null,\n      \"_tf_policy_handles_more_than_one_loss\": false,\n      \"_disable_preprocessor_api\": false,\n      \"_disable_action_flattening\": false,\n      \"_disable_initialize_loss_from_dummy_batch\": false,\n      \"_dont_auto_sync_env_runner_states\": false,\n      \"env_task_fn\": -1,\n      \"enable_connectors\": -1,\n      \"simple_optimizer\": true,\n      \"policy_map_cache\": -1,\n      \"worker_cls\": -1,\n      \"synchronize_filters\": -1,\n      \"enable_async_evaluation\": -1,\n      \"custom_async_evaluation_function\": -1,\n      \"_enable_rl_module_api\": -1,\n      \"auto_wrap_old_gym_envs\": -1,\n      \"always_attach_evaluation_results\": -1,\n      \"replay_sequence_length\": null,\n      \"_disable_execution_plan_api\": -1,\n      \"use_critic\": true,\n      \"use_gae\": true,\n      \"use_kl_loss\": true,\n      \"kl_coeff\": 0.2,\n      \"kl_target\": 0.01,\n      \"vf_loss_coeff\": 1.0,\n      \"entropy_coeff\": 0.0,\n      \"clip_param\": 0.2,\n      \"vf_clip_param\": 10.0,\n      \"entropy_coeff_schedule\": null,\n      \"lr_schedule\": null,\n      \"sgd_minibatch_size\": -1,\n      \"vf_share_layers\": -1,\n      \"__stdout_file__\": null,\n      \"__stderr_file__\": null,\n      \"lambda\": 0.95,\n      \"input\": \"sampler\",\n      \"policies\": {\n        \"agent_0\": [\n          null,\n          null,\n          null,\n          {}\n        ],\n        \"agent_1\": [\n          null,\n          null,\n          null,\n          {}\n        ],\n        \"agent_2\": [\n          null,\n          null,\n          null,\n          {}\n        ],\n        \"agent_3\": [\n          null,\n          null,\n          null,\n          {}\n        ],\n        \"agent_4\": [\n          null,\n          null,\n          null,\n          {}\n        ],\n        \"agent_5\": [\n          null,\n          null,\n          null,\n          {}\n        ],\n        \"agent_6\": [\n          null,\n          null,\n          null,\n          {}\n        ],\n        \"agent_7\": [\n          null,\n          null,\n          null,\n          {}\n        ],\n        \"agent_8\": [\n          null,\n          null,\n          null,\n          {}\n        ],\n        \"agent_9\": [\n          null,\n          null,\n          null,\n          {}\n        ],\n        \"agent_10\": [\n          null,\n          null,\n          null,\n          {}\n        ],\n        \"agent_11\": [\n          null,\n          null,\n          null,\n          {}\n        ],\n        \"agent_12\": [\n          null,\n          null,\n          null,\n          {}\n        ],\n        \"agent_13\": [\n          null,\n          null,\n          null,\n          {}\n        ],\n        \"agent_14\": [\n          null,\n          null,\n          null,\n          {}\n        ],\n        \"agent_15\": [\n          null,\n          null,\n          null,\n          {}\n        ],\n        \"agent_16\": [\n          null,\n          null,\n          null,\n          {}\n        ],\n        \"agent_17\": [\n          null,\n          null,\n          null,\n          {}\n        ],\n        \"agent_18\": [\n          null,\n          null,\n          null,\n          {}\n        ],\n        \"agent_19\": [\n          null,\n          null,\n          null,\n          {}\n        ],\n        \"agent_20\": [\n          null,\n          null,\n          null,\n          {}\n        ]\n      },\n      \"callbacks\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059533000000000000008c1d7261792e726c6c69622e63616c6c6261636b732e63616c6c6261636b73948c0d524c6c696243616c6c6261636b9493942e\"\n      },\n      \"create_env_on_driver\": false,\n      \"custom_eval_function\": null,\n      \"framework\": \"torch\"\n    },\n    \"time_since_restore\": 31.19081139564514,\n    \"iterations_since_restore\": 1,\n    \"perf\": {\n      \"cpu_util_percent\": 8.854545454545452,\n      \"ram_util_percent\": 25.363636363636363,\n      \"gpu_util_percent0\": 0.23772727272727268,\n      \"vram_util_percent0\": 0.08104765288448727\n    },\n    \"experiment_tag\": \"0\"\n  },\n  \"last_result_time\": 1761037777.3918147,\n  \"metric_analysis\": {\n    \"num_healthy_workers\": {\n      \"max\": 3,\n      \"min\": 3,\n      \"avg\": 3,\n      \"last\": 3,\n      \"last-5-avg\": 3,\n      \"last-10-avg\": 3\n    },\n    \"actor_manager_num_outstanding_async_reqs\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"num_remote_worker_restarts\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"num_agent_steps_sampled\": {\n      \"max\": 84000,\n      \"min\": 84000,\n      \"avg\": 84000,\n      \"last\": 84000,\n      \"last-5-avg\": 84000,\n      \"last-10-avg\": 84000\n    },\n    \"num_agent_steps_trained\": {\n      \"max\": 84000,\n      \"min\": 84000,\n      \"avg\": 84000,\n      \"last\": 84000,\n      \"last-5-avg\": 84000,\n      \"last-10-avg\": 84000\n    },\n    \"num_env_steps_sampled\": {\n      \"max\": 4000,\n      \"min\": 4000,\n      \"avg\": 4000,\n      \"last\": 4000,\n      \"last-5-avg\": 4000,\n      \"last-10-avg\": 4000\n    },\n    \"num_env_steps_trained\": {\n      \"max\": 4000,\n      \"min\": 4000,\n      \"avg\": 4000,\n      \"last\": 4000,\n      \"last-5-avg\": 4000,\n      \"last-10-avg\": 4000\n    },\n    \"num_env_steps_sampled_this_iter\": {\n      \"max\": 4000,\n      \"min\": 4000,\n      \"avg\": 4000,\n      \"last\": 4000,\n      \"last-5-avg\": 4000,\n      \"last-10-avg\": 4000\n    },\n    \"num_env_steps_trained_this_iter\": {\n      \"max\": 4000,\n      \"min\": 4000,\n      \"avg\": 4000,\n      \"last\": 4000,\n      \"last-5-avg\": 4000,\n      \"last-10-avg\": 4000\n    },\n    \"num_env_steps_sampled_throughput_per_sec\": {\n      \"max\": 128.324312796662,\n      \"min\": 128.324312796662,\n      \"avg\": 128.324312796662,\n      \"last\": 128.324312796662,\n      \"last-5-avg\": 128.324312796662,\n      \"last-10-avg\": 128.324312796662\n    },\n    \"num_env_steps_trained_throughput_per_sec\": {\n      \"max\": 128.324312796662,\n      \"min\": 128.324312796662,\n      \"avg\": 128.324312796662,\n      \"last\": 128.324312796662,\n      \"last-5-avg\": 128.324312796662,\n      \"last-10-avg\": 128.324312796662\n    },\n    \"timesteps_total\": {\n      \"max\": 4000,\n      \"min\": 4000,\n      \"avg\": 4000,\n      \"last\": 4000,\n      \"last-5-avg\": 4000,\n      \"last-10-avg\": 4000\n    },\n    \"num_env_steps_sampled_lifetime\": {\n      \"max\": 4000,\n      \"min\": 4000,\n      \"avg\": 4000,\n      \"last\": 4000,\n      \"last-5-avg\": 4000,\n      \"last-10-avg\": 4000\n    },\n    \"num_agent_steps_sampled_lifetime\": {\n      \"max\": 84000,\n      \"min\": 84000,\n      \"avg\": 84000,\n      \"last\": 84000,\n      \"last-5-avg\": 84000,\n      \"last-10-avg\": 84000\n    },\n    \"num_steps_trained_this_iter\": {\n      \"max\": 4000,\n      \"min\": 4000,\n      \"avg\": 4000,\n      \"last\": 4000,\n      \"last-5-avg\": 4000,\n      \"last-10-avg\": 4000\n    },\n    \"agent_timesteps_total\": {\n      \"max\": 84000,\n      \"min\": 84000,\n      \"avg\": 84000,\n      \"last\": 84000,\n      \"last-5-avg\": 84000,\n      \"last-10-avg\": 84000\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 31.19081139564514,\n      \"min\": 31.19081139564514,\n      \"avg\": 31.19081139564514,\n      \"last\": 31.19081139564514,\n      \"last-5-avg\": 31.19081139564514,\n      \"last-10-avg\": 31.19081139564514\n    },\n    \"time_total_s\": {\n      \"max\": 31.19081139564514,\n      \"min\": 31.19081139564514,\n      \"avg\": 31.19081139564514,\n      \"last\": 31.19081139564514,\n      \"last-5-avg\": 31.19081139564514,\n      \"last-10-avg\": 31.19081139564514\n    },\n    \"time_since_restore\": {\n      \"max\": 31.19081139564514,\n      \"min\": 31.19081139564514,\n      \"avg\": 31.19081139564514,\n      \"last\": 31.19081139564514,\n      \"last-5-avg\": 31.19081139564514,\n      \"last-10-avg\": 31.19081139564514\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"info/num_env_steps_sampled\": {\n      \"max\": 4000,\n      \"min\": 4000,\n      \"avg\": 4000,\n      \"last\": 4000,\n      \"last-5-avg\": 4000,\n      \"last-10-avg\": 4000\n    },\n    \"info/num_env_steps_trained\": {\n      \"max\": 4000,\n      \"min\": 4000,\n      \"avg\": 4000,\n      \"last\": 4000,\n      \"last-5-avg\": 4000,\n      \"last-10-avg\": 4000\n    },\n    \"info/num_agent_steps_sampled\": {\n      \"max\": 84000,\n      \"min\": 84000,\n      \"avg\": 84000,\n      \"last\": 84000,\n      \"last-5-avg\": 84000,\n      \"last-10-avg\": 84000\n    },\n    \"info/num_agent_steps_trained\": {\n      \"max\": 84000,\n      \"min\": 84000,\n      \"avg\": 84000,\n      \"last\": 84000,\n      \"last-5-avg\": 84000,\n      \"last-10-avg\": 84000\n    },\n    \"env_runners/episode_reward_max\": {\n      \"max\": -43.929999999999694,\n      \"min\": -43.929999999999694,\n      \"avg\": -43.929999999999694,\n      \"last\": -43.929999999999694,\n      \"last-5-avg\": -43.929999999999694,\n      \"last-10-avg\": -43.929999999999694\n    },\n    \"env_runners/episode_reward_min\": {\n      \"max\": -61.56000000000211,\n      \"min\": -61.56000000000211,\n      \"avg\": -61.56000000000211,\n      \"last\": -61.56000000000211,\n      \"last-5-avg\": -61.56000000000211,\n      \"last-10-avg\": -61.56000000000211\n    },\n    \"env_runners/episode_reward_mean\": {\n      \"max\": -54.30500000000122,\n      \"min\": -54.30500000000122,\n      \"avg\": -54.30500000000122,\n      \"last\": -54.30500000000122,\n      \"last-5-avg\": -54.30500000000122,\n      \"last-10-avg\": -54.30500000000122\n    },\n    \"env_runners/episode_len_mean\": {\n      \"max\": 500.0,\n      \"min\": 500.0,\n      \"avg\": 500.0,\n      \"last\": 500.0,\n      \"last-5-avg\": 500.0,\n      \"last-10-avg\": 500.0\n    },\n    \"env_runners/episodes_timesteps_total\": {\n      \"max\": 3000,\n      \"min\": 3000,\n      \"avg\": 3000,\n      \"last\": 3000,\n      \"last-5-avg\": 3000,\n      \"last-10-avg\": 3000\n    },\n    \"env_runners/num_faulty_episodes\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"env_runners/num_episodes\": {\n      \"max\": 6,\n      \"min\": 6,\n      \"avg\": 6,\n      \"last\": 6,\n      \"last-5-avg\": 6,\n      \"last-10-avg\": 6\n    },\n    \"env_runners/episode_return_max\": {\n      \"max\": -43.929999999999694,\n      \"min\": -43.929999999999694,\n      \"avg\": -43.929999999999694,\n      \"last\": -43.929999999999694,\n      \"last-5-avg\": -43.929999999999694,\n      \"last-10-avg\": -43.929999999999694\n    },\n    \"env_runners/episode_return_min\": {\n      \"max\": -61.56000000000211,\n      \"min\": -61.56000000000211,\n      \"avg\": -61.56000000000211,\n      \"last\": -61.56000000000211,\n      \"last-5-avg\": -61.56000000000211,\n      \"last-10-avg\": -61.56000000000211\n    },\n    \"env_runners/episode_return_mean\": {\n      \"max\": -54.30500000000122,\n      \"min\": -54.30500000000122,\n      \"avg\": -54.30500000000122,\n      \"last\": -54.30500000000122,\n      \"last-5-avg\": -54.30500000000122,\n      \"last-10-avg\": -54.30500000000122\n    },\n    \"env_runners/episodes_this_iter\": {\n      \"max\": 6,\n      \"min\": 6,\n      \"avg\": 6,\n      \"last\": 6,\n      \"last-5-avg\": 6,\n      \"last-10-avg\": 6\n    },\n    \"timers/training_iteration_time_ms\": {\n      \"max\": 31171.028,\n      \"min\": 31171.028,\n      \"avg\": 31171.028,\n      \"last\": 31171.028,\n      \"last-5-avg\": 31171.028,\n      \"last-10-avg\": 31171.028\n    },\n    \"timers/restore_workers_time_ms\": {\n      \"max\": 0.012,\n      \"min\": 0.012,\n      \"avg\": 0.012,\n      \"last\": 0.012,\n      \"last-5-avg\": 0.012,\n      \"last-10-avg\": 0.012\n    },\n    \"timers/training_step_time_ms\": {\n      \"max\": 31170.99,\n      \"min\": 31170.99,\n      \"avg\": 31170.99,\n      \"last\": 31170.99,\n      \"last-5-avg\": 31170.99,\n      \"last-10-avg\": 31170.99\n    },\n    \"timers/sample_time_ms\": {\n      \"max\": 20658.006,\n      \"min\": 20658.006,\n      \"avg\": 20658.006,\n      \"last\": 20658.006,\n      \"last-5-avg\": 20658.006,\n      \"last-10-avg\": 20658.006\n    },\n    \"timers/learn_time_ms\": {\n      \"max\": 10486.003,\n      \"min\": 10486.003,\n      \"avg\": 10486.003,\n      \"last\": 10486.003,\n      \"last-5-avg\": 10486.003,\n      \"last-10-avg\": 10486.003\n    },\n    \"timers/learn_throughput\": {\n      \"max\": 381.461,\n      \"min\": 381.461,\n      \"avg\": 381.461,\n      \"last\": 381.461,\n      \"last-5-avg\": 381.461,\n      \"last-10-avg\": 381.461\n    },\n    \"timers/synch_weights_time_ms\": {\n      \"max\": 25.959,\n      \"min\": 25.959,\n      \"avg\": 25.959,\n      \"last\": 25.959,\n      \"last-5-avg\": 25.959,\n      \"last-10-avg\": 25.959\n    },\n    \"counters/num_env_steps_sampled\": {\n      \"max\": 4000,\n      \"min\": 4000,\n      \"avg\": 4000,\n      \"last\": 4000,\n      \"last-5-avg\": 4000,\n      \"last-10-avg\": 4000\n    },\n    \"counters/num_env_steps_trained\": {\n      \"max\": 4000,\n      \"min\": 4000,\n      \"avg\": 4000,\n      \"last\": 4000,\n      \"last-5-avg\": 4000,\n      \"last-10-avg\": 4000\n    },\n    \"counters/num_agent_steps_sampled\": {\n      \"max\": 84000,\n      \"min\": 84000,\n      \"avg\": 84000,\n      \"last\": 84000,\n      \"last-5-avg\": 84000,\n      \"last-10-avg\": 84000\n    },\n    \"counters/num_agent_steps_trained\": {\n      \"max\": 84000,\n      \"min\": 84000,\n      \"avg\": 84000,\n      \"last\": 84000,\n      \"last-5-avg\": 84000,\n      \"last-10-avg\": 84000\n    },\n    \"perf/cpu_util_percent\": {\n      \"max\": 8.854545454545452,\n      \"min\": 8.854545454545452,\n      \"avg\": 8.854545454545452,\n      \"last\": 8.854545454545452,\n      \"last-5-avg\": 8.854545454545452,\n      \"last-10-avg\": 8.854545454545452\n    },\n    \"perf/ram_util_percent\": {\n      \"max\": 25.363636363636363,\n      \"min\": 25.363636363636363,\n      \"avg\": 25.363636363636363,\n      \"last\": 25.363636363636363,\n      \"last-5-avg\": 25.363636363636363,\n      \"last-10-avg\": 25.363636363636363\n    },\n    \"perf/gpu_util_percent0\": {\n      \"max\": 0.23772727272727268,\n      \"min\": 0.23772727272727268,\n      \"avg\": 0.23772727272727268,\n      \"last\": 0.23772727272727268,\n      \"last-5-avg\": 0.23772727272727268,\n      \"last-10-avg\": 0.23772727272727268\n    },\n    \"perf/vram_util_percent0\": {\n      \"max\": 0.08104765288448727,\n      \"min\": 0.08104765288448727,\n      \"avg\": 0.08104765288448727,\n      \"last\": 0.08104765288448727,\n      \"last-5-avg\": 0.08104765288448727,\n      \"last-10-avg\": 0.08104765288448727\n    },\n    \"env_runners/policy_reward_min/agent_0\": {\n      \"max\": -5.190000000000026,\n      \"min\": -5.190000000000026,\n      \"avg\": -5.190000000000026,\n      \"last\": -5.190000000000026,\n      \"last-5-avg\": -5.190000000000026,\n      \"last-10-avg\": -5.190000000000026\n    },\n    \"env_runners/policy_reward_min/agent_1\": {\n      \"max\": -5.260000000000027,\n      \"min\": -5.260000000000027,\n      \"avg\": -5.260000000000027,\n      \"last\": -5.260000000000027,\n      \"last-5-avg\": -5.260000000000027,\n      \"last-10-avg\": -5.260000000000027\n    },\n    \"env_runners/policy_reward_min/agent_2\": {\n      \"max\": -0.5000000000000003,\n      \"min\": -0.5000000000000003,\n      \"avg\": -0.5000000000000003,\n      \"last\": -0.5000000000000003,\n      \"last-5-avg\": -0.5000000000000003,\n      \"last-10-avg\": -0.5000000000000003\n    },\n    \"env_runners/policy_reward_min/agent_3\": {\n      \"max\": -5.320000000000028,\n      \"min\": -5.320000000000028,\n      \"avg\": -5.320000000000028,\n      \"last\": -5.320000000000028,\n      \"last-5-avg\": -5.320000000000028,\n      \"last-10-avg\": -5.320000000000028\n    },\n    \"env_runners/policy_reward_min/agent_4\": {\n      \"max\": -0.5000000000000003,\n      \"min\": -0.5000000000000003,\n      \"avg\": -0.5000000000000003,\n      \"last\": -0.5000000000000003,\n      \"last-5-avg\": -0.5000000000000003,\n      \"last-10-avg\": -0.5000000000000003\n    },\n    \"env_runners/policy_reward_min/agent_5\": {\n      \"max\": -4.0700000000000145,\n      \"min\": -4.0700000000000145,\n      \"avg\": -4.0700000000000145,\n      \"last\": -4.0700000000000145,\n      \"last-5-avg\": -4.0700000000000145,\n      \"last-10-avg\": -4.0700000000000145\n    },\n    \"env_runners/policy_reward_min/agent_6\": {\n      \"max\": -5.130000000000026,\n      \"min\": -5.130000000000026,\n      \"avg\": -5.130000000000026,\n      \"last\": -5.130000000000026,\n      \"last-5-avg\": -5.130000000000026,\n      \"last-10-avg\": -5.130000000000026\n    },\n    \"env_runners/policy_reward_min/agent_7\": {\n      \"max\": -0.5000000000000003,\n      \"min\": -0.5000000000000003,\n      \"avg\": -0.5000000000000003,\n      \"last\": -0.5000000000000003,\n      \"last-5-avg\": -0.5000000000000003,\n      \"last-10-avg\": -0.5000000000000003\n    },\n    \"env_runners/policy_reward_min/agent_8\": {\n      \"max\": -0.5000000000000003,\n      \"min\": -0.5000000000000003,\n      \"avg\": -0.5000000000000003,\n      \"last\": -0.5000000000000003,\n      \"last-5-avg\": -0.5000000000000003,\n      \"last-10-avg\": -0.5000000000000003\n    },\n    \"env_runners/policy_reward_min/agent_9\": {\n      \"max\": -0.5000000000000003,\n      \"min\": -0.5000000000000003,\n      \"avg\": -0.5000000000000003,\n      \"last\": -0.5000000000000003,\n      \"last-5-avg\": -0.5000000000000003,\n      \"last-10-avg\": -0.5000000000000003\n    },\n    \"env_runners/policy_reward_min/agent_10\": {\n      \"max\": -5.290000000000028,\n      \"min\": -5.290000000000028,\n      \"avg\": -5.290000000000028,\n      \"last\": -5.290000000000028,\n      \"last-5-avg\": -5.290000000000028,\n      \"last-10-avg\": -5.290000000000028\n    },\n    \"env_runners/policy_reward_min/agent_11\": {\n      \"max\": -5.330000000000028,\n      \"min\": -5.330000000000028,\n      \"avg\": -5.330000000000028,\n      \"last\": -5.330000000000028,\n      \"last-5-avg\": -5.330000000000028,\n      \"last-10-avg\": -5.330000000000028\n    },\n    \"env_runners/policy_reward_min/agent_12\": {\n      \"max\": -5.290000000000028,\n      \"min\": -5.290000000000028,\n      \"avg\": -5.290000000000028,\n      \"last\": -5.290000000000028,\n      \"last-5-avg\": -5.290000000000028,\n      \"last-10-avg\": -5.290000000000028\n    },\n    \"env_runners/policy_reward_min/agent_13\": {\n      \"max\": -5.080000000000025,\n      \"min\": -5.080000000000025,\n      \"avg\": -5.080000000000025,\n      \"last\": -5.080000000000025,\n      \"last-5-avg\": -5.080000000000025,\n      \"last-10-avg\": -5.080000000000025\n    },\n    \"env_runners/policy_reward_min/agent_14\": {\n      \"max\": -4.880000000000023,\n      \"min\": -4.880000000000023,\n      \"avg\": -4.880000000000023,\n      \"last\": -4.880000000000023,\n      \"last-5-avg\": -4.880000000000023,\n      \"last-10-avg\": -4.880000000000023\n    },\n    \"env_runners/policy_reward_min/agent_15\": {\n      \"max\": -5.230000000000027,\n      \"min\": -5.230000000000027,\n      \"avg\": -5.230000000000027,\n      \"last\": -5.230000000000027,\n      \"last-5-avg\": -5.230000000000027,\n      \"last-10-avg\": -5.230000000000027\n    },\n    \"env_runners/policy_reward_min/agent_16\": {\n      \"max\": -5.100000000000026,\n      \"min\": -5.100000000000026,\n      \"avg\": -5.100000000000026,\n      \"last\": -5.100000000000026,\n      \"last-5-avg\": -5.100000000000026,\n      \"last-10-avg\": -5.100000000000026\n    },\n    \"env_runners/policy_reward_min/agent_17\": {\n      \"max\": -5.330000000000028,\n      \"min\": -5.330000000000028,\n      \"avg\": -5.330000000000028,\n      \"last\": -5.330000000000028,\n      \"last-5-avg\": -5.330000000000028,\n      \"last-10-avg\": -5.330000000000028\n    },\n    \"env_runners/policy_reward_min/agent_18\": {\n      \"max\": -4.630000000000019,\n      \"min\": -4.630000000000019,\n      \"avg\": -4.630000000000019,\n      \"last\": -4.630000000000019,\n      \"last-5-avg\": -4.630000000000019,\n      \"last-10-avg\": -4.630000000000019\n    },\n    \"env_runners/policy_reward_min/agent_19\": {\n      \"max\": -4.910000000000023,\n      \"min\": -4.910000000000023,\n      \"avg\": -4.910000000000023,\n      \"last\": -4.910000000000023,\n      \"last-5-avg\": -4.910000000000023,\n      \"last-10-avg\": -4.910000000000023\n    },\n    \"env_runners/policy_reward_min/agent_20\": {\n      \"max\": -4.980000000000024,\n      \"min\": -4.980000000000024,\n      \"avg\": -4.980000000000024,\n      \"last\": -4.980000000000024,\n      \"last-5-avg\": -4.980000000000024,\n      \"last-10-avg\": -4.980000000000024\n    },\n    \"env_runners/policy_reward_max/agent_0\": {\n      \"max\": -0.5000000000000003,\n      \"min\": -0.5000000000000003,\n      \"avg\": -0.5000000000000003,\n      \"last\": -0.5000000000000003,\n      \"last-5-avg\": -0.5000000000000003,\n      \"last-10-avg\": -0.5000000000000003\n    },\n    \"env_runners/policy_reward_max/agent_1\": {\n      \"max\": -0.5000000000000003,\n      \"min\": -0.5000000000000003,\n      \"avg\": -0.5000000000000003,\n      \"last\": -0.5000000000000003,\n      \"last-5-avg\": -0.5000000000000003,\n      \"last-10-avg\": -0.5000000000000003\n    },\n    \"env_runners/policy_reward_max/agent_2\": {\n      \"max\": -0.5000000000000003,\n      \"min\": -0.5000000000000003,\n      \"avg\": -0.5000000000000003,\n      \"last\": -0.5000000000000003,\n      \"last-5-avg\": -0.5000000000000003,\n      \"last-10-avg\": -0.5000000000000003\n    },\n    \"env_runners/policy_reward_max/agent_3\": {\n      \"max\": -0.5000000000000003,\n      \"min\": -0.5000000000000003,\n      \"avg\": -0.5000000000000003,\n      \"last\": -0.5000000000000003,\n      \"last-5-avg\": -0.5000000000000003,\n      \"last-10-avg\": -0.5000000000000003\n    },\n    \"env_runners/policy_reward_max/agent_4\": {\n      \"max\": -0.5000000000000003,\n      \"min\": -0.5000000000000003,\n      \"avg\": -0.5000000000000003,\n      \"last\": -0.5000000000000003,\n      \"last-5-avg\": -0.5000000000000003,\n      \"last-10-avg\": -0.5000000000000003\n    },\n    \"env_runners/policy_reward_max/agent_5\": {\n      \"max\": -0.5000000000000003,\n      \"min\": -0.5000000000000003,\n      \"avg\": -0.5000000000000003,\n      \"last\": -0.5000000000000003,\n      \"last-5-avg\": -0.5000000000000003,\n      \"last-10-avg\": -0.5000000000000003\n    },\n    \"env_runners/policy_reward_max/agent_6\": {\n      \"max\": -0.5000000000000003,\n      \"min\": -0.5000000000000003,\n      \"avg\": -0.5000000000000003,\n      \"last\": -0.5000000000000003,\n      \"last-5-avg\": -0.5000000000000003,\n      \"last-10-avg\": -0.5000000000000003\n    },\n    \"env_runners/policy_reward_max/agent_7\": {\n      \"max\": -0.5000000000000003,\n      \"min\": -0.5000000000000003,\n      \"avg\": -0.5000000000000003,\n      \"last\": -0.5000000000000003,\n      \"last-5-avg\": -0.5000000000000003,\n      \"last-10-avg\": -0.5000000000000003\n    },\n    \"env_runners/policy_reward_max/agent_8\": {\n      \"max\": -0.5000000000000003,\n      \"min\": -0.5000000000000003,\n      \"avg\": -0.5000000000000003,\n      \"last\": -0.5000000000000003,\n      \"last-5-avg\": -0.5000000000000003,\n      \"last-10-avg\": -0.5000000000000003\n    },\n    \"env_runners/policy_reward_max/agent_9\": {\n      \"max\": -0.5000000000000003,\n      \"min\": -0.5000000000000003,\n      \"avg\": -0.5000000000000003,\n      \"last\": -0.5000000000000003,\n      \"last-5-avg\": -0.5000000000000003,\n      \"last-10-avg\": -0.5000000000000003\n    },\n    \"env_runners/policy_reward_max/agent_10\": {\n      \"max\": -0.5000000000000003,\n      \"min\": -0.5000000000000003,\n      \"avg\": -0.5000000000000003,\n      \"last\": -0.5000000000000003,\n      \"last-5-avg\": -0.5000000000000003,\n      \"last-10-avg\": -0.5000000000000003\n    },\n    \"env_runners/policy_reward_max/agent_11\": {\n      \"max\": -0.5000000000000003,\n      \"min\": -0.5000000000000003,\n      \"avg\": -0.5000000000000003,\n      \"last\": -0.5000000000000003,\n      \"last-5-avg\": -0.5000000000000003,\n      \"last-10-avg\": -0.5000000000000003\n    },\n    \"env_runners/policy_reward_max/agent_12\": {\n      \"max\": -0.5000000000000003,\n      \"min\": -0.5000000000000003,\n      \"avg\": -0.5000000000000003,\n      \"last\": -0.5000000000000003,\n      \"last-5-avg\": -0.5000000000000003,\n      \"last-10-avg\": -0.5000000000000003\n    },\n    \"env_runners/policy_reward_max/agent_13\": {\n      \"max\": -0.5000000000000003,\n      \"min\": -0.5000000000000003,\n      \"avg\": -0.5000000000000003,\n      \"last\": -0.5000000000000003,\n      \"last-5-avg\": -0.5000000000000003,\n      \"last-10-avg\": -0.5000000000000003\n    },\n    \"env_runners/policy_reward_max/agent_14\": {\n      \"max\": -3.68000000000001,\n      \"min\": -3.68000000000001,\n      \"avg\": -3.68000000000001,\n      \"last\": -3.68000000000001,\n      \"last-5-avg\": -3.68000000000001,\n      \"last-10-avg\": -3.68000000000001\n    },\n    \"env_runners/policy_reward_max/agent_15\": {\n      \"max\": -4.090000000000013,\n      \"min\": -4.090000000000013,\n      \"avg\": -4.090000000000013,\n      \"last\": -4.090000000000013,\n      \"last-5-avg\": -4.090000000000013,\n      \"last-10-avg\": -4.090000000000013\n    },\n    \"env_runners/policy_reward_max/agent_16\": {\n      \"max\": -3.940000000000013,\n      \"min\": -3.940000000000013,\n      \"avg\": -3.940000000000013,\n      \"last\": -3.940000000000013,\n      \"last-5-avg\": -3.940000000000013,\n      \"last-10-avg\": -3.940000000000013\n    },\n    \"env_runners/policy_reward_max/agent_17\": {\n      \"max\": -3.950000000000013,\n      \"min\": -3.950000000000013,\n      \"avg\": -3.950000000000013,\n      \"last\": -3.950000000000013,\n      \"last-5-avg\": -3.950000000000013,\n      \"last-10-avg\": -3.950000000000013\n    },\n    \"env_runners/policy_reward_max/agent_18\": {\n      \"max\": -3.6700000000000097,\n      \"min\": -3.6700000000000097,\n      \"avg\": -3.6700000000000097,\n      \"last\": -3.6700000000000097,\n      \"last-5-avg\": -3.6700000000000097,\n      \"last-10-avg\": -3.6700000000000097\n    },\n    \"env_runners/policy_reward_max/agent_19\": {\n      \"max\": -4.220000000000016,\n      \"min\": -4.220000000000016,\n      \"avg\": -4.220000000000016,\n      \"last\": -4.220000000000016,\n      \"last-5-avg\": -4.220000000000016,\n      \"last-10-avg\": -4.220000000000016\n    },\n    \"env_runners/policy_reward_max/agent_20\": {\n      \"max\": -4.140000000000015,\n      \"min\": -4.140000000000015,\n      \"avg\": -4.140000000000015,\n      \"last\": -4.140000000000015,\n      \"last-5-avg\": -4.140000000000015,\n      \"last-10-avg\": -4.140000000000015\n    },\n    \"env_runners/policy_reward_mean/agent_0\": {\n      \"max\": -1.3300000000000047,\n      \"min\": -1.3300000000000047,\n      \"avg\": -1.3300000000000047,\n      \"last\": -1.3300000000000047,\n      \"last-5-avg\": -1.3300000000000047,\n      \"last-10-avg\": -1.3300000000000047\n    },\n    \"env_runners/policy_reward_mean/agent_1\": {\n      \"max\": -2.823333333333346,\n      \"min\": -2.823333333333346,\n      \"avg\": -2.823333333333346,\n      \"last\": -2.823333333333346,\n      \"last-5-avg\": -2.823333333333346,\n      \"last-10-avg\": -2.823333333333346\n    },\n    \"env_runners/policy_reward_mean/agent_2\": {\n      \"max\": -0.5000000000000003,\n      \"min\": -0.5000000000000003,\n      \"avg\": -0.5000000000000003,\n      \"last\": -0.5000000000000003,\n      \"last-5-avg\": -0.5000000000000003,\n      \"last-10-avg\": -0.5000000000000003\n    },\n    \"env_runners/policy_reward_mean/agent_3\": {\n      \"max\": -2.491666666666676,\n      \"min\": -2.491666666666676,\n      \"avg\": -2.491666666666676,\n      \"last\": -2.491666666666676,\n      \"last-5-avg\": -2.491666666666676,\n      \"last-10-avg\": -2.491666666666676\n    },\n    \"env_runners/policy_reward_mean/agent_4\": {\n      \"max\": -0.5000000000000003,\n      \"min\": -0.5000000000000003,\n      \"avg\": -0.5000000000000003,\n      \"last\": -0.5000000000000003,\n      \"last-5-avg\": -0.5000000000000003,\n      \"last-10-avg\": -0.5000000000000003\n    },\n    \"env_runners/policy_reward_mean/agent_5\": {\n      \"max\": -1.8083333333333353,\n      \"min\": -1.8083333333333353,\n      \"avg\": -1.8083333333333353,\n      \"last\": -1.8083333333333353,\n      \"last-5-avg\": -1.8083333333333353,\n      \"last-10-avg\": -1.8083333333333353\n    },\n    \"env_runners/policy_reward_mean/agent_6\": {\n      \"max\": -1.321666666666671,\n      \"min\": -1.321666666666671,\n      \"avg\": -1.321666666666671,\n      \"last\": -1.321666666666671,\n      \"last-5-avg\": -1.321666666666671,\n      \"last-10-avg\": -1.321666666666671\n    },\n    \"env_runners/policy_reward_mean/agent_7\": {\n      \"max\": -0.5000000000000003,\n      \"min\": -0.5000000000000003,\n      \"avg\": -0.5000000000000003,\n      \"last\": -0.5000000000000003,\n      \"last-5-avg\": -0.5000000000000003,\n      \"last-10-avg\": -0.5000000000000003\n    },\n    \"env_runners/policy_reward_mean/agent_8\": {\n      \"max\": -0.5000000000000003,\n      \"min\": -0.5000000000000003,\n      \"avg\": -0.5000000000000003,\n      \"last\": -0.5000000000000003,\n      \"last-5-avg\": -0.5000000000000003,\n      \"last-10-avg\": -0.5000000000000003\n    },\n    \"env_runners/policy_reward_mean/agent_9\": {\n      \"max\": -0.5000000000000003,\n      \"min\": -0.5000000000000003,\n      \"avg\": -0.5000000000000003,\n      \"last\": -0.5000000000000003,\n      \"last-5-avg\": -0.5000000000000003,\n      \"last-10-avg\": -0.5000000000000003\n    },\n    \"env_runners/policy_reward_mean/agent_10\": {\n      \"max\": -2.8700000000000134,\n      \"min\": -2.8700000000000134,\n      \"avg\": -2.8700000000000134,\n      \"last\": -2.8700000000000134,\n      \"last-5-avg\": -2.8700000000000134,\n      \"last-10-avg\": -2.8700000000000134\n    },\n    \"env_runners/policy_reward_mean/agent_11\": {\n      \"max\": -1.7183333333333384,\n      \"min\": -1.7183333333333384,\n      \"avg\": -1.7183333333333384,\n      \"last\": -1.7183333333333384,\n      \"last-5-avg\": -1.7183333333333384,\n      \"last-10-avg\": -1.7183333333333384\n    },\n    \"env_runners/policy_reward_mean/agent_12\": {\n      \"max\": -2.7466666666666786,\n      \"min\": -2.7466666666666786,\n      \"avg\": -2.7466666666666786,\n      \"last\": -2.7466666666666786,\n      \"last-5-avg\": -2.7466666666666786,\n      \"last-10-avg\": -2.7466666666666786\n    },\n    \"env_runners/policy_reward_mean/agent_13\": {\n      \"max\": -3.065000000000012,\n      \"min\": -3.065000000000012,\n      \"avg\": -3.065000000000012,\n      \"last\": -3.065000000000012,\n      \"last-5-avg\": -3.065000000000012,\n      \"last-10-avg\": -3.065000000000012\n    },\n    \"env_runners/policy_reward_mean/agent_14\": {\n      \"max\": -4.31833333333335,\n      \"min\": -4.31833333333335,\n      \"avg\": -4.31833333333335,\n      \"last\": -4.31833333333335,\n      \"last-5-avg\": -4.31833333333335,\n      \"last-10-avg\": -4.31833333333335\n    },\n    \"env_runners/policy_reward_mean/agent_15\": {\n      \"max\": -4.810000000000023,\n      \"min\": -4.810000000000023,\n      \"avg\": -4.810000000000023,\n      \"last\": -4.810000000000023,\n      \"last-5-avg\": -4.810000000000023,\n      \"last-10-avg\": -4.810000000000023\n    },\n    \"env_runners/policy_reward_mean/agent_16\": {\n      \"max\": -4.563333333333353,\n      \"min\": -4.563333333333353,\n      \"avg\": -4.563333333333353,\n      \"last\": -4.563333333333353,\n      \"last-5-avg\": -4.563333333333353,\n      \"last-10-avg\": -4.563333333333353\n    },\n    \"env_runners/policy_reward_mean/agent_17\": {\n      \"max\": -4.7816666666666885,\n      \"min\": -4.7816666666666885,\n      \"avg\": -4.7816666666666885,\n      \"last\": -4.7816666666666885,\n      \"last-5-avg\": -4.7816666666666885,\n      \"last-10-avg\": -4.7816666666666885\n    },\n    \"env_runners/policy_reward_mean/agent_18\": {\n      \"max\": -4.063333333333348,\n      \"min\": -4.063333333333348,\n      \"avg\": -4.063333333333348,\n      \"last\": -4.063333333333348,\n      \"last-5-avg\": -4.063333333333348,\n      \"last-10-avg\": -4.063333333333348\n    },\n    \"env_runners/policy_reward_mean/agent_19\": {\n      \"max\": -4.61000000000002,\n      \"min\": -4.61000000000002,\n      \"avg\": -4.61000000000002,\n      \"last\": -4.61000000000002,\n      \"last-5-avg\": -4.61000000000002,\n      \"last-10-avg\": -4.61000000000002\n    },\n    \"env_runners/policy_reward_mean/agent_20\": {\n      \"max\": -4.483333333333352,\n      \"min\": -4.483333333333352,\n      \"avg\": -4.483333333333352,\n      \"last\": -4.483333333333352,\n      \"last-5-avg\": -4.483333333333352,\n      \"last-10-avg\": -4.483333333333352\n    },\n    \"env_runners/sampler_perf/mean_raw_obs_processing_ms\": {\n      \"max\": 1.860233524956411,\n      \"min\": 1.860233524956411,\n      \"avg\": 1.860233524956411,\n      \"last\": 1.860233524956411,\n      \"last-5-avg\": 1.860233524956411,\n      \"last-10-avg\": 1.860233524956411\n    },\n    \"env_runners/sampler_perf/mean_inference_ms\": {\n      \"max\": 9.928458898973238,\n      \"min\": 9.928458898973238,\n      \"avg\": 9.928458898973238,\n      \"last\": 9.928458898973238,\n      \"last-5-avg\": 9.928458898973238,\n      \"last-10-avg\": 9.928458898973238\n    },\n    \"env_runners/sampler_perf/mean_action_processing_ms\": {\n      \"max\": 0.6863239248299343,\n      \"min\": 0.6863239248299343,\n      \"avg\": 0.6863239248299343,\n      \"last\": 0.6863239248299343,\n      \"last-5-avg\": 0.6863239248299343,\n      \"last-10-avg\": 0.6863239248299343\n    },\n    \"env_runners/sampler_perf/mean_env_wait_ms\": {\n      \"max\": 2.746555278078143,\n      \"min\": 2.746555278078143,\n      \"avg\": 2.746555278078143,\n      \"last\": 2.746555278078143,\n      \"last-5-avg\": 2.746555278078143,\n      \"last-10-avg\": 2.746555278078143\n    },\n    \"env_runners/sampler_perf/mean_env_render_ms\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"env_runners/connector_metrics/ObsPreprocessorConnector_ms\": {\n      \"max\": 0.002566027262854198,\n      \"min\": 0.002566027262854198,\n      \"avg\": 0.002566027262854198,\n      \"last\": 0.002566027262854198,\n      \"last-5-avg\": 0.002566027262854198,\n      \"last-10-avg\": 0.002566027262854198\n    },\n    \"env_runners/connector_metrics/StateBufferConnector_ms\": {\n      \"max\": 0.0014021283104306175,\n      \"min\": 0.0014021283104306175,\n      \"avg\": 0.0014021283104306175,\n      \"last\": 0.0014021283104306175,\n      \"last-5-avg\": 0.0014021283104306175,\n      \"last-10-avg\": 0.0014021283104306175\n    },\n    \"env_runners/connector_metrics/ViewRequirementAgentConnector_ms\": {\n      \"max\": 0.03029732477097284,\n      \"min\": 0.03029732477097284,\n      \"avg\": 0.03029732477097284,\n      \"last\": 0.03029732477097284,\n      \"last-5-avg\": 0.03029732477097284,\n      \"last-10-avg\": 0.03029732477097284\n    },\n    \"info/learner/agent_5/num_agent_steps_trained\": {\n      \"max\": 250.0,\n      \"min\": 250.0,\n      \"avg\": 250.0,\n      \"last\": 250.0,\n      \"last-5-avg\": 250.0,\n      \"last-10-avg\": 250.0\n    },\n    \"info/learner/agent_5/num_grad_updates_lifetime\": {\n      \"max\": 80.5,\n      \"min\": 80.5,\n      \"avg\": 80.5,\n      \"last\": 80.5,\n      \"last-5-avg\": 80.5,\n      \"last-10-avg\": 80.5\n    },\n    \"info/learner/agent_5/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": 79.5,\n      \"min\": 79.5,\n      \"avg\": 79.5,\n      \"last\": 79.5,\n      \"last-5-avg\": 79.5,\n      \"last-10-avg\": 79.5\n    },\n    \"info/learner/agent_4/num_agent_steps_trained\": {\n      \"max\": 250.0,\n      \"min\": 250.0,\n      \"avg\": 250.0,\n      \"last\": 250.0,\n      \"last-5-avg\": 250.0,\n      \"last-10-avg\": 250.0\n    },\n    \"info/learner/agent_4/num_grad_updates_lifetime\": {\n      \"max\": 80.5,\n      \"min\": 80.5,\n      \"avg\": 80.5,\n      \"last\": 80.5,\n      \"last-5-avg\": 80.5,\n      \"last-10-avg\": 80.5\n    },\n    \"info/learner/agent_4/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": 79.5,\n      \"min\": 79.5,\n      \"avg\": 79.5,\n      \"last\": 79.5,\n      \"last-5-avg\": 79.5,\n      \"last-10-avg\": 79.5\n    },\n    \"info/learner/agent_13/num_agent_steps_trained\": {\n      \"max\": 250.0,\n      \"min\": 250.0,\n      \"avg\": 250.0,\n      \"last\": 250.0,\n      \"last-5-avg\": 250.0,\n      \"last-10-avg\": 250.0\n    },\n    \"info/learner/agent_13/num_grad_updates_lifetime\": {\n      \"max\": 80.5,\n      \"min\": 80.5,\n      \"avg\": 80.5,\n      \"last\": 80.5,\n      \"last-5-avg\": 80.5,\n      \"last-10-avg\": 80.5\n    },\n    \"info/learner/agent_13/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": 79.5,\n      \"min\": 79.5,\n      \"avg\": 79.5,\n      \"last\": 79.5,\n      \"last-5-avg\": 79.5,\n      \"last-10-avg\": 79.5\n    },\n    \"info/learner/agent_0/num_agent_steps_trained\": {\n      \"max\": 250.0,\n      \"min\": 250.0,\n      \"avg\": 250.0,\n      \"last\": 250.0,\n      \"last-5-avg\": 250.0,\n      \"last-10-avg\": 250.0\n    },\n    \"info/learner/agent_0/num_grad_updates_lifetime\": {\n      \"max\": 80.5,\n      \"min\": 80.5,\n      \"avg\": 80.5,\n      \"last\": 80.5,\n      \"last-5-avg\": 80.5,\n      \"last-10-avg\": 80.5\n    },\n    \"info/learner/agent_0/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": 79.5,\n      \"min\": 79.5,\n      \"avg\": 79.5,\n      \"last\": 79.5,\n      \"last-5-avg\": 79.5,\n      \"last-10-avg\": 79.5\n    },\n    \"info/learner/agent_15/num_agent_steps_trained\": {\n      \"max\": 250.0,\n      \"min\": 250.0,\n      \"avg\": 250.0,\n      \"last\": 250.0,\n      \"last-5-avg\": 250.0,\n      \"last-10-avg\": 250.0\n    },\n    \"info/learner/agent_15/num_grad_updates_lifetime\": {\n      \"max\": 80.5,\n      \"min\": 80.5,\n      \"avg\": 80.5,\n      \"last\": 80.5,\n      \"last-5-avg\": 80.5,\n      \"last-10-avg\": 80.5\n    },\n    \"info/learner/agent_15/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": 79.5,\n      \"min\": 79.5,\n      \"avg\": 79.5,\n      \"last\": 79.5,\n      \"last-5-avg\": 79.5,\n      \"last-10-avg\": 79.5\n    },\n    \"info/learner/agent_19/num_agent_steps_trained\": {\n      \"max\": 250.0,\n      \"min\": 250.0,\n      \"avg\": 250.0,\n      \"last\": 250.0,\n      \"last-5-avg\": 250.0,\n      \"last-10-avg\": 250.0\n    },\n    \"info/learner/agent_19/num_grad_updates_lifetime\": {\n      \"max\": 80.5,\n      \"min\": 80.5,\n      \"avg\": 80.5,\n      \"last\": 80.5,\n      \"last-5-avg\": 80.5,\n      \"last-10-avg\": 80.5\n    },\n    \"info/learner/agent_19/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": 79.5,\n      \"min\": 79.5,\n      \"avg\": 79.5,\n      \"last\": 79.5,\n      \"last-5-avg\": 79.5,\n      \"last-10-avg\": 79.5\n    },\n    \"info/learner/agent_3/num_agent_steps_trained\": {\n      \"max\": 250.0,\n      \"min\": 250.0,\n      \"avg\": 250.0,\n      \"last\": 250.0,\n      \"last-5-avg\": 250.0,\n      \"last-10-avg\": 250.0\n    },\n    \"info/learner/agent_3/num_grad_updates_lifetime\": {\n      \"max\": 80.5,\n      \"min\": 80.5,\n      \"avg\": 80.5,\n      \"last\": 80.5,\n      \"last-5-avg\": 80.5,\n      \"last-10-avg\": 80.5\n    },\n    \"info/learner/agent_3/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": 79.5,\n      \"min\": 79.5,\n      \"avg\": 79.5,\n      \"last\": 79.5,\n      \"last-5-avg\": 79.5,\n      \"last-10-avg\": 79.5\n    },\n    \"info/learner/agent_20/num_agent_steps_trained\": {\n      \"max\": 250.0,\n      \"min\": 250.0,\n      \"avg\": 250.0,\n      \"last\": 250.0,\n      \"last-5-avg\": 250.0,\n      \"last-10-avg\": 250.0\n    },\n    \"info/learner/agent_20/num_grad_updates_lifetime\": {\n      \"max\": 80.5,\n      \"min\": 80.5,\n      \"avg\": 80.5,\n      \"last\": 80.5,\n      \"last-5-avg\": 80.5,\n      \"last-10-avg\": 80.5\n    },\n    \"info/learner/agent_20/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": 79.5,\n      \"min\": 79.5,\n      \"avg\": 79.5,\n      \"last\": 79.5,\n      \"last-5-avg\": 79.5,\n      \"last-10-avg\": 79.5\n    },\n    \"info/learner/agent_2/num_agent_steps_trained\": {\n      \"max\": 250.0,\n      \"min\": 250.0,\n      \"avg\": 250.0,\n      \"last\": 250.0,\n      \"last-5-avg\": 250.0,\n      \"last-10-avg\": 250.0\n    },\n    \"info/learner/agent_2/num_grad_updates_lifetime\": {\n      \"max\": 80.5,\n      \"min\": 80.5,\n      \"avg\": 80.5,\n      \"last\": 80.5,\n      \"last-5-avg\": 80.5,\n      \"last-10-avg\": 80.5\n    },\n    \"info/learner/agent_2/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": 79.5,\n      \"min\": 79.5,\n      \"avg\": 79.5,\n      \"last\": 79.5,\n      \"last-5-avg\": 79.5,\n      \"last-10-avg\": 79.5\n    },\n    \"info/learner/agent_7/num_agent_steps_trained\": {\n      \"max\": 250.0,\n      \"min\": 250.0,\n      \"avg\": 250.0,\n      \"last\": 250.0,\n      \"last-5-avg\": 250.0,\n      \"last-10-avg\": 250.0\n    },\n    \"info/learner/agent_7/num_grad_updates_lifetime\": {\n      \"max\": 80.5,\n      \"min\": 80.5,\n      \"avg\": 80.5,\n      \"last\": 80.5,\n      \"last-5-avg\": 80.5,\n      \"last-10-avg\": 80.5\n    },\n    \"info/learner/agent_7/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": 79.5,\n      \"min\": 79.5,\n      \"avg\": 79.5,\n      \"last\": 79.5,\n      \"last-5-avg\": 79.5,\n      \"last-10-avg\": 79.5\n    },\n    \"info/learner/agent_10/num_agent_steps_trained\": {\n      \"max\": 250.0,\n      \"min\": 250.0,\n      \"avg\": 250.0,\n      \"last\": 250.0,\n      \"last-5-avg\": 250.0,\n      \"last-10-avg\": 250.0\n    },\n    \"info/learner/agent_10/num_grad_updates_lifetime\": {\n      \"max\": 80.5,\n      \"min\": 80.5,\n      \"avg\": 80.5,\n      \"last\": 80.5,\n      \"last-5-avg\": 80.5,\n      \"last-10-avg\": 80.5\n    },\n    \"info/learner/agent_10/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": 79.5,\n      \"min\": 79.5,\n      \"avg\": 79.5,\n      \"last\": 79.5,\n      \"last-5-avg\": 79.5,\n      \"last-10-avg\": 79.5\n    },\n    \"info/learner/agent_8/num_agent_steps_trained\": {\n      \"max\": 250.0,\n      \"min\": 250.0,\n      \"avg\": 250.0,\n      \"last\": 250.0,\n      \"last-5-avg\": 250.0,\n      \"last-10-avg\": 250.0\n    },\n    \"info/learner/agent_8/num_grad_updates_lifetime\": {\n      \"max\": 80.5,\n      \"min\": 80.5,\n      \"avg\": 80.5,\n      \"last\": 80.5,\n      \"last-5-avg\": 80.5,\n      \"last-10-avg\": 80.5\n    },\n    \"info/learner/agent_8/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": 79.5,\n      \"min\": 79.5,\n      \"avg\": 79.5,\n      \"last\": 79.5,\n      \"last-5-avg\": 79.5,\n      \"last-10-avg\": 79.5\n    },\n    \"info/learner/agent_9/num_agent_steps_trained\": {\n      \"max\": 250.0,\n      \"min\": 250.0,\n      \"avg\": 250.0,\n      \"last\": 250.0,\n      \"last-5-avg\": 250.0,\n      \"last-10-avg\": 250.0\n    },\n    \"info/learner/agent_9/num_grad_updates_lifetime\": {\n      \"max\": 80.5,\n      \"min\": 80.5,\n      \"avg\": 80.5,\n      \"last\": 80.5,\n      \"last-5-avg\": 80.5,\n      \"last-10-avg\": 80.5\n    },\n    \"info/learner/agent_9/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": 79.5,\n      \"min\": 79.5,\n      \"avg\": 79.5,\n      \"last\": 79.5,\n      \"last-5-avg\": 79.5,\n      \"last-10-avg\": 79.5\n    },\n    \"info/learner/agent_11/num_agent_steps_trained\": {\n      \"max\": 250.0,\n      \"min\": 250.0,\n      \"avg\": 250.0,\n      \"last\": 250.0,\n      \"last-5-avg\": 250.0,\n      \"last-10-avg\": 250.0\n    },\n    \"info/learner/agent_11/num_grad_updates_lifetime\": {\n      \"max\": 80.5,\n      \"min\": 80.5,\n      \"avg\": 80.5,\n      \"last\": 80.5,\n      \"last-5-avg\": 80.5,\n      \"last-10-avg\": 80.5\n    },\n    \"info/learner/agent_11/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": 79.5,\n      \"min\": 79.5,\n      \"avg\": 79.5,\n      \"last\": 79.5,\n      \"last-5-avg\": 79.5,\n      \"last-10-avg\": 79.5\n    },\n    \"info/learner/agent_6/num_agent_steps_trained\": {\n      \"max\": 250.0,\n      \"min\": 250.0,\n      \"avg\": 250.0,\n      \"last\": 250.0,\n      \"last-5-avg\": 250.0,\n      \"last-10-avg\": 250.0\n    },\n    \"info/learner/agent_6/num_grad_updates_lifetime\": {\n      \"max\": 80.5,\n      \"min\": 80.5,\n      \"avg\": 80.5,\n      \"last\": 80.5,\n      \"last-5-avg\": 80.5,\n      \"last-10-avg\": 80.5\n    },\n    \"info/learner/agent_6/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": 79.5,\n      \"min\": 79.5,\n      \"avg\": 79.5,\n      \"last\": 79.5,\n      \"last-5-avg\": 79.5,\n      \"last-10-avg\": 79.5\n    },\n    \"info/learner/agent_16/num_agent_steps_trained\": {\n      \"max\": 250.0,\n      \"min\": 250.0,\n      \"avg\": 250.0,\n      \"last\": 250.0,\n      \"last-5-avg\": 250.0,\n      \"last-10-avg\": 250.0\n    },\n    \"info/learner/agent_16/num_grad_updates_lifetime\": {\n      \"max\": 80.5,\n      \"min\": 80.5,\n      \"avg\": 80.5,\n      \"last\": 80.5,\n      \"last-5-avg\": 80.5,\n      \"last-10-avg\": 80.5\n    },\n    \"info/learner/agent_16/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": 79.5,\n      \"min\": 79.5,\n      \"avg\": 79.5,\n      \"last\": 79.5,\n      \"last-5-avg\": 79.5,\n      \"last-10-avg\": 79.5\n    },\n    \"info/learner/agent_1/num_agent_steps_trained\": {\n      \"max\": 250.0,\n      \"min\": 250.0,\n      \"avg\": 250.0,\n      \"last\": 250.0,\n      \"last-5-avg\": 250.0,\n      \"last-10-avg\": 250.0\n    },\n    \"info/learner/agent_1/num_grad_updates_lifetime\": {\n      \"max\": 80.5,\n      \"min\": 80.5,\n      \"avg\": 80.5,\n      \"last\": 80.5,\n      \"last-5-avg\": 80.5,\n      \"last-10-avg\": 80.5\n    },\n    \"info/learner/agent_1/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": 79.5,\n      \"min\": 79.5,\n      \"avg\": 79.5,\n      \"last\": 79.5,\n      \"last-5-avg\": 79.5,\n      \"last-10-avg\": 79.5\n    },\n    \"info/learner/agent_12/num_agent_steps_trained\": {\n      \"max\": 250.0,\n      \"min\": 250.0,\n      \"avg\": 250.0,\n      \"last\": 250.0,\n      \"last-5-avg\": 250.0,\n      \"last-10-avg\": 250.0\n    },\n    \"info/learner/agent_12/num_grad_updates_lifetime\": {\n      \"max\": 80.5,\n      \"min\": 80.5,\n      \"avg\": 80.5,\n      \"last\": 80.5,\n      \"last-5-avg\": 80.5,\n      \"last-10-avg\": 80.5\n    },\n    \"info/learner/agent_12/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": 79.5,\n      \"min\": 79.5,\n      \"avg\": 79.5,\n      \"last\": 79.5,\n      \"last-5-avg\": 79.5,\n      \"last-10-avg\": 79.5\n    },\n    \"info/learner/agent_14/num_agent_steps_trained\": {\n      \"max\": 250.0,\n      \"min\": 250.0,\n      \"avg\": 250.0,\n      \"last\": 250.0,\n      \"last-5-avg\": 250.0,\n      \"last-10-avg\": 250.0\n    },\n    \"info/learner/agent_14/num_grad_updates_lifetime\": {\n      \"max\": 80.5,\n      \"min\": 80.5,\n      \"avg\": 80.5,\n      \"last\": 80.5,\n      \"last-5-avg\": 80.5,\n      \"last-10-avg\": 80.5\n    },\n    \"info/learner/agent_14/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": 79.5,\n      \"min\": 79.5,\n      \"avg\": 79.5,\n      \"last\": 79.5,\n      \"last-5-avg\": 79.5,\n      \"last-10-avg\": 79.5\n    },\n    \"info/learner/agent_17/num_agent_steps_trained\": {\n      \"max\": 250.0,\n      \"min\": 250.0,\n      \"avg\": 250.0,\n      \"last\": 250.0,\n      \"last-5-avg\": 250.0,\n      \"last-10-avg\": 250.0\n    },\n    \"info/learner/agent_17/num_grad_updates_lifetime\": {\n      \"max\": 80.5,\n      \"min\": 80.5,\n      \"avg\": 80.5,\n      \"last\": 80.5,\n      \"last-5-avg\": 80.5,\n      \"last-10-avg\": 80.5\n    },\n    \"info/learner/agent_17/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": 79.5,\n      \"min\": 79.5,\n      \"avg\": 79.5,\n      \"last\": 79.5,\n      \"last-5-avg\": 79.5,\n      \"last-10-avg\": 79.5\n    },\n    \"info/learner/agent_18/num_agent_steps_trained\": {\n      \"max\": 250.0,\n      \"min\": 250.0,\n      \"avg\": 250.0,\n      \"last\": 250.0,\n      \"last-5-avg\": 250.0,\n      \"last-10-avg\": 250.0\n    },\n    \"info/learner/agent_18/num_grad_updates_lifetime\": {\n      \"max\": 80.5,\n      \"min\": 80.5,\n      \"avg\": 80.5,\n      \"last\": 80.5,\n      \"last-5-avg\": 80.5,\n      \"last-10-avg\": 80.5\n    },\n    \"info/learner/agent_18/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": 79.5,\n      \"min\": 79.5,\n      \"avg\": 79.5,\n      \"last\": 79.5,\n      \"last-5-avg\": 79.5,\n      \"last-10-avg\": 79.5\n    },\n    \"info/learner/agent_5/learner_stats/allreduce_latency\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/agent_5/learner_stats/grad_gnorm\": {\n      \"max\": 0.6628228642046452,\n      \"min\": 0.6628228642046452,\n      \"avg\": 0.6628228642046452,\n      \"last\": 0.6628228642046452,\n      \"last-5-avg\": 0.6628228642046452,\n      \"last-10-avg\": 0.6628228642046452\n    },\n    \"info/learner/agent_5/learner_stats/cur_kl_coeff\": {\n      \"max\": 0.19999999999999998,\n      \"min\": 0.19999999999999998,\n      \"avg\": 0.19999999999999998,\n      \"last\": 0.19999999999999998,\n      \"last-5-avg\": 0.19999999999999998,\n      \"last-10-avg\": 0.19999999999999998\n    },\n    \"info/learner/agent_5/learner_stats/cur_lr\": {\n      \"max\": 5.000000000000001e-05,\n      \"min\": 5.000000000000001e-05,\n      \"avg\": 5.000000000000001e-05,\n      \"last\": 5.000000000000001e-05,\n      \"last-5-avg\": 5.000000000000001e-05,\n      \"last-10-avg\": 5.000000000000001e-05\n    },\n    \"info/learner/agent_5/learner_stats/total_loss\": {\n      \"max\": -0.04359709990203555,\n      \"min\": -0.04359709990203555,\n      \"avg\": -0.04359709990203555,\n      \"last\": -0.04359709990203555,\n      \"last-5-avg\": -0.04359709990203555,\n      \"last-10-avg\": -0.04359709990203555\n    },\n    \"info/learner/agent_5/learner_stats/policy_loss\": {\n      \"max\": -0.04675849936320446,\n      \"min\": -0.04675849936320446,\n      \"avg\": -0.04675849936320446,\n      \"last\": -0.04675849936320446,\n      \"last-5-avg\": -0.04675849936320446,\n      \"last-10-avg\": -0.04675849936320446\n    },\n    \"info/learner/agent_5/learner_stats/vf_loss\": {\n      \"max\": 0.0019867469956807325,\n      \"min\": 0.0019867469956807325,\n      \"avg\": 0.0019867469956807325,\n      \"last\": 0.0019867469956807325,\n      \"last-5-avg\": 0.0019867469956807325,\n      \"last-10-avg\": 0.0019867469956807325\n    },\n    \"info/learner/agent_5/learner_stats/vf_explained_var\": {\n      \"max\": 0.6375932186841965,\n      \"min\": 0.6375932186841965,\n      \"avg\": 0.6375932186841965,\n      \"last\": 0.6375932186841965,\n      \"last-5-avg\": 0.6375932186841965,\n      \"last-10-avg\": 0.6375932186841965\n    },\n    \"info/learner/agent_5/learner_stats/kl\": {\n      \"max\": 0.005873261537294639,\n      \"min\": 0.005873261537294639,\n      \"avg\": 0.005873261537294639,\n      \"last\": 0.005873261537294639,\n      \"last-5-avg\": 0.005873261537294639,\n      \"last-10-avg\": 0.005873261537294639\n    },\n    \"info/learner/agent_5/learner_stats/entropy\": {\n      \"max\": 6.176175844669342,\n      \"min\": 6.176175844669342,\n      \"avg\": 6.176175844669342,\n      \"last\": 6.176175844669342,\n      \"last-5-avg\": 6.176175844669342,\n      \"last-10-avg\": 6.176175844669342\n    },\n    \"info/learner/agent_5/learner_stats/entropy_coeff\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/agent_4/learner_stats/allreduce_latency\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/agent_4/learner_stats/grad_gnorm\": {\n      \"max\": 0.3928613349795341,\n      \"min\": 0.3928613349795341,\n      \"avg\": 0.3928613349795341,\n      \"last\": 0.3928613349795341,\n      \"last-5-avg\": 0.3928613349795341,\n      \"last-10-avg\": 0.3928613349795341\n    },\n    \"info/learner/agent_4/learner_stats/cur_kl_coeff\": {\n      \"max\": 0.19999999999999998,\n      \"min\": 0.19999999999999998,\n      \"avg\": 0.19999999999999998,\n      \"last\": 0.19999999999999998,\n      \"last-5-avg\": 0.19999999999999998,\n      \"last-10-avg\": 0.19999999999999998\n    },\n    \"info/learner/agent_4/learner_stats/cur_lr\": {\n      \"max\": 5.000000000000001e-05,\n      \"min\": 5.000000000000001e-05,\n      \"avg\": 5.000000000000001e-05,\n      \"last\": 5.000000000000001e-05,\n      \"last-5-avg\": 5.000000000000001e-05,\n      \"last-10-avg\": 5.000000000000001e-05\n    },\n    \"info/learner/agent_4/learner_stats/total_loss\": {\n      \"max\": -0.03879295451552025,\n      \"min\": -0.03879295451552025,\n      \"avg\": -0.03879295451552025,\n      \"last\": -0.03879295451552025,\n      \"last-5-avg\": -0.03879295451552025,\n      \"last-10-avg\": -0.03879295451552025\n    },\n    \"info/learner/agent_4/learner_stats/policy_loss\": {\n      \"max\": -0.04008008027740288,\n      \"min\": -0.04008008027740288,\n      \"avg\": -0.04008008027740288,\n      \"last\": -0.04008008027740288,\n      \"last-5-avg\": -0.04008008027740288,\n      \"last-10-avg\": -0.04008008027740288\n    },\n    \"info/learner/agent_4/learner_stats/vf_loss\": {\n      \"max\": 0.00022955927232146678,\n      \"min\": 0.00022955927232146678,\n      \"avg\": 0.00022955927232146678,\n      \"last\": 0.00022955927232146678,\n      \"last-5-avg\": 0.00022955927232146678,\n      \"last-10-avg\": 0.00022955927232146678\n    },\n    \"info/learner/agent_4/learner_stats/vf_explained_var\": {\n      \"max\": 0.8434331394731999,\n      \"min\": 0.8434331394731999,\n      \"avg\": 0.8434331394731999,\n      \"last\": 0.8434331394731999,\n      \"last-5-avg\": 0.8434331394731999,\n      \"last-10-avg\": 0.8434331394731999\n    },\n    \"info/learner/agent_4/learner_stats/kl\": {\n      \"max\": 0.005287830300358109,\n      \"min\": 0.005287830300358109,\n      \"avg\": 0.005287830300358109,\n      \"last\": 0.005287830300358109,\n      \"last-5-avg\": 0.005287830300358109,\n      \"last-10-avg\": 0.005287830300358109\n    },\n    \"info/learner/agent_4/learner_stats/entropy\": {\n      \"max\": 6.17685629427433,\n      \"min\": 6.17685629427433,\n      \"avg\": 6.17685629427433,\n      \"last\": 6.17685629427433,\n      \"last-5-avg\": 6.17685629427433,\n      \"last-10-avg\": 6.17685629427433\n    },\n    \"info/learner/agent_4/learner_stats/entropy_coeff\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/agent_13/learner_stats/allreduce_latency\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/agent_13/learner_stats/grad_gnorm\": {\n      \"max\": 0.6848604042083025,\n      \"min\": 0.6848604042083025,\n      \"avg\": 0.6848604042083025,\n      \"last\": 0.6848604042083025,\n      \"last-5-avg\": 0.6848604042083025,\n      \"last-10-avg\": 0.6848604042083025\n    },\n    \"info/learner/agent_13/learner_stats/cur_kl_coeff\": {\n      \"max\": 0.19999999999999998,\n      \"min\": 0.19999999999999998,\n      \"avg\": 0.19999999999999998,\n      \"last\": 0.19999999999999998,\n      \"last-5-avg\": 0.19999999999999998,\n      \"last-10-avg\": 0.19999999999999998\n    },\n    \"info/learner/agent_13/learner_stats/cur_lr\": {\n      \"max\": 5.000000000000001e-05,\n      \"min\": 5.000000000000001e-05,\n      \"avg\": 5.000000000000001e-05,\n      \"last\": 5.000000000000001e-05,\n      \"last-5-avg\": 5.000000000000001e-05,\n      \"last-10-avg\": 5.000000000000001e-05\n    },\n    \"info/learner/agent_13/learner_stats/total_loss\": {\n      \"max\": -0.04350265678258438,\n      \"min\": -0.04350265678258438,\n      \"avg\": -0.04350265678258438,\n      \"last\": -0.04350265678258438,\n      \"last-5-avg\": -0.04350265678258438,\n      \"last-10-avg\": -0.04350265678258438\n    },\n    \"info/learner/agent_13/learner_stats/policy_loss\": {\n      \"max\": -0.0463587378297234,\n      \"min\": -0.0463587378297234,\n      \"avg\": -0.0463587378297234,\n      \"last\": -0.0463587378297234,\n      \"last-5-avg\": -0.0463587378297234,\n      \"last-10-avg\": -0.0463587378297234\n    },\n    \"info/learner/agent_13/learner_stats/vf_loss\": {\n      \"max\": 0.0018354731666477165,\n      \"min\": 0.0018354731666477165,\n      \"avg\": 0.0018354731666477165,\n      \"last\": 0.0018354731666477165,\n      \"last-5-avg\": 0.0018354731666477165,\n      \"last-10-avg\": 0.0018354731666477165\n    },\n    \"info/learner/agent_13/learner_stats/vf_explained_var\": {\n      \"max\": 0.7413824584335089,\n      \"min\": 0.7413824584335089,\n      \"avg\": 0.7413824584335089,\n      \"last\": 0.7413824584335089,\n      \"last-5-avg\": 0.7413824584335089,\n      \"last-10-avg\": 0.7413824584335089\n    },\n    \"info/learner/agent_13/learner_stats/kl\": {\n      \"max\": 0.005103038757056311,\n      \"min\": 0.005103038757056311,\n      \"avg\": 0.005103038757056311,\n      \"last\": 0.005103038757056311,\n      \"last-5-avg\": 0.005103038757056311,\n      \"last-10-avg\": 0.005103038757056311\n    },\n    \"info/learner/agent_13/learner_stats/entropy\": {\n      \"max\": 6.1769769310951235,\n      \"min\": 6.1769769310951235,\n      \"avg\": 6.1769769310951235,\n      \"last\": 6.1769769310951235,\n      \"last-5-avg\": 6.1769769310951235,\n      \"last-10-avg\": 6.1769769310951235\n    },\n    \"info/learner/agent_13/learner_stats/entropy_coeff\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/agent_0/learner_stats/allreduce_latency\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/agent_0/learner_stats/grad_gnorm\": {\n      \"max\": 0.6007273502647876,\n      \"min\": 0.6007273502647876,\n      \"avg\": 0.6007273502647876,\n      \"last\": 0.6007273502647876,\n      \"last-5-avg\": 0.6007273502647876,\n      \"last-10-avg\": 0.6007273502647876\n    },\n    \"info/learner/agent_0/learner_stats/cur_kl_coeff\": {\n      \"max\": 0.19999999999999998,\n      \"min\": 0.19999999999999998,\n      \"avg\": 0.19999999999999998,\n      \"last\": 0.19999999999999998,\n      \"last-5-avg\": 0.19999999999999998,\n      \"last-10-avg\": 0.19999999999999998\n    },\n    \"info/learner/agent_0/learner_stats/cur_lr\": {\n      \"max\": 5.000000000000001e-05,\n      \"min\": 5.000000000000001e-05,\n      \"avg\": 5.000000000000001e-05,\n      \"last\": 5.000000000000001e-05,\n      \"last-5-avg\": 5.000000000000001e-05,\n      \"last-10-avg\": 5.000000000000001e-05\n    },\n    \"info/learner/agent_0/learner_stats/total_loss\": {\n      \"max\": -0.04672154011859675,\n      \"min\": -0.04672154011859675,\n      \"avg\": -0.04672154011859675,\n      \"last\": -0.04672154011859675,\n      \"last-5-avg\": -0.04672154011859675,\n      \"last-10-avg\": -0.04672154011859675\n    },\n    \"info/learner/agent_0/learner_stats/policy_loss\": {\n      \"max\": -0.048813783389050514,\n      \"min\": -0.048813783389050514,\n      \"avg\": -0.048813783389050514,\n      \"last\": -0.048813783389050514,\n      \"last-5-avg\": -0.048813783389050514,\n      \"last-10-avg\": -0.048813783389050514\n    },\n    \"info/learner/agent_0/learner_stats/vf_loss\": {\n      \"max\": 0.0009674807578448963,\n      \"min\": 0.0009674807578448963,\n      \"avg\": 0.0009674807578448963,\n      \"last\": 0.0009674807578448963,\n      \"last-5-avg\": 0.0009674807578448963,\n      \"last-10-avg\": 0.0009674807578448963\n    },\n    \"info/learner/agent_0/learner_stats/vf_explained_var\": {\n      \"max\": 0.7767446111887694,\n      \"min\": 0.7767446111887694,\n      \"avg\": 0.7767446111887694,\n      \"last\": 0.7767446111887694,\n      \"last-5-avg\": 0.7767446111887694,\n      \"last-10-avg\": 0.7767446111887694\n    },\n    \"info/learner/agent_0/learner_stats/kl\": {\n      \"max\": 0.005623814247610426,\n      \"min\": 0.005623814247610426,\n      \"avg\": 0.005623814247610426,\n      \"last\": 0.005623814247610426,\n      \"last-5-avg\": 0.005623814247610426,\n      \"last-10-avg\": 0.005623814247610426\n    },\n    \"info/learner/agent_0/learner_stats/entropy\": {\n      \"max\": 6.176413765549659,\n      \"min\": 6.176413765549659,\n      \"avg\": 6.176413765549659,\n      \"last\": 6.176413765549659,\n      \"last-5-avg\": 6.176413765549659,\n      \"last-10-avg\": 6.176413765549659\n    },\n    \"info/learner/agent_0/learner_stats/entropy_coeff\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/agent_15/learner_stats/allreduce_latency\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/agent_15/learner_stats/grad_gnorm\": {\n      \"max\": 0.7731216736137867,\n      \"min\": 0.7731216736137867,\n      \"avg\": 0.7731216736137867,\n      \"last\": 0.7731216736137867,\n      \"last-5-avg\": 0.7731216736137867,\n      \"last-10-avg\": 0.7731216736137867\n    },\n    \"info/learner/agent_15/learner_stats/cur_kl_coeff\": {\n      \"max\": 0.19999999999999998,\n      \"min\": 0.19999999999999998,\n      \"avg\": 0.19999999999999998,\n      \"last\": 0.19999999999999998,\n      \"last-5-avg\": 0.19999999999999998,\n      \"last-10-avg\": 0.19999999999999998\n    },\n    \"info/learner/agent_15/learner_stats/cur_lr\": {\n      \"max\": 5.000000000000001e-05,\n      \"min\": 5.000000000000001e-05,\n      \"avg\": 5.000000000000001e-05,\n      \"last\": 5.000000000000001e-05,\n      \"last-5-avg\": 5.000000000000001e-05,\n      \"last-10-avg\": 5.000000000000001e-05\n    },\n    \"info/learner/agent_15/learner_stats/total_loss\": {\n      \"max\": -0.04177166289955494,\n      \"min\": -0.04177166289955494,\n      \"avg\": -0.04177166289955494,\n      \"last\": -0.04177166289955494,\n      \"last-5-avg\": -0.04177166289955494,\n      \"last-10-avg\": -0.04177166289955494\n    },\n    \"info/learner/agent_15/learner_stats/policy_loss\": {\n      \"max\": -0.04610337391786743,\n      \"min\": -0.04610337391786743,\n      \"avg\": -0.04610337391786743,\n      \"last\": -0.04610337391786743,\n      \"last-5-avg\": -0.04610337391786743,\n      \"last-10-avg\": -0.04610337391786743\n    },\n    \"info/learner/agent_15/learner_stats/vf_loss\": {\n      \"max\": 0.0033900260561495086,\n      \"min\": 0.0033900260561495086,\n      \"avg\": 0.0033900260561495086,\n      \"last\": 0.0033900260561495086,\n      \"last-5-avg\": 0.0033900260561495086,\n      \"last-10-avg\": 0.0033900260561495086\n    },\n    \"info/learner/agent_15/learner_stats/vf_explained_var\": {\n      \"max\": 0.24210648238658905,\n      \"min\": 0.24210648238658905,\n      \"avg\": 0.24210648238658905,\n      \"last\": 0.24210648238658905,\n      \"last-5-avg\": 0.24210648238658905,\n      \"last-10-avg\": 0.24210648238658905\n    },\n    \"info/learner/agent_15/learner_stats/kl\": {\n      \"max\": 0.004708427456148456,\n      \"min\": 0.004708427456148456,\n      \"avg\": 0.004708427456148456,\n      \"last\": 0.004708427456148456,\n      \"last-5-avg\": 0.004708427456148456,\n      \"last-10-avg\": 0.004708427456148456\n    },\n    \"info/learner/agent_15/learner_stats/entropy\": {\n      \"max\": 6.177436506748199,\n      \"min\": 6.177436506748199,\n      \"avg\": 6.177436506748199,\n      \"last\": 6.177436506748199,\n      \"last-5-avg\": 6.177436506748199,\n      \"last-10-avg\": 6.177436506748199\n    },\n    \"info/learner/agent_15/learner_stats/entropy_coeff\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/agent_19/learner_stats/allreduce_latency\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/agent_19/learner_stats/grad_gnorm\": {\n      \"max\": 0.7953502051532269,\n      \"min\": 0.7953502051532269,\n      \"avg\": 0.7953502051532269,\n      \"last\": 0.7953502051532269,\n      \"last-5-avg\": 0.7953502051532269,\n      \"last-10-avg\": 0.7953502051532269\n    },\n    \"info/learner/agent_19/learner_stats/cur_kl_coeff\": {\n      \"max\": 0.19999999999999998,\n      \"min\": 0.19999999999999998,\n      \"avg\": 0.19999999999999998,\n      \"last\": 0.19999999999999998,\n      \"last-5-avg\": 0.19999999999999998,\n      \"last-10-avg\": 0.19999999999999998\n    },\n    \"info/learner/agent_19/learner_stats/cur_lr\": {\n      \"max\": 5.000000000000001e-05,\n      \"min\": 5.000000000000001e-05,\n      \"avg\": 5.000000000000001e-05,\n      \"last\": 5.000000000000001e-05,\n      \"last-5-avg\": 5.000000000000001e-05,\n      \"last-10-avg\": 5.000000000000001e-05\n    },\n    \"info/learner/agent_19/learner_stats/total_loss\": {\n      \"max\": -0.04062979888840346,\n      \"min\": -0.04062979888840346,\n      \"avg\": -0.04062979888840346,\n      \"last\": -0.04062979888840346,\n      \"last-5-avg\": -0.04062979888840346,\n      \"last-10-avg\": -0.04062979888840346\n    },\n    \"info/learner/agent_19/learner_stats/policy_loss\": {\n      \"max\": -0.045478487486252564,\n      \"min\": -0.045478487486252564,\n      \"avg\": -0.045478487486252564,\n      \"last\": -0.045478487486252564,\n      \"last-5-avg\": -0.045478487486252564,\n      \"last-10-avg\": -0.045478487486252564\n    },\n    \"info/learner/agent_19/learner_stats/vf_loss\": {\n      \"max\": 0.0038975650291831697,\n      \"min\": 0.0038975650291831697,\n      \"avg\": 0.0038975650291831697,\n      \"last\": 0.0038975650291831697,\n      \"last-5-avg\": 0.0038975650291831697,\n      \"last-10-avg\": 0.0038975650291831697\n    },\n    \"info/learner/agent_19/learner_stats/vf_explained_var\": {\n      \"max\": 0.26418117992579937,\n      \"min\": 0.26418117992579937,\n      \"avg\": 0.26418117992579937,\n      \"last\": 0.26418117992579937,\n      \"last-5-avg\": 0.26418117992579937,\n      \"last-10-avg\": 0.26418117992579937\n    },\n    \"info/learner/agent_19/learner_stats/kl\": {\n      \"max\": 0.004755612317012492,\n      \"min\": 0.004755612317012492,\n      \"avg\": 0.004755612317012492,\n      \"last\": 0.004755612317012492,\n      \"last-5-avg\": 0.004755612317012492,\n      \"last-10-avg\": 0.004755612317012492\n    },\n    \"info/learner/agent_19/learner_stats/entropy\": {\n      \"max\": 6.177408641576767,\n      \"min\": 6.177408641576767,\n      \"avg\": 6.177408641576767,\n      \"last\": 6.177408641576767,\n      \"last-5-avg\": 6.177408641576767,\n      \"last-10-avg\": 6.177408641576767\n    },\n    \"info/learner/agent_19/learner_stats/entropy_coeff\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/agent_3/learner_stats/allreduce_latency\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/agent_3/learner_stats/grad_gnorm\": {\n      \"max\": 0.6569609351456165,\n      \"min\": 0.6569609351456165,\n      \"avg\": 0.6569609351456165,\n      \"last\": 0.6569609351456165,\n      \"last-5-avg\": 0.6569609351456165,\n      \"last-10-avg\": 0.6569609351456165\n    },\n    \"info/learner/agent_3/learner_stats/cur_kl_coeff\": {\n      \"max\": 0.19999999999999998,\n      \"min\": 0.19999999999999998,\n      \"avg\": 0.19999999999999998,\n      \"last\": 0.19999999999999998,\n      \"last-5-avg\": 0.19999999999999998,\n      \"last-10-avg\": 0.19999999999999998\n    },\n    \"info/learner/agent_3/learner_stats/cur_lr\": {\n      \"max\": 5.000000000000001e-05,\n      \"min\": 5.000000000000001e-05,\n      \"avg\": 5.000000000000001e-05,\n      \"last\": 5.000000000000001e-05,\n      \"last-5-avg\": 5.000000000000001e-05,\n      \"last-10-avg\": 5.000000000000001e-05\n    },\n    \"info/learner/agent_3/learner_stats/total_loss\": {\n      \"max\": -0.04531698364662588,\n      \"min\": -0.04531698364662588,\n      \"avg\": -0.04531698364662588,\n      \"last\": -0.04531698364662588,\n      \"last-5-avg\": -0.04531698364662588,\n      \"last-10-avg\": -0.04531698364662588\n    },\n    \"info/learner/agent_3/learner_stats/policy_loss\": {\n      \"max\": -0.047864361766914956,\n      \"min\": -0.047864361766914956,\n      \"avg\": -0.047864361766914956,\n      \"last\": -0.047864361766914956,\n      \"last-5-avg\": -0.047864361766914956,\n      \"last-10-avg\": -0.047864361766914956\n    },\n    \"info/learner/agent_3/learner_stats/vf_loss\": {\n      \"max\": 0.001497053426965067,\n      \"min\": 0.001497053426965067,\n      \"avg\": 0.001497053426965067,\n      \"last\": 0.001497053426965067,\n      \"last-5-avg\": 0.001497053426965067,\n      \"last-10-avg\": 0.001497053426965067\n    },\n    \"info/learner/agent_3/learner_stats/vf_explained_var\": {\n      \"max\": 0.7605365939438343,\n      \"min\": 0.7605365939438343,\n      \"avg\": 0.7605365939438343,\n      \"last\": 0.7605365939438343,\n      \"last-5-avg\": 0.7605365939438343,\n      \"last-10-avg\": 0.7605365939438343\n    },\n    \"info/learner/agent_3/learner_stats/kl\": {\n      \"max\": 0.005251618787201551,\n      \"min\": 0.005251618787201551,\n      \"avg\": 0.005251618787201551,\n      \"last\": 0.005251618787201551,\n      \"last-5-avg\": 0.005251618787201551,\n      \"last-10-avg\": 0.005251618787201551\n    },\n    \"info/learner/agent_3/learner_stats/entropy\": {\n      \"max\": 6.1768194258213045,\n      \"min\": 6.1768194258213045,\n      \"avg\": 6.1768194258213045,\n      \"last\": 6.1768194258213045,\n      \"last-5-avg\": 6.1768194258213045,\n      \"last-10-avg\": 6.1768194258213045\n    },\n    \"info/learner/agent_3/learner_stats/entropy_coeff\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/agent_20/learner_stats/allreduce_latency\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/agent_20/learner_stats/grad_gnorm\": {\n      \"max\": 0.7734985277056694,\n      \"min\": 0.7734985277056694,\n      \"avg\": 0.7734985277056694,\n      \"last\": 0.7734985277056694,\n      \"last-5-avg\": 0.7734985277056694,\n      \"last-10-avg\": 0.7734985277056694\n    },\n    \"info/learner/agent_20/learner_stats/cur_kl_coeff\": {\n      \"max\": 0.19999999999999998,\n      \"min\": 0.19999999999999998,\n      \"avg\": 0.19999999999999998,\n      \"last\": 0.19999999999999998,\n      \"last-5-avg\": 0.19999999999999998,\n      \"last-10-avg\": 0.19999999999999998\n    },\n    \"info/learner/agent_20/learner_stats/cur_lr\": {\n      \"max\": 5.000000000000001e-05,\n      \"min\": 5.000000000000001e-05,\n      \"avg\": 5.000000000000001e-05,\n      \"last\": 5.000000000000001e-05,\n      \"last-5-avg\": 5.000000000000001e-05,\n      \"last-10-avg\": 5.000000000000001e-05\n    },\n    \"info/learner/agent_20/learner_stats/total_loss\": {\n      \"max\": -0.039919372356234814,\n      \"min\": -0.039919372356234814,\n      \"avg\": -0.039919372356234814,\n      \"last\": -0.039919372356234814,\n      \"last-5-avg\": -0.039919372356234814,\n      \"last-10-avg\": -0.039919372356234814\n    },\n    \"info/learner/agent_20/learner_stats/policy_loss\": {\n      \"max\": -0.04478425519773736,\n      \"min\": -0.04478425519773736,\n      \"avg\": -0.04478425519773736,\n      \"last\": -0.04478425519773736,\n      \"last-5-avg\": -0.04478425519773736,\n      \"last-10-avg\": -0.04478425519773736\n    },\n    \"info/learner/agent_20/learner_stats/vf_loss\": {\n      \"max\": 0.0038360671256668865,\n      \"min\": 0.0038360671256668865,\n      \"avg\": 0.0038360671256668865,\n      \"last\": 0.0038360671256668865,\n      \"last-5-avg\": 0.0038360671256668865,\n      \"last-10-avg\": 0.0038360671256668865\n    },\n    \"info/learner/agent_20/learner_stats/vf_explained_var\": {\n      \"max\": 0.24774767979979515,\n      \"min\": 0.24774767979979515,\n      \"avg\": 0.24774767979979515,\n      \"last\": 0.24774767979979515,\n      \"last-5-avg\": 0.24774767979979515,\n      \"last-10-avg\": 0.24774767979979515\n    },\n    \"info/learner/agent_20/learner_stats/kl\": {\n      \"max\": 0.0051440823540133355,\n      \"min\": 0.0051440823540133355,\n      \"avg\": 0.0051440823540133355,\n      \"last\": 0.0051440823540133355,\n      \"last-5-avg\": 0.0051440823540133355,\n      \"last-10-avg\": 0.0051440823540133355\n    },\n    \"info/learner/agent_20/learner_stats/entropy\": {\n      \"max\": 6.177019014954567,\n      \"min\": 6.177019014954567,\n      \"avg\": 6.177019014954567,\n      \"last\": 6.177019014954567,\n      \"last-5-avg\": 6.177019014954567,\n      \"last-10-avg\": 6.177019014954567\n    },\n    \"info/learner/agent_20/learner_stats/entropy_coeff\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/agent_2/learner_stats/allreduce_latency\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/agent_2/learner_stats/grad_gnorm\": {\n      \"max\": 0.5963431052863598,\n      \"min\": 0.5963431052863598,\n      \"avg\": 0.5963431052863598,\n      \"last\": 0.5963431052863598,\n      \"last-5-avg\": 0.5963431052863598,\n      \"last-10-avg\": 0.5963431052863598\n    },\n    \"info/learner/agent_2/learner_stats/cur_kl_coeff\": {\n      \"max\": 0.19999999999999998,\n      \"min\": 0.19999999999999998,\n      \"avg\": 0.19999999999999998,\n      \"last\": 0.19999999999999998,\n      \"last-5-avg\": 0.19999999999999998,\n      \"last-10-avg\": 0.19999999999999998\n    },\n    \"info/learner/agent_2/learner_stats/cur_lr\": {\n      \"max\": 5.000000000000001e-05,\n      \"min\": 5.000000000000001e-05,\n      \"avg\": 5.000000000000001e-05,\n      \"last\": 5.000000000000001e-05,\n      \"last-5-avg\": 5.000000000000001e-05,\n      \"last-10-avg\": 5.000000000000001e-05\n    },\n    \"info/learner/agent_2/learner_stats/total_loss\": {\n      \"max\": -0.03828517465663026,\n      \"min\": -0.03828517465663026,\n      \"avg\": -0.03828517465663026,\n      \"last\": -0.03828517465663026,\n      \"last-5-avg\": -0.03828517465663026,\n      \"last-10-avg\": -0.03828517465663026\n    },\n    \"info/learner/agent_2/learner_stats/policy_loss\": {\n      \"max\": -0.03931753882789053,\n      \"min\": -0.03931753882789053,\n      \"avg\": -0.03931753882789053,\n      \"last\": -0.03931753882789053,\n      \"last-5-avg\": -0.03931753882789053,\n      \"last-10-avg\": -0.03931753882789053\n    },\n    \"info/learner/agent_2/learner_stats/vf_loss\": {\n      \"max\": 1.7230370237086844e-05,\n      \"min\": 1.7230370237086844e-05,\n      \"avg\": 1.7230370237086844e-05,\n      \"last\": 1.7230370237086844e-05,\n      \"last-5-avg\": 1.7230370237086844e-05,\n      \"last-10-avg\": 1.7230370237086844e-05\n    },\n    \"info/learner/agent_2/learner_stats/vf_explained_var\": {\n      \"max\": 0.6368009079247713,\n      \"min\": 0.6368009079247713,\n      \"avg\": 0.6368009079247713,\n      \"last\": 0.6368009079247713,\n      \"last-5-avg\": 0.6368009079247713,\n      \"last-10-avg\": 0.6368009079247713\n    },\n    \"info/learner/agent_2/learner_stats/kl\": {\n      \"max\": 0.005075663798538699,\n      \"min\": 0.005075663798538699,\n      \"avg\": 0.005075663798538699,\n      \"last\": 0.005075663798538699,\n      \"last-5-avg\": 0.005075663798538699,\n      \"last-10-avg\": 0.005075663798538699\n    },\n    \"info/learner/agent_2/learner_stats/entropy\": {\n      \"max\": 6.177039608359337,\n      \"min\": 6.177039608359337,\n      \"avg\": 6.177039608359337,\n      \"last\": 6.177039608359337,\n      \"last-5-avg\": 6.177039608359337,\n      \"last-10-avg\": 6.177039608359337\n    },\n    \"info/learner/agent_2/learner_stats/entropy_coeff\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/agent_7/learner_stats/allreduce_latency\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/agent_7/learner_stats/grad_gnorm\": {\n      \"max\": 0.4248142417520285,\n      \"min\": 0.4248142417520285,\n      \"avg\": 0.4248142417520285,\n      \"last\": 0.4248142417520285,\n      \"last-5-avg\": 0.4248142417520285,\n      \"last-10-avg\": 0.4248142417520285\n    },\n    \"info/learner/agent_7/learner_stats/cur_kl_coeff\": {\n      \"max\": 0.19999999999999998,\n      \"min\": 0.19999999999999998,\n      \"avg\": 0.19999999999999998,\n      \"last\": 0.19999999999999998,\n      \"last-5-avg\": 0.19999999999999998,\n      \"last-10-avg\": 0.19999999999999998\n    },\n    \"info/learner/agent_7/learner_stats/cur_lr\": {\n      \"max\": 5.000000000000001e-05,\n      \"min\": 5.000000000000001e-05,\n      \"avg\": 5.000000000000001e-05,\n      \"last\": 5.000000000000001e-05,\n      \"last-5-avg\": 5.000000000000001e-05,\n      \"last-10-avg\": 5.000000000000001e-05\n    },\n    \"info/learner/agent_7/learner_stats/total_loss\": {\n      \"max\": -0.04500943329912843,\n      \"min\": -0.04500943329912843,\n      \"avg\": -0.04500943329912843,\n      \"last\": -0.04500943329912843,\n      \"last-5-avg\": -0.04500943329912843,\n      \"last-10-avg\": -0.04500943329912843\n    },\n    \"info/learner/agent_7/learner_stats/policy_loss\": {\n      \"max\": -0.04642385820334312,\n      \"min\": -0.04642385820334312,\n      \"avg\": -0.04642385820334312,\n      \"last\": -0.04642385820334312,\n      \"last-5-avg\": -0.04642385820334312,\n      \"last-10-avg\": -0.04642385820334312\n    },\n    \"info/learner/agent_7/learner_stats/vf_loss\": {\n      \"max\": 0.00037911689840939287,\n      \"min\": 0.00037911689840939287,\n      \"avg\": 0.00037911689840939287,\n      \"last\": 0.00037911689840939287,\n      \"last-5-avg\": 0.00037911689840939287,\n      \"last-10-avg\": 0.00037911689840939287\n    },\n    \"info/learner/agent_7/learner_stats/vf_explained_var\": {\n      \"max\": 0.8246649790555238,\n      \"min\": 0.8246649790555238,\n      \"avg\": 0.8246649790555238,\n      \"last\": 0.8246649790555238,\n      \"last-5-avg\": 0.8246649790555238,\n      \"last-10-avg\": 0.8246649790555238\n    },\n    \"info/learner/agent_7/learner_stats/kl\": {\n      \"max\": 0.005176538858677304,\n      \"min\": 0.005176538858677304,\n      \"avg\": 0.005176538858677304,\n      \"last\": 0.005176538858677304,\n      \"last-5-avg\": 0.005176538858677304,\n      \"last-10-avg\": 0.005176538858677304\n    },\n    \"info/learner/agent_7/learner_stats/entropy\": {\n      \"max\": 6.176957020163536,\n      \"min\": 6.176957020163536,\n      \"avg\": 6.176957020163536,\n      \"last\": 6.176957020163536,\n      \"last-5-avg\": 6.176957020163536,\n      \"last-10-avg\": 6.176957020163536\n    },\n    \"info/learner/agent_7/learner_stats/entropy_coeff\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/agent_10/learner_stats/allreduce_latency\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/agent_10/learner_stats/grad_gnorm\": {\n      \"max\": 0.7114672303199768,\n      \"min\": 0.7114672303199768,\n      \"avg\": 0.7114672303199768,\n      \"last\": 0.7114672303199768,\n      \"last-5-avg\": 0.7114672303199768,\n      \"last-10-avg\": 0.7114672303199768\n    },\n    \"info/learner/agent_10/learner_stats/cur_kl_coeff\": {\n      \"max\": 0.19999999999999998,\n      \"min\": 0.19999999999999998,\n      \"avg\": 0.19999999999999998,\n      \"last\": 0.19999999999999998,\n      \"last-5-avg\": 0.19999999999999998,\n      \"last-10-avg\": 0.19999999999999998\n    },\n    \"info/learner/agent_10/learner_stats/cur_lr\": {\n      \"max\": 5.000000000000001e-05,\n      \"min\": 5.000000000000001e-05,\n      \"avg\": 5.000000000000001e-05,\n      \"last\": 5.000000000000001e-05,\n      \"last-5-avg\": 5.000000000000001e-05,\n      \"last-10-avg\": 5.000000000000001e-05\n    },\n    \"info/learner/agent_10/learner_stats/total_loss\": {\n      \"max\": -0.04261054965400035,\n      \"min\": -0.04261054965400035,\n      \"avg\": -0.04261054965400035,\n      \"last\": -0.04261054965400035,\n      \"last-5-avg\": -0.04261054965400035,\n      \"last-10-avg\": -0.04261054965400035\n    },\n    \"info/learner/agent_10/learner_stats/policy_loss\": {\n      \"max\": -0.04558037797396537,\n      \"min\": -0.04558037797396537,\n      \"avg\": -0.04558037797396537,\n      \"last\": -0.04558037797396537,\n      \"last-5-avg\": -0.04558037797396537,\n      \"last-10-avg\": -0.04558037797396537\n    },\n    \"info/learner/agent_10/learner_stats/vf_loss\": {\n      \"max\": 0.0021062425913441984,\n      \"min\": 0.0021062425913441984,\n      \"avg\": 0.0021062425913441984,\n      \"last\": 0.0021062425913441984,\n      \"last-5-avg\": 0.0021062425913441984,\n      \"last-10-avg\": 0.0021062425913441984\n    },\n    \"info/learner/agent_10/learner_stats/vf_explained_var\": {\n      \"max\": 0.7238317221403122,\n      \"min\": 0.7238317221403122,\n      \"avg\": 0.7238317221403122,\n      \"last\": 0.7238317221403122,\n      \"last-5-avg\": 0.7238317221403122,\n      \"last-10-avg\": 0.7238317221403122\n    },\n    \"info/learner/agent_10/learner_stats/kl\": {\n      \"max\": 0.004317931410400888,\n      \"min\": 0.004317931410400888,\n      \"avg\": 0.004317931410400888,\n      \"last\": 0.004317931410400888,\n      \"last-5-avg\": 0.004317931410400888,\n      \"last-10-avg\": 0.004317931410400888\n    },\n    \"info/learner/agent_10/learner_stats/entropy\": {\n      \"max\": 6.177790689468384,\n      \"min\": 6.177790689468384,\n      \"avg\": 6.177790689468384,\n      \"last\": 6.177790689468384,\n      \"last-5-avg\": 6.177790689468384,\n      \"last-10-avg\": 6.177790689468384\n    },\n    \"info/learner/agent_10/learner_stats/entropy_coeff\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/agent_8/learner_stats/allreduce_latency\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/agent_8/learner_stats/grad_gnorm\": {\n      \"max\": 0.38750932244583963,\n      \"min\": 0.38750932244583963,\n      \"avg\": 0.38750932244583963,\n      \"last\": 0.38750932244583963,\n      \"last-5-avg\": 0.38750932244583963,\n      \"last-10-avg\": 0.38750932244583963\n    },\n    \"info/learner/agent_8/learner_stats/cur_kl_coeff\": {\n      \"max\": 0.19999999999999998,\n      \"min\": 0.19999999999999998,\n      \"avg\": 0.19999999999999998,\n      \"last\": 0.19999999999999998,\n      \"last-5-avg\": 0.19999999999999998,\n      \"last-10-avg\": 0.19999999999999998\n    },\n    \"info/learner/agent_8/learner_stats/cur_lr\": {\n      \"max\": 5.000000000000001e-05,\n      \"min\": 5.000000000000001e-05,\n      \"avg\": 5.000000000000001e-05,\n      \"last\": 5.000000000000001e-05,\n      \"last-5-avg\": 5.000000000000001e-05,\n      \"last-10-avg\": 5.000000000000001e-05\n    },\n    \"info/learner/agent_8/learner_stats/total_loss\": {\n      \"max\": -0.04238021403034509,\n      \"min\": -0.04238021403034509,\n      \"avg\": -0.04238021403034509,\n      \"last\": -0.04238021403034509,\n      \"last-5-avg\": -0.04238021403034509,\n      \"last-10-avg\": -0.04238021403034509\n    },\n    \"info/learner/agent_8/learner_stats/policy_loss\": {\n      \"max\": -0.043361809103225825,\n      \"min\": -0.043361809103225825,\n      \"avg\": -0.043361809103225825,\n      \"last\": -0.043361809103225825,\n      \"last-5-avg\": -0.043361809103225825,\n      \"last-10-avg\": -0.043361809103225825\n    },\n    \"info/learner/agent_8/learner_stats/vf_loss\": {\n      \"max\": 0.00023282966037072584,\n      \"min\": 0.00023282966037072584,\n      \"avg\": 0.00023282966037072584,\n      \"last\": 0.00023282966037072584,\n      \"last-5-avg\": 0.00023282966037072584,\n      \"last-10-avg\": 0.00023282966037072584\n    },\n    \"info/learner/agent_8/learner_stats/vf_explained_var\": {\n      \"max\": 0.8575464218854905,\n      \"min\": 0.8575464218854905,\n      \"avg\": 0.8575464218854905,\n      \"last\": 0.8575464218854905,\n      \"last-5-avg\": 0.8575464218854905,\n      \"last-10-avg\": 0.8575464218854905\n    },\n    \"info/learner/agent_8/learner_stats/kl\": {\n      \"max\": 0.003743829339146032,\n      \"min\": 0.003743829339146032,\n      \"avg\": 0.003743829339146032,\n      \"last\": 0.003743829339146032,\n      \"last-5-avg\": 0.003743829339146032,\n      \"last-10-avg\": 0.003743829339146032\n    },\n    \"info/learner/agent_8/learner_stats/entropy\": {\n      \"max\": 6.178380465507507,\n      \"min\": 6.178380465507507,\n      \"avg\": 6.178380465507507,\n      \"last\": 6.178380465507507,\n      \"last-5-avg\": 6.178380465507507,\n      \"last-10-avg\": 6.178380465507507\n    },\n    \"info/learner/agent_8/learner_stats/entropy_coeff\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/agent_9/learner_stats/allreduce_latency\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/agent_9/learner_stats/grad_gnorm\": {\n      \"max\": 0.620915948972106,\n      \"min\": 0.620915948972106,\n      \"avg\": 0.620915948972106,\n      \"last\": 0.620915948972106,\n      \"last-5-avg\": 0.620915948972106,\n      \"last-10-avg\": 0.620915948972106\n    },\n    \"info/learner/agent_9/learner_stats/cur_kl_coeff\": {\n      \"max\": 0.19999999999999998,\n      \"min\": 0.19999999999999998,\n      \"avg\": 0.19999999999999998,\n      \"last\": 0.19999999999999998,\n      \"last-5-avg\": 0.19999999999999998,\n      \"last-10-avg\": 0.19999999999999998\n    },\n    \"info/learner/agent_9/learner_stats/cur_lr\": {\n      \"max\": 5.000000000000001e-05,\n      \"min\": 5.000000000000001e-05,\n      \"avg\": 5.000000000000001e-05,\n      \"last\": 5.000000000000001e-05,\n      \"last-5-avg\": 5.000000000000001e-05,\n      \"last-10-avg\": 5.000000000000001e-05\n    },\n    \"info/learner/agent_9/learner_stats/total_loss\": {\n      \"max\": -0.03920738640881609,\n      \"min\": -0.03920738640881609,\n      \"avg\": -0.03920738640881609,\n      \"last\": -0.03920738640881609,\n      \"last-5-avg\": -0.03920738640881609,\n      \"last-10-avg\": -0.03920738640881609\n    },\n    \"info/learner/agent_9/learner_stats/policy_loss\": {\n      \"max\": -0.04024473679164657,\n      \"min\": -0.04024473679164657,\n      \"avg\": -0.04024473679164657,\n      \"last\": -0.04024473679164657,\n      \"last-5-avg\": -0.04024473679164657,\n      \"last-10-avg\": -0.04024473679164657\n    },\n    \"info/learner/agent_9/learner_stats/vf_loss\": {\n      \"max\": 9.855738909436695e-06,\n      \"min\": 9.855738909436695e-06,\n      \"avg\": 9.855738909436695e-06,\n      \"last\": 9.855738909436695e-06,\n      \"last-5-avg\": 9.855738909436695e-06,\n      \"last-10-avg\": 9.855738909436695e-06\n    },\n    \"info/learner/agent_9/learner_stats/vf_explained_var\": {\n      \"max\": 0.7513076294213533,\n      \"min\": 0.7513076294213533,\n      \"avg\": 0.7513076294213533,\n      \"last\": 0.7513076294213533,\n      \"last-5-avg\": 0.7513076294213533,\n      \"last-10-avg\": 0.7513076294213533\n    },\n    \"info/learner/agent_9/learner_stats/kl\": {\n      \"max\": 0.005137474206799197,\n      \"min\": 0.005137474206799197,\n      \"avg\": 0.005137474206799197,\n      \"last\": 0.005137474206799197,\n      \"last-5-avg\": 0.005137474206799197,\n      \"last-10-avg\": 0.005137474206799197\n    },\n    \"info/learner/agent_9/learner_stats/entropy\": {\n      \"max\": 6.176993077993393,\n      \"min\": 6.176993077993393,\n      \"avg\": 6.176993077993393,\n      \"last\": 6.176993077993393,\n      \"last-5-avg\": 6.176993077993393,\n      \"last-10-avg\": 6.176993077993393\n    },\n    \"info/learner/agent_9/learner_stats/entropy_coeff\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/agent_11/learner_stats/allreduce_latency\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/agent_11/learner_stats/grad_gnorm\": {\n      \"max\": 0.6695550084114075,\n      \"min\": 0.6695550084114075,\n      \"avg\": 0.6695550084114075,\n      \"last\": 0.6695550084114075,\n      \"last-5-avg\": 0.6695550084114075,\n      \"last-10-avg\": 0.6695550084114075\n    },\n    \"info/learner/agent_11/learner_stats/cur_kl_coeff\": {\n      \"max\": 0.19999999999999998,\n      \"min\": 0.19999999999999998,\n      \"avg\": 0.19999999999999998,\n      \"last\": 0.19999999999999998,\n      \"last-5-avg\": 0.19999999999999998,\n      \"last-10-avg\": 0.19999999999999998\n    },\n    \"info/learner/agent_11/learner_stats/cur_lr\": {\n      \"max\": 5.000000000000001e-05,\n      \"min\": 5.000000000000001e-05,\n      \"avg\": 5.000000000000001e-05,\n      \"last\": 5.000000000000001e-05,\n      \"last-5-avg\": 5.000000000000001e-05,\n      \"last-10-avg\": 5.000000000000001e-05\n    },\n    \"info/learner/agent_11/learner_stats/total_loss\": {\n      \"max\": -0.0433435093404114,\n      \"min\": -0.0433435093404114,\n      \"avg\": -0.0433435093404114,\n      \"last\": -0.0433435093404114,\n      \"last-5-avg\": -0.0433435093404114,\n      \"last-10-avg\": -0.0433435093404114\n    },\n    \"info/learner/agent_11/learner_stats/policy_loss\": {\n      \"max\": -0.04586449110647663,\n      \"min\": -0.04586449110647663,\n      \"avg\": -0.04586449110647663,\n      \"last\": -0.04586449110647663,\n      \"last-5-avg\": -0.04586449110647663,\n      \"last-10-avg\": -0.04586449110647663\n    },\n    \"info/learner/agent_11/learner_stats/vf_loss\": {\n      \"max\": 0.0013849644300535147,\n      \"min\": 0.0013849644300535147,\n      \"avg\": 0.0013849644300535147,\n      \"last\": 0.0013849644300535147,\n      \"last-5-avg\": 0.0013849644300535147,\n      \"last-10-avg\": 0.0013849644300535147\n    },\n    \"info/learner/agent_11/learner_stats/vf_explained_var\": {\n      \"max\": 0.7541764177381992,\n      \"min\": 0.7541764177381992,\n      \"avg\": 0.7541764177381992,\n      \"last\": 0.7541764177381992,\n      \"last-5-avg\": 0.7541764177381992,\n      \"last-10-avg\": 0.7541764177381992\n    },\n    \"info/learner/agent_11/learner_stats/kl\": {\n      \"max\": 0.005680086939082685,\n      \"min\": 0.005680086939082685,\n      \"avg\": 0.005680086939082685,\n      \"last\": 0.005680086939082685,\n      \"last-5-avg\": 0.005680086939082685,\n      \"last-10-avg\": 0.005680086939082685\n    },\n    \"info/learner/agent_11/learner_stats/entropy\": {\n      \"max\": 6.176377484202385,\n      \"min\": 6.176377484202385,\n      \"avg\": 6.176377484202385,\n      \"last\": 6.176377484202385,\n      \"last-5-avg\": 6.176377484202385,\n      \"last-10-avg\": 6.176377484202385\n    },\n    \"info/learner/agent_11/learner_stats/entropy_coeff\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/agent_6/learner_stats/allreduce_latency\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/agent_6/learner_stats/grad_gnorm\": {\n      \"max\": 0.5933342272415757,\n      \"min\": 0.5933342272415757,\n      \"avg\": 0.5933342272415757,\n      \"last\": 0.5933342272415757,\n      \"last-5-avg\": 0.5933342272415757,\n      \"last-10-avg\": 0.5933342272415757\n    },\n    \"info/learner/agent_6/learner_stats/cur_kl_coeff\": {\n      \"max\": 0.19999999999999998,\n      \"min\": 0.19999999999999998,\n      \"avg\": 0.19999999999999998,\n      \"last\": 0.19999999999999998,\n      \"last-5-avg\": 0.19999999999999998,\n      \"last-10-avg\": 0.19999999999999998\n    },\n    \"info/learner/agent_6/learner_stats/cur_lr\": {\n      \"max\": 5.000000000000001e-05,\n      \"min\": 5.000000000000001e-05,\n      \"avg\": 5.000000000000001e-05,\n      \"last\": 5.000000000000001e-05,\n      \"last-5-avg\": 5.000000000000001e-05,\n      \"last-10-avg\": 5.000000000000001e-05\n    },\n    \"info/learner/agent_6/learner_stats/total_loss\": {\n      \"max\": -0.04571261985984165,\n      \"min\": -0.04571261985984165,\n      \"avg\": -0.04571261985984165,\n      \"last\": -0.04571261985984165,\n      \"last-5-avg\": -0.04571261985984165,\n      \"last-10-avg\": -0.04571261985984165\n    },\n    \"info/learner/agent_6/learner_stats/policy_loss\": {\n      \"max\": -0.04761210111209948,\n      \"min\": -0.04761210111209948,\n      \"avg\": -0.04761210111209948,\n      \"last\": -0.04761210111209948,\n      \"last-5-avg\": -0.04761210111209948,\n      \"last-10-avg\": -0.04761210111209948\n    },\n    \"info/learner/agent_6/learner_stats/vf_loss\": {\n      \"max\": 0.000872174321852981,\n      \"min\": 0.000872174321852981,\n      \"avg\": 0.000872174321852981,\n      \"last\": 0.000872174321852981,\n      \"last-5-avg\": 0.000872174321852981,\n      \"last-10-avg\": 0.000872174321852981\n    },\n    \"info/learner/agent_6/learner_stats/vf_explained_var\": {\n      \"max\": 0.7932753082364797,\n      \"min\": 0.7932753082364797,\n      \"avg\": 0.7932753082364797,\n      \"last\": 0.7932753082364797,\n      \"last-5-avg\": 0.7932753082364797,\n      \"last-10-avg\": 0.7932753082364797\n    },\n    \"info/learner/agent_6/learner_stats/kl\": {\n      \"max\": 0.005136534875055077,\n      \"min\": 0.005136534875055077,\n      \"avg\": 0.005136534875055077,\n      \"last\": 0.005136534875055077,\n      \"last-5-avg\": 0.005136534875055077,\n      \"last-10-avg\": 0.005136534875055077\n    },\n    \"info/learner/agent_6/learner_stats/entropy\": {\n      \"max\": 6.176899519562721,\n      \"min\": 6.176899519562721,\n      \"avg\": 6.176899519562721,\n      \"last\": 6.176899519562721,\n      \"last-5-avg\": 6.176899519562721,\n      \"last-10-avg\": 6.176899519562721\n    },\n    \"info/learner/agent_6/learner_stats/entropy_coeff\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/agent_16/learner_stats/allreduce_latency\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/agent_16/learner_stats/grad_gnorm\": {\n      \"max\": 0.7869379967451096,\n      \"min\": 0.7869379967451096,\n      \"avg\": 0.7869379967451096,\n      \"last\": 0.7869379967451096,\n      \"last-5-avg\": 0.7869379967451096,\n      \"last-10-avg\": 0.7869379967451096\n    },\n    \"info/learner/agent_16/learner_stats/cur_kl_coeff\": {\n      \"max\": 0.19999999999999998,\n      \"min\": 0.19999999999999998,\n      \"avg\": 0.19999999999999998,\n      \"last\": 0.19999999999999998,\n      \"last-5-avg\": 0.19999999999999998,\n      \"last-10-avg\": 0.19999999999999998\n    },\n    \"info/learner/agent_16/learner_stats/cur_lr\": {\n      \"max\": 5.000000000000001e-05,\n      \"min\": 5.000000000000001e-05,\n      \"avg\": 5.000000000000001e-05,\n      \"last\": 5.000000000000001e-05,\n      \"last-5-avg\": 5.000000000000001e-05,\n      \"last-10-avg\": 5.000000000000001e-05\n    },\n    \"info/learner/agent_16/learner_stats/total_loss\": {\n      \"max\": -0.04269255140898167,\n      \"min\": -0.04269255140898167,\n      \"avg\": -0.04269255140898167,\n      \"last\": -0.04269255140898167,\n      \"last-5-avg\": -0.04269255140898167,\n      \"last-10-avg\": -0.04269255140898167\n    },\n    \"info/learner/agent_16/learner_stats/policy_loss\": {\n      \"max\": -0.04759652213833761,\n      \"min\": -0.04759652213833761,\n      \"avg\": -0.04759652213833761,\n      \"last\": -0.04759652213833761,\n      \"last-5-avg\": -0.04759652213833761,\n      \"last-10-avg\": -0.04759652213833761\n    },\n    \"info/learner/agent_16/learner_stats/vf_loss\": {\n      \"max\": 0.0038235232066654136,\n      \"min\": 0.0038235232066654136,\n      \"avg\": 0.0038235232066654136,\n      \"last\": 0.0038235232066654136,\n      \"last-5-avg\": 0.0038235232066654136,\n      \"last-10-avg\": 0.0038235232066654136\n    },\n    \"info/learner/agent_16/learner_stats/vf_explained_var\": {\n      \"max\": 0.27241815663874147,\n      \"min\": 0.27241815663874147,\n      \"avg\": 0.27241815663874147,\n      \"last\": 0.27241815663874147,\n      \"last-5-avg\": 0.27241815663874147,\n      \"last-10-avg\": 0.27241815663874147\n    },\n    \"info/learner/agent_16/learner_stats/kl\": {\n      \"max\": 0.005402238416832006,\n      \"min\": 0.005402238416832006,\n      \"avg\": 0.005402238416832006,\n      \"last\": 0.005402238416832006,\n      \"last-5-avg\": 0.005402238416832006,\n      \"last-10-avg\": 0.005402238416832006\n    },\n    \"info/learner/agent_16/learner_stats/entropy\": {\n      \"max\": 6.176775121688843,\n      \"min\": 6.176775121688843,\n      \"avg\": 6.176775121688843,\n      \"last\": 6.176775121688843,\n      \"last-5-avg\": 6.176775121688843,\n      \"last-10-avg\": 6.176775121688843\n    },\n    \"info/learner/agent_16/learner_stats/entropy_coeff\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/agent_1/learner_stats/allreduce_latency\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/agent_1/learner_stats/grad_gnorm\": {\n      \"max\": 0.7498519621789456,\n      \"min\": 0.7498519621789456,\n      \"avg\": 0.7498519621789456,\n      \"last\": 0.7498519621789456,\n      \"last-5-avg\": 0.7498519621789456,\n      \"last-10-avg\": 0.7498519621789456\n    },\n    \"info/learner/agent_1/learner_stats/cur_kl_coeff\": {\n      \"max\": 0.19999999999999998,\n      \"min\": 0.19999999999999998,\n      \"avg\": 0.19999999999999998,\n      \"last\": 0.19999999999999998,\n      \"last-5-avg\": 0.19999999999999998,\n      \"last-10-avg\": 0.19999999999999998\n    },\n    \"info/learner/agent_1/learner_stats/cur_lr\": {\n      \"max\": 5.000000000000001e-05,\n      \"min\": 5.000000000000001e-05,\n      \"avg\": 5.000000000000001e-05,\n      \"last\": 5.000000000000001e-05,\n      \"last-5-avg\": 5.000000000000001e-05,\n      \"last-10-avg\": 5.000000000000001e-05\n    },\n    \"info/learner/agent_1/learner_stats/total_loss\": {\n      \"max\": -0.04078422211532597,\n      \"min\": -0.04078422211532597,\n      \"avg\": -0.04078422211532597,\n      \"last\": -0.04078422211532597,\n      \"last-5-avg\": -0.04078422211532597,\n      \"last-10-avg\": -0.04078422211532597\n    },\n    \"info/learner/agent_1/learner_stats/policy_loss\": {\n      \"max\": -0.044464020896703,\n      \"min\": -0.044464020896703,\n      \"avg\": -0.044464020896703,\n      \"last\": -0.044464020896703,\n      \"last-5-avg\": -0.044464020896703,\n      \"last-10-avg\": -0.044464020896703\n    },\n    \"info/learner/agent_1/learner_stats/vf_loss\": {\n      \"max\": 0.0027592750334861195,\n      \"min\": 0.0027592750334861195,\n      \"avg\": 0.0027592750334861195,\n      \"last\": 0.0027592750334861195,\n      \"last-5-avg\": 0.0027592750334861195,\n      \"last-10-avg\": 0.0027592750334861195\n    },\n    \"info/learner/agent_1/learner_stats/vf_explained_var\": {\n      \"max\": 0.6717534307390451,\n      \"min\": 0.6717534307390451,\n      \"avg\": 0.6717534307390451,\n      \"last\": 0.6717534307390451,\n      \"last-5-avg\": 0.6717534307390451,\n      \"last-10-avg\": 0.6717534307390451\n    },\n    \"info/learner/agent_1/learner_stats/kl\": {\n      \"max\": 0.004602619858746948,\n      \"min\": 0.004602619858746948,\n      \"avg\": 0.004602619858746948,\n      \"last\": 0.004602619858746948,\n      \"last-5-avg\": 0.004602619858746948,\n      \"last-10-avg\": 0.004602619858746948\n    },\n    \"info/learner/agent_1/learner_stats/entropy\": {\n      \"max\": 6.177507683634758,\n      \"min\": 6.177507683634758,\n      \"avg\": 6.177507683634758,\n      \"last\": 6.177507683634758,\n      \"last-5-avg\": 6.177507683634758,\n      \"last-10-avg\": 6.177507683634758\n    },\n    \"info/learner/agent_1/learner_stats/entropy_coeff\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/agent_12/learner_stats/allreduce_latency\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/agent_12/learner_stats/grad_gnorm\": {\n      \"max\": 0.6966248460114002,\n      \"min\": 0.6966248460114002,\n      \"avg\": 0.6966248460114002,\n      \"last\": 0.6966248460114002,\n      \"last-5-avg\": 0.6966248460114002,\n      \"last-10-avg\": 0.6966248460114002\n    },\n    \"info/learner/agent_12/learner_stats/cur_kl_coeff\": {\n      \"max\": 0.19999999999999998,\n      \"min\": 0.19999999999999998,\n      \"avg\": 0.19999999999999998,\n      \"last\": 0.19999999999999998,\n      \"last-5-avg\": 0.19999999999999998,\n      \"last-10-avg\": 0.19999999999999998\n    },\n    \"info/learner/agent_12/learner_stats/cur_lr\": {\n      \"max\": 5.000000000000001e-05,\n      \"min\": 5.000000000000001e-05,\n      \"avg\": 5.000000000000001e-05,\n      \"last\": 5.000000000000001e-05,\n      \"last-5-avg\": 5.000000000000001e-05,\n      \"last-10-avg\": 5.000000000000001e-05\n    },\n    \"info/learner/agent_12/learner_stats/total_loss\": {\n      \"max\": -0.04409215200175822,\n      \"min\": -0.04409215200175822,\n      \"avg\": -0.04409215200175822,\n      \"last\": -0.04409215200175822,\n      \"last-5-avg\": -0.04409215200175822,\n      \"last-10-avg\": -0.04409215200175822\n    },\n    \"info/learner/agent_12/learner_stats/policy_loss\": {\n      \"max\": -0.04699938178237062,\n      \"min\": -0.04699938178237062,\n      \"avg\": -0.04699938178237062,\n      \"last\": -0.04699938178237062,\n      \"last-5-avg\": -0.04699938178237062,\n      \"last-10-avg\": -0.04699938178237062\n    },\n    \"info/learner/agent_12/learner_stats/vf_loss\": {\n      \"max\": 0.0020329539838712662,\n      \"min\": 0.0020329539838712662,\n      \"avg\": 0.0020329539838712662,\n      \"last\": 0.0020329539838712662,\n      \"last-5-avg\": 0.0020329539838712662,\n      \"last-10-avg\": 0.0020329539838712662\n    },\n    \"info/learner/agent_12/learner_stats/vf_explained_var\": {\n      \"max\": 0.7333294101059437,\n      \"min\": 0.7333294101059437,\n      \"avg\": 0.7333294101059437,\n      \"last\": 0.7333294101059437,\n      \"last-5-avg\": 0.7333294101059437,\n      \"last-10-avg\": 0.7333294101059437\n    },\n    \"info/learner/agent_12/learner_stats/kl\": {\n      \"max\": 0.004371380647398837,\n      \"min\": 0.004371380647398837,\n      \"avg\": 0.004371380647398837,\n      \"last\": 0.004371380647398837,\n      \"last-5-avg\": 0.004371380647398837,\n      \"last-10-avg\": 0.004371380647398837\n    },\n    \"info/learner/agent_12/learner_stats/entropy\": {\n      \"max\": 6.177722862362861,\n      \"min\": 6.177722862362861,\n      \"avg\": 6.177722862362861,\n      \"last\": 6.177722862362861,\n      \"last-5-avg\": 6.177722862362861,\n      \"last-10-avg\": 6.177722862362861\n    },\n    \"info/learner/agent_12/learner_stats/entropy_coeff\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/agent_14/learner_stats/allreduce_latency\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/agent_14/learner_stats/grad_gnorm\": {\n      \"max\": 0.7747931212186814,\n      \"min\": 0.7747931212186814,\n      \"avg\": 0.7747931212186814,\n      \"last\": 0.7747931212186814,\n      \"last-5-avg\": 0.7747931212186814,\n      \"last-10-avg\": 0.7747931212186814\n    },\n    \"info/learner/agent_14/learner_stats/cur_kl_coeff\": {\n      \"max\": 0.19999999999999998,\n      \"min\": 0.19999999999999998,\n      \"avg\": 0.19999999999999998,\n      \"last\": 0.19999999999999998,\n      \"last-5-avg\": 0.19999999999999998,\n      \"last-10-avg\": 0.19999999999999998\n    },\n    \"info/learner/agent_14/learner_stats/cur_lr\": {\n      \"max\": 5.000000000000001e-05,\n      \"min\": 5.000000000000001e-05,\n      \"avg\": 5.000000000000001e-05,\n      \"last\": 5.000000000000001e-05,\n      \"last-5-avg\": 5.000000000000001e-05,\n      \"last-10-avg\": 5.000000000000001e-05\n    },\n    \"info/learner/agent_14/learner_stats/total_loss\": {\n      \"max\": -0.04396464388810273,\n      \"min\": -0.04396464388810273,\n      \"avg\": -0.04396464388810273,\n      \"last\": -0.04396464388810273,\n      \"last-5-avg\": -0.04396464388810273,\n      \"last-10-avg\": -0.04396464388810273\n    },\n    \"info/learner/agent_14/learner_stats/policy_loss\": {\n      \"max\": -0.049254749249666926,\n      \"min\": -0.049254749249666926,\n      \"avg\": -0.049254749249666926,\n      \"last\": -0.049254749249666926,\n      \"last-5-avg\": -0.049254749249666926,\n      \"last-10-avg\": -0.049254749249666926\n    },\n    \"info/learner/agent_14/learner_stats/vf_loss\": {\n      \"max\": 0.004284306976478547,\n      \"min\": 0.004284306976478547,\n      \"avg\": 0.004284306976478547,\n      \"last\": 0.004284306976478547,\n      \"last-5-avg\": 0.004284306976478547,\n      \"last-10-avg\": 0.004284306976478547\n    },\n    \"info/learner/agent_14/learner_stats/vf_explained_var\": {\n      \"max\": 0.27437673695385456,\n      \"min\": 0.27437673695385456,\n      \"avg\": 0.27437673695385456,\n      \"last\": 0.27437673695385456,\n      \"last-5-avg\": 0.27437673695385456,\n      \"last-10-avg\": 0.27437673695385456\n    },\n    \"info/learner/agent_14/learner_stats/kl\": {\n      \"max\": 0.0050289939891399625,\n      \"min\": 0.0050289939891399625,\n      \"avg\": 0.0050289939891399625,\n      \"last\": 0.0050289939891399625,\n      \"last-5-avg\": 0.0050289939891399625,\n      \"last-10-avg\": 0.0050289939891399625\n    },\n    \"info/learner/agent_14/learner_stats/entropy\": {\n      \"max\": 6.177122569084167,\n      \"min\": 6.177122569084167,\n      \"avg\": 6.177122569084167,\n      \"last\": 6.177122569084167,\n      \"last-5-avg\": 6.177122569084167,\n      \"last-10-avg\": 6.177122569084167\n    },\n    \"info/learner/agent_14/learner_stats/entropy_coeff\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/agent_17/learner_stats/allreduce_latency\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/agent_17/learner_stats/grad_gnorm\": {\n      \"max\": 0.7749452617019414,\n      \"min\": 0.7749452617019414,\n      \"avg\": 0.7749452617019414,\n      \"last\": 0.7749452617019414,\n      \"last-5-avg\": 0.7749452617019414,\n      \"last-10-avg\": 0.7749452617019414\n    },\n    \"info/learner/agent_17/learner_stats/cur_kl_coeff\": {\n      \"max\": 0.19999999999999998,\n      \"min\": 0.19999999999999998,\n      \"avg\": 0.19999999999999998,\n      \"last\": 0.19999999999999998,\n      \"last-5-avg\": 0.19999999999999998,\n      \"last-10-avg\": 0.19999999999999998\n    },\n    \"info/learner/agent_17/learner_stats/cur_lr\": {\n      \"max\": 5.000000000000001e-05,\n      \"min\": 5.000000000000001e-05,\n      \"avg\": 5.000000000000001e-05,\n      \"last\": 5.000000000000001e-05,\n      \"last-5-avg\": 5.000000000000001e-05,\n      \"last-10-avg\": 5.000000000000001e-05\n    },\n    \"info/learner/agent_17/learner_stats/total_loss\": {\n      \"max\": -0.044516423007007686,\n      \"min\": -0.044516423007007686,\n      \"avg\": -0.044516423007007686,\n      \"last\": -0.044516423007007686,\n      \"last-5-avg\": -0.044516423007007686,\n      \"last-10-avg\": -0.044516423007007686\n    },\n    \"info/learner/agent_17/learner_stats/policy_loss\": {\n      \"max\": -0.0490830973663833,\n      \"min\": -0.0490830973663833,\n      \"avg\": -0.0490830973663833,\n      \"last\": -0.0490830973663833,\n      \"last-5-avg\": -0.0490830973663833,\n      \"last-10-avg\": -0.0490830973663833\n    },\n    \"info/learner/agent_17/learner_stats/vf_loss\": {\n      \"max\": 0.003491356852464378,\n      \"min\": 0.003491356852464378,\n      \"avg\": 0.003491356852464378,\n      \"last\": 0.003491356852464378,\n      \"last-5-avg\": 0.003491356852464378,\n      \"last-10-avg\": 0.003491356852464378\n    },\n    \"info/learner/agent_17/learner_stats/vf_explained_var\": {\n      \"max\": 0.280439143627882,\n      \"min\": 0.280439143627882,\n      \"avg\": 0.280439143627882,\n      \"last\": 0.280439143627882,\n      \"last-5-avg\": 0.280439143627882,\n      \"last-10-avg\": 0.280439143627882\n    },\n    \"info/learner/agent_17/learner_stats/kl\": {\n      \"max\": 0.005376582742837854,\n      \"min\": 0.005376582742837854,\n      \"avg\": 0.005376582742837854,\n      \"last\": 0.005376582742837854,\n      \"last-5-avg\": 0.005376582742837854,\n      \"last-10-avg\": 0.005376582742837854\n    },\n    \"info/learner/agent_17/learner_stats/entropy\": {\n      \"max\": 6.176796442270279,\n      \"min\": 6.176796442270279,\n      \"avg\": 6.176796442270279,\n      \"last\": 6.176796442270279,\n      \"last-5-avg\": 6.176796442270279,\n      \"last-10-avg\": 6.176796442270279\n    },\n    \"info/learner/agent_17/learner_stats/entropy_coeff\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/agent_18/learner_stats/allreduce_latency\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/agent_18/learner_stats/grad_gnorm\": {\n      \"max\": 0.7722561895847321,\n      \"min\": 0.7722561895847321,\n      \"avg\": 0.7722561895847321,\n      \"last\": 0.7722561895847321,\n      \"last-5-avg\": 0.7722561895847321,\n      \"last-10-avg\": 0.7722561895847321\n    },\n    \"info/learner/agent_18/learner_stats/cur_kl_coeff\": {\n      \"max\": 0.19999999999999998,\n      \"min\": 0.19999999999999998,\n      \"avg\": 0.19999999999999998,\n      \"last\": 0.19999999999999998,\n      \"last-5-avg\": 0.19999999999999998,\n      \"last-10-avg\": 0.19999999999999998\n    },\n    \"info/learner/agent_18/learner_stats/cur_lr\": {\n      \"max\": 5.000000000000001e-05,\n      \"min\": 5.000000000000001e-05,\n      \"avg\": 5.000000000000001e-05,\n      \"last\": 5.000000000000001e-05,\n      \"last-5-avg\": 5.000000000000001e-05,\n      \"last-10-avg\": 5.000000000000001e-05\n    },\n    \"info/learner/agent_18/learner_stats/total_loss\": {\n      \"max\": -0.040038841503701406,\n      \"min\": -0.040038841503701406,\n      \"avg\": -0.040038841503701406,\n      \"last\": -0.040038841503701406,\n      \"last-5-avg\": -0.040038841503701406,\n      \"last-10-avg\": -0.040038841503701406\n    },\n    \"info/learner/agent_18/learner_stats/policy_loss\": {\n      \"max\": -0.045286459196358916,\n      \"min\": -0.045286459196358916,\n      \"avg\": -0.045286459196358916,\n      \"last\": -0.045286459196358916,\n      \"last-5-avg\": -0.045286459196358916,\n      \"last-10-avg\": -0.045286459196358916\n    },\n    \"info/learner/agent_18/learner_stats/vf_loss\": {\n      \"max\": 0.004272990216122707,\n      \"min\": 0.004272990216122707,\n      \"avg\": 0.004272990216122707,\n      \"last\": 0.004272990216122707,\n      \"last-5-avg\": 0.004272990216122707,\n      \"last-10-avg\": 0.004272990216122707\n    },\n    \"info/learner/agent_18/learner_stats/vf_explained_var\": {\n      \"max\": 0.3040101286023855,\n      \"min\": 0.3040101286023855,\n      \"avg\": 0.3040101286023855,\n      \"last\": 0.3040101286023855,\n      \"last-5-avg\": 0.3040101286023855,\n      \"last-10-avg\": 0.3040101286023855\n    },\n    \"info/learner/agent_18/learner_stats/kl\": {\n      \"max\": 0.0048731343600820765,\n      \"min\": 0.0048731343600820765,\n      \"avg\": 0.0048731343600820765,\n      \"last\": 0.0048731343600820765,\n      \"last-5-avg\": 0.0048731343600820765,\n      \"last-10-avg\": 0.0048731343600820765\n    },\n    \"info/learner/agent_18/learner_stats/entropy\": {\n      \"max\": 6.177304804325104,\n      \"min\": 6.177304804325104,\n      \"avg\": 6.177304804325104,\n      \"last\": 6.177304804325104,\n      \"last-5-avg\": 6.177304804325104,\n      \"last-10-avg\": 6.177304804325104\n    },\n    \"info/learner/agent_18/learner_stats/entropy_coeff\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"num_healthy_workers\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b03612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b03612e\"\n      }\n    },\n    \"actor_manager_num_outstanding_async_reqs\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"num_remote_worker_restarts\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"num_agent_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944a20480100612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944a20480100612e\"\n      }\n    },\n    \"num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944a20480100612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944a20480100612e\"\n      }\n    },\n    \"num_env_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944da00f612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944da00f612e\"\n      }\n    },\n    \"num_env_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944da00f612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944da00f612e\"\n      }\n    },\n    \"num_env_steps_sampled_this_iter\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944da00f612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944da00f612e\"\n      }\n    },\n    \"num_env_steps_trained_this_iter\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944da00f612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944da00f612e\"\n      }\n    },\n    \"num_env_steps_sampled_throughput_per_sec\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740600a60c53aeace612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740600a60c53aeace612e\"\n      }\n    },\n    \"num_env_steps_trained_throughput_per_sec\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740600a60c53aeace612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740600a60c53aeace612e\"\n      }\n    },\n    \"timesteps_total\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944da00f612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944da00f612e\"\n      }\n    },\n    \"num_env_steps_sampled_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944da00f612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944da00f612e\"\n      }\n    },\n    \"num_agent_steps_sampled_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944a20480100612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944a20480100612e\"\n      }\n    },\n    \"num_steps_trained_this_iter\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944da00f612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944da00f612e\"\n      }\n    },\n    \"agent_timesteps_total\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944a20480100612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944a20480100612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403f30d904000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403f30d904000000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403f30d904000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403f30d904000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403f30d904000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403f30d904000000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"info/num_env_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944da00f612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944da00f612e\"\n      }\n    },\n    \"info/num_env_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944da00f612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944da00f612e\"\n      }\n    },\n    \"info/num_agent_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944a20480100612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944a20480100612e\"\n      }\n    },\n    \"info/num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944a20480100612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944a20480100612e\"\n      }\n    },\n    \"env_runners/episode_reward_max\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308aca3703d0af745c09486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308aca3703d0af745c09486945294612e\"\n      }\n    },\n    \"env_runners/episode_reward_min\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430871e27a14aec74ec09486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430871e27a14aec74ec09486945294612e\"\n      }\n    },\n    \"env_runners/episode_reward_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430883a4703d0a274bc09486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430883a4703d0a274bc09486945294612e\"\n      }\n    },\n    \"env_runners/episode_len_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000407f409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000407f409486945294612e\"\n      }\n    },\n    \"env_runners/episodes_timesteps_total\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944db80b612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944db80b612e\"\n      }\n    },\n    \"env_runners/num_faulty_episodes\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"env_runners/num_episodes\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b06612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b06612e\"\n      }\n    },\n    \"env_runners/episode_return_max\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308aca3703d0af745c09486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308aca3703d0af745c09486945294612e\"\n      }\n    },\n    \"env_runners/episode_return_min\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430871e27a14aec74ec09486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430871e27a14aec74ec09486945294612e\"\n      }\n    },\n    \"env_runners/episode_return_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430883a4703d0a274bc09486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430883a4703d0a274bc09486945294612e\"\n      }\n    },\n    \"env_runners/episodes_this_iter\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b06612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b06612e\"\n      }\n    },\n    \"timers/training_iteration_time_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740de70c1cac08312612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740de70c1cac08312612e\"\n      }\n    },\n    \"timers/restore_workers_time_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473f889374bc6a7efa612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473f889374bc6a7efa612e\"\n      }\n    },\n    \"timers/training_step_time_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740de70bf5c28f5c3612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740de70bf5c28f5c3612e\"\n      }\n    },\n    \"timers/sample_time_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740d42c80624dd2f2612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740d42c80624dd2f2612e\"\n      }\n    },\n    \"timers/learn_time_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c47b00624dd2f2612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c47b00624dd2f2612e\"\n      }\n    },\n    \"timers/learn_throughput\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474077d7604189374c612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474077d7604189374c612e\"\n      }\n    },\n    \"timers/synch_weights_time_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474039f5810624dd2f612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474039f5810624dd2f612e\"\n      }\n    },\n    \"counters/num_env_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944da00f612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944da00f612e\"\n      }\n    },\n    \"counters/num_env_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944da00f612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944da00f612e\"\n      }\n    },\n    \"counters/num_agent_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944a20480100612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944a20480100612e\"\n      }\n    },\n    \"counters/num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944a20480100612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944a20480100612e\"\n      }\n    },\n    \"perf/cpu_util_percent\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308b46f58fb86b521409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308b46f58fb86b521409486945294612e\"\n      }\n    },\n    \"perf/ram_util_percent\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085d74d145175d39409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085d74d145175d39409486945294612e\"\n      }\n    },\n    \"perf/gpu_util_percent0\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243086c8edde6d86dce3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243086c8edde6d86dce3f9486945294612e\"\n      }\n    },\n    \"perf/vram_util_percent0\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430863728efa89bfb43f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430863728efa89bfb43f9486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_min/agent_0\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e0f5285c8fc214c09486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e0f5285c8fc214c09486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_min/agent_1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430829d7a3703d0a15c09486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430829d7a3703d0a15c09486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_min/agent_2\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308030000000000e0bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308030000000000e0bf9486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_min/agent_3\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430867e17a14ae4715c09486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430867e17a14ae4715c09486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_min/agent_4\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308030000000000e0bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308030000000000e0bf9486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_min/agent_5\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430858e17a14ae4710c09486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430858e17a14ae4710c09486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_min/agent_6\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a2eb51b81e8514c09486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a2eb51b81e8514c09486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_min/agent_7\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308030000000000e0bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308030000000000e0bf9486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_min/agent_8\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308030000000000e0bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308030000000000e0bf9486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_min/agent_9\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308030000000000e0bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308030000000000e0bf9486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_min/agent_10\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308485c8fc2f52815c09486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308485c8fc2f52815c09486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_min/agent_11\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430871b81e85eb5115c09486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430871b81e85eb5115c09486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_min/agent_12\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308485c8fc2f52815c09486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308485c8fc2f52815c09486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_min/agent_13\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243086eb81e85eb5114c09486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243086eb81e85eb5114c09486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_min/agent_14\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089feb51b81e8513c09486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089feb51b81e8513c09486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_min/agent_15\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080a52b81e85eb14c09486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080a52b81e85eb14c09486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_min/agent_16\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430884666666666614c09486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430884666666666614c09486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_min/agent_17\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430871b81e85eb5115c09486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430871b81e85eb5115c09486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_min/agent_18\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089beb51b81e8512c09486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089beb51b81e8512c09486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_min/agent_19\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308be703d0ad7a313c09486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308be703d0ad7a313c09486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_min/agent_20\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080752b81e85eb13c09486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080752b81e85eb13c09486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_max/agent_0\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308030000000000e0bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308030000000000e0bf9486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_max/agent_1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308030000000000e0bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308030000000000e0bf9486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_max/agent_2\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308030000000000e0bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308030000000000e0bf9486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_max/agent_3\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308030000000000e0bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308030000000000e0bf9486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_max/agent_4\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308030000000000e0bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308030000000000e0bf9486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_max/agent_5\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308030000000000e0bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308030000000000e0bf9486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_max/agent_6\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308030000000000e0bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308030000000000e0bf9486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_max/agent_7\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308030000000000e0bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308030000000000e0bf9486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_max/agent_8\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308030000000000e0bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308030000000000e0bf9486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_max/agent_9\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308030000000000e0bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308030000000000e0bf9486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_max/agent_10\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308030000000000e0bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308030000000000e0bf9486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_max/agent_11\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308030000000000e0bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308030000000000e0bf9486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_max/agent_12\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308030000000000e0bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308030000000000e0bf9486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_max/agent_13\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308030000000000e0bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308030000000000e0bf9486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_max/agent_14\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308873d0ad7a3700dc09486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308873d0ad7a3700dc09486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_max/agent_15\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243086b8fc2f5285c10c09486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243086b8fc2f5285c10c09486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_max/agent_16\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a2eb51b81e850fc09486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a2eb51b81e850fc09486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_max/agent_17\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308b799999999990fc09486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308b799999999990fc09486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_max/agent_18\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308728fc2f5285c0dc09486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308728fc2f5285c0dc09486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_max/agent_19\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f37a14ae47e110c09486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f37a14ae47e110c09486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_max/agent_20\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a0c2f5285c8f10c09486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a0c2f5285c8f10c09486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_mean/agent_0\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085de17a14ae47f5bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085de17a14ae47f5bf9486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_mean/agent_1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308b3fc62c92f9606c09486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308b3fc62c92f9606c09486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_mean/agent_2\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308030000000000e0bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308030000000000e0bf9486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_mean/agent_3\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430804efeeeeeeee03c09486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430804efeeeeeeee03c09486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_mean/agent_4\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308030000000000e0bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308030000000000e0bf9486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_mean/agent_5\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f8eeeeeeeeeefcbf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f8eeeeeeeeeefcbf9486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_mean/agent_6\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430839bf58f28b25f5bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430839bf58f28b25f5bf9486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_mean/agent_7\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308030000000000e0bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308030000000000e0bf9486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_mean/agent_8\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308030000000000e0bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308030000000000e0bf9486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_mean/agent_9\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308030000000000e0bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308030000000000e0bf9486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_mean/agent_10\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430814295c8fc2f506c09486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430814295c8fc2f506c09486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_mean/agent_11\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430895b1e4174b7efbbf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430895b1e4174b7efbbf9486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_mean/agent_12\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430814c6925f2cf905c09486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430814c6925f2cf905c09486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_mean/agent_13\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a0eb51b81e8508c09486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a0eb51b81e8508c09486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_mean/agent_14\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308d9925f2cf94511c09486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308d9925f2cf94511c09486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_mean/agent_15\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308570ad7a3703d13c09486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308570ad7a3703d13c09486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_mean/agent_16\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430857a70d74da4012c09486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430857a70d74da4012c09486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_mean/agent_17\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308b9d3063a6d2013c09486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308b9d3063a6d2013c09486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_mean/agent_18\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430851a70d74da4010c09486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430851a70d74da4010c09486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_mean/agent_19\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308873d0ad7a37012c09486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308873d0ad7a37012c09486945294612e\"\n      }\n    },\n    \"env_runners/policy_reward_mean/agent_20\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430804efeeeeeeee11c09486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430804efeeeeeeee11c09486945294612e\"\n      }\n    },\n    \"env_runners/sampler_perf/mean_raw_obs_processing_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f5c4893a84c3fd3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f5c4893a84c3fd3f9486945294612e\"\n      }\n    },\n    \"env_runners/sampler_perf/mean_inference_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085b8afdf65edb23409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085b8afdf65edb23409486945294612e\"\n      }\n    },\n    \"env_runners/sampler_perf/mean_action_processing_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f96b73975df6e53f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f96b73975df6e53f9486945294612e\"\n      }\n    },\n    \"env_runners/sampler_perf/mean_env_wait_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308b50340f9f1f805409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308b50340f9f1f805409486945294612e\"\n      }\n    },\n    \"env_runners/sampler_perf/mean_env_render_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      }\n    },\n    \"env_runners/connector_metrics/ObsPreprocessorConnector_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308665996655905653f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308665996655905653f9486945294612e\"\n      }\n    },\n    \"env_runners/connector_metrics/StateBufferConnector_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cff33ccff3f8563f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cff33ccff3f8563f9486945294612e\"\n      }\n    },\n    \"env_runners/connector_metrics/ViewRequirementAgentConnector_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080cc3300c43069f3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080cc3300c43069f3f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_5/num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000406f409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000406f409486945294612e\"\n      }\n    },\n    \"info/learner/agent_5/num_grad_updates_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000002054409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000002054409486945294612e\"\n      }\n    },\n    \"info/learner/agent_5/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000e053409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000e053409486945294612e\"\n      }\n    },\n    \"info/learner/agent_4/num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000406f409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000406f409486945294612e\"\n      }\n    },\n    \"info/learner/agent_4/num_grad_updates_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000002054409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000002054409486945294612e\"\n      }\n    },\n    \"info/learner/agent_4/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000e053409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000e053409486945294612e\"\n      }\n    },\n    \"info/learner/agent_13/num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000406f409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000406f409486945294612e\"\n      }\n    },\n    \"info/learner/agent_13/num_grad_updates_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000002054409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000002054409486945294612e\"\n      }\n    },\n    \"info/learner/agent_13/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000e053409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000e053409486945294612e\"\n      }\n    },\n    \"info/learner/agent_0/num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000406f409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000406f409486945294612e\"\n      }\n    },\n    \"info/learner/agent_0/num_grad_updates_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000002054409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000002054409486945294612e\"\n      }\n    },\n    \"info/learner/agent_0/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000e053409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000e053409486945294612e\"\n      }\n    },\n    \"info/learner/agent_15/num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000406f409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000406f409486945294612e\"\n      }\n    },\n    \"info/learner/agent_15/num_grad_updates_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000002054409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000002054409486945294612e\"\n      }\n    },\n    \"info/learner/agent_15/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000e053409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000e053409486945294612e\"\n      }\n    },\n    \"info/learner/agent_19/num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000406f409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000406f409486945294612e\"\n      }\n    },\n    \"info/learner/agent_19/num_grad_updates_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000002054409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000002054409486945294612e\"\n      }\n    },\n    \"info/learner/agent_19/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000e053409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000e053409486945294612e\"\n      }\n    },\n    \"info/learner/agent_3/num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000406f409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000406f409486945294612e\"\n      }\n    },\n    \"info/learner/agent_3/num_grad_updates_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000002054409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000002054409486945294612e\"\n      }\n    },\n    \"info/learner/agent_3/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000e053409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000e053409486945294612e\"\n      }\n    },\n    \"info/learner/agent_20/num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000406f409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000406f409486945294612e\"\n      }\n    },\n    \"info/learner/agent_20/num_grad_updates_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000002054409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000002054409486945294612e\"\n      }\n    },\n    \"info/learner/agent_20/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000e053409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000e053409486945294612e\"\n      }\n    },\n    \"info/learner/agent_2/num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000406f409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000406f409486945294612e\"\n      }\n    },\n    \"info/learner/agent_2/num_grad_updates_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000002054409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000002054409486945294612e\"\n      }\n    },\n    \"info/learner/agent_2/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000e053409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000e053409486945294612e\"\n      }\n    },\n    \"info/learner/agent_7/num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000406f409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000406f409486945294612e\"\n      }\n    },\n    \"info/learner/agent_7/num_grad_updates_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000002054409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000002054409486945294612e\"\n      }\n    },\n    \"info/learner/agent_7/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000e053409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000e053409486945294612e\"\n      }\n    },\n    \"info/learner/agent_10/num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000406f409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000406f409486945294612e\"\n      }\n    },\n    \"info/learner/agent_10/num_grad_updates_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000002054409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000002054409486945294612e\"\n      }\n    },\n    \"info/learner/agent_10/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000e053409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000e053409486945294612e\"\n      }\n    },\n    \"info/learner/agent_8/num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000406f409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000406f409486945294612e\"\n      }\n    },\n    \"info/learner/agent_8/num_grad_updates_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000002054409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000002054409486945294612e\"\n      }\n    },\n    \"info/learner/agent_8/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000e053409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000e053409486945294612e\"\n      }\n    },\n    \"info/learner/agent_9/num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000406f409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000406f409486945294612e\"\n      }\n    },\n    \"info/learner/agent_9/num_grad_updates_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000002054409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000002054409486945294612e\"\n      }\n    },\n    \"info/learner/agent_9/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000e053409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000e053409486945294612e\"\n      }\n    },\n    \"info/learner/agent_11/num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000406f409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000406f409486945294612e\"\n      }\n    },\n    \"info/learner/agent_11/num_grad_updates_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000002054409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000002054409486945294612e\"\n      }\n    },\n    \"info/learner/agent_11/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000e053409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000e053409486945294612e\"\n      }\n    },\n    \"info/learner/agent_6/num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000406f409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000406f409486945294612e\"\n      }\n    },\n    \"info/learner/agent_6/num_grad_updates_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000002054409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000002054409486945294612e\"\n      }\n    },\n    \"info/learner/agent_6/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000e053409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000e053409486945294612e\"\n      }\n    },\n    \"info/learner/agent_16/num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000406f409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000406f409486945294612e\"\n      }\n    },\n    \"info/learner/agent_16/num_grad_updates_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000002054409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000002054409486945294612e\"\n      }\n    },\n    \"info/learner/agent_16/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000e053409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000e053409486945294612e\"\n      }\n    },\n    \"info/learner/agent_1/num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000406f409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000406f409486945294612e\"\n      }\n    },\n    \"info/learner/agent_1/num_grad_updates_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000002054409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000002054409486945294612e\"\n      }\n    },\n    \"info/learner/agent_1/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000e053409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000e053409486945294612e\"\n      }\n    },\n    \"info/learner/agent_12/num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000406f409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000406f409486945294612e\"\n      }\n    },\n    \"info/learner/agent_12/num_grad_updates_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000002054409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000002054409486945294612e\"\n      }\n    },\n    \"info/learner/agent_12/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000e053409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000e053409486945294612e\"\n      }\n    },\n    \"info/learner/agent_14/num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000406f409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000406f409486945294612e\"\n      }\n    },\n    \"info/learner/agent_14/num_grad_updates_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000002054409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000002054409486945294612e\"\n      }\n    },\n    \"info/learner/agent_14/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000e053409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000e053409486945294612e\"\n      }\n    },\n    \"info/learner/agent_17/num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000406f409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000406f409486945294612e\"\n      }\n    },\n    \"info/learner/agent_17/num_grad_updates_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000002054409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000002054409486945294612e\"\n      }\n    },\n    \"info/learner/agent_17/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000e053409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000e053409486945294612e\"\n      }\n    },\n    \"info/learner/agent_18/num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000406f409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000406f409486945294612e\"\n      }\n    },\n    \"info/learner/agent_18/num_grad_updates_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000002054409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000002054409486945294612e\"\n      }\n    },\n    \"info/learner/agent_18/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000e053409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000e053409486945294612e\"\n      }\n    },\n    \"info/learner/agent_5/learner_stats/allreduce_latency\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      }\n    },\n    \"info/learner/agent_5/learner_stats/grad_gnorm\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a99994bd835e53f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a99994bd835e53f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_5/learner_stats/cur_kl_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308999999999999c93f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308999999999999c93f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_5/learner_stats/cur_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082e431cebe2360a3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082e431cebe2360a3f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_5/learner_stats/total_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430833338fec5b52a6bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430833338fec5b52a6bf9486945294612e\"\n      }\n    },\n    \"info/learner/agent_5/learner_stats/policy_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308666626e3baf0a7bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308666626e3baf0a7bf9486945294612e\"\n      }\n    },\n    \"info/learner/agent_5/learner_stats/vf_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243086666e6ab8246603f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243086666e6ab8246603f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_5/learner_stats/vf_explained_var\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcccce42967e43f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcccce42967e43f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_5/learner_stats/kl\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a9993a38f0e783f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a9993a38f0e783f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_5/learner_stats/entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcccc7067b418409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcccc7067b418409486945294612e\"\n      }\n    },\n    \"info/learner/agent_5/learner_stats/entropy_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      }\n    },\n    \"info/learner/agent_4/learner_stats/allreduce_latency\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      }\n    },\n    \"info/learner/agent_4/learner_stats/grad_gnorm\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308666666dea324d93f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308666666dea324d93f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_4/learner_stats/cur_kl_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308999999999999c93f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308999999999999c93f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_4/learner_stats/cur_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082e431cebe2360a3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082e431cebe2360a3f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_4/learner_stats/total_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083333eb8dabdca3bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083333eb8dabdca3bf9486945294612e\"\n      }\n    },\n    \"info/learner/agent_4/learner_stats/policy_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308666606546085a4bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308666606546085a4bf9486945294612e\"\n      }\n    },\n    \"info/learner/agent_4/learner_stats/vf_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcc5c22bb162e3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcc5c22bb162e3f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_4/learner_stats/vf_explained_var\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcccc7e67fdea3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcccc7e67fdea3f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_4/learner_stats/kl\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430833334f23b1a8753f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430833334f23b1a8753f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_4/learner_stats/entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000d119b518409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000d119b518409486945294612e\"\n      }\n    },\n    \"info/learner/agent_4/learner_stats/entropy_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      }\n    },\n    \"info/learner/agent_13/learner_stats/allreduce_latency\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      }\n    },\n    \"info/learner/agent_13/learner_stats/grad_gnorm\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcccc5d60eae53f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcccc5d60eae53f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_13/learner_stats/cur_kl_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308999999999999c93f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308999999999999c93f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_13/learner_stats/cur_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082e431cebe2360a3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082e431cebe2360a3f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_13/learner_stats/total_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308333357f0fa45a6bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308333357f0fa45a6bf9486945294612e\"\n      }\n    },\n    \"info/learner/agent_13/learner_stats/policy_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a99b91d55bca7bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a99b91d55bca7bf9486945294612e\"\n      }\n    },\n    \"info/learner/agent_13/learner_stats/vf_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcc4c4e88125e3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcc4c4e88125e3f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_13/learner_stats/vf_explained_var\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a9999b467b9e73f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a9999b467b9e73f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_13/learner_stats/kl\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800002689ece6743f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800002689ece6743f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_13/learner_stats/entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcccc7039b518409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcccc7039b518409486945294612e\"\n      }\n    },\n    \"info/learner/agent_13/learner_stats/entropy_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      }\n    },\n    \"info/learner/agent_0/learner_stats/allreduce_latency\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      }\n    },\n    \"info/learner/agent_0/learner_stats/grad_gnorm\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308666666902839e33f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308666666902839e33f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_0/learner_stats/cur_kl_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308999999999999c93f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308999999999999c93f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_0/learner_stats/cur_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082e431cebe2360a3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082e431cebe2360a3f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_0/learner_stats/total_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000a8bde2eba7bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000a8bde2eba7bf9486945294612e\"\n      }\n    },\n    \"info/learner/agent_0/learner_stats/policy_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000080c61efea8bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000080c61efea8bf9486945294612e\"\n      }\n    },\n    \"info/learner/agent_0/learner_stats/vf_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083333731bd1b34f3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083333731bd1b34f3f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_0/learner_stats/vf_explained_var\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcccc8317dbe83f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcccc8317dbe83f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_0/learner_stats/kl\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430833335b24ff08773f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430833335b24ff08773f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_0/learner_stats/entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308666666cfa5b418409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308666666cfa5b418409486945294612e\"\n      }\n    },\n    \"info/learner/agent_0/learner_stats/entropy_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      }\n    },\n    \"info/learner/agent_15/learner_stats/allreduce_latency\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      }\n    },\n    \"info/learner/agent_15/learner_stats/grad_gnorm\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000aa69bde83f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000aa69bde83f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_15/learner_stats/cur_kl_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308999999999999c93f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308999999999999c93f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_15/learner_stats/cur_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082e431cebe2360a3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082e431cebe2360a3f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_15/learner_stats/total_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430833331b6c1863a5bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430833331b6c1863a5bf9486945294612e\"\n      }\n    },\n    \"info/learner/agent_15/learner_stats/policy_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcc6c86dc9aa7bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcc6c86dc9aa7bf9486945294612e\"\n      }\n    },\n    \"info/learner/agent_15/learner_stats/vf_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243086666666166c56b3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243086666666166c56b3f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_15/learner_stats/vf_explained_var\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000006058fdce3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000006058fdce3f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_15/learner_stats/kl\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308333309df2449733f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308333309df2449733f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_15/learner_stats/entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308666666eab1b518409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308666666eab1b518409486945294612e\"\n      }\n    },\n    \"info/learner/agent_15/learner_stats/entropy_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      }\n    },\n    \"info/learner/agent_19/learner_stats/allreduce_latency\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      }\n    },\n    \"info/learner/agent_19/learner_stats/grad_gnorm\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000468273e93f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000468273e93f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_19/learner_stats/cur_kl_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308999999999999c93f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308999999999999c93f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_19/learner_stats/cur_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082e431cebe2360a3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082e431cebe2360a3f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_19/learner_stats/total_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000f0d26dcda4bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000f0d26dcda4bf9486945294612e\"\n      }\n    },\n    \"info/learner/agent_19/learner_stats/policy_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a99d9d0f448a7bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a99d9d0f448a7bf9486945294612e\"\n      }\n    },\n    \"info/learner/agent_19/learner_stats/vf_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083333b34ac9ed6f3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083333b34ac9ed6f3f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_19/learner_stats/vf_explained_var\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000002e58e8d03f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000002e58e8d03f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_19/learner_stats/kl\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000fcf59e7a733f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000fcf59e7a733f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_19/learner_stats/entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243086666669caab518409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243086666669caab518409486945294612e\"\n      }\n    },\n    \"info/learner/agent_19/learner_stats/entropy_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      }\n    },\n    \"info/learner/agent_3/learner_stats/allreduce_latency\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      }\n    },\n    \"info/learner/agent_3/learner_stats/grad_gnorm\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308666666f0d205e53f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308666666f0d205e53f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_3/learner_stats/cur_kl_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308999999999999c93f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308999999999999c93f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_3/learner_stats/cur_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082e431cebe2360a3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082e431cebe2360a3f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_3/learner_stats/total_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430866666ea5c933a7bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430866666ea5c933a7bf9486945294612e\"\n      }\n    },\n    \"info/learner/agent_3/learner_stats/policy_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a99dd78ad81a8bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a99dd78ad81a8bf9486945294612e\"\n      }\n    },\n    \"info/learner/agent_3/learner_stats/vf_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308666696e01887583f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308666696e01887583f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_3/learner_stats/vf_explained_var\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdccccd65056e83f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdccccd65056e83f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_3/learner_stats/kl\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcc12afb882753f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcc12afb882753f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_3/learner_stats/entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcccc2610b518409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcccc2610b518409486945294612e\"\n      }\n    },\n    \"info/learner/agent_3/learner_stats/entropy_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      }\n    },\n    \"info/learner/agent_20/learner_stats/allreduce_latency\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      }\n    },\n    \"info/learner/agent_20/learner_stats/grad_gnorm\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000fc7fc0e83f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000fc7fc0e83f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_20/learner_stats/cur_kl_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308999999999999c93f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308999999999999c93f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_20/learner_stats/cur_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082e431cebe2360a3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082e431cebe2360a3f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_20/learner_stats/total_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430866667edd4f70a4bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430866667edd4f70a4bf9486945294612e\"\n      }\n    },\n    \"info/learner/agent_20/learner_stats/policy_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243086666e63ef6eda6bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243086666e63ef6eda6bf9486945294612e\"\n      }\n    },\n    \"info/learner/agent_20/learner_stats/vf_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308333333dbd06c6f3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308333333dbd06c6f3f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_20/learner_stats/vf_explained_var\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083333332b32b6cf3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083333332b32b6cf3f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_20/learner_stats/kl\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a99a717f611753f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a99a717f611753f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_20/learner_stats/entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000007944b518409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000007944b518409486945294612e\"\n      }\n    },\n    \"info/learner/agent_20/learner_stats/entropy_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      }\n    },\n    \"info/learner/agent_2/learner_stats/allreduce_latency\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      }\n    },\n    \"info/learner/agent_2/learner_stats/grad_gnorm\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcccc223e15e33f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcccc223e15e33f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_2/learner_stats/cur_kl_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308999999999999c93f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308999999999999c93f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_2/learner_stats/cur_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082e431cebe2360a3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082e431cebe2360a3f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_2/learner_stats/total_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcc244a1d9aa3bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcc244a1d9aa3bf9486945294612e\"\n      }\n    },\n    \"info/learner/agent_2/learner_stats/policy_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a99d9ae6d21a4bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a99d9ae6d21a4bf9486945294612e\"\n      }\n    },\n    \"info/learner/agent_2/learner_stats/vf_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083333d3063e11f23e9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083333d3063e11f23e9486945294612e\"\n      }\n    },\n    \"info/learner/agent_2/learner_stats/vf_explained_var\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083333334cac60e43f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083333334cac60e43f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_2/learner_stats/kl\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcc522038ca743f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcc522038ca743f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_2/learner_stats/entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000df49b518409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000df49b518409486945294612e\"\n      }\n    },\n    \"info/learner/agent_2/learner_stats/entropy_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      }\n    },\n    \"info/learner/agent_7/learner_stats/allreduce_latency\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      }\n    },\n    \"info/learner/agent_7/learner_stats/grad_gnorm\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcccc122830db3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcccc122830db3f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_7/learner_stats/cur_kl_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308999999999999c93f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308999999999999c93f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_7/learner_stats/cur_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082e431cebe2360a3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082e431cebe2360a3f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_7/learner_stats/total_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000010f8790ba7bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000010f8790ba7bf9486945294612e\"\n      }\n    },\n    \"info/learner/agent_7/learner_stats/policy_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a997931dec4a7bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a997931dec4a7bf9486945294612e\"\n      }\n    },\n    \"info/learner/agent_7/learner_stats/vf_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308666616ae86d8383f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308666616ae86d8383f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_7/learner_stats/vf_explained_var\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308666666cfa763ea3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308666666cfa763ea3f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_7/learner_stats/kl\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000ac91fe33753f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000ac91fe33753f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_7/learner_stats/entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a99993834b518409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a99993834b518409486945294612e\"\n      }\n    },\n    \"info/learner/agent_7/learner_stats/entropy_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      }\n    },\n    \"info/learner/agent_10/learner_stats/allreduce_latency\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      }\n    },\n    \"info/learner/agent_10/learner_stats/grad_gnorm\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdccccec56c4e63f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdccccec56c4e63f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_10/learner_stats/cur_kl_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308999999999999c93f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308999999999999c93f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_10/learner_stats/cur_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082e431cebe2360a3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082e431cebe2360a3f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_10/learner_stats/total_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000075ca0cd1a5bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000075ca0cd1a5bf9486945294612e\"\n      }\n    },\n    \"info/learner/agent_10/learner_stats/policy_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a9979b14f56a7bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a9979b14f56a7bf9486945294612e\"\n      }\n    },\n    \"info/learner/agent_10/learner_stats/vf_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308333383611c41613f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308333383611c41613f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_10/learner_stats/vf_explained_var\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcccc24a129e73f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcccc24a129e73f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_10/learner_stats/kl\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcc1ae3adaf713f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcc1ae3adaf713f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_10/learner_stats/entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308333333c30eb618409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308333333c30eb618409486945294612e\"\n      }\n    },\n    \"info/learner/agent_10/learner_stats/entropy_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      }\n    },\n    \"info/learner/agent_8/learner_stats/allreduce_latency\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      }\n    },\n    \"info/learner/agent_8/learner_stats/grad_gnorm\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083333b3e6f3ccd83f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083333b3e6f3ccd83f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_8/learner_stats/cur_kl_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308999999999999c93f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308999999999999c93f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_8/learner_stats/cur_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082e431cebe2360a3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082e431cebe2360a3f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_8/learner_stats/total_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800008402dcb2a5bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800008402dcb2a5bf9486945294612e\"\n      }\n    },\n    \"info/learner/agent_8/learner_stats/policy_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdccfcdf8433a6bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdccfcdf8433a6bf9486945294612e\"\n      }\n    },\n    \"info/learner/agent_8/learner_stats/vf_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdccbc8d77842e3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdccbc8d77842e3f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_8/learner_stats/vf_explained_var\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a9999310571eb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a9999310571eb3f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_8/learner_stats/kl\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a99591261ab6e3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a99591261ab6e3f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_8/learner_stats/entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243086666665ea9b618409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243086666665ea9b618409486945294612e\"\n      }\n    },\n    \"info/learner/agent_8/learner_stats/entropy_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      }\n    },\n    \"info/learner/agent_9/learner_stats/allreduce_latency\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      }\n    },\n    \"info/learner/agent_9/learner_stats/grad_gnorm\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcccc1f8bdee33f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcccc1f8bdee33f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_9/learner_stats/cur_kl_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308999999999999c93f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308999999999999c93f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_9/learner_stats/cur_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082e431cebe2360a3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082e431cebe2360a3f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_9/learner_stats/total_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243086666c694fd12a4bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243086666c694fd12a4bf9486945294612e\"\n      }\n    },\n    \"info/learner/agent_9/learner_stats/policy_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243086666b648f59aa4bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243086666b648f59aa4bf9486945294612e\"\n      }\n    },\n    \"info/learner/agent_9/learner_stats/vf_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000007142abe43e9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000007142abe43e9486945294612e\"\n      }\n    },\n    \"info/learner/agent_9/learner_stats/vf_explained_var\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083333334cb60ae83f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083333334cb60ae83f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_9/learner_stats/kl\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430866663c3b080b753f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430866663c3b080b753f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_9/learner_stats/entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308666666ac3db518409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308666666ac3db518409486945294612e\"\n      }\n    },\n    \"info/learner/agent_9/learner_stats/entropy_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      }\n    },\n    \"info/learner/agent_11/learner_stats/allreduce_latency\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      }\n    },\n    \"info/learner/agent_11/learner_stats/grad_gnorm\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000a0fe6ce53f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000a0fe6ce53f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_11/learner_stats/cur_kl_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308999999999999c93f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308999999999999c93f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_11/learner_stats/cur_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082e431cebe2360a3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082e431cebe2360a3f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_11/learner_stats/total_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcc38d61e31a6bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcc38d61e31a6bf9486945294612e\"\n      }\n    },\n    \"info/learner/agent_11/learner_stats/policy_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083333b3f28c7ba7bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083333b3f28c7ba7bf9486945294612e\"\n      }\n    },\n    \"info/learner/agent_11/learner_stats/vf_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a99b93bf6b0563f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a99b93bf6b0563f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_11/learner_stats/vf_explained_var\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308333333953622e83f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308333333953622e83f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_11/learner_stats/kl\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcc44ba0044773f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcc44ba0044773f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_11/learner_stats/entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a99994c9cb418409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a99994c9cb418409486945294612e\"\n      }\n    },\n    \"info/learner/agent_11/learner_stats/entropy_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      }\n    },\n    \"info/learner/agent_6/learner_stats/allreduce_latency\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      }\n    },\n    \"info/learner/agent_6/learner_stats/grad_gnorm\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083333b30f98fce23f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083333b30f98fce23f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_6/learner_stats/cur_kl_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308999999999999c93f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308999999999999c93f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_6/learner_stats/cur_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082e431cebe2360a3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082e431cebe2360a3f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_6/learner_stats/total_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000a0fea467a7bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000a0fea467a7bf9486945294612e\"\n      }\n    },\n    \"info/learner/agent_6/learner_stats/policy_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308333357029d60a8bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308333357029d60a8bf9486945294612e\"\n      }\n    },\n    \"info/learner/agent_6/learner_stats/vf_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a99291854944c3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a99291854944c3f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_6/learner_stats/vf_explained_var\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308333333e68262e93f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308333333e68262e93f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_6/learner_stats/kl\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a99d9140c0a753f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a99d9140c0a753f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_6/learner_stats/entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcccc2525b518409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcccc2525b518409486945294612e\"\n      }\n    },\n    \"info/learner/agent_6/learner_stats/entropy_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      }\n    },\n    \"info/learner/agent_16/learner_stats/allreduce_latency\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      }\n    },\n    \"info/learner/agent_16/learner_stats/grad_gnorm\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000098982ee93f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000098982ee93f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_16/learner_stats/cur_kl_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308999999999999c93f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308999999999999c93f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_16/learner_stats/cur_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082e431cebe2360a3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082e431cebe2360a3f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_16/learner_stats/total_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430833332b50ccdba5bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430833332b50ccdba5bf9486945294612e\"\n      }\n    },\n    \"info/learner/agent_16/learner_stats/policy_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a99f943925ea8bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a99f943925ea8bf9486945294612e\"\n      }\n    },\n    \"info/learner/agent_16/learner_stats/vf_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a99196482526f3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a99196482526f3f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_16/learner_stats/vf_explained_var\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308666666904c6fd13f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308666666904c6fd13f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_16/learner_stats/kl\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430833333555a820763f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430833333555a820763f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_16/learner_stats/entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a99998904b518409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a99998904b518409486945294612e\"\n      }\n    },\n    \"info/learner/agent_16/learner_stats/entropy_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      }\n    },\n    \"info/learner/agent_1/learner_stats/allreduce_latency\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      }\n    },\n    \"info/learner/agent_1/learner_stats/grad_gnorm\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcccc8ac9fee73f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcccc8ac9fee73f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_1/learner_stats/cur_kl_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308999999999999c93f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308999999999999c93f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_1/learner_stats/cur_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082e431cebe2360a3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082e431cebe2360a3f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_1/learner_stats/total_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430833335b68abe1a4bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430833335b68abe1a4bf9486945294612e\"\n      }\n    },\n    \"info/learner/agent_1/learner_stats/policy_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308333333f7fcc3a6bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308333333f7fcc3a6bf9486945294612e\"\n      }\n    },\n    \"info/learner/agent_1/learner_stats/vf_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a99f1809e9a663f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a99f1809e9a663f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_1/learner_stats/vf_explained_var\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000d017fe53f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000d017fe53f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_1/learner_stats/kl\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcc4e5c32da723f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcc4e5c32da723f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_1/learner_stats/entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000093c4b518409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000093c4b518409486945294612e\"\n      }\n    },\n    \"info/learner/agent_1/learner_stats/entropy_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      }\n    },\n    \"info/learner/agent_12/learner_stats/allreduce_latency\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      }\n    },\n    \"info/learner/agent_12/learner_stats/grad_gnorm\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430866666630c04ae63f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430866666630c04ae63f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_12/learner_stats/cur_kl_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308999999999999c93f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308999999999999c93f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_12/learner_stats/cur_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082e431cebe2360a3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082e431cebe2360a3f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_12/learner_stats/total_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083333b71d3f93a6bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083333b71d3f93a6bf9486945294612e\"\n      }\n    },\n    \"info/learner/agent_12/learner_stats/policy_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000608f4d10a8bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000608f4d10a8bf9486945294612e\"\n      }\n    },\n    \"info/learner/agent_12/learner_stats/vf_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000dc69a7603f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000dc69a7603f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_12/learner_stats/vf_explained_var\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083333333d6f77e73f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083333333d6f77e73f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_12/learner_stats/kl\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000b48eb9e7713f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000b48eb9e7713f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_12/learner_stats/entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308666666fbfcb518409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308666666fbfcb518409486945294612e\"\n      }\n    },\n    \"info/learner/agent_12/learner_stats/entropy_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      }\n    },\n    \"info/learner/agent_14/learner_stats/allreduce_latency\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      }\n    },\n    \"info/learner/agent_14/learner_stats/grad_gnorm\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a9999f11acbe83f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a9999f11acbe83f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_14/learner_stats/cur_kl_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308999999999999c93f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308999999999999c93f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_14/learner_stats/cur_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082e431cebe2360a3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082e431cebe2360a3f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_14/learner_stats/total_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800005ca78882a6bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800005ca78882a6bf9486945294612e\"\n      }\n    },\n    \"info/learner/agent_14/learner_stats/policy_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430866666622eb37a9bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430866666622eb37a9bf9486945294612e\"\n      }\n    },\n    \"info/learner/agent_14/learner_stats/vf_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a9999e56b8c713f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a9999e56b8c713f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_14/learner_stats/vf_explained_var\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000072638fd13f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000072638fd13f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_14/learner_stats/kl\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083333714b4899743f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083333714b4899743f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_14/learner_stats/entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243086666669e5fb518409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243086666669e5fb518409486945294612e\"\n      }\n    },\n    \"info/learner/agent_14/learner_stats/entropy_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      }\n    },\n    \"info/learner/agent_17/learner_stats/allreduce_latency\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      }\n    },\n    \"info/learner/agent_17/learner_stats/grad_gnorm\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308666666015acce83f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308666666015acce83f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_17/learner_stats/cur_kl_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308999999999999c93f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308999999999999c93f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_17/learner_stats/cur_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082e431cebe2360a3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082e431cebe2360a3f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_17/learner_stats/total_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243086666e649dbcaa6bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243086666e649dbcaa6bf9486945294612e\"\n      }\n    },\n    \"info/learner/agent_17/learner_stats/policy_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083333f3736b21a9bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083333f3736b21a9bf9486945294612e\"\n      }\n    },\n    \"info/learner/agent_17/learner_stats/vf_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000f0e7996c3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000f0e7996c3f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_17/learner_stats/vf_explained_var\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a999905b7f2d13f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a999905b7f2d13f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_17/learner_stats/kl\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083333b770c105763f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083333b770c105763f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_17/learner_stats/entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308666666200ab518409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308666666200ab518409486945294612e\"\n      }\n    },\n    \"info/learner/agent_17/learner_stats/entropy_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      }\n    },\n    \"info/learner/agent_18/learner_stats/allreduce_latency\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      }\n    },\n    \"info/learner/agent_18/learner_stats/grad_gnorm\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcccc9c52b6e83f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdcccc9c52b6e83f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_18/learner_stats/cur_kl_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308999999999999c93f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308999999999999c93f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_18/learner_stats/cur_lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082e431cebe2360a3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082e431cebe2360a3f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_18/learner_stats/total_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000a895f87fa4bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000a895f87fa4bf9486945294612e\"\n      }\n    },\n    \"info/learner/agent_18/learner_stats/policy_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243086666666ac92fa7bf9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243086666666ac92fa7bf9486945294612e\"\n      }\n    },\n    \"info/learner/agent_18/learner_stats/vf_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000c0138e80713f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000c0138e80713f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_18/learner_stats/vf_explained_var\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000e6e674d33f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000e6e674d33f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_18/learner_stats/kl\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800004a0bdaf5733f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800004a0bdaf5733f9486945294612e\"\n      }\n    },\n    \"info/learner/agent_18/learner_stats/entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000648fb518409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000648fb518409486945294612e\"\n      }\n    },\n    \"info/learner/agent_18/learner_stats/entropy_coeff\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000000000009486945294612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b0a8c11636865636b706f696e745f61745f656e6494888c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"]], "runner_data": {"_earliest_stopping_actor": Infinity, "_actor_cleanup_timeout": 600, "_actor_force_cleanup_timeout": 10, "_reuse_actors": false, "_buffer_length": 1, "_buffer_min_time_s": 0.0, "_buffer_max_time_s": 100.0, "_max_pending_trials": 200, "_metric": null, "_total_time": 31.19081139564514, "_iteration": 500, "_has_errored": false, "_fail_fast": false, "_print_trial_errors": true, "_cached_trial_decisions": {}, "_queued_trial_decisions": {}, "_should_stop_experiment": false, "_stopper": {"_type": "CLOUDPICKLE_FALLBACK", "value": "8005952c000000000000008c157261792e74756e652e73746f707065722e6e6f6f70948c0b4e6f6f7053746f707065729493942981942e"}, "_start_time": 1761037737.8143225, "_session_str": "2025-10-21_11-08-57", "_checkpoint_period": "auto", "_trial_checkpoint_config": {"_type": "CLOUDPICKLE_FALLBACK", "value": "800595f1000000000000008c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b0a8c11636865636b706f696e745f61745f656e6494888c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394680c75622e"}, "_resumed": false}, "stats": {"start_time": 1761037737.8143225}}