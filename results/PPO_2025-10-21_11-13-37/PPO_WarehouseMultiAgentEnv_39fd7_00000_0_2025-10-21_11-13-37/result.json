{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_8": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.140539428591728, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 0.7075945429503918, "policy_loss": 0.2582107515190728, "vf_loss": 0.16896722599631175, "vf_explained_var": 0.853314621374011, "kl": 1.4020828064531088, "entropy": 5.5594239115715025, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 80.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_16": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 25.922313112020493, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 2.909427310153842, "policy_loss": 0.3712875543162227, "vf_loss": 1.8658954783342778, "vf_explained_var": 0.5861474428325891, "kl": 3.3612211644649506, "entropy": 4.706009775400162, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 80.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_12": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 12.68486671447754, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 0.7558403613045812, "policy_loss": 0.31219323268160226, "vf_loss": 0.19976353322854265, "vf_explained_var": 0.8367843385785818, "kl": 1.2194179959595204, "entropy": 5.7888218581676485, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 80.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_9": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 18.623741130530835, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 1.322148467041552, "policy_loss": 0.33175665135495364, "vf_loss": 0.669356209388934, "vf_explained_var": 0.8196484614163637, "kl": 1.605177990347147, "entropy": 5.533794575929642, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 80.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_18": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 22.190278872847557, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 3.1984523206949236, "policy_loss": 0.3577908233739436, "vf_loss": 2.2219395991414785, "vf_explained_var": 0.6240279231220484, "kl": 3.093609407544136, "entropy": 4.7402071669697765, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 80.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_13": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 20.917253236472607, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 1.564487580396235, "policy_loss": 0.3182495993562043, "vf_loss": 1.014940442633815, "vf_explained_var": 0.8670172166079283, "kl": 1.1564876601099967, "entropy": 5.700843173265457, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 80.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_3": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 17.939312538504602, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 1.7972294725477695, "policy_loss": 0.2548474171664566, "vf_loss": 1.2598389142658561, "vf_explained_var": 0.670100798457861, "kl": 1.4127156488597392, "entropy": 5.6369787633419035, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 80.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_15": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 17.697725838422777, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 4.878683724999428, "policy_loss": 0.34386169323697685, "vf_loss": 3.9397541761398314, "vf_explained_var": 0.46359149664640426, "kl": 2.975339111685753, "entropy": 5.1075133115053175, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 80.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 14.790137031674385, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 3.1012048423290253, "policy_loss": 0.22046753005124628, "vf_loss": 2.581346246600151, "vf_explained_var": 0.24276619553565978, "kl": 1.4969551481306553, "entropy": 5.602184382081032, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 80.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_7": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 12.34231458157301, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 0.7672130290418864, "policy_loss": 0.27721744501031936, "vf_loss": 0.15816317037679256, "vf_explained_var": 0.8469978149980306, "kl": 1.659162037819624, "entropy": 5.557389372587204, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 80.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_11": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 20.112644056975842, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 0.8905976939946413, "policy_loss": 0.286087732296437, "vf_loss": 0.28574956881348046, "vf_explained_var": 0.7565394043922424, "kl": 1.593801886588335, "entropy": 5.567036774754524, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 80.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_2": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 14.382683610916137, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 2.3261967841535807, "policy_loss": 0.26756305270828307, "vf_loss": 1.829257296351716, "vf_explained_var": 0.6248304296284914, "kl": 1.1468822598457336, "entropy": 5.7346660733222965, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 80.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_14": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 37.244556894898416, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 1.7504643384367227, "policy_loss": 0.32099902667105196, "vf_loss": 0.7967305978760123, "vf_explained_var": 0.7704779442399741, "kl": 3.1636734917759894, "entropy": 4.550308698415757, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 80.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_4": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 12.158841042220592, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 1.6366031132638454, "policy_loss": 0.34600120298564435, "vf_loss": 1.012275956699159, "vf_explained_var": 0.7395870495587588, "kl": 1.3916297025978566, "entropy": 5.70402663052082, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 80.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_20": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 22.86595795750618, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 2.621627641096711, "policy_loss": 0.3051105807069689, "vf_loss": 1.7724330337718128, "vf_explained_var": 0.7274530801922083, "kl": 2.720420132577419, "entropy": 4.937820851802826, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 80.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_17": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 22.85746844112873, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 1.8585724137723445, "policy_loss": 0.27369602862745523, "vf_loss": 1.0383461510296912, "vf_explained_var": 0.7102992802858352, "kl": 2.732651102542877, "entropy": 4.999016800522805, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 80.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_10": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 20.098088036477566, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 0.9455190196633338, "policy_loss": 0.3033091430552304, "vf_loss": 0.3397112673032098, "vf_explained_var": 0.7649087131023407, "kl": 1.5124930404126644, "entropy": 5.777406877279281, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 80.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_6": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 15.097924077510834, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 0.8222498893737793, "policy_loss": 0.29448552639223635, "vf_loss": 0.26396061523118985, "vf_explained_var": 0.868539284542203, "kl": 1.3190187141299248, "entropy": 5.734875398874283, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 80.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_5": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 15.032764856517314, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 2.3491626143455506, "policy_loss": 0.3102897187229246, "vf_loss": 1.7555787540972232, "vf_explained_var": 0.6634922318160534, "kl": 1.4164706975221635, "entropy": 5.725546091794968, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 80.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 17.913424189388753, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 1.1795613998547196, "policy_loss": 0.35700496535282583, "vf_loss": 0.4590356923523359, "vf_explained_var": 0.8061516541987658, "kl": 1.8176037102937699, "entropy": 5.5090344786643985, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 80.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_19": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 22.447539107501505, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 1.8729838013648987, "policy_loss": 0.36074965661391617, "vf_loss": 1.0327356635127216, "vf_explained_var": 0.8068738069385291, "kl": 2.3974924072623254, "entropy": 5.354813361167908, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 80.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}}, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 84000, "num_agent_steps_trained": 84000}, "env_runners": {"episode_reward_max": -44.1999999999997, "episode_reward_min": -70.14000000000262, "episode_reward_mean": -55.18333333333439, "episode_len_mean": 500.0, "episode_media": {}, "episodes_timesteps_total": 3000, "policy_reward_min": {"agent_0": -0.5000000000000003, "agent_1": -1.8899999999999926, "agent_2": -5.190000000000026, "agent_3": -5.200000000000027, "agent_4": -5.090000000000026, "agent_5": -4.990000000000024, "agent_6": -5.330000000000028, "agent_7": -5.200000000000027, "agent_8": -5.200000000000027, "agent_9": -5.210000000000027, "agent_10": -4.880000000000023, "agent_11": -5.300000000000027, "agent_12": -5.340000000000028, "agent_13": -5.270000000000027, "agent_14": -5.310000000000027, "agent_15": -5.120000000000026, "agent_16": -5.360000000000028, "agent_17": -5.070000000000025, "agent_18": -4.880000000000023, "agent_19": -5.180000000000026, "agent_20": -5.190000000000026}, "policy_reward_max": {"agent_0": -0.5000000000000003, "agent_1": -0.5000000000000003, "agent_2": -0.5000000000000003, "agent_3": -0.5000000000000003, "agent_4": -0.5000000000000003, "agent_5": -0.5000000000000003, "agent_6": -0.5000000000000003, "agent_7": -0.5000000000000003, "agent_8": -0.5000000000000003, "agent_9": -0.5000000000000003, "agent_10": -0.5000000000000003, "agent_11": -0.5000000000000003, "agent_12": -0.5000000000000003, "agent_13": -0.5000000000000003, "agent_14": -4.280000000000016, "agent_15": -4.330000000000018, "agent_16": -4.080000000000014, "agent_17": -4.2700000000000164, "agent_18": -3.740000000000011, "agent_19": -3.5200000000000085, "agent_20": -3.850000000000012}, "policy_reward_mean": {"agent_0": -0.5000000000000003, "agent_1": -0.7316666666666657, "agent_2": -1.3600000000000048, "agent_3": -2.0466666666666753, "agent_4": -1.2650000000000043, "agent_5": -1.2483333333333375, "agent_6": -2.8583333333333463, "agent_7": -2.6533333333333444, "agent_8": -2.023333333333342, "agent_9": -1.4566666666666706, "agent_10": -1.765000000000006, "agent_11": -1.300000000000005, "agent_12": -2.10000000000001, "agent_13": -2.051666666666675, "agent_14": -4.653333333333354, "agent_15": -4.753333333333355, "agent_16": -4.57500000000002, "agent_17": -4.718333333333355, "agent_18": -4.321666666666684, "agent_19": -4.5416666666666865, "agent_20": -4.260000000000017}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-44.1999999999997, -47.869999999999905, -53.90000000000077, -56.50000000000109, -70.14000000000262, -58.4900000000023], "episode_lengths": [500, 500, 500, 500, 500, 500], "policy_agent_0_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003], "policy_agent_1_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -1.8899999999999926], "policy_agent_2_reward": [-0.5000000000000003, -0.5000000000000003, -0.9700000000000008, -0.5000000000000003, -5.190000000000026, -0.5000000000000003], "policy_agent_3_reward": [-0.5000000000000003, -0.5000000000000003, -5.080000000000025, -5.200000000000027, -0.5000000000000003, -0.5000000000000003], "policy_agent_4_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.090000000000026, -0.5000000000000003], "policy_agent_5_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -4.990000000000024, -0.5000000000000003, -0.5000000000000003], "policy_agent_6_reward": [-0.5000000000000003, -0.5000000000000003, -0.6800000000000005, -5.330000000000028, -5.250000000000027, -4.890000000000023], "policy_agent_7_reward": [-5.200000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -4.350000000000017, -4.870000000000023], "policy_agent_8_reward": [-0.5000000000000003, -5.200000000000027, -0.5000000000000003, -4.9400000000000235, -0.5000000000000003, -0.5000000000000003], "policy_agent_9_reward": [-0.5000000000000003, -0.5000000000000003, -5.210000000000027, -0.5000000000000003, -0.5000000000000003, -1.5299999999999958], "policy_agent_10_reward": [-0.5000000000000003, -0.5000000000000003, -3.710000000000011, -0.5000000000000003, -4.880000000000023, -0.5000000000000003], "policy_agent_11_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.300000000000027, -0.5000000000000003], "policy_agent_12_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.340000000000028, -5.260000000000027], "policy_agent_13_reward": [-0.5000000000000003, -5.040000000000025, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.270000000000027], "policy_agent_14_reward": [-5.310000000000027, -4.650000000000021, -4.450000000000018, -4.63000000000002, -4.280000000000016, -4.600000000000021], "policy_agent_15_reward": [-4.710000000000021, -5.090000000000026, -4.7800000000000225, -5.120000000000026, -4.490000000000019, -4.330000000000018], "policy_agent_16_reward": [-5.040000000000025, -4.390000000000017, -5.360000000000028, -4.280000000000016, -4.080000000000014, -4.300000000000017], "policy_agent_17_reward": [-4.500000000000019, -5.070000000000025, -4.2700000000000164, -4.840000000000023, -4.560000000000019, -5.070000000000025], "policy_agent_18_reward": [-3.740000000000011, -4.300000000000016, -4.880000000000023, -4.490000000000019, -4.780000000000022, -3.740000000000011], "policy_agent_19_reward": [-5.180000000000026, -4.280000000000016, -4.8200000000000225, -3.5200000000000085, -4.9000000000000234, -4.55000000000002], "policy_agent_20_reward": [-4.020000000000014, -3.850000000000012, -5.190000000000026, -4.160000000000015, -4.150000000000015, -4.1900000000000155]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.847854073091411, "mean_inference_ms": 9.007504441372214, "mean_action_processing_ms": 0.7125211027053947, "mean_env_wait_ms": 2.7119335895031647, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0024740658109150236, "StateBufferConnector_ms": 0.0013531200469486296, "ViewRequirementAgentConnector_ms": 0.02999002971346416}, "num_episodes": 6, "episode_return_max": -44.1999999999997, "episode_return_min": -70.14000000000262, "episode_return_mean": -55.18333333333439, "episodes_this_iter": 6}, "num_healthy_workers": 3, "actor_manager_num_outstanding_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 84000, "num_agent_steps_trained": 84000, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 134.2097838544741, "num_env_steps_trained_throughput_per_sec": 134.2097838544741, "timesteps_total": 4000, "num_env_steps_sampled_lifetime": 4000, "num_agent_steps_sampled_lifetime": 84000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 84000, "timers": {"training_iteration_time_ms": 29804.093, "restore_workers_time_ms": 0.013, "training_step_time_ms": 29804.054, "sample_time_ms": 19416.999, "learn_time_ms": 10367.483, "learn_throughput": 385.822, "synch_weights_time_ms": 18.52}, "counters": {"num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 84000, "num_agent_steps_trained": 84000}, "done": false, "training_iteration": 1, "trial_id": "39fd7_00000", "date": "2025-10-21_11-14-15", "timestamp": 1761038055, "time_this_iter_s": 29.815984964370728, "time_total_s": 29.815984964370728, "pid": 3259979, "hostname": "xuezhi-Precision-3660", "node_ip": "130.238.16.41", "config": {"exploration_config": {"type": "StochasticSampling"}, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 1, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "torch_ddp_kwargs": {}, "torch_skip_nan_gradients": false, "env": "<class 'train_utils.WarehouseMultiAgentEnv'>", "env_config": {"env_id": "tarware-extralarge-14agvs-7pickers-partialobs-chg-v1"}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "_is_atari": null, "disable_env_checking": false, "render_env": true, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 3, "create_local_env_runner": true, "num_envs_per_env_runner": 1, "gym_env_vectorize_mode": "SYNC", "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "episodes_to_numpy": true, "max_requests_in_flight_per_env_runner": 1, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "merge_env_runner_states": "training_only", "broadcast_env_runner_states": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "sampler_perf_stats_ema_coef": null, "_is_online": true, "num_learners": 0, "num_gpus_per_learner": 1, "num_cpus_per_learner": "auto", "num_aggregator_actors_per_learner": 0, "max_requests_in_flight_per_aggregator_actor": 3, "local_gpu_idx": 0, "max_requests_in_flight_per_learner": 3, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "_train_batch_size_per_learner": null, "train_batch_size": 4000, "num_epochs": 10, "minibatch_size": 256, "shuffle_batch_per_epoch": true, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "log_std_clip_param": 20.0, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1, "_disable_preprocessor_api": false, "_disable_action_flattening": false}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "_learner_class": null, "callbacks_on_algorithm_init": null, "callbacks_on_env_runners_recreated": null, "callbacks_on_offline_eval_runners_recreated": null, "callbacks_on_checkpoint_loaded": null, "callbacks_on_environment_created": null, "callbacks_on_episode_created": null, "callbacks_on_episode_start": null, "callbacks_on_episode_step": null, "callbacks_on_episode_end": null, "callbacks_on_evaluate_start": null, "callbacks_on_evaluate_end": null, "callbacks_on_evaluate_offline_start": null, "callbacks_on_evaluate_offline_end": null, "callbacks_on_sample_end": null, "callbacks_on_train_result": null, "explore": true, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "_prior_exploration_config": null, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function train.<locals>.<lambda> at 0x782de3eb3eb0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "offline_data_class": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "input_read_episodes": false, "input_read_sample_batches": false, "input_read_batch_size": null, "input_filesystem": null, "input_filesystem_kwargs": {}, "input_compress_columns": ["obs", "new_obs"], "input_spaces_jsonable": true, "materialize_data": false, "materialize_mapped_data": true, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "ignore_final_observation": false, "prelearner_class": null, "prelearner_buffer_class": null, "prelearner_buffer_kwargs": {}, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "output_max_rows_per_file": null, "output_write_remaining_data": false, "output_write_method": "write_parquet", "output_write_method_kwargs": {}, "output_filesystem": null, "output_filesystem_kwargs": {}, "output_write_episodes": true, "offline_sampling": false, "evaluation_interval": 10, "evaluation_duration": 5, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_auto_duration_min_env_steps_per_sample": 100, "evaluation_auto_duration_max_env_steps_per_sample": 2000, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": {"explore": false}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "offline_evaluation_interval": null, "num_offline_eval_runners": 0, "offline_evaluation_type": null, "offline_eval_runner_class": null, "offline_loss_for_module_fn": null, "offline_evaluation_duration": 1, "offline_evaluation_parallel_to_training": false, "offline_evaluation_timeout_s": 120.0, "num_cpus_per_offline_eval_runner": 1, "num_gpus_per_offline_eval_runner": 0, "custom_resources_per_offline_eval_runner": {}, "restart_failed_offline_eval_runners": true, "ignore_offline_eval_runner_failures": false, "max_num_offline_eval_runner_restarts": 1000, "offline_eval_runner_restore_timeout_s": 1800.0, "max_requests_in_flight_per_offline_eval_runner": 1, "validate_offline_eval_runners_after_construction": true, "offline_eval_runner_health_probe_timeout_s": 30.0, "offline_eval_rl_module_inference_only": false, "broadcast_offline_eval_runner_states": false, "offline_eval_batch_size_per_runner": 256, "dataset_num_iters_per_eval_runner": 1, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "log_gradients": false, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "restart_failed_env_runners": true, "ignore_env_runner_failures": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30.0, "env_runner_restore_timeout_s": 1800.0, "_model_config": {}, "_rl_module_spec": null, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "_validate_config": true, "_use_msgpack_checkpoints": false, "_torch_grad_scaler_class": null, "_torch_lr_scheduler_classes": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "env_task_fn": -1, "enable_connectors": -1, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "clip_param": 0.2, "vf_clip_param": 10.0, "entropy_coeff_schedule": null, "lr_schedule": null, "sgd_minibatch_size": -1, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.95, "input": "sampler", "policies": {"agent_0": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_1": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_2": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_3": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_4": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_5": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_6": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_7": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_8": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_9": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_10": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_11": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_12": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_13": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_14": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_15": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_16": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_17": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_18": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_19": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_20": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}]}, "callbacks": "<class 'ray.rllib.callbacks.callbacks.RLlibCallback'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 29.815984964370728, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 8.94047619047619, "ram_util_percent": 25.476190476190474, "gpu_util_percent0": 0.23285714285714285, "vram_util_percent0": 0.08242142973457092}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_8": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.488988135755062, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": 0.019572375163261314, "policy_loss": -0.04368459669058211, "vf_loss": 0.0590146858652588, "vf_explained_var": 0.9153979744762182, "kl": 0.014140951112341352, "entropy": 5.862080827355385, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 240.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_16": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.770236422121524, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": 0.05219082831754349, "policy_loss": -0.04309599999833154, "vf_loss": 0.09002928267000243, "vf_explained_var": 0.9580704472959042, "kl": 0.017525153605973426, "entropy": 5.139072981476784, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 240.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_12": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.577015250921249, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.015910569207335357, "policy_loss": -0.048614906083093955, "vf_loss": 0.029824662586906924, "vf_explained_var": 0.8751518551260233, "kl": 0.009598909856142793, "entropy": 5.8756665050983425, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 240.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_9": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 11.389691752195358, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": 0.11057277883228381, "policy_loss": -0.031853219645563514, "vf_loss": 0.13808012414956466, "vf_explained_var": 0.8770888142287732, "kl": 0.014486249669382278, "entropy": 5.781835415959359, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 240.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_18": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 11.126721784472466, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": 0.0933421189110959, "policy_loss": -0.03715626602061093, "vf_loss": 0.12399680827511475, "vf_explained_var": 0.9394021179527045, "kl": 0.021671921995113398, "entropy": 5.338224744796753, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 240.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_13": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.455243057012558, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": 0.019834623132192065, "policy_loss": -0.046002006813068874, "vf_loss": 0.061780568002723156, "vf_explained_var": 0.9685967456549406, "kl": 0.013520208217255015, "entropy": 5.7826892018318174, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 240.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_3": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.134804585576058, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.0017987878673011437, "policy_loss": -0.04617691953608301, "vf_loss": 0.0412267153209541, "vf_explained_var": 0.9370324581861496, "kl": 0.01050472384427813, "entropy": 5.8244696140289305, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 240.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_15": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 17.798896625638008, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": 0.17706276283133776, "policy_loss": -0.03214097376912832, "vf_loss": 0.2019011446973309, "vf_explained_var": 0.8965712387114764, "kl": 0.02434197360105735, "entropy": 5.343249434232712, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 240.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.40847814232111, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.0038271872559562325, "policy_loss": -0.04426395886403043, "vf_loss": 0.03708634391659871, "vf_explained_var": 0.9123383935540914, "kl": 0.01116809441961123, "entropy": 5.827942353487015, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 240.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_7": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.37691004127264, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.01871007880399702, "policy_loss": -0.05043109423131682, "vf_loss": 0.02828532918356359, "vf_explained_var": 0.929989006742835, "kl": 0.011452288132822286, "entropy": 5.827725118398666, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 240.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_11": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.843731717765332, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.007101144397165626, "policy_loss": -0.04844220811064588, "vf_loss": 0.03819812593283132, "vf_explained_var": 0.9471514321863651, "kl": 0.010476457488340338, "entropy": 5.815086016058922, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 240.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_2": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.027316001057625, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": 0.03333992976695299, "policy_loss": -0.03931517812306993, "vf_loss": 0.06866136907483451, "vf_explained_var": 0.9757160682231187, "kl": 0.01331246200179521, "entropy": 5.899442878365517, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 240.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_14": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.021852950751782, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": 0.05246054642193485, "policy_loss": -0.043148849753197285, "vf_loss": 0.08996739031281323, "vf_explained_var": 0.9233314845710993, "kl": 0.01880668218503049, "entropy": 5.245085448026657, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 240.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_4": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.0185874700546265, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": 0.002035859678289853, "policy_loss": -0.0478168421483133, "vf_loss": 0.046191660716431215, "vf_explained_var": 0.9344823241233826, "kl": 0.01220347057883373, "entropy": 5.8562833815813065, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 240.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_20": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.931756553053855, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": 0.06800961372500751, "policy_loss": -0.045153245504479855, "vf_loss": 0.10771616188576445, "vf_explained_var": 0.9540482617914676, "kl": 0.018155653105180768, "entropy": 5.235535597801208, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 240.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_17": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 14.47623664289713, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": 0.09225266536232084, "policy_loss": -0.04573292957502417, "vf_loss": 0.1316849718336016, "vf_explained_var": 0.921874712780118, "kl": 0.021002079641487613, "entropy": 5.378866431117058, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 240.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_10": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.935275627672672, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": 0.001066556003934238, "policy_loss": -0.04182529971585609, "vf_loss": 0.04024994522333145, "vf_explained_var": 0.9345779858529568, "kl": 0.008806370091413796, "entropy": 5.887388396263122, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 240.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_6": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.97931509912014, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.022173635799845215, "policy_loss": -0.05240293477254454, "vf_loss": 0.027354430675040932, "vf_explained_var": 0.9099126730114222, "kl": 0.009582893493545819, "entropy": 5.832526838779449, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 240.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_5": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.066010662913323, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": 0.0026428658340591936, "policy_loss": -0.04566805476497393, "vf_loss": 0.04494624769431539, "vf_explained_var": 0.9710451055318117, "kl": 0.011215578018001354, "entropy": 5.8369407027959825, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 240.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.092037673294544, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.014049168933706824, "policy_loss": -0.04756225166493096, "vf_loss": 0.03031245678430423, "vf_explained_var": 0.9163040988147259, "kl": 0.010668751951959344, "entropy": 5.7716227799654005, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 240.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_19": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.669110815227032, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": 0.03178685831662733, "policy_loss": -0.04400266966986237, "vf_loss": 0.07109738043509424, "vf_explained_var": 0.881499269977212, "kl": 0.01564049491188909, "entropy": 5.607721841335296, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 240.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}}, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 168000, "num_agent_steps_trained": 168000}, "env_runners": {"episode_reward_max": -44.1999999999997, "episode_reward_min": -70.14000000000262, "episode_reward_mean": -56.06466666666794, "episode_len_mean": 500.0, "episode_media": {}, "episodes_timesteps_total": 7500, "policy_reward_min": {"agent_0": -5.230000000000027, "agent_1": -5.280000000000027, "agent_2": -5.210000000000027, "agent_3": -5.250000000000027, "agent_4": -5.090000000000026, "agent_5": -5.130000000000026, "agent_6": -5.330000000000028, "agent_7": -5.3700000000000285, "agent_8": -5.200000000000027, "agent_9": -5.310000000000027, "agent_10": -5.340000000000028, "agent_11": -5.300000000000027, "agent_12": -5.340000000000028, "agent_13": -5.310000000000027, "agent_14": -5.330000000000028, "agent_15": -5.240000000000027, "agent_16": -5.360000000000028, "agent_17": -5.360000000000028, "agent_18": -5.360000000000028, "agent_19": -5.180000000000026, "agent_20": -5.190000000000026}, "policy_reward_max": {"agent_0": -0.5000000000000003, "agent_1": -0.5000000000000003, "agent_2": -0.5000000000000003, "agent_3": -0.5000000000000003, "agent_4": -0.5000000000000003, "agent_5": -0.5000000000000003, "agent_6": -0.5000000000000003, "agent_7": -0.5000000000000003, "agent_8": -0.5000000000000003, "agent_9": -0.5000000000000003, "agent_10": -0.5000000000000003, "agent_11": -0.5000000000000003, "agent_12": -0.5000000000000003, "agent_13": -0.5000000000000003, "agent_14": -3.66000000000001, "agent_15": -3.470000000000007, "agent_16": -3.3100000000000054, "agent_17": -3.850000000000012, "agent_18": -3.740000000000011, "agent_19": -3.5200000000000085, "agent_20": -3.850000000000012}, "policy_reward_mean": {"agent_0": -1.4333333333333385, "agent_1": -1.6793333333333382, "agent_2": -2.5273333333333436, "agent_3": -1.4353333333333387, "agent_4": -1.0966666666666702, "agent_5": -1.1080000000000036, "agent_6": -1.8426666666666738, "agent_7": -1.7806666666666726, "agent_8": -1.3033333333333375, "agent_9": -1.5853333333333381, "agent_10": -2.542000000000011, "agent_11": -1.4400000000000055, "agent_12": -2.4480000000000097, "agent_13": -2.1600000000000086, "agent_14": -4.645333333333355, "agent_15": -4.62400000000002, "agent_16": -4.282666666666683, "agent_17": -4.792666666666689, "agent_18": -4.451333333333351, "agent_19": -4.51400000000002, "agent_20": -4.372666666666684}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-44.1999999999997, -47.869999999999905, -53.90000000000077, -56.50000000000109, -70.14000000000262, -58.4900000000023, -44.69999999999998, -64.51000000000346, -51.620000000000566, -65.79000000000308, -67.35000000000318, -53.23000000000039, -53.17000000000061, -56.740000000001125, -52.76000000000032], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_agent_0_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.9300000000000007, -0.5000000000000003, -5.230000000000027, -0.5000000000000003, -5.210000000000027, -0.5000000000000003, -4.63000000000002], "policy_agent_1_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -1.8899999999999926, -3.2700000000000053, -4.680000000000021, -0.5000000000000003, -5.280000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.070000000000025, -0.5000000000000003], "policy_agent_2_reward": [-0.5000000000000003, -0.5000000000000003, -0.9700000000000008, -0.5000000000000003, -5.190000000000026, -0.5000000000000003, -4.590000000000019, -5.130000000000026, -4.100000000000015, -5.210000000000027, -5.180000000000026, -4.040000000000013, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003], "policy_agent_3_reward": [-0.5000000000000003, -0.5000000000000003, -5.080000000000025, -5.200000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.250000000000027, -0.5000000000000003], "policy_agent_4_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.090000000000026, -0.5000000000000003, -0.5000000000000003, -4.8600000000000225, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003], "policy_agent_5_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -4.990000000000024, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.130000000000026, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003], "policy_agent_6_reward": [-0.5000000000000003, -0.5000000000000003, -0.6800000000000005, -5.330000000000028, -5.250000000000027, -4.890000000000023, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -1.3099999999999978, -0.5000000000000003, -0.9200000000000007, -0.5000000000000003, -5.260000000000027], "policy_agent_7_reward": [-5.200000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -4.350000000000017, -4.870000000000023, -0.5000000000000003, -1.9199999999999924, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.3700000000000285, -0.5000000000000003, -0.5000000000000003], "policy_agent_8_reward": [-0.5000000000000003, -5.200000000000027, -0.5000000000000003, -4.9400000000000235, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -3.4100000000000072, -0.5000000000000003], "policy_agent_9_reward": [-0.5000000000000003, -0.5000000000000003, -5.210000000000027, -0.5000000000000003, -0.5000000000000003, -1.5299999999999958, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -1.5499999999999956, -5.310000000000027, -5.180000000000026, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003], "policy_agent_10_reward": [-0.5000000000000003, -0.5000000000000003, -3.710000000000011, -0.5000000000000003, -4.880000000000023, -0.5000000000000003, -0.5000000000000003, -5.340000000000028, -5.270000000000027, -4.890000000000023, -4.930000000000024, -0.5000000000000003, -5.110000000000025, -0.5000000000000003, -0.5000000000000003], "policy_agent_11_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.300000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.030000000000024, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.270000000000027], "policy_agent_12_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.340000000000028, -5.260000000000027, -0.5000000000000003, -1.8599999999999928, -0.5000000000000003, -5.300000000000027, -5.190000000000026, -4.690000000000021, -0.5000000000000003, -5.080000000000025, -0.5000000000000003], "policy_agent_13_reward": [-0.5000000000000003, -5.040000000000025, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.270000000000027, -0.5000000000000003, -5.270000000000027, -4.590000000000019, -5.310000000000027, -2.4199999999999964, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003], "policy_agent_14_reward": [-5.310000000000027, -4.650000000000021, -4.450000000000018, -4.63000000000002, -4.280000000000016, -4.600000000000021, -4.050000000000014, -5.240000000000027, -4.060000000000014, -3.66000000000001, -5.320000000000028, -4.880000000000023, -4.060000000000014, -5.330000000000028, -5.160000000000026], "policy_agent_15_reward": [-4.710000000000021, -5.090000000000026, -4.7800000000000225, -5.120000000000026, -4.490000000000019, -4.330000000000018, -5.240000000000027, -4.9400000000000235, -5.230000000000027, -4.260000000000016, -3.470000000000007, -4.760000000000022, -4.040000000000013, -4.430000000000018, -4.470000000000018], "policy_agent_16_reward": [-5.040000000000025, -4.390000000000017, -5.360000000000028, -4.280000000000016, -4.080000000000014, -4.300000000000017, -3.760000000000011, -3.3100000000000054, -4.960000000000024, -3.8300000000000125, -3.860000000000012, -4.380000000000018, -3.980000000000014, -4.280000000000016, -4.430000000000018], "policy_agent_17_reward": [-4.500000000000019, -5.070000000000025, -4.2700000000000164, -4.840000000000023, -4.560000000000019, -5.070000000000025, -3.850000000000012, -5.260000000000027, -4.61000000000002, -4.240000000000016, -4.780000000000022, -5.360000000000028, -5.350000000000028, -5.340000000000028, -4.790000000000022], "policy_agent_18_reward": [-3.740000000000011, -4.300000000000016, -4.880000000000023, -4.490000000000019, -4.780000000000022, -3.740000000000011, -4.750000000000021, -4.3800000000000185, -4.460000000000019, -3.9100000000000135, -4.470000000000019, -5.360000000000028, -5.080000000000025, -3.8900000000000126, -4.54000000000002], "policy_agent_19_reward": [-5.180000000000026, -4.280000000000016, -4.8200000000000225, -3.5200000000000085, -4.9000000000000234, -4.55000000000002, -5.170000000000027, -4.63000000000002, -4.1100000000000145, -4.9400000000000235, -3.9900000000000135, -4.8600000000000225, -4.350000000000017, -4.680000000000021, -3.7300000000000106], "policy_agent_20_reward": [-4.020000000000014, -3.850000000000012, -5.190000000000026, -4.160000000000015, -4.150000000000015, -4.1900000000000155, -4.020000000000014, -4.1900000000000155, -4.300000000000018, -4.780000000000022, -3.860000000000012, -4.220000000000016, -4.700000000000021, -4.980000000000024, -4.980000000000024]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.8681285074004639, "mean_inference_ms": 8.999633440338004, "mean_action_processing_ms": 0.6957371164799445, "mean_env_wait_ms": 2.7105099941067454, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0025688655792720735, "StateBufferConnector_ms": 0.0013942567128983755, "ViewRequirementAgentConnector_ms": 0.031277868482801646}, "num_episodes": 9, "episode_return_max": -44.1999999999997, "episode_return_min": -70.14000000000262, "episode_return_mean": -56.06466666666794, "episodes_this_iter": 9}, "num_healthy_workers": 3, "actor_manager_num_outstanding_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 168000, "num_agent_steps_trained": 168000, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 133.5047655582415, "num_env_steps_trained_throughput_per_sec": 133.5047655582415, "timesteps_total": 8000, "num_env_steps_sampled_lifetime": 8000, "num_agent_steps_sampled_lifetime": 168000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 168000, "timers": {"training_iteration_time_ms": 29882.789, "restore_workers_time_ms": 0.013, "training_step_time_ms": 29882.749, "sample_time_ms": 19471.541, "learn_time_ms": 10391.316, "learn_throughput": 384.937, "synch_weights_time_ms": 17.969}, "counters": {"num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 168000, "num_agent_steps_trained": 168000}, "done": false, "training_iteration": 2, "trial_id": "39fd7_00000", "date": "2025-10-21_11-14-45", "timestamp": 1761038085, "time_this_iter_s": 29.972845792770386, "time_total_s": 59.78883075714111, "pid": 3259979, "hostname": "xuezhi-Precision-3660", "node_ip": "130.238.16.41", "config": {"exploration_config": {"type": "StochasticSampling"}, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 1, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "torch_ddp_kwargs": {}, "torch_skip_nan_gradients": false, "env": "<class 'train_utils.WarehouseMultiAgentEnv'>", "env_config": {"env_id": "tarware-extralarge-14agvs-7pickers-partialobs-chg-v1"}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "_is_atari": null, "disable_env_checking": false, "render_env": true, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 3, "create_local_env_runner": true, "num_envs_per_env_runner": 1, "gym_env_vectorize_mode": "SYNC", "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "episodes_to_numpy": true, "max_requests_in_flight_per_env_runner": 1, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "merge_env_runner_states": "training_only", "broadcast_env_runner_states": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "sampler_perf_stats_ema_coef": null, "_is_online": true, "num_learners": 0, "num_gpus_per_learner": 1, "num_cpus_per_learner": "auto", "num_aggregator_actors_per_learner": 0, "max_requests_in_flight_per_aggregator_actor": 3, "local_gpu_idx": 0, "max_requests_in_flight_per_learner": 3, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "_train_batch_size_per_learner": null, "train_batch_size": 4000, "num_epochs": 10, "minibatch_size": 256, "shuffle_batch_per_epoch": true, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "log_std_clip_param": 20.0, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1, "_disable_preprocessor_api": false, "_disable_action_flattening": false}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "_learner_class": null, "callbacks_on_algorithm_init": null, "callbacks_on_env_runners_recreated": null, "callbacks_on_offline_eval_runners_recreated": null, "callbacks_on_checkpoint_loaded": null, "callbacks_on_environment_created": null, "callbacks_on_episode_created": null, "callbacks_on_episode_start": null, "callbacks_on_episode_step": null, "callbacks_on_episode_end": null, "callbacks_on_evaluate_start": null, "callbacks_on_evaluate_end": null, "callbacks_on_evaluate_offline_start": null, "callbacks_on_evaluate_offline_end": null, "callbacks_on_sample_end": null, "callbacks_on_train_result": null, "explore": true, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "_prior_exploration_config": null, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function train.<locals>.<lambda> at 0x782de3eccca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "offline_data_class": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "input_read_episodes": false, "input_read_sample_batches": false, "input_read_batch_size": null, "input_filesystem": null, "input_filesystem_kwargs": {}, "input_compress_columns": ["obs", "new_obs"], "input_spaces_jsonable": true, "materialize_data": false, "materialize_mapped_data": true, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "ignore_final_observation": false, "prelearner_class": null, "prelearner_buffer_class": null, "prelearner_buffer_kwargs": {}, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "output_max_rows_per_file": null, "output_write_remaining_data": false, "output_write_method": "write_parquet", "output_write_method_kwargs": {}, "output_filesystem": null, "output_filesystem_kwargs": {}, "output_write_episodes": true, "offline_sampling": false, "evaluation_interval": 10, "evaluation_duration": 5, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_auto_duration_min_env_steps_per_sample": 100, "evaluation_auto_duration_max_env_steps_per_sample": 2000, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": {"explore": false}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "offline_evaluation_interval": null, "num_offline_eval_runners": 0, "offline_evaluation_type": null, "offline_eval_runner_class": null, "offline_loss_for_module_fn": null, "offline_evaluation_duration": 1, "offline_evaluation_parallel_to_training": false, "offline_evaluation_timeout_s": 120.0, "num_cpus_per_offline_eval_runner": 1, "num_gpus_per_offline_eval_runner": 0, "custom_resources_per_offline_eval_runner": {}, "restart_failed_offline_eval_runners": true, "ignore_offline_eval_runner_failures": false, "max_num_offline_eval_runner_restarts": 1000, "offline_eval_runner_restore_timeout_s": 1800.0, "max_requests_in_flight_per_offline_eval_runner": 1, "validate_offline_eval_runners_after_construction": true, "offline_eval_runner_health_probe_timeout_s": 30.0, "offline_eval_rl_module_inference_only": false, "broadcast_offline_eval_runner_states": false, "offline_eval_batch_size_per_runner": 256, "dataset_num_iters_per_eval_runner": 1, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "log_gradients": false, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "restart_failed_env_runners": true, "ignore_env_runner_failures": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30.0, "env_runner_restore_timeout_s": 1800.0, "_model_config": {}, "_rl_module_spec": null, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "_validate_config": true, "_use_msgpack_checkpoints": false, "_torch_grad_scaler_class": null, "_torch_lr_scheduler_classes": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "env_task_fn": -1, "enable_connectors": -1, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "clip_param": 0.2, "vf_clip_param": 10.0, "entropy_coeff_schedule": null, "lr_schedule": null, "sgd_minibatch_size": -1, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.95, "input": "sampler", "policies": {"agent_0": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_1": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_2": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_3": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_4": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_5": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_6": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_7": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_8": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_9": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_10": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_11": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_12": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_13": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_14": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_15": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_16": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_17": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_18": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_19": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_20": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}]}, "callbacks": "<class 'ray.rllib.callbacks.callbacks.RLlibCallback'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 59.78883075714111, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 9.336585365853658, "ram_util_percent": 27.426829268292682, "gpu_util_percent0": 0.2324390243902439, "vram_util_percent0": 0.09311782858913104}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_8": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.810513193905353, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.010693292007272249, "policy_loss": -0.049231488078658, "vf_loss": 0.03537667159107514, "vf_explained_var": 0.9191034357994795, "kl": 0.010538416234866111, "entropy": 5.824640715122223, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 400.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_16": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.8937881484627725, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": 0.01035757762438152, "policy_loss": -0.0498078173463, "vf_loss": 0.05623337009456009, "vf_explained_var": 0.9687354627996683, "kl": 0.01310675357436443, "entropy": 5.05405889749527, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 400.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_12": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.661247557401657, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.026510089849762154, "policy_loss": -0.05212726189638488, "vf_loss": 0.022989831498125567, "vf_explained_var": 0.9100403696298599, "kl": 0.008757801332558301, "entropy": 5.865606534481048, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 400.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_9": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.89436416476965, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": 0.04692915598716354, "policy_loss": -0.038677673757774755, "vf_loss": 0.08226068420917727, "vf_explained_var": 0.9455658920109272, "kl": 0.011153810729339029, "entropy": 5.770250058174133, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 400.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_18": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.826131439208984, "cur_kl_coeff": 0.45000000000000007, "cur_lr": 5.000000000000001e-05, "total_loss": 0.028750198846682905, "policy_loss": -0.051313353367731906, "vf_loss": 0.07366976265329868, "vf_explained_var": 0.9726794358342886, "kl": 0.014208420413460921, "entropy": 5.219659423828125, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 400.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_13": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.098457941412926, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.006849379032792058, "policy_loss": -0.047009939303825375, "vf_loss": 0.03696925176191144, "vf_explained_var": 0.9730062112212181, "kl": 0.010637692372709218, "entropy": 5.726161721348762, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 400.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_3": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.862232159078121, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.017643802220118233, "policy_loss": -0.04881296129606198, "vf_loss": 0.0284256617189385, "vf_explained_var": 0.9538019325584173, "kl": 0.009144992536870632, "entropy": 5.808881908655167, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 400.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_15": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 12.217761000990867, "cur_kl_coeff": 0.45000000000000007, "cur_lr": 5.000000000000001e-05, "total_loss": 0.061102013610070574, "policy_loss": -0.043862846921547315, "vf_loss": 0.09757216342259198, "vf_explained_var": 0.9519745077937841, "kl": 0.01642821461418273, "entropy": 5.343465450406074, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 400.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.900310191512108, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.021699520049151034, "policy_loss": -0.04967415105784312, "vf_loss": 0.025226752244634554, "vf_explained_var": 0.9601141475141048, "kl": 0.009159591771120978, "entropy": 5.80200215280056, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 400.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_7": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.405450975894928, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.030664499929116573, "policy_loss": -0.054658334052510325, "vf_loss": 0.02095538000576198, "vf_explained_var": 0.9459668204188347, "kl": 0.010128176576481818, "entropy": 5.7954560071229935, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 400.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_11": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.699781174957752, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.020099135599593865, "policy_loss": -0.0512041385163684, "vf_loss": 0.028444136321195402, "vf_explained_var": 0.9338881902396678, "kl": 0.008869557960383644, "entropy": 5.7736024081707, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 400.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_2": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.526150266826153, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": 0.007300067170581315, "policy_loss": -0.04414945421449375, "vf_loss": 0.048230066680116576, "vf_explained_var": 0.9758788410574197, "kl": 0.010731516449277478, "entropy": 5.869557276368141, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 400.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_14": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.415626189112663, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": 0.02563175882678479, "policy_loss": -0.047194440916064194, "vf_loss": 0.06871437304653227, "vf_explained_var": 0.8974584132432938, "kl": 0.01370608822739996, "entropy": 5.098146370053291, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 400.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_4": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.7481862008571625, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.018447614961769433, "policy_loss": -0.04899296001676703, "vf_loss": 0.027417289253207855, "vf_explained_var": 0.9599146597087383, "kl": 0.010426850735250515, "entropy": 5.851697304844857, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 400.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_20": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.85315673649311, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": 0.018722319495282136, "policy_loss": -0.04995686356851366, "vf_loss": 0.06431566355749965, "vf_explained_var": 0.953971092402935, "kl": 0.014545066504830294, "entropy": 5.0750642865896225, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 400.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_17": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 15.026229633390903, "cur_kl_coeff": 0.45000000000000007, "cur_lr": 5.000000000000001e-05, "total_loss": 0.07487454209767748, "policy_loss": -0.04359714460806572, "vf_loss": 0.11193067367421464, "vf_explained_var": 0.9153381988406182, "kl": 0.014535581998698635, "entropy": 5.27205383181572, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 400.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_10": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.489381036162376, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.010350957122864202, "policy_loss": -0.044593780828290616, "vf_loss": 0.03179612359381281, "vf_explained_var": 0.9202494598925114, "kl": 0.008155670852833313, "entropy": 5.844716879725456, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 400.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_6": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.4168884485960005, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.023408503175596708, "policy_loss": -0.05058933082545991, "vf_loss": 0.024430587686947548, "vf_explained_var": 0.9453969169408083, "kl": 0.009167466675840707, "entropy": 5.811889505386352, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 400.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_5": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.802472828328609, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.010973363928496838, "policy_loss": -0.04613578530261293, "vf_loss": 0.03214337263489142, "vf_explained_var": 0.9655484393239021, "kl": 0.010063497552949663, "entropy": 5.828563722968101, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 400.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.534158946573735, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.027195620330167, "policy_loss": -0.05018189439433627, "vf_loss": 0.02028514084231574, "vf_explained_var": 0.9646349120885134, "kl": 0.009003776568765567, "entropy": 5.727672758698463, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 400.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_19": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.626990123093128, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.00387276338879019, "policy_loss": -0.052053136826725674, "vf_loss": 0.044878975121537226, "vf_explained_var": 0.8919454995542765, "kl": 0.011004664002832332, "entropy": 5.547178158164025, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 400.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}}, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 252000, "num_agent_steps_trained": 252000}, "env_runners": {"episode_reward_max": -44.1999999999997, "episode_reward_min": -70.14000000000262, "episode_reward_mean": -55.98363636363767, "episode_len_mean": 500.0, "episode_media": {}, "episodes_timesteps_total": 11000, "policy_reward_min": {"agent_0": -5.350000000000028, "agent_1": -5.280000000000027, "agent_2": -5.310000000000027, "agent_3": -5.250000000000027, "agent_4": -5.250000000000027, "agent_5": -5.130000000000026, "agent_6": -5.330000000000028, "agent_7": -5.3700000000000285, "agent_8": -5.300000000000027, "agent_9": -5.320000000000028, "agent_10": -5.340000000000028, "agent_11": -5.300000000000027, "agent_12": -5.340000000000028, "agent_13": -5.310000000000027, "agent_14": -5.330000000000028, "agent_15": -5.240000000000027, "agent_16": -5.360000000000028, "agent_17": -5.360000000000028, "agent_18": -5.360000000000028, "agent_19": -5.180000000000026, "agent_20": -5.190000000000026}, "policy_reward_max": {"agent_0": -0.5000000000000003, "agent_1": -0.5000000000000003, "agent_2": -0.5000000000000003, "agent_3": -0.5000000000000003, "agent_4": -0.5000000000000003, "agent_5": -0.5000000000000003, "agent_6": -0.5000000000000003, "agent_7": -0.5000000000000003, "agent_8": -0.5000000000000003, "agent_9": -0.5000000000000003, "agent_10": -0.5000000000000003, "agent_11": -0.5000000000000003, "agent_12": -0.5000000000000003, "agent_13": -0.5000000000000003, "agent_14": -3.66000000000001, "agent_15": -3.470000000000007, "agent_16": -3.3100000000000054, "agent_17": -3.7100000000000097, "agent_18": -3.740000000000011, "agent_19": -3.5200000000000085, "agent_20": -3.4600000000000075}, "policy_reward_mean": {"agent_0": -1.3981818181818229, "agent_1": -1.3040909090909125, "agent_2": -2.9440909090909226, "agent_3": -1.5622727272727333, "agent_4": -1.6204545454545511, "agent_5": -1.1072727272727307, "agent_6": -1.7195454545454607, "agent_7": -1.5881818181818235, "agent_8": -1.2659090909090949, "agent_9": -1.8777272727272796, "agent_10": -2.15681818181819, "agent_11": -1.7254545454545522, "agent_12": -2.146363636363645, "agent_13": -1.8595454545454613, "agent_14": -4.5822727272727475, "agent_15": -4.647272727272747, "agent_16": -4.419545454545473, "agent_17": -4.661363636363657, "agent_18": -4.529545454545474, "agent_19": -4.4995454545454745, "agent_20": -4.368181818181835}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-44.1999999999997, -47.869999999999905, -53.90000000000077, -56.50000000000109, -70.14000000000262, -58.4900000000023, -44.69999999999998, -64.51000000000346, -51.620000000000566, -65.79000000000308, -67.35000000000318, -53.23000000000039, -53.17000000000061, -56.740000000001125, -52.76000000000032, -62.44000000000218, -50.530000000001344, -63.63000000000317, -46.849999999999895, -67.7200000000026, -45.89999999999993, -53.600000000000826], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_agent_0_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.9300000000000007, -0.5000000000000003, -5.230000000000027, -0.5000000000000003, -5.210000000000027, -0.5000000000000003, -4.63000000000002, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.350000000000028, -0.5000000000000003, -0.5000000000000003, -1.409999999999997], "policy_agent_1_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -1.8899999999999926, -3.2700000000000053, -4.680000000000021, -0.5000000000000003, -5.280000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.070000000000025, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003], "policy_agent_2_reward": [-0.5000000000000003, -0.5000000000000003, -0.9700000000000008, -0.5000000000000003, -5.190000000000026, -0.5000000000000003, -4.590000000000019, -5.130000000000026, -4.100000000000015, -5.210000000000027, -5.180000000000026, -4.040000000000013, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.310000000000027, -0.5000000000000003, -5.280000000000027, -0.5000000000000003, -5.280000000000027, -4.910000000000023, -5.080000000000025], "policy_agent_3_reward": [-0.5000000000000003, -0.5000000000000003, -5.080000000000025, -5.200000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.250000000000027, -0.5000000000000003, -5.210000000000027, -0.5000000000000003, -5.130000000000026, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003], "policy_agent_4_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.090000000000026, -0.5000000000000003, -0.5000000000000003, -4.8600000000000225, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.190000000000026, -2.0999999999999925, -5.250000000000027, -0.5000000000000003, -0.5000000000000003, -5.160000000000026, -0.5000000000000003], "policy_agent_5_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -4.990000000000024, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.130000000000026, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -4.7400000000000215, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003], "policy_agent_6_reward": [-0.5000000000000003, -0.5000000000000003, -0.6800000000000005, -5.330000000000028, -5.250000000000027, -4.890000000000023, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -1.3099999999999978, -0.5000000000000003, -0.9200000000000007, -0.5000000000000003, -5.260000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -4.370000000000017, -0.5000000000000003, -3.320000000000006], "policy_agent_7_reward": [-5.200000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -4.350000000000017, -4.870000000000023, -0.5000000000000003, -1.9199999999999924, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.3700000000000285, -0.5000000000000003, -0.5000000000000003, -5.230000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003], "policy_agent_8_reward": [-0.5000000000000003, -5.200000000000027, -0.5000000000000003, -4.9400000000000235, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -3.4100000000000072, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.300000000000027, -0.5000000000000003, -0.5000000000000003], "policy_agent_9_reward": [-0.5000000000000003, -0.5000000000000003, -5.210000000000027, -0.5000000000000003, -0.5000000000000003, -1.5299999999999958, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -1.5499999999999956, -5.310000000000027, -5.180000000000026, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.290000000000028, -0.5000000000000003, -5.320000000000028, -0.5000000000000003, -4.920000000000023], "policy_agent_10_reward": [-0.5000000000000003, -0.5000000000000003, -3.710000000000011, -0.5000000000000003, -4.880000000000023, -0.5000000000000003, -0.5000000000000003, -5.340000000000028, -5.270000000000027, -4.890000000000023, -4.930000000000024, -0.5000000000000003, -5.110000000000025, -0.5000000000000003, -0.5000000000000003, -5.090000000000026, -1.729999999999994, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003], "policy_agent_11_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.300000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.030000000000024, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.270000000000027, -0.5000000000000003, -4.760000000000022, -4.380000000000018, -0.5000000000000003, -5.220000000000026, -0.5000000000000003, -0.5000000000000003], "policy_agent_12_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.340000000000028, -5.260000000000027, -0.5000000000000003, -1.8599999999999928, -0.5000000000000003, -5.300000000000027, -5.190000000000026, -4.690000000000021, -0.5000000000000003, -5.080000000000025, -0.5000000000000003, -0.5000000000000003, -5.230000000000027, -2.77, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003], "policy_agent_13_reward": [-0.5000000000000003, -5.040000000000025, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.270000000000027, -0.5000000000000003, -5.270000000000027, -4.590000000000019, -5.310000000000027, -2.4199999999999964, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.9100000000000007, -0.5000000000000003, -0.5000000000000003, -5.100000000000025, -0.5000000000000003, -0.5000000000000003], "policy_agent_14_reward": [-5.310000000000027, -4.650000000000021, -4.450000000000018, -4.63000000000002, -4.280000000000016, -4.600000000000021, -4.050000000000014, -5.240000000000027, -4.060000000000014, -3.66000000000001, -5.320000000000028, -4.880000000000023, -4.060000000000014, -5.330000000000028, -5.160000000000026, -3.6700000000000097, -4.840000000000023, -4.510000000000019, -4.790000000000022, -4.480000000000018, -3.7000000000000104, -5.140000000000026], "policy_agent_15_reward": [-4.710000000000021, -5.090000000000026, -4.7800000000000225, -5.120000000000026, -4.490000000000019, -4.330000000000018, -5.240000000000027, -4.9400000000000235, -5.230000000000027, -4.260000000000016, -3.470000000000007, -4.760000000000022, -4.040000000000013, -4.430000000000018, -4.470000000000018, -4.800000000000022, -4.990000000000024, -4.360000000000017, -4.680000000000021, -4.410000000000018, -4.8600000000000225, -4.780000000000022], "policy_agent_16_reward": [-5.040000000000025, -4.390000000000017, -5.360000000000028, -4.280000000000016, -4.080000000000014, -4.300000000000017, -3.760000000000011, -3.3100000000000054, -4.960000000000024, -3.8300000000000125, -3.860000000000012, -4.380000000000018, -3.980000000000014, -4.280000000000016, -4.430000000000018, -5.240000000000027, -4.210000000000017, -4.440000000000018, -4.710000000000021, -5.160000000000026, -4.340000000000017, -4.890000000000023], "policy_agent_17_reward": [-4.500000000000019, -5.070000000000025, -4.2700000000000164, -4.840000000000023, -4.560000000000019, -5.070000000000025, -3.850000000000012, -5.260000000000027, -4.61000000000002, -4.240000000000016, -4.780000000000022, -5.360000000000028, -5.350000000000028, -5.340000000000028, -4.790000000000022, -4.560000000000019, -4.480000000000018, -4.000000000000013, -4.050000000000014, -5.220000000000026, -3.7100000000000097, -4.64000000000002], "policy_agent_18_reward": [-3.740000000000011, -4.300000000000016, -4.880000000000023, -4.490000000000019, -4.780000000000022, -3.740000000000011, -4.750000000000021, -4.3800000000000185, -4.460000000000019, -3.9100000000000135, -4.470000000000019, -5.360000000000028, -5.080000000000025, -3.8900000000000126, -4.54000000000002, -4.57000000000002, -4.52000000000002, -4.960000000000024, -4.9400000000000235, -4.52000000000002, -4.250000000000016, -5.120000000000025], "policy_agent_19_reward": [-5.180000000000026, -4.280000000000016, -4.8200000000000225, -3.5200000000000085, -4.9000000000000234, -4.55000000000002, -5.170000000000027, -4.63000000000002, -4.1100000000000145, -4.9400000000000235, -3.9900000000000135, -4.8600000000000225, -4.350000000000017, -4.680000000000021, -3.7300000000000106, -4.130000000000015, -4.800000000000023, -4.62000000000002, -3.7000000000000104, -5.150000000000026, -4.720000000000021, -4.160000000000015], "policy_agent_20_reward": [-4.020000000000014, -3.850000000000012, -5.190000000000026, -4.160000000000015, -4.150000000000015, -4.1900000000000155, -4.020000000000014, -4.1900000000000155, -4.300000000000018, -4.780000000000022, -3.860000000000012, -4.220000000000016, -4.700000000000021, -4.980000000000024, -4.980000000000024, -4.9400000000000235, -3.4600000000000075, -4.64000000000002, -3.890000000000012, -4.1900000000000155, -4.250000000000016, -5.140000000000025]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.8798969761582556, "mean_inference_ms": 9.003430735910563, "mean_action_processing_ms": 0.6907255598133765, "mean_env_wait_ms": 2.713624999269325, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.002578171816739169, "StateBufferConnector_ms": 0.0014172487960749374, "ViewRequirementAgentConnector_ms": 0.03179832970425164}, "num_episodes": 7, "episode_return_max": -44.1999999999997, "episode_return_min": -70.14000000000262, "episode_return_mean": -55.98363636363767, "episodes_this_iter": 7}, "num_healthy_workers": 3, "actor_manager_num_outstanding_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 252000, "num_agent_steps_trained": 252000, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 131.26255734115384, "num_env_steps_trained_throughput_per_sec": 131.26255734115384, "timesteps_total": 12000, "num_env_steps_sampled_lifetime": 12000, "num_agent_steps_sampled_lifetime": 252000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 252000, "timers": {"training_iteration_time_ms": 30079.62, "restore_workers_time_ms": 0.013, "training_step_time_ms": 30079.58, "sample_time_ms": 19558.272, "learn_time_ms": 10501.734, "learn_throughput": 380.889, "synch_weights_time_ms": 17.415}, "counters": {"num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 252000, "num_agent_steps_trained": 252000}, "done": false, "training_iteration": 3, "trial_id": "39fd7_00000", "date": "2025-10-21_11-15-15", "timestamp": 1761038115, "time_this_iter_s": 30.487999200820923, "time_total_s": 90.27682995796204, "pid": 3259979, "hostname": "xuezhi-Precision-3660", "node_ip": "130.238.16.41", "config": {"exploration_config": {"type": "StochasticSampling"}, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 1, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "torch_ddp_kwargs": {}, "torch_skip_nan_gradients": false, "env": "<class 'train_utils.WarehouseMultiAgentEnv'>", "env_config": {"env_id": "tarware-extralarge-14agvs-7pickers-partialobs-chg-v1"}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "_is_atari": null, "disable_env_checking": false, "render_env": true, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 3, "create_local_env_runner": true, "num_envs_per_env_runner": 1, "gym_env_vectorize_mode": "SYNC", "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "episodes_to_numpy": true, "max_requests_in_flight_per_env_runner": 1, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "merge_env_runner_states": "training_only", "broadcast_env_runner_states": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "sampler_perf_stats_ema_coef": null, "_is_online": true, "num_learners": 0, "num_gpus_per_learner": 1, "num_cpus_per_learner": "auto", "num_aggregator_actors_per_learner": 0, "max_requests_in_flight_per_aggregator_actor": 3, "local_gpu_idx": 0, "max_requests_in_flight_per_learner": 3, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "_train_batch_size_per_learner": null, "train_batch_size": 4000, "num_epochs": 10, "minibatch_size": 256, "shuffle_batch_per_epoch": true, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "log_std_clip_param": 20.0, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1, "_disable_preprocessor_api": false, "_disable_action_flattening": false}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "_learner_class": null, "callbacks_on_algorithm_init": null, "callbacks_on_env_runners_recreated": null, "callbacks_on_offline_eval_runners_recreated": null, "callbacks_on_checkpoint_loaded": null, "callbacks_on_environment_created": null, "callbacks_on_episode_created": null, "callbacks_on_episode_start": null, "callbacks_on_episode_step": null, "callbacks_on_episode_end": null, "callbacks_on_evaluate_start": null, "callbacks_on_evaluate_end": null, "callbacks_on_evaluate_offline_start": null, "callbacks_on_evaluate_offline_end": null, "callbacks_on_sample_end": null, "callbacks_on_train_result": null, "explore": true, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "_prior_exploration_config": null, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function train.<locals>.<lambda> at 0x782de3eccf70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "offline_data_class": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "input_read_episodes": false, "input_read_sample_batches": false, "input_read_batch_size": null, "input_filesystem": null, "input_filesystem_kwargs": {}, "input_compress_columns": ["obs", "new_obs"], "input_spaces_jsonable": true, "materialize_data": false, "materialize_mapped_data": true, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "ignore_final_observation": false, "prelearner_class": null, "prelearner_buffer_class": null, "prelearner_buffer_kwargs": {}, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "output_max_rows_per_file": null, "output_write_remaining_data": false, "output_write_method": "write_parquet", "output_write_method_kwargs": {}, "output_filesystem": null, "output_filesystem_kwargs": {}, "output_write_episodes": true, "offline_sampling": false, "evaluation_interval": 10, "evaluation_duration": 5, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_auto_duration_min_env_steps_per_sample": 100, "evaluation_auto_duration_max_env_steps_per_sample": 2000, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": {"explore": false}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "offline_evaluation_interval": null, "num_offline_eval_runners": 0, "offline_evaluation_type": null, "offline_eval_runner_class": null, "offline_loss_for_module_fn": null, "offline_evaluation_duration": 1, "offline_evaluation_parallel_to_training": false, "offline_evaluation_timeout_s": 120.0, "num_cpus_per_offline_eval_runner": 1, "num_gpus_per_offline_eval_runner": 0, "custom_resources_per_offline_eval_runner": {}, "restart_failed_offline_eval_runners": true, "ignore_offline_eval_runner_failures": false, "max_num_offline_eval_runner_restarts": 1000, "offline_eval_runner_restore_timeout_s": 1800.0, "max_requests_in_flight_per_offline_eval_runner": 1, "validate_offline_eval_runners_after_construction": true, "offline_eval_runner_health_probe_timeout_s": 30.0, "offline_eval_rl_module_inference_only": false, "broadcast_offline_eval_runner_states": false, "offline_eval_batch_size_per_runner": 256, "dataset_num_iters_per_eval_runner": 1, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "log_gradients": false, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "restart_failed_env_runners": true, "ignore_env_runner_failures": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30.0, "env_runner_restore_timeout_s": 1800.0, "_model_config": {}, "_rl_module_spec": null, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "_validate_config": true, "_use_msgpack_checkpoints": false, "_torch_grad_scaler_class": null, "_torch_lr_scheduler_classes": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "env_task_fn": -1, "enable_connectors": -1, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "clip_param": 0.2, "vf_clip_param": 10.0, "entropy_coeff_schedule": null, "lr_schedule": null, "sgd_minibatch_size": -1, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.95, "input": "sampler", "policies": {"agent_0": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_1": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_2": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_3": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_4": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_5": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_6": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_7": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_8": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_9": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_10": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_11": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_12": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_13": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_14": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_15": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_16": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_17": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_18": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_19": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_20": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}]}, "callbacks": "<class 'ray.rllib.callbacks.callbacks.RLlibCallback'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 90.27682995796204, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 9.173809523809522, "ram_util_percent": 27.40952380952381, "gpu_util_percent0": 0.23833333333333334, "vram_util_percent0": 0.09248377416428223}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_8": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.565699380636215, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.02062815877434332, "policy_loss": -0.048437225187080914, "vf_loss": 0.025118963414570317, "vf_explained_var": 0.9195328917354345, "kl": 0.00896700918281632, "entropy": 5.883498266339302, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 560.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_16": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.909195338189602, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": 0.007516876529552974, "policy_loss": -0.04903575953212567, "vf_loss": 0.05299071720219217, "vf_explained_var": 0.9293155252933503, "kl": 0.011873062962954506, "entropy": 5.183989009261131, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 560.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_12": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.850909048318863, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.033580672351672544, "policy_loss": -0.05312201365886722, "vf_loss": 0.017029291464132255, "vf_explained_var": 0.8850342784076929, "kl": 0.008373500486337537, "entropy": 5.87007777094841, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 560.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_9": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.373228643834591, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": 0.005213499400269939, "policy_loss": -0.04367786111833993, "vf_loss": 0.046107181819388644, "vf_explained_var": 0.8566954221576453, "kl": 0.009280593609552207, "entropy": 5.802306926250457, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 560.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_18": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.24530972391367, "cur_kl_coeff": 0.45000000000000007, "cur_lr": 5.000000000000001e-05, "total_loss": 0.039179365764721294, "policy_loss": -0.042845593104721046, "vf_loss": 0.07476885366486385, "vf_explained_var": 0.9588482443243265, "kl": 0.016124677365266713, "entropy": 5.311384609341621, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 560.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_13": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.802103659510612, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.019643419011845253, "policy_loss": -0.04819156642188318, "vf_loss": 0.026044414154603145, "vf_explained_var": 0.9593252334743738, "kl": 0.008345776640355462, "entropy": 5.807295155525208, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 560.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_3": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.892480997741222, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.015469232748728245, "policy_loss": -0.04497860846604453, "vf_loss": 0.026833131635794417, "vf_explained_var": 0.9505596429109573, "kl": 0.008920809969177813, "entropy": 5.812868410348893, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 560.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_15": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.041154338419437, "cur_kl_coeff": 0.45000000000000007, "cur_lr": 5.000000000000001e-05, "total_loss": 0.040186923689907415, "policy_loss": -0.044684934115502985, "vf_loss": 0.07824395450297743, "vf_explained_var": 0.9387842629104852, "kl": 0.014728675107426292, "entropy": 5.450821802020073, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 560.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.710075442492962, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.023581070407817605, "policy_loss": -0.046472694649128246, "vf_loss": 0.020529327131225728, "vf_explained_var": 0.9579701330512762, "kl": 0.007874322091442532, "entropy": 5.852869710326194, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 560.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_7": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.087619586288929, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.0332036061125109, "policy_loss": -0.05586294847016689, "vf_loss": 0.01948674491723068, "vf_explained_var": 0.9181702319532633, "kl": 0.010575327786861382, "entropy": 5.827049332857132, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 560.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_11": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.85712615698576, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.023872284073149785, "policy_loss": -0.05212582231033593, "vf_loss": 0.02550350222736597, "vf_explained_var": 0.9304233089089393, "kl": 0.009166789264600905, "entropy": 5.767682534456253, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 560.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_2": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.144985641539097, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.003404513774148654, "policy_loss": -0.04212628556997515, "vf_loss": 0.035809219215298074, "vf_explained_var": 0.9614577133208513, "kl": 0.00970850985055094, "entropy": 5.877293661236763, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 560.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_14": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.126671409606933, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": 0.013867205023416318, "policy_loss": -0.04910987107869005, "vf_loss": 0.05917814285494387, "vf_explained_var": 0.8783588413149118, "kl": 0.012663109921579069, "entropy": 5.158784905076027, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 560.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_4": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.939986015856266, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.028615571879345224, "policy_loss": -0.05058838677941822, "vf_loss": 0.019546725493273697, "vf_explained_var": 0.9148248616605997, "kl": 0.00808696191152194, "entropy": 5.896754312515259, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 560.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_20": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.873276574909687, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": 0.017547883608494887, "policy_loss": -0.04667332395911217, "vf_loss": 0.06015458604088053, "vf_explained_var": 0.9436748147010803, "kl": 0.01355539904606062, "entropy": 5.167838171124458, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 560.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_17": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.433696430921554, "cur_kl_coeff": 0.45000000000000007, "cur_lr": 5.000000000000001e-05, "total_loss": 0.027583826548652723, "policy_loss": -0.04207084931258578, "vf_loss": 0.06403833492076956, "vf_explained_var": 0.8973815541714429, "kl": 0.012480757786019125, "entropy": 5.403447473049164, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 560.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_10": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.0628060266375545, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.014968021805543685, "policy_loss": -0.0429517537530046, "vf_loss": 0.025749077001819387, "vf_explained_var": 0.8794045742601156, "kl": 0.007448848163722483, "entropy": 5.885242784023285, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 560.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_6": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.492561504244804, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.03083025840460323, "policy_loss": -0.054203112894902004, "vf_loss": 0.020765595670673063, "vf_explained_var": 0.9522502090781927, "kl": 0.008690861024147465, "entropy": 5.823420202732086, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 560.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_5": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.136015282571316, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.02055042936553946, "policy_loss": -0.049202661593153604, "vf_loss": 0.025879232998704538, "vf_explained_var": 0.9197142798453569, "kl": 0.009243328684352719, "entropy": 5.88635220527649, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 560.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.8944594651460647, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.03166370656254003, "policy_loss": -0.05192372825113125, "vf_loss": 0.017548474672366865, "vf_explained_var": 0.9169642653316259, "kl": 0.009038490187720457, "entropy": 5.73448136150837, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 560.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_19": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.722698013484478, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.008257098267495166, "policy_loss": -0.0493081979569979, "vf_loss": 0.03818751761573367, "vf_explained_var": 0.8529009573161602, "kl": 0.009545274703100404, "entropy": 5.553467658162117, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 560.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}}, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "env_runners": {"episode_reward_max": -44.1999999999997, "episode_reward_min": -70.14000000000262, "episode_reward_mean": -57.27333333333494, "episode_len_mean": 500.0, "episode_media": {}, "episodes_timesteps_total": 15000, "policy_reward_min": {"agent_0": -5.3700000000000285, "agent_1": -5.280000000000027, "agent_2": -5.320000000000028, "agent_3": -5.250000000000027, "agent_4": -5.360000000000028, "agent_5": -5.130000000000026, "agent_6": -5.330000000000028, "agent_7": -5.3700000000000285, "agent_8": -5.300000000000027, "agent_9": -5.320000000000028, "agent_10": -5.340000000000028, "agent_11": -5.330000000000028, "agent_12": -5.340000000000028, "agent_13": -5.3700000000000285, "agent_14": -5.350000000000028, "agent_15": -5.240000000000027, "agent_16": -5.360000000000028, "agent_17": -5.360000000000028, "agent_18": -5.360000000000028, "agent_19": -5.180000000000026, "agent_20": -5.2100000000000275}, "policy_reward_max": {"agent_0": -0.5000000000000003, "agent_1": -0.5000000000000003, "agent_2": -0.5000000000000003, "agent_3": -0.5000000000000003, "agent_4": -0.5000000000000003, "agent_5": -0.5000000000000003, "agent_6": -0.5000000000000003, "agent_7": -0.5000000000000003, "agent_8": -0.5000000000000003, "agent_9": -0.5000000000000003, "agent_10": -0.5000000000000003, "agent_11": -0.5000000000000003, "agent_12": -0.5000000000000003, "agent_13": -0.5000000000000003, "agent_14": -3.66000000000001, "agent_15": -3.470000000000007, "agent_16": -3.3100000000000054, "agent_17": -3.7100000000000097, "agent_18": -3.66000000000001, "agent_19": -3.5200000000000085, "agent_20": -3.4600000000000075}, "policy_reward_mean": {"agent_0": -1.535000000000005, "agent_1": -1.4393333333333374, "agent_2": -2.6096666666666777, "agent_3": -1.4020000000000048, "agent_4": -1.9370000000000076, "agent_5": -1.0956666666666701, "agent_6": -1.6870000000000054, "agent_7": -2.003333333333341, "agent_8": -1.5376666666666723, "agent_9": -1.8916666666666733, "agent_10": -2.273333333333342, "agent_11": -2.010333333333342, "agent_12": -2.1796666666666753, "agent_13": -2.088333333333341, "agent_14": -4.580000000000019, "agent_15": -4.5370000000000195, "agent_16": -4.402333333333352, "agent_17": -4.659000000000021, "agent_18": -4.557333333333353, "agent_19": -4.520333333333353, "agent_20": -4.327333333333351}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-44.1999999999997, -47.869999999999905, -53.90000000000077, -56.50000000000109, -70.14000000000262, -58.4900000000023, -44.69999999999998, -64.51000000000346, -51.620000000000566, -65.79000000000308, -67.35000000000318, -53.23000000000039, -53.17000000000061, -56.740000000001125, -52.76000000000032, -62.44000000000218, -50.530000000001344, -63.63000000000317, -46.849999999999895, -67.7200000000026, -45.89999999999993, -53.600000000000826, -48.90999999999976, -59.22000000000259, -62.70000000000288, -66.84000000000268, -60.74000000000206, -61.32000000000323, -64.25000000000297, -62.580000000003146], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_agent_0_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.9300000000000007, -0.5000000000000003, -5.230000000000027, -0.5000000000000003, -5.210000000000027, -0.5000000000000003, -4.63000000000002, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.350000000000028, -0.5000000000000003, -0.5000000000000003, -1.409999999999997, -0.5000000000000003, -0.5000000000000003, -2.129999999999993, -5.290000000000028, -0.5000000000000003, -5.3700000000000285, -0.5000000000000003, -0.5000000000000003], "policy_agent_1_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -1.8899999999999926, -3.2700000000000053, -4.680000000000021, -0.5000000000000003, -5.280000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.070000000000025, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -1.4999999999999962, -0.5000000000000003, -0.5000000000000003, -5.180000000000026, -0.5000000000000003, -4.930000000000024, -0.8800000000000007], "policy_agent_2_reward": [-0.5000000000000003, -0.5000000000000003, -0.9700000000000008, -0.5000000000000003, -5.190000000000026, -0.5000000000000003, -4.590000000000019, -5.130000000000026, -4.100000000000015, -5.210000000000027, -5.180000000000026, -4.040000000000013, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.310000000000027, -0.5000000000000003, -5.280000000000027, -0.5000000000000003, -5.280000000000027, -4.910000000000023, -5.080000000000025, -0.5000000000000003, -0.5000000000000003, -5.320000000000028, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.200000000000027, -0.5000000000000003], "policy_agent_3_reward": [-0.5000000000000003, -0.5000000000000003, -5.080000000000025, -5.200000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.250000000000027, -0.5000000000000003, -5.210000000000027, -0.5000000000000003, -5.130000000000026, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -4.1900000000000155, -0.5000000000000003, -0.5000000000000003], "policy_agent_4_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.090000000000026, -0.5000000000000003, -0.5000000000000003, -4.8600000000000225, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.190000000000026, -2.0999999999999925, -5.250000000000027, -0.5000000000000003, -0.5000000000000003, -5.160000000000026, -0.5000000000000003, -5.360000000000028, -0.5000000000000003, -5.150000000000026, -4.980000000000024, -0.5000000000000003, -0.5000000000000003, -4.970000000000024, -0.5000000000000003], "policy_agent_5_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -4.990000000000024, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.130000000000026, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -4.7400000000000215, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.010000000000025], "policy_agent_6_reward": [-0.5000000000000003, -0.5000000000000003, -0.6800000000000005, -5.330000000000028, -5.250000000000027, -4.890000000000023, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -1.3099999999999978, -0.5000000000000003, -0.9200000000000007, -0.5000000000000003, -5.260000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -4.370000000000017, -0.5000000000000003, -3.320000000000006, -5.250000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -1.189999999999999, -0.5000000000000003, -3.840000000000012], "policy_agent_7_reward": [-5.200000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -4.350000000000017, -4.870000000000023, -0.5000000000000003, -1.9199999999999924, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.3700000000000285, -0.5000000000000003, -0.5000000000000003, -5.230000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -4.1900000000000155, -5.350000000000028, -0.5000000000000003, -5.340000000000028, -5.170000000000027, -3.610000000000009, -0.5000000000000003], "policy_agent_8_reward": [-0.5000000000000003, -5.200000000000027, -0.5000000000000003, -4.9400000000000235, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -3.4100000000000072, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.300000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.240000000000027, -5.240000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.300000000000027], "policy_agent_9_reward": [-0.5000000000000003, -0.5000000000000003, -5.210000000000027, -0.5000000000000003, -0.5000000000000003, -1.5299999999999958, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -1.5499999999999956, -5.310000000000027, -5.180000000000026, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.290000000000028, -0.5000000000000003, -5.320000000000028, -0.5000000000000003, -4.920000000000023, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.250000000000027, -5.180000000000026, -2.3899999999999957, -0.5000000000000003, -0.6200000000000004], "policy_agent_10_reward": [-0.5000000000000003, -0.5000000000000003, -3.710000000000011, -0.5000000000000003, -4.880000000000023, -0.5000000000000003, -0.5000000000000003, -5.340000000000028, -5.270000000000027, -4.890000000000023, -4.930000000000024, -0.5000000000000003, -5.110000000000025, -0.5000000000000003, -0.5000000000000003, -5.090000000000026, -1.729999999999994, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.300000000000027, -0.5000000000000003, -5.250000000000027, -0.5000000000000003, -0.5000000000000003, -5.150000000000026, -3.050000000000003], "policy_agent_11_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.300000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.030000000000024, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.270000000000027, -0.5000000000000003, -4.760000000000022, -4.380000000000018, -0.5000000000000003, -5.220000000000026, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.200000000000027, -4.64000000000002, -0.5000000000000003, -5.330000000000028, -5.180000000000026, -0.5000000000000003, -0.5000000000000003], "policy_agent_12_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.340000000000028, -5.260000000000027, -0.5000000000000003, -1.8599999999999928, -0.5000000000000003, -5.300000000000027, -5.190000000000026, -4.690000000000021, -0.5000000000000003, -5.080000000000025, -0.5000000000000003, -0.5000000000000003, -5.230000000000027, -2.77, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.230000000000027, -0.5000000000000003, -5.320000000000028, -0.5000000000000003, -5.120000000000026], "policy_agent_13_reward": [-0.5000000000000003, -5.040000000000025, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.270000000000027, -0.5000000000000003, -5.270000000000027, -4.590000000000019, -5.310000000000027, -2.4199999999999964, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.9100000000000007, -0.5000000000000003, -0.5000000000000003, -5.100000000000025, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -2.309999999999995, -0.5000000000000003, -5.3700000000000285, -2.0699999999999923, -0.5000000000000003, -5.310000000000027, -5.180000000000026], "policy_agent_14_reward": [-5.310000000000027, -4.650000000000021, -4.450000000000018, -4.63000000000002, -4.280000000000016, -4.600000000000021, -4.050000000000014, -5.240000000000027, -4.060000000000014, -3.66000000000001, -5.320000000000028, -4.880000000000023, -4.060000000000014, -5.330000000000028, -5.160000000000026, -3.6700000000000097, -4.840000000000023, -4.510000000000019, -4.790000000000022, -4.480000000000018, -3.7000000000000104, -5.140000000000026, -5.350000000000028, -4.810000000000022, -3.8000000000000114, -3.9900000000000135, -5.240000000000027, -4.410000000000018, -4.380000000000017, -4.610000000000021], "policy_agent_15_reward": [-4.710000000000021, -5.090000000000026, -4.7800000000000225, -5.120000000000026, -4.490000000000019, -4.330000000000018, -5.240000000000027, -4.9400000000000235, -5.230000000000027, -4.260000000000016, -3.470000000000007, -4.760000000000022, -4.040000000000013, -4.430000000000018, -4.470000000000018, -4.800000000000022, -4.990000000000024, -4.360000000000017, -4.680000000000021, -4.410000000000018, -4.8600000000000225, -4.780000000000022, -3.600000000000009, -4.1100000000000145, -5.090000000000026, -4.160000000000015, -4.760000000000022, -4.110000000000014, -4.210000000000016, -3.8300000000000116], "policy_agent_16_reward": [-5.040000000000025, -4.390000000000017, -5.360000000000028, -4.280000000000016, -4.080000000000014, -4.300000000000017, -3.760000000000011, -3.3100000000000054, -4.960000000000024, -3.8300000000000125, -3.860000000000012, -4.380000000000018, -3.980000000000014, -4.280000000000016, -4.430000000000018, -5.240000000000027, -4.210000000000017, -4.440000000000018, -4.710000000000021, -5.160000000000026, -4.340000000000017, -4.890000000000023, -3.9000000000000123, -3.950000000000013, -4.3800000000000185, -4.370000000000018, -4.750000000000021, -4.340000000000017, -4.3100000000000165, -4.840000000000022], "policy_agent_17_reward": [-4.500000000000019, -5.070000000000025, -4.2700000000000164, -4.840000000000023, -4.560000000000019, -5.070000000000025, -3.850000000000012, -5.260000000000027, -4.61000000000002, -4.240000000000016, -4.780000000000022, -5.360000000000028, -5.350000000000028, -5.340000000000028, -4.790000000000022, -4.560000000000019, -4.480000000000018, -4.000000000000013, -4.050000000000014, -5.220000000000026, -3.7100000000000097, -4.64000000000002, -5.270000000000027, -4.300000000000018, -4.550000000000019, -4.9000000000000234, -4.300000000000017, -4.490000000000019, -4.560000000000019, -4.850000000000023], "policy_agent_18_reward": [-3.740000000000011, -4.300000000000016, -4.880000000000023, -4.490000000000019, -4.780000000000022, -3.740000000000011, -4.750000000000021, -4.3800000000000185, -4.460000000000019, -3.9100000000000135, -4.470000000000019, -5.360000000000028, -5.080000000000025, -3.8900000000000126, -4.54000000000002, -4.57000000000002, -4.52000000000002, -4.960000000000024, -4.9400000000000235, -4.52000000000002, -4.250000000000016, -5.120000000000025, -5.310000000000027, -5.280000000000027, -4.950000000000024, -4.54000000000002, -4.240000000000016, -3.66000000000001, -4.8600000000000225, -4.2300000000000155], "policy_agent_19_reward": [-5.180000000000026, -4.280000000000016, -4.8200000000000225, -3.5200000000000085, -4.9000000000000234, -4.55000000000002, -5.170000000000027, -4.63000000000002, -4.1100000000000145, -4.9400000000000235, -3.9900000000000135, -4.8600000000000225, -4.350000000000017, -4.680000000000021, -3.7300000000000106, -4.130000000000015, -4.800000000000023, -4.62000000000002, -3.7000000000000104, -5.150000000000026, -4.720000000000021, -4.160000000000015, -5.110000000000025, -4.830000000000023, -4.000000000000013, -5.070000000000025, -4.64000000000002, -4.170000000000016, -4.8200000000000225, -3.9800000000000133], "policy_agent_20_reward": [-4.020000000000014, -3.850000000000012, -5.190000000000026, -4.160000000000015, -4.150000000000015, -4.1900000000000155, -4.020000000000014, -4.1900000000000155, -4.300000000000018, -4.780000000000022, -3.860000000000012, -4.220000000000016, -4.700000000000021, -4.980000000000024, -4.980000000000024, -4.9400000000000235, -3.4600000000000075, -4.64000000000002, -3.890000000000012, -4.1900000000000155, -4.250000000000016, -5.140000000000025, -3.760000000000011, -4.200000000000016, -4.100000000000015, -4.440000000000018, -5.2100000000000275, -3.8300000000000116, -3.940000000000013, -4.240000000000016]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.898525024083368, "mean_inference_ms": 9.061993915661755, "mean_action_processing_ms": 0.6917252983464465, "mean_env_wait_ms": 2.7322592059064603, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0026221880837092324, "StateBufferConnector_ms": 0.0014621492416139633, "ViewRequirementAgentConnector_ms": 0.03255056956457713}, "num_episodes": 8, "episode_return_max": -44.1999999999997, "episode_return_min": -70.14000000000262, "episode_return_mean": -57.27333333333494, "episodes_this_iter": 8}, "num_healthy_workers": 3, "actor_manager_num_outstanding_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 127.04979409368507, "num_env_steps_trained_throughput_per_sec": 127.04979409368507, "timesteps_total": 16000, "num_env_steps_sampled_lifetime": 16000, "num_agent_steps_sampled_lifetime": 336000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 336000, "timers": {"training_iteration_time_ms": 30430.647, "restore_workers_time_ms": 0.013, "training_step_time_ms": 30430.604, "sample_time_ms": 19947.553, "learn_time_ms": 10463.385, "learn_throughput": 382.285, "synch_weights_time_ms": 17.187}, "counters": {"num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "done": false, "training_iteration": 4, "trial_id": "39fd7_00000", "date": "2025-10-21_11-15-47", "timestamp": 1761038147, "time_this_iter_s": 31.493460655212402, "time_total_s": 121.77029061317444, "pid": 3259979, "hostname": "xuezhi-Precision-3660", "node_ip": "130.238.16.41", "config": {"exploration_config": {"type": "StochasticSampling"}, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 1, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "torch_ddp_kwargs": {}, "torch_skip_nan_gradients": false, "env": "<class 'train_utils.WarehouseMultiAgentEnv'>", "env_config": {"env_id": "tarware-extralarge-14agvs-7pickers-partialobs-chg-v1"}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "_is_atari": null, "disable_env_checking": false, "render_env": true, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 3, "create_local_env_runner": true, "num_envs_per_env_runner": 1, "gym_env_vectorize_mode": "SYNC", "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "episodes_to_numpy": true, "max_requests_in_flight_per_env_runner": 1, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "merge_env_runner_states": "training_only", "broadcast_env_runner_states": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "sampler_perf_stats_ema_coef": null, "_is_online": true, "num_learners": 0, "num_gpus_per_learner": 1, "num_cpus_per_learner": "auto", "num_aggregator_actors_per_learner": 0, "max_requests_in_flight_per_aggregator_actor": 3, "local_gpu_idx": 0, "max_requests_in_flight_per_learner": 3, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "_train_batch_size_per_learner": null, "train_batch_size": 4000, "num_epochs": 10, "minibatch_size": 256, "shuffle_batch_per_epoch": true, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "log_std_clip_param": 20.0, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1, "_disable_preprocessor_api": false, "_disable_action_flattening": false}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "_learner_class": null, "callbacks_on_algorithm_init": null, "callbacks_on_env_runners_recreated": null, "callbacks_on_offline_eval_runners_recreated": null, "callbacks_on_checkpoint_loaded": null, "callbacks_on_environment_created": null, "callbacks_on_episode_created": null, "callbacks_on_episode_start": null, "callbacks_on_episode_step": null, "callbacks_on_episode_end": null, "callbacks_on_evaluate_start": null, "callbacks_on_evaluate_end": null, "callbacks_on_evaluate_offline_start": null, "callbacks_on_evaluate_offline_end": null, "callbacks_on_sample_end": null, "callbacks_on_train_result": null, "explore": true, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "_prior_exploration_config": null, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function train.<locals>.<lambda> at 0x782de3b3d630>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "offline_data_class": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "input_read_episodes": false, "input_read_sample_batches": false, "input_read_batch_size": null, "input_filesystem": null, "input_filesystem_kwargs": {}, "input_compress_columns": ["obs", "new_obs"], "input_spaces_jsonable": true, "materialize_data": false, "materialize_mapped_data": true, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "ignore_final_observation": false, "prelearner_class": null, "prelearner_buffer_class": null, "prelearner_buffer_kwargs": {}, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "output_max_rows_per_file": null, "output_write_remaining_data": false, "output_write_method": "write_parquet", "output_write_method_kwargs": {}, "output_filesystem": null, "output_filesystem_kwargs": {}, "output_write_episodes": true, "offline_sampling": false, "evaluation_interval": 10, "evaluation_duration": 5, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_auto_duration_min_env_steps_per_sample": 100, "evaluation_auto_duration_max_env_steps_per_sample": 2000, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": {"explore": false}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "offline_evaluation_interval": null, "num_offline_eval_runners": 0, "offline_evaluation_type": null, "offline_eval_runner_class": null, "offline_loss_for_module_fn": null, "offline_evaluation_duration": 1, "offline_evaluation_parallel_to_training": false, "offline_evaluation_timeout_s": 120.0, "num_cpus_per_offline_eval_runner": 1, "num_gpus_per_offline_eval_runner": 0, "custom_resources_per_offline_eval_runner": {}, "restart_failed_offline_eval_runners": true, "ignore_offline_eval_runner_failures": false, "max_num_offline_eval_runner_restarts": 1000, "offline_eval_runner_restore_timeout_s": 1800.0, "max_requests_in_flight_per_offline_eval_runner": 1, "validate_offline_eval_runners_after_construction": true, "offline_eval_runner_health_probe_timeout_s": 30.0, "offline_eval_rl_module_inference_only": false, "broadcast_offline_eval_runner_states": false, "offline_eval_batch_size_per_runner": 256, "dataset_num_iters_per_eval_runner": 1, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "log_gradients": false, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "restart_failed_env_runners": true, "ignore_env_runner_failures": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30.0, "env_runner_restore_timeout_s": 1800.0, "_model_config": {}, "_rl_module_spec": null, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "_validate_config": true, "_use_msgpack_checkpoints": false, "_torch_grad_scaler_class": null, "_torch_lr_scheduler_classes": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "env_task_fn": -1, "enable_connectors": -1, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "clip_param": 0.2, "vf_clip_param": 10.0, "entropy_coeff_schedule": null, "lr_schedule": null, "sgd_minibatch_size": -1, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.95, "input": "sampler", "policies": {"agent_0": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_1": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_2": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_3": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_4": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_5": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_6": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_7": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_8": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_9": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_10": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_11": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_12": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_13": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_14": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_15": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_16": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_17": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_18": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_19": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_20": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}]}, "callbacks": "<class 'ray.rllib.callbacks.callbacks.RLlibCallback'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 121.77029061317444, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 11.397727272727273, "ram_util_percent": 28.545454545454547, "gpu_util_percent0": 0.2409090909090909, "vram_util_percent0": 0.09438757383310388}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_8": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.894648589193821, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.026620208914391697, "policy_loss": -0.054267546784831214, "vf_loss": 0.024734842247562484, "vf_explained_var": 0.8820582736283541, "kl": 0.009708315695367897, "entropy": 5.834384733438492, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 720.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_16": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.1038778424263, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.0068866459056152966, "policy_loss": -0.055755110437166876, "vf_loss": 0.04505327882943675, "vf_explained_var": 0.9332339938730001, "kl": 0.012717284994137396, "entropy": 5.188779953122139, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 720.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_12": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.4283685237169266, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.0385962718326482, "policy_loss": -0.0567216804556665, "vf_loss": 0.015581495242076925, "vf_explained_var": 0.8819954343140125, "kl": 0.008479711548280233, "entropy": 5.875854209065437, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 720.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_9": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.820322746038437, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.00043835496180690827, "policy_loss": -0.04736332601169124, "vf_loss": 0.0437371835228987, "vf_explained_var": 0.9392896223813295, "kl": 0.010625958449304649, "entropy": 5.7425052464008335, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 720.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_18": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.226685644686222, "cur_kl_coeff": 0.45000000000000007, "cur_lr": 5.000000000000001e-05, "total_loss": 0.017720971314702183, "policy_loss": -0.050986970445956105, "vf_loss": 0.06246622961480171, "vf_explained_var": 0.9174321368336678, "kl": 0.013870473280505025, "entropy": 5.310596930980682, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 720.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_13": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.514367216825486, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.022947598378232216, "policy_loss": -0.05062884178769309, "vf_loss": 0.024789610592415558, "vf_explained_var": 0.9332868468016386, "kl": 0.009638776382718912, "entropy": 5.801472011208534, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 720.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_3": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.932000614702702, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.025997989748429973, "policy_loss": -0.05360386322718114, "vf_loss": 0.02473444324277807, "vf_explained_var": 0.9539863847196102, "kl": 0.009571430782190615, "entropy": 5.814936807751655, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 720.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_15": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.375897355377674, "cur_kl_coeff": 0.45000000000000007, "cur_lr": 5.000000000000001e-05, "total_loss": 0.02839939172263257, "policy_loss": -0.04464448903891025, "vf_loss": 0.0674808141309768, "vf_explained_var": 0.9259612575173378, "kl": 0.012362369414957719, "entropy": 5.391762188076973, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 720.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.226534689962864, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.030807409847329836, "policy_loss": -0.056152927645030104, "vf_loss": 0.02231496486638207, "vf_explained_var": 0.9322462283074856, "kl": 0.01010183953633259, "entropy": 5.807202884554863, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 720.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_7": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.532576377689838, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.03690213555091759, "policy_loss": -0.06046324527123943, "vf_loss": 0.020413172722328454, "vf_explained_var": 0.891661212593317, "kl": 0.010493123043330476, "entropy": 5.817466416954995, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 720.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_11": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.9540931895375255, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.030643436245736667, "policy_loss": -0.05639420612715185, "vf_loss": 0.023190349084325136, "vf_explained_var": 0.8835129640996456, "kl": 0.008534736128917923, "entropy": 5.717816364765167, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 720.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_2": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.037226255238056, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.01742932065099012, "policy_loss": -0.04758743073325604, "vf_loss": 0.02746332825627178, "vf_explained_var": 0.9485845565795898, "kl": 0.008982604479224167, "entropy": 5.882116892933846, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 720.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_14": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.92712313234806, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": 0.011183257999073248, "policy_loss": -0.04917437480180524, "vf_loss": 0.056701678072568026, "vf_explained_var": 0.9028330352157354, "kl": 0.012186520237073086, "entropy": 5.208330509066582, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 720.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_4": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.943991656601429, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.03412811123489519, "policy_loss": -0.05712200020207092, "vf_loss": 0.02026644166908227, "vf_explained_var": 0.9614517450332641, "kl": 0.009091494023064094, "entropy": 5.874823033809662, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 720.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_20": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.790345720946789, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": 0.013636553738615475, "policy_loss": -0.049205840317881666, "vf_loss": 0.058466973877511916, "vf_explained_var": 0.9507158488035202, "kl": 0.014584735609185984, "entropy": 5.177644151449203, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 720.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_17": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.674319449067116, "cur_kl_coeff": 0.45000000000000007, "cur_lr": 5.000000000000001e-05, "total_loss": 0.01724517649417976, "policy_loss": -0.05193784225557465, "vf_loss": 0.06376051793340594, "vf_explained_var": 0.9061090979725123, "kl": 0.012050003464547859, "entropy": 5.3554235845804214, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 720.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_10": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.7125504821538926, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.025698755231132964, "policy_loss": -0.049501270387554544, "vf_loss": 0.02150740113283973, "vf_explained_var": 0.8742848064750433, "kl": 0.007650380606003071, "entropy": 5.864794141054153, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 720.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_6": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.4831384181976315, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.03385326408024412, "policy_loss": -0.05726933417608961, "vf_loss": 0.020640658956835978, "vf_explained_var": 0.9183525085449219, "kl": 0.009251369539366982, "entropy": 5.793844848871231, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 720.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_5": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.334457221627235, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.02577336654503597, "policy_loss": -0.05180297315819189, "vf_loss": 0.023300350835779682, "vf_explained_var": 0.9563818577677011, "kl": 0.009097518158486051, "entropy": 5.868705204129219, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 720.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.8658809065818787, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.03329590940411435, "policy_loss": -0.053491488190775274, "vf_loss": 0.017264585476368666, "vf_explained_var": 0.8671106226742268, "kl": 0.009769979465204415, "entropy": 5.688706484436989, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 720.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_19": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.160759131610393, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.015964599400467704, "policy_loss": -0.05419044533191482, "vf_loss": 0.03525767814135179, "vf_explained_var": 0.9204186622053385, "kl": 0.009893888378122263, "entropy": 5.5600863069295885, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 720.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}}, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 420000, "num_agent_steps_trained": 420000}, "env_runners": {"episode_reward_max": -44.1999999999997, "episode_reward_min": -70.14000000000262, "episode_reward_mean": -56.60564102564253, "episode_len_mean": 500.0, "episode_media": {}, "episodes_timesteps_total": 19500, "policy_reward_min": {"agent_0": -5.3700000000000285, "agent_1": -5.280000000000027, "agent_2": -5.320000000000028, "agent_3": -5.350000000000028, "agent_4": -5.360000000000028, "agent_5": -5.130000000000026, "agent_6": -5.330000000000028, "agent_7": -5.3700000000000285, "agent_8": -5.330000000000028, "agent_9": -5.320000000000028, "agent_10": -5.340000000000028, "agent_11": -5.360000000000028, "agent_12": -5.340000000000028, "agent_13": -5.3700000000000285, "agent_14": -5.360000000000028, "agent_15": -5.250000000000027, "agent_16": -5.360000000000028, "agent_17": -5.360000000000028, "agent_18": -5.360000000000028, "agent_19": -5.310000000000027, "agent_20": -5.2100000000000275}, "policy_reward_max": {"agent_0": -0.5000000000000003, "agent_1": -0.5000000000000003, "agent_2": -0.5000000000000003, "agent_3": -0.5000000000000003, "agent_4": -0.5000000000000003, "agent_5": -0.5000000000000003, "agent_6": -0.5000000000000003, "agent_7": -0.5000000000000003, "agent_8": -0.5000000000000003, "agent_9": -0.5000000000000003, "agent_10": -0.5000000000000003, "agent_11": -0.5000000000000003, "agent_12": -0.5000000000000003, "agent_13": -0.5000000000000003, "agent_14": -3.66000000000001, "agent_15": -3.470000000000007, "agent_16": -3.3100000000000054, "agent_17": -3.7100000000000097, "agent_18": -3.66000000000001, "agent_19": -3.5200000000000085, "agent_20": -3.4600000000000075}, "policy_reward_mean": {"agent_0": -1.3671794871794911, "agent_1": -1.4461538461538503, "agent_2": -2.28128205128206, "agent_3": -1.6587179487179553, "agent_4": -1.7987179487179548, "agent_5": -1.2792307692307732, "agent_6": -1.6846153846153902, "agent_7": -1.7679487179487243, "agent_8": -1.7694871794871863, "agent_9": -1.8141025641025708, "agent_10": -2.065384615384623, "agent_11": -2.1120512820512904, "agent_12": -1.9141025641025715, "agent_13": -2.083333333333341, "agent_14": -4.543076923076943, "agent_15": -4.557948717948738, "agent_16": -4.445641025641044, "agent_17": -4.594871794871813, "agent_18": -4.496153846153864, "agent_19": -4.566666666666687, "agent_20": -4.358974358974376}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-44.1999999999997, -47.869999999999905, -53.90000000000077, -56.50000000000109, -70.14000000000262, -58.4900000000023, -44.69999999999998, -64.51000000000346, -51.620000000000566, -65.79000000000308, -67.35000000000318, -53.23000000000039, -53.17000000000061, -56.740000000001125, -52.76000000000032, -62.44000000000218, -50.530000000001344, -63.63000000000317, -46.849999999999895, -67.7200000000026, -45.89999999999993, -53.600000000000826, -48.90999999999976, -59.22000000000259, -62.70000000000288, -66.84000000000268, -60.74000000000206, -61.32000000000323, -64.25000000000297, -62.580000000003146, -54.430000000001264, -56.92000000000129, -46.52000000000107, -51.0100000000003, -65.43000000000282, -50.4200000000003, -56.18000000000112, -47.1500000000003, -61.3600000000021], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_agent_0_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.9300000000000007, -0.5000000000000003, -5.230000000000027, -0.5000000000000003, -5.210000000000027, -0.5000000000000003, -4.63000000000002, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.350000000000028, -0.5000000000000003, -0.5000000000000003, -1.409999999999997, -0.5000000000000003, -0.5000000000000003, -2.129999999999993, -5.290000000000028, -0.5000000000000003, -5.3700000000000285, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -3.2700000000000053, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003], "policy_agent_1_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -1.8899999999999926, -3.2700000000000053, -4.680000000000021, -0.5000000000000003, -5.280000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.070000000000025, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -1.4999999999999962, -0.5000000000000003, -0.5000000000000003, -5.180000000000026, -0.5000000000000003, -4.930000000000024, -0.8800000000000007, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.100000000000025, -0.5000000000000003, -4.6200000000000205], "policy_agent_2_reward": [-0.5000000000000003, -0.5000000000000003, -0.9700000000000008, -0.5000000000000003, -5.190000000000026, -0.5000000000000003, -4.590000000000019, -5.130000000000026, -4.100000000000015, -5.210000000000027, -5.180000000000026, -4.040000000000013, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.310000000000027, -0.5000000000000003, -5.280000000000027, -0.5000000000000003, -5.280000000000027, -4.910000000000023, -5.080000000000025, -0.5000000000000003, -0.5000000000000003, -5.320000000000028, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.200000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -1.8899999999999926, -5.290000000000028, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003], "policy_agent_3_reward": [-0.5000000000000003, -0.5000000000000003, -5.080000000000025, -5.200000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.250000000000027, -0.5000000000000003, -5.210000000000027, -0.5000000000000003, -5.130000000000026, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -4.1900000000000155, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -4.330000000000017, -5.350000000000028, -5.200000000000027, -0.5000000000000003, -5.250000000000027], "policy_agent_4_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.090000000000026, -0.5000000000000003, -0.5000000000000003, -4.8600000000000225, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.190000000000026, -2.0999999999999925, -5.250000000000027, -0.5000000000000003, -0.5000000000000003, -5.160000000000026, -0.5000000000000003, -5.360000000000028, -0.5000000000000003, -5.150000000000026, -4.980000000000024, -0.5000000000000003, -0.5000000000000003, -4.970000000000024, -0.5000000000000003, -2.239999999999994, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -4.930000000000024, -1.8699999999999928, -0.5000000000000003], "policy_agent_5_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -4.990000000000024, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.130000000000026, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -4.7400000000000215, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.010000000000025, -4.360000000000017, -4.930000000000024, -0.5000000000000003, -0.5000000000000003, -4.730000000000022, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003], "policy_agent_6_reward": [-0.5000000000000003, -0.5000000000000003, -0.6800000000000005, -5.330000000000028, -5.250000000000027, -4.890000000000023, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -1.3099999999999978, -0.5000000000000003, -0.9200000000000007, -0.5000000000000003, -5.260000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -4.370000000000017, -0.5000000000000003, -3.320000000000006, -5.250000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -1.189999999999999, -0.5000000000000003, -3.840000000000012, -0.5000000000000003, -0.5000000000000003, -1.8199999999999932, -0.5000000000000003, -5.160000000000026, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.110000000000025], "policy_agent_7_reward": [-5.200000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -4.350000000000017, -4.870000000000023, -0.5000000000000003, -1.9199999999999924, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.3700000000000285, -0.5000000000000003, -0.5000000000000003, -5.230000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -4.1900000000000155, -5.350000000000028, -0.5000000000000003, -5.340000000000028, -5.170000000000027, -3.610000000000009, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -4.850000000000023, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003], "policy_agent_8_reward": [-0.5000000000000003, -5.200000000000027, -0.5000000000000003, -4.9400000000000235, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -3.4100000000000072, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.300000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.240000000000027, -5.240000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.300000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.200000000000027, -5.330000000000028, -0.5000000000000003, -0.5000000000000003, -4.840000000000023, -5.010000000000025], "policy_agent_9_reward": [-0.5000000000000003, -0.5000000000000003, -5.210000000000027, -0.5000000000000003, -0.5000000000000003, -1.5299999999999958, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -1.5499999999999956, -5.310000000000027, -5.180000000000026, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.290000000000028, -0.5000000000000003, -5.320000000000028, -0.5000000000000003, -4.920000000000023, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.250000000000027, -5.180000000000026, -2.3899999999999957, -0.5000000000000003, -0.6200000000000004, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.250000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.250000000000027], "policy_agent_10_reward": [-0.5000000000000003, -0.5000000000000003, -3.710000000000011, -0.5000000000000003, -4.880000000000023, -0.5000000000000003, -0.5000000000000003, -5.340000000000028, -5.270000000000027, -4.890000000000023, -4.930000000000024, -0.5000000000000003, -5.110000000000025, -0.5000000000000003, -0.5000000000000003, -5.090000000000026, -1.729999999999994, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.300000000000027, -0.5000000000000003, -5.250000000000027, -0.5000000000000003, -0.5000000000000003, -5.150000000000026, -3.050000000000003, -0.5000000000000003, -5.010000000000025, -3.840000000000012, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003], "policy_agent_11_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.300000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.030000000000024, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.270000000000027, -0.5000000000000003, -4.760000000000022, -4.380000000000018, -0.5000000000000003, -5.220000000000026, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.200000000000027, -4.64000000000002, -0.5000000000000003, -5.330000000000028, -5.180000000000026, -0.5000000000000003, -0.5000000000000003, -4.760000000000022, -0.8600000000000007, -0.5000000000000003, -0.5000000000000003, -5.360000000000028, -3.770000000000011, -5.310000000000027, -0.5000000000000003, -0.5000000000000003], "policy_agent_12_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.340000000000028, -5.260000000000027, -0.5000000000000003, -1.8599999999999928, -0.5000000000000003, -5.300000000000027, -5.190000000000026, -4.690000000000021, -0.5000000000000003, -5.080000000000025, -0.5000000000000003, -0.5000000000000003, -5.230000000000027, -2.77, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.230000000000027, -0.5000000000000003, -5.320000000000028, -0.5000000000000003, -5.120000000000026, -0.5000000000000003, -5.040000000000025, -0.7200000000000005, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003], "policy_agent_13_reward": [-0.5000000000000003, -5.040000000000025, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.270000000000027, -0.5000000000000003, -5.270000000000027, -4.590000000000019, -5.310000000000027, -2.4199999999999964, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.9100000000000007, -0.5000000000000003, -0.5000000000000003, -5.100000000000025, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -2.309999999999995, -0.5000000000000003, -5.3700000000000285, -2.0699999999999923, -0.5000000000000003, -5.310000000000027, -5.180000000000026, -5.3700000000000285, -5.300000000000027, -4.930000000000024, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003], "policy_agent_14_reward": [-5.310000000000027, -4.650000000000021, -4.450000000000018, -4.63000000000002, -4.280000000000016, -4.600000000000021, -4.050000000000014, -5.240000000000027, -4.060000000000014, -3.66000000000001, -5.320000000000028, -4.880000000000023, -4.060000000000014, -5.330000000000028, -5.160000000000026, -3.6700000000000097, -4.840000000000023, -4.510000000000019, -4.790000000000022, -4.480000000000018, -3.7000000000000104, -5.140000000000026, -5.350000000000028, -4.810000000000022, -3.8000000000000114, -3.9900000000000135, -5.240000000000027, -4.410000000000018, -4.380000000000017, -4.610000000000021, -5.360000000000028, -3.870000000000011, -3.960000000000014, -4.6200000000000205, -4.930000000000024, -4.010000000000013, -3.9200000000000137, -5.320000000000028, -3.790000000000011], "policy_agent_15_reward": [-4.710000000000021, -5.090000000000026, -4.7800000000000225, -5.120000000000026, -4.490000000000019, -4.330000000000018, -5.240000000000027, -4.9400000000000235, -5.230000000000027, -4.260000000000016, -3.470000000000007, -4.760000000000022, -4.040000000000013, -4.430000000000018, -4.470000000000018, -4.800000000000022, -4.990000000000024, -4.360000000000017, -4.680000000000021, -4.410000000000018, -4.8600000000000225, -4.780000000000022, -3.600000000000009, -4.1100000000000145, -5.090000000000026, -4.160000000000015, -4.760000000000022, -4.110000000000014, -4.210000000000016, -3.8300000000000116, -4.750000000000021, -4.870000000000023, -4.6200000000000205, -3.760000000000011, -4.830000000000022, -5.090000000000026, -4.240000000000016, -5.250000000000027, -4.240000000000016], "policy_agent_16_reward": [-5.040000000000025, -4.390000000000017, -5.360000000000028, -4.280000000000016, -4.080000000000014, -4.300000000000017, -3.760000000000011, -3.3100000000000054, -4.960000000000024, -3.8300000000000125, -3.860000000000012, -4.380000000000018, -3.980000000000014, -4.280000000000016, -4.430000000000018, -5.240000000000027, -4.210000000000017, -4.440000000000018, -4.710000000000021, -5.160000000000026, -4.340000000000017, -4.890000000000023, -3.9000000000000123, -3.950000000000013, -4.3800000000000185, -4.370000000000018, -4.750000000000021, -4.340000000000017, -4.3100000000000165, -4.840000000000022, -4.120000000000014, -4.450000000000018, -4.470000000000018, -4.60000000000002, -4.920000000000023, -4.2700000000000164, -4.490000000000019, -5.280000000000027, -4.710000000000021], "policy_agent_17_reward": [-4.500000000000019, -5.070000000000025, -4.2700000000000164, -4.840000000000023, -4.560000000000019, -5.070000000000025, -3.850000000000012, -5.260000000000027, -4.61000000000002, -4.240000000000016, -4.780000000000022, -5.360000000000028, -5.350000000000028, -5.340000000000028, -4.790000000000022, -4.560000000000019, -4.480000000000018, -4.000000000000013, -4.050000000000014, -5.220000000000026, -3.7100000000000097, -4.64000000000002, -5.270000000000027, -4.300000000000018, -4.550000000000019, -4.9000000000000234, -4.300000000000017, -4.490000000000019, -4.560000000000019, -4.850000000000023, -4.370000000000017, -4.5000000000000195, -3.840000000000012, -4.340000000000017, -4.060000000000015, -4.780000000000022, -4.120000000000014, -5.080000000000025, -4.340000000000017], "policy_agent_18_reward": [-3.740000000000011, -4.300000000000016, -4.880000000000023, -4.490000000000019, -4.780000000000022, -3.740000000000011, -4.750000000000021, -4.3800000000000185, -4.460000000000019, -3.9100000000000135, -4.470000000000019, -5.360000000000028, -5.080000000000025, -3.8900000000000126, -4.54000000000002, -4.57000000000002, -4.52000000000002, -4.960000000000024, -4.9400000000000235, -4.52000000000002, -4.250000000000016, -5.120000000000025, -5.310000000000027, -5.280000000000027, -4.950000000000024, -4.54000000000002, -4.240000000000016, -3.66000000000001, -4.8600000000000225, -4.2300000000000155, -4.64000000000002, -3.950000000000013, -4.020000000000014, -4.180000000000016, -3.920000000000013, -4.430000000000018, -4.180000000000016, -5.040000000000025, -4.2700000000000164], "policy_agent_19_reward": [-5.180000000000026, -4.280000000000016, -4.8200000000000225, -3.5200000000000085, -4.9000000000000234, -4.55000000000002, -5.170000000000027, -4.63000000000002, -4.1100000000000145, -4.9400000000000235, -3.9900000000000135, -4.8600000000000225, -4.350000000000017, -4.680000000000021, -3.7300000000000106, -4.130000000000015, -4.800000000000023, -4.62000000000002, -3.7000000000000104, -5.150000000000026, -4.720000000000021, -4.160000000000015, -5.110000000000025, -4.830000000000023, -4.000000000000013, -5.070000000000025, -4.64000000000002, -4.170000000000016, -4.8200000000000225, -3.9800000000000133, -4.650000000000021, -5.310000000000027, -3.950000000000013, -4.410000000000018, -4.480000000000018, -5.130000000000026, -4.990000000000024, -4.450000000000018, -5.120000000000026], "policy_agent_20_reward": [-4.020000000000014, -3.850000000000012, -5.190000000000026, -4.160000000000015, -4.150000000000015, -4.1900000000000155, -4.020000000000014, -4.1900000000000155, -4.300000000000018, -4.780000000000022, -3.860000000000012, -4.220000000000016, -4.700000000000021, -4.980000000000024, -4.980000000000024, -4.9400000000000235, -3.4600000000000075, -4.64000000000002, -3.890000000000012, -4.1900000000000155, -4.250000000000016, -5.140000000000025, -3.760000000000011, -4.200000000000016, -4.100000000000015, -4.440000000000018, -5.2100000000000275, -3.8300000000000116, -3.940000000000013, -4.240000000000016, -4.810000000000022, -4.330000000000017, -3.9600000000000133, -4.260000000000016, -4.130000000000015, -4.8200000000000225, -4.700000000000021, -4.020000000000015, -5.150000000000026]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.9140365538799466, "mean_inference_ms": 9.108569951076383, "mean_action_processing_ms": 0.6931312122641773, "mean_env_wait_ms": 2.7478918903804237, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.002359383272164034, "StateBufferConnector_ms": 0.0014756334279191945, "ViewRequirementAgentConnector_ms": 0.03279684809683589}, "num_episodes": 9, "episode_return_max": -44.1999999999997, "episode_return_min": -70.14000000000262, "episode_return_mean": -56.60564102564253, "episodes_this_iter": 9}, "num_healthy_workers": 3, "actor_manager_num_outstanding_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 420000, "num_agent_steps_trained": 420000, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 130.16038412529247, "num_env_steps_trained_throughput_per_sec": 130.16038412529247, "timesteps_total": 20000, "num_env_steps_sampled_lifetime": 20000, "num_agent_steps_sampled_lifetime": 420000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 420000, "timers": {"training_iteration_time_ms": 30490.782, "restore_workers_time_ms": 0.013, "training_step_time_ms": 30490.738, "sample_time_ms": 20035.64, "learn_time_ms": 10435.446, "learn_throughput": 383.309, "synch_weights_time_ms": 17.171}, "counters": {"num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 420000, "num_agent_steps_trained": 420000}, "done": false, "training_iteration": 5, "trial_id": "39fd7_00000", "date": "2025-10-21_11-16-18", "timestamp": 1761038178, "time_this_iter_s": 30.744977235794067, "time_total_s": 152.5152678489685, "pid": 3259979, "hostname": "xuezhi-Precision-3660", "node_ip": "130.238.16.41", "config": {"exploration_config": {"type": "StochasticSampling"}, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 1, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "torch_ddp_kwargs": {}, "torch_skip_nan_gradients": false, "env": "<class 'train_utils.WarehouseMultiAgentEnv'>", "env_config": {"env_id": "tarware-extralarge-14agvs-7pickers-partialobs-chg-v1"}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "_is_atari": null, "disable_env_checking": false, "render_env": true, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 3, "create_local_env_runner": true, "num_envs_per_env_runner": 1, "gym_env_vectorize_mode": "SYNC", "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "episodes_to_numpy": true, "max_requests_in_flight_per_env_runner": 1, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "merge_env_runner_states": "training_only", "broadcast_env_runner_states": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "sampler_perf_stats_ema_coef": null, "_is_online": true, "num_learners": 0, "num_gpus_per_learner": 1, "num_cpus_per_learner": "auto", "num_aggregator_actors_per_learner": 0, "max_requests_in_flight_per_aggregator_actor": 3, "local_gpu_idx": 0, "max_requests_in_flight_per_learner": 3, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "_train_batch_size_per_learner": null, "train_batch_size": 4000, "num_epochs": 10, "minibatch_size": 256, "shuffle_batch_per_epoch": true, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "log_std_clip_param": 20.0, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1, "_disable_preprocessor_api": false, "_disable_action_flattening": false}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "_learner_class": null, "callbacks_on_algorithm_init": null, "callbacks_on_env_runners_recreated": null, "callbacks_on_offline_eval_runners_recreated": null, "callbacks_on_checkpoint_loaded": null, "callbacks_on_environment_created": null, "callbacks_on_episode_created": null, "callbacks_on_episode_start": null, "callbacks_on_episode_step": null, "callbacks_on_episode_end": null, "callbacks_on_evaluate_start": null, "callbacks_on_evaluate_end": null, "callbacks_on_evaluate_offline_start": null, "callbacks_on_evaluate_offline_end": null, "callbacks_on_sample_end": null, "callbacks_on_train_result": null, "explore": true, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "_prior_exploration_config": null, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function train.<locals>.<lambda> at 0x782de3e0b0a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "offline_data_class": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "input_read_episodes": false, "input_read_sample_batches": false, "input_read_batch_size": null, "input_filesystem": null, "input_filesystem_kwargs": {}, "input_compress_columns": ["obs", "new_obs"], "input_spaces_jsonable": true, "materialize_data": false, "materialize_mapped_data": true, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "ignore_final_observation": false, "prelearner_class": null, "prelearner_buffer_class": null, "prelearner_buffer_kwargs": {}, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "output_max_rows_per_file": null, "output_write_remaining_data": false, "output_write_method": "write_parquet", "output_write_method_kwargs": {}, "output_filesystem": null, "output_filesystem_kwargs": {}, "output_write_episodes": true, "offline_sampling": false, "evaluation_interval": 10, "evaluation_duration": 5, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_auto_duration_min_env_steps_per_sample": 100, "evaluation_auto_duration_max_env_steps_per_sample": 2000, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": {"explore": false}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "offline_evaluation_interval": null, "num_offline_eval_runners": 0, "offline_evaluation_type": null, "offline_eval_runner_class": null, "offline_loss_for_module_fn": null, "offline_evaluation_duration": 1, "offline_evaluation_parallel_to_training": false, "offline_evaluation_timeout_s": 120.0, "num_cpus_per_offline_eval_runner": 1, "num_gpus_per_offline_eval_runner": 0, "custom_resources_per_offline_eval_runner": {}, "restart_failed_offline_eval_runners": true, "ignore_offline_eval_runner_failures": false, "max_num_offline_eval_runner_restarts": 1000, "offline_eval_runner_restore_timeout_s": 1800.0, "max_requests_in_flight_per_offline_eval_runner": 1, "validate_offline_eval_runners_after_construction": true, "offline_eval_runner_health_probe_timeout_s": 30.0, "offline_eval_rl_module_inference_only": false, "broadcast_offline_eval_runner_states": false, "offline_eval_batch_size_per_runner": 256, "dataset_num_iters_per_eval_runner": 1, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "log_gradients": false, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "restart_failed_env_runners": true, "ignore_env_runner_failures": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30.0, "env_runner_restore_timeout_s": 1800.0, "_model_config": {}, "_rl_module_spec": null, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "_validate_config": true, "_use_msgpack_checkpoints": false, "_torch_grad_scaler_class": null, "_torch_lr_scheduler_classes": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "env_task_fn": -1, "enable_connectors": -1, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "clip_param": 0.2, "vf_clip_param": 10.0, "entropy_coeff_schedule": null, "lr_schedule": null, "sgd_minibatch_size": -1, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.95, "input": "sampler", "policies": {"agent_0": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_1": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_2": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_3": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_4": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_5": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_6": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_7": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_8": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_9": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_10": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_11": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_12": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_13": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_14": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_15": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_16": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_17": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_18": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_19": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_20": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}]}, "callbacks": "<class 'ray.rllib.callbacks.callbacks.RLlibCallback'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 152.5152678489685, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 9.513953488372092, "ram_util_percent": 28.71860465116278, "gpu_util_percent0": 0.20953488372093027, "vram_util_percent0": 0.09536928687472307}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_8": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.325883848965168, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.025877460595802405, "policy_loss": -0.04892137433635071, "vf_loss": 0.02010060783068184, "vf_explained_var": 0.9026119560003281, "kl": 0.009811020506822388, "entropy": 5.81775543987751, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 880.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_16": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.867075979709625, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.012080481841985602, "policy_loss": -0.051403428299818185, "vf_loss": 0.03580913770711049, "vf_explained_var": 0.9308287035673857, "kl": 0.011712694293328241, "entropy": 5.143245434761047, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 880.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_12": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.715974934399128, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.03896457155424286, "policy_loss": -0.055568693910026924, "vf_loss": 0.014077457555686124, "vf_explained_var": 0.7727896425873041, "kl": 0.008422216310828201, "entropy": 5.8180253356695175, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 880.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_9": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.810369327664375, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.004120671332930215, "policy_loss": -0.0449557053623721, "vf_loss": 0.0378827529901173, "vf_explained_var": 0.8963370501995087, "kl": 0.009840937228302515, "entropy": 5.7774668186903, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 880.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_18": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.511508983373642, "cur_kl_coeff": 0.45000000000000007, "cur_lr": 5.000000000000001e-05, "total_loss": -0.006680047456757166, "policy_loss": -0.05293033164343797, "vf_loss": 0.04109906469238922, "vf_explained_var": 0.9278672661632299, "kl": 0.011447154117563096, "entropy": 5.254668143391609, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 880.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_13": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.9445130065083505, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.02552019074646523, "policy_loss": -0.04881454023998231, "vf_loss": 0.020734207978239282, "vf_explained_var": 0.9544048178941011, "kl": 0.008533802588371785, "entropy": 5.819066652655602, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 880.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_3": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.929103821516037, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.033394166188372765, "policy_loss": -0.05313024108763784, "vf_loss": 0.017209572345018388, "vf_explained_var": 0.9381090570241213, "kl": 0.008421668796193538, "entropy": 5.789717358350754, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 880.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_15": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.084250912070274, "cur_kl_coeff": 0.45000000000000007, "cur_lr": 5.000000000000001e-05, "total_loss": 0.010569905219017527, "policy_loss": -0.05123681509285234, "vf_loss": 0.056071976863313465, "vf_explained_var": 0.9257583398371935, "kl": 0.012743874662830728, "entropy": 5.3667526006698605, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 880.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.7095365315675735, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.036885589790472295, "policy_loss": -0.053457419031474274, "vf_loss": 0.01405233962868806, "vf_explained_var": 0.9433404710143805, "kl": 0.00839829617481897, "entropy": 5.8052456200122835, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 880.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_7": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.407416772842407, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.03953639316750923, "policy_loss": -0.05798518425435759, "vf_loss": 0.015450859934207983, "vf_explained_var": 0.883885246515274, "kl": 0.009993107314971893, "entropy": 5.805803266167641, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 880.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_11": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.441049771010876, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.031249514316732528, "policy_loss": -0.052558639843482524, "vf_loss": 0.018497809913242236, "vf_explained_var": 0.9416177239269018, "kl": 0.009371051039658107, "entropy": 5.719743317365646, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 880.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_2": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.197447058558464, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.021543395958724433, "policy_loss": -0.04727128626254853, "vf_loss": 0.022959645465016366, "vf_explained_var": 0.9521559793502092, "kl": 0.009227486425515963, "entropy": 5.877851942181588, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 880.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_14": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.479313959181309, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.004949952666356694, "policy_loss": -0.050882744375849144, "vf_loss": 0.04246214769082144, "vf_explained_var": 0.8854693837463856, "kl": 0.011568814810917571, "entropy": 5.197022414207458, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 880.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_4": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.054039973020553, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.03666855115588987, "policy_loss": -0.05298601710528601, "vf_loss": 0.013754339440492914, "vf_explained_var": 0.9450866471976042, "kl": 0.008543753359316847, "entropy": 5.854490453004837, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 880.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_20": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.033988787233829, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.011875636714103166, "policy_loss": -0.04930000410240609, "vf_loss": 0.033860863937297835, "vf_explained_var": 0.9599889323115349, "kl": 0.0118783436817472, "entropy": 5.190995383262634, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 880.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_17": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.899699199199676, "cur_kl_coeff": 0.45000000000000007, "cur_lr": 5.000000000000001e-05, "total_loss": 0.00010983952670358121, "policy_loss": -0.0520496049997746, "vf_loss": 0.04723681861069053, "vf_explained_var": 0.8789351586252451, "kl": 0.010939168283539403, "entropy": 5.393995907902718, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 880.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_10": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.6235608965158463, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.029544839743175545, "policy_loss": -0.049161567473493054, "vf_loss": 0.017422978836111724, "vf_explained_var": 0.9229669850319624, "kl": 0.007312499209479029, "entropy": 5.8579712241888044, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 880.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_6": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.309162122011185, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.03861372672836296, "policy_loss": -0.05724424956715666, "vf_loss": 0.01584424214961473, "vf_explained_var": 0.9620422225445509, "kl": 0.009287599788305956, "entropy": 5.784202909469604, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 880.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_5": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.586349815130234, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.030923877876193728, "policy_loss": -0.05366074499324895, "vf_loss": 0.0198404041439062, "vf_explained_var": 0.9765337225049734, "kl": 0.009654876681224778, "entropy": 5.817906254529953, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 880.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.001361657679081, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.0349097691825591, "policy_loss": -0.05274537870427594, "vf_loss": 0.01501762175175827, "vf_explained_var": 0.8939868956804276, "kl": 0.009393294243276484, "entropy": 5.7270156115293505, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 880.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_19": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.671070441603661, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.015421936530037783, "policy_loss": -0.05257220384664833, "vf_loss": 0.03408130406169221, "vf_explained_var": 0.8929550476372242, "kl": 0.010229880876214615, "entropy": 5.609122014045715, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 880.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}}, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 504000, "num_agent_steps_trained": 504000}, "env_runners": {"episode_reward_max": -44.1999999999997, "episode_reward_min": -70.14000000000262, "episode_reward_mean": -56.872608695653625, "episode_len_mean": 500.0, "episode_media": {}, "episodes_timesteps_total": 23000, "policy_reward_min": {"agent_0": -5.3700000000000285, "agent_1": -5.300000000000027, "agent_2": -5.320000000000028, "agent_3": -5.350000000000028, "agent_4": -5.380000000000028, "agent_5": -5.330000000000028, "agent_6": -5.330000000000028, "agent_7": -5.3700000000000285, "agent_8": -5.330000000000028, "agent_9": -5.320000000000028, "agent_10": -5.340000000000028, "agent_11": -5.360000000000028, "agent_12": -5.340000000000028, "agent_13": -5.3700000000000285, "agent_14": -5.360000000000028, "agent_15": -5.300000000000027, "agent_16": -5.360000000000028, "agent_17": -5.360000000000028, "agent_18": -5.360000000000028, "agent_19": -5.310000000000027, "agent_20": -5.2100000000000275}, "policy_reward_max": {"agent_0": -0.5000000000000003, "agent_1": -0.5000000000000003, "agent_2": -0.5000000000000003, "agent_3": -0.5000000000000003, "agent_4": -0.5000000000000003, "agent_5": -0.5000000000000003, "agent_6": -0.5000000000000003, "agent_7": -0.5000000000000003, "agent_8": -0.5000000000000003, "agent_9": -0.5000000000000003, "agent_10": -0.5000000000000003, "agent_11": -0.5000000000000003, "agent_12": -0.5000000000000003, "agent_13": -0.5000000000000003, "agent_14": -3.66000000000001, "agent_15": -3.470000000000007, "agent_16": -3.3100000000000054, "agent_17": -3.7100000000000097, "agent_18": -3.66000000000001, "agent_19": -3.5200000000000085, "agent_20": -3.4600000000000075}, "policy_reward_mean": {"agent_0": -1.51847826086957, "agent_1": -1.604347826086962, "agent_2": -2.1658695652173994, "agent_3": -1.6786956521739198, "agent_4": -1.911304347826094, "agent_5": -1.4536956521739182, "agent_6": -1.7067391304347885, "agent_7": -1.7506521739130496, "agent_8": -1.576304347826093, "agent_9": -1.623478260869571, "agent_10": -1.92173913043479, "agent_11": -2.163695652173922, "agent_12": -1.8019565217391373, "agent_13": -2.14782608695653, "agent_14": -4.551739130434801, "agent_15": -4.58695652173915, "agent_16": -4.506304347826107, "agent_17": -4.623478260869585, "agent_18": -4.537173913043497, "agent_19": -4.641086956521759, "agent_20": -4.401086956521757}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-44.1999999999997, -47.869999999999905, -53.90000000000077, -56.50000000000109, -70.14000000000262, -58.4900000000023, -44.69999999999998, -64.51000000000346, -51.620000000000566, -65.79000000000308, -67.35000000000318, -53.23000000000039, -53.17000000000061, -56.740000000001125, -52.76000000000032, -62.44000000000218, -50.530000000001344, -63.63000000000317, -46.849999999999895, -67.7200000000026, -45.89999999999993, -53.600000000000826, -48.90999999999976, -59.22000000000259, -62.70000000000288, -66.84000000000268, -60.74000000000206, -61.32000000000323, -64.25000000000297, -62.580000000003146, -54.430000000001264, -56.92000000000129, -46.52000000000107, -51.0100000000003, -65.43000000000282, -50.4200000000003, -56.18000000000112, -47.1500000000003, -61.3600000000021, -70.07000000000218, -53.19000000000036, -59.090000000001254, -55.52000000000135, -53.760000000000396, -50.13999999999981, -66.75000000000264], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_agent_0_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.9300000000000007, -0.5000000000000003, -5.230000000000027, -0.5000000000000003, -5.210000000000027, -0.5000000000000003, -4.63000000000002, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.350000000000028, -0.5000000000000003, -0.5000000000000003, -1.409999999999997, -0.5000000000000003, -0.5000000000000003, -2.129999999999993, -5.290000000000028, -0.5000000000000003, -5.3700000000000285, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -3.2700000000000053, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.130000000000026, -0.5000000000000003, -4.700000000000021, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -4.700000000000021], "policy_agent_1_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -1.8899999999999926, -3.2700000000000053, -4.680000000000021, -0.5000000000000003, -5.280000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.070000000000025, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -1.4999999999999962, -0.5000000000000003, -0.5000000000000003, -5.180000000000026, -0.5000000000000003, -4.930000000000024, -0.8800000000000007, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.100000000000025, -0.5000000000000003, -4.6200000000000205, -5.140000000000025, -0.5000000000000003, -4.960000000000024, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.300000000000027], "policy_agent_2_reward": [-0.5000000000000003, -0.5000000000000003, -0.9700000000000008, -0.5000000000000003, -5.190000000000026, -0.5000000000000003, -4.590000000000019, -5.130000000000026, -4.100000000000015, -5.210000000000027, -5.180000000000026, -4.040000000000013, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.310000000000027, -0.5000000000000003, -5.280000000000027, -0.5000000000000003, -5.280000000000027, -4.910000000000023, -5.080000000000025, -0.5000000000000003, -0.5000000000000003, -5.320000000000028, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.200000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -1.8899999999999926, -5.290000000000028, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.280000000000027, -0.5000000000000003, -0.5000000000000003, -2.8800000000000012, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003], "policy_agent_3_reward": [-0.5000000000000003, -0.5000000000000003, -5.080000000000025, -5.200000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.250000000000027, -0.5000000000000003, -5.210000000000027, -0.5000000000000003, -5.130000000000026, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -4.1900000000000155, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -4.330000000000017, -5.350000000000028, -5.200000000000027, -0.5000000000000003, -5.250000000000027, -0.6500000000000005, -5.030000000000024, -0.5000000000000003, -4.850000000000023, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003], "policy_agent_4_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.090000000000026, -0.5000000000000003, -0.5000000000000003, -4.8600000000000225, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.190000000000026, -2.0999999999999925, -5.250000000000027, -0.5000000000000003, -0.5000000000000003, -5.160000000000026, -0.5000000000000003, -5.360000000000028, -0.5000000000000003, -5.150000000000026, -4.980000000000024, -0.5000000000000003, -0.5000000000000003, -4.970000000000024, -0.5000000000000003, -2.239999999999994, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -4.930000000000024, -1.8699999999999928, -0.5000000000000003, -5.380000000000028, -5.300000000000027, -0.5000000000000003, -5.090000000000026, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003], "policy_agent_5_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -4.990000000000024, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.130000000000026, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -4.7400000000000215, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.010000000000025, -4.360000000000017, -4.930000000000024, -0.5000000000000003, -0.5000000000000003, -4.730000000000022, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.330000000000028, -0.5000000000000003, -4.590000000000019, -0.5000000000000003, -5.060000000000025], "policy_agent_6_reward": [-0.5000000000000003, -0.5000000000000003, -0.6800000000000005, -5.330000000000028, -5.250000000000027, -4.890000000000023, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -1.3099999999999978, -0.5000000000000003, -0.9200000000000007, -0.5000000000000003, -5.260000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -4.370000000000017, -0.5000000000000003, -3.320000000000006, -5.250000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -1.189999999999999, -0.5000000000000003, -3.840000000000012, -0.5000000000000003, -0.5000000000000003, -1.8199999999999932, -0.5000000000000003, -5.160000000000026, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.110000000000025, -5.020000000000024, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.290000000000028, -0.5000000000000003, -0.5000000000000003], "policy_agent_7_reward": [-5.200000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -4.350000000000017, -4.870000000000023, -0.5000000000000003, -1.9199999999999924, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.3700000000000285, -0.5000000000000003, -0.5000000000000003, -5.230000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -4.1900000000000155, -5.350000000000028, -0.5000000000000003, -5.340000000000028, -5.170000000000027, -3.610000000000009, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -4.850000000000023, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.220000000000026, -3.860000000000012], "policy_agent_8_reward": [-0.5000000000000003, -5.200000000000027, -0.5000000000000003, -4.9400000000000235, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -3.4100000000000072, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.300000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.240000000000027, -5.240000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.300000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.200000000000027, -5.330000000000028, -0.5000000000000003, -0.5000000000000003, -4.840000000000023, -5.010000000000025, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003], "policy_agent_9_reward": [-0.5000000000000003, -0.5000000000000003, -5.210000000000027, -0.5000000000000003, -0.5000000000000003, -1.5299999999999958, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -1.5499999999999956, -5.310000000000027, -5.180000000000026, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.290000000000028, -0.5000000000000003, -5.320000000000028, -0.5000000000000003, -4.920000000000023, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.250000000000027, -5.180000000000026, -2.3899999999999957, -0.5000000000000003, -0.6200000000000004, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.250000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.250000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.9300000000000007, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003], "policy_agent_10_reward": [-0.5000000000000003, -0.5000000000000003, -3.710000000000011, -0.5000000000000003, -4.880000000000023, -0.5000000000000003, -0.5000000000000003, -5.340000000000028, -5.270000000000027, -4.890000000000023, -4.930000000000024, -0.5000000000000003, -5.110000000000025, -0.5000000000000003, -0.5000000000000003, -5.090000000000026, -1.729999999999994, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.300000000000027, -0.5000000000000003, -5.250000000000027, -0.5000000000000003, -0.5000000000000003, -5.150000000000026, -3.050000000000003, -0.5000000000000003, -5.010000000000025, -3.840000000000012, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -4.850000000000023, -0.5000000000000003], "policy_agent_11_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.300000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.030000000000024, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.270000000000027, -0.5000000000000003, -4.760000000000022, -4.380000000000018, -0.5000000000000003, -5.220000000000026, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.200000000000027, -4.64000000000002, -0.5000000000000003, -5.330000000000028, -5.180000000000026, -0.5000000000000003, -0.5000000000000003, -4.760000000000022, -0.8600000000000007, -0.5000000000000003, -0.5000000000000003, -5.360000000000028, -3.770000000000011, -5.310000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.200000000000027, -4.60000000000002, -0.5000000000000003, -0.5000000000000003, -5.360000000000028], "policy_agent_12_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.340000000000028, -5.260000000000027, -0.5000000000000003, -1.8599999999999928, -0.5000000000000003, -5.300000000000027, -5.190000000000026, -4.690000000000021, -0.5000000000000003, -5.080000000000025, -0.5000000000000003, -0.5000000000000003, -5.230000000000027, -2.77, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.230000000000027, -0.5000000000000003, -5.320000000000028, -0.5000000000000003, -5.120000000000026, -0.5000000000000003, -5.040000000000025, -0.7200000000000005, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.240000000000027], "policy_agent_13_reward": [-0.5000000000000003, -5.040000000000025, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.270000000000027, -0.5000000000000003, -5.270000000000027, -4.590000000000019, -5.310000000000027, -2.4199999999999964, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.9100000000000007, -0.5000000000000003, -0.5000000000000003, -5.100000000000025, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -2.309999999999995, -0.5000000000000003, -5.3700000000000285, -2.0699999999999923, -0.5000000000000003, -5.310000000000027, -5.180000000000026, -5.3700000000000285, -5.300000000000027, -4.930000000000024, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.350000000000028, -5.260000000000027, -0.5000000000000003, -0.5000000000000003, -4.9400000000000235, -0.5000000000000003, -0.5000000000000003], "policy_agent_14_reward": [-5.310000000000027, -4.650000000000021, -4.450000000000018, -4.63000000000002, -4.280000000000016, -4.600000000000021, -4.050000000000014, -5.240000000000027, -4.060000000000014, -3.66000000000001, -5.320000000000028, -4.880000000000023, -4.060000000000014, -5.330000000000028, -5.160000000000026, -3.6700000000000097, -4.840000000000023, -4.510000000000019, -4.790000000000022, -4.480000000000018, -3.7000000000000104, -5.140000000000026, -5.350000000000028, -4.810000000000022, -3.8000000000000114, -3.9900000000000135, -5.240000000000027, -4.410000000000018, -4.380000000000017, -4.610000000000021, -5.360000000000028, -3.870000000000011, -3.960000000000014, -4.6200000000000205, -4.930000000000024, -4.010000000000013, -3.9200000000000137, -5.320000000000028, -3.790000000000011, -5.340000000000028, -4.090000000000014, -4.980000000000024, -3.9000000000000123, -5.010000000000025, -4.7400000000000215, -4.140000000000015], "policy_agent_15_reward": [-4.710000000000021, -5.090000000000026, -4.7800000000000225, -5.120000000000026, -4.490000000000019, -4.330000000000018, -5.240000000000027, -4.9400000000000235, -5.230000000000027, -4.260000000000016, -3.470000000000007, -4.760000000000022, -4.040000000000013, -4.430000000000018, -4.470000000000018, -4.800000000000022, -4.990000000000024, -4.360000000000017, -4.680000000000021, -4.410000000000018, -4.8600000000000225, -4.780000000000022, -3.600000000000009, -4.1100000000000145, -5.090000000000026, -4.160000000000015, -4.760000000000022, -4.110000000000014, -4.210000000000016, -3.8300000000000116, -4.750000000000021, -4.870000000000023, -4.6200000000000205, -3.760000000000011, -4.830000000000022, -5.090000000000026, -4.240000000000016, -5.250000000000027, -4.240000000000016, -4.0700000000000145, -4.490000000000019, -4.360000000000017, -4.980000000000024, -5.070000000000025, -4.970000000000024, -5.300000000000027], "policy_agent_16_reward": [-5.040000000000025, -4.390000000000017, -5.360000000000028, -4.280000000000016, -4.080000000000014, -4.300000000000017, -3.760000000000011, -3.3100000000000054, -4.960000000000024, -3.8300000000000125, -3.860000000000012, -4.380000000000018, -3.980000000000014, -4.280000000000016, -4.430000000000018, -5.240000000000027, -4.210000000000017, -4.440000000000018, -4.710000000000021, -5.160000000000026, -4.340000000000017, -4.890000000000023, -3.9000000000000123, -3.950000000000013, -4.3800000000000185, -4.370000000000018, -4.750000000000021, -4.340000000000017, -4.3100000000000165, -4.840000000000022, -4.120000000000014, -4.450000000000018, -4.470000000000018, -4.60000000000002, -4.920000000000023, -4.2700000000000164, -4.490000000000019, -5.280000000000027, -4.710000000000021, -5.190000000000027, -4.090000000000014, -4.530000000000019, -5.130000000000026, -4.970000000000024, -5.350000000000028, -4.650000000000021], "policy_agent_17_reward": [-4.500000000000019, -5.070000000000025, -4.2700000000000164, -4.840000000000023, -4.560000000000019, -5.070000000000025, -3.850000000000012, -5.260000000000027, -4.61000000000002, -4.240000000000016, -4.780000000000022, -5.360000000000028, -5.350000000000028, -5.340000000000028, -4.790000000000022, -4.560000000000019, -4.480000000000018, -4.000000000000013, -4.050000000000014, -5.220000000000026, -3.7100000000000097, -4.64000000000002, -5.270000000000027, -4.300000000000018, -4.550000000000019, -4.9000000000000234, -4.300000000000017, -4.490000000000019, -4.560000000000019, -4.850000000000023, -4.370000000000017, -4.5000000000000195, -3.840000000000012, -4.340000000000017, -4.060000000000015, -4.780000000000022, -4.120000000000014, -5.080000000000025, -4.340000000000017, -5.170000000000027, -4.890000000000023, -4.700000000000021, -5.330000000000028, -5.200000000000027, -4.260000000000016, -3.9300000000000126], "policy_agent_18_reward": [-3.740000000000011, -4.300000000000016, -4.880000000000023, -4.490000000000019, -4.780000000000022, -3.740000000000011, -4.750000000000021, -4.3800000000000185, -4.460000000000019, -3.9100000000000135, -4.470000000000019, -5.360000000000028, -5.080000000000025, -3.8900000000000126, -4.54000000000002, -4.57000000000002, -4.52000000000002, -4.960000000000024, -4.9400000000000235, -4.52000000000002, -4.250000000000016, -5.120000000000025, -5.310000000000027, -5.280000000000027, -4.950000000000024, -4.54000000000002, -4.240000000000016, -3.66000000000001, -4.8600000000000225, -4.2300000000000155, -4.64000000000002, -3.950000000000013, -4.020000000000014, -4.180000000000016, -3.920000000000013, -4.430000000000018, -4.180000000000016, -5.040000000000025, -4.2700000000000164, -5.150000000000026, -4.7400000000000215, -5.290000000000028, -3.9100000000000126, -4.150000000000015, -4.790000000000022, -5.330000000000028], "policy_agent_19_reward": [-5.180000000000026, -4.280000000000016, -4.8200000000000225, -3.5200000000000085, -4.9000000000000234, -4.55000000000002, -5.170000000000027, -4.63000000000002, -4.1100000000000145, -4.9400000000000235, -3.9900000000000135, -4.8600000000000225, -4.350000000000017, -4.680000000000021, -3.7300000000000106, -4.130000000000015, -4.800000000000023, -4.62000000000002, -3.7000000000000104, -5.150000000000026, -4.720000000000021, -4.160000000000015, -5.110000000000025, -4.830000000000023, -4.000000000000013, -5.070000000000025, -4.64000000000002, -4.170000000000016, -4.8200000000000225, -3.9800000000000133, -4.650000000000021, -5.310000000000027, -3.950000000000013, -4.410000000000018, -4.480000000000018, -5.130000000000026, -4.990000000000024, -4.450000000000018, -5.120000000000026, -4.880000000000023, -5.050000000000025, -5.030000000000024, -5.290000000000028, -4.710000000000021, -5.210000000000027, -5.220000000000026], "policy_agent_20_reward": [-4.020000000000014, -3.850000000000012, -5.190000000000026, -4.160000000000015, -4.150000000000015, -4.1900000000000155, -4.020000000000014, -4.1900000000000155, -4.300000000000018, -4.780000000000022, -3.860000000000012, -4.220000000000016, -4.700000000000021, -4.980000000000024, -4.980000000000024, -4.9400000000000235, -3.4600000000000075, -4.64000000000002, -3.890000000000012, -4.1900000000000155, -4.250000000000016, -5.140000000000025, -3.760000000000011, -4.200000000000016, -4.100000000000015, -4.440000000000018, -5.2100000000000275, -3.8300000000000116, -3.940000000000013, -4.240000000000016, -4.810000000000022, -4.330000000000017, -3.9600000000000133, -4.260000000000016, -4.130000000000015, -4.8200000000000225, -4.700000000000021, -4.020000000000015, -5.150000000000026, -4.8200000000000225, -4.750000000000021, -5.010000000000025, -4.130000000000016, -4.330000000000017, -4.750000000000021, -4.660000000000021]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.9221825675663375, "mean_inference_ms": 9.132544495168153, "mean_action_processing_ms": 0.6937512306191522, "mean_env_wait_ms": 2.7558891323794197, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0022239319779611276, "StateBufferConnector_ms": 0.0014817986182297732, "ViewRequirementAgentConnector_ms": 0.0329091435387021}, "num_episodes": 7, "episode_return_max": -44.1999999999997, "episode_return_min": -70.14000000000262, "episode_return_mean": -56.872608695653625, "episodes_this_iter": 7}, "num_healthy_workers": 3, "actor_manager_num_outstanding_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 504000, "num_agent_steps_trained": 504000, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 131.1529920957829, "num_env_steps_trained_throughput_per_sec": 131.1529920957829, "timesteps_total": 24000, "num_env_steps_sampled_lifetime": 24000, "num_agent_steps_sampled_lifetime": 504000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 504000, "timers": {"training_iteration_time_ms": 30492.109, "restore_workers_time_ms": 0.014, "training_step_time_ms": 30492.064, "sample_time_ms": 20053.446, "learn_time_ms": 10418.953, "learn_throughput": 383.916, "synch_weights_time_ms": 17.023}, "counters": {"num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 504000, "num_agent_steps_trained": 504000}, "done": false, "training_iteration": 6, "trial_id": "39fd7_00000", "date": "2025-10-21_11-16-48", "timestamp": 1761038208, "time_this_iter_s": 30.50886058807373, "time_total_s": 183.02412843704224, "pid": 3259979, "hostname": "xuezhi-Precision-3660", "node_ip": "130.238.16.41", "config": {"exploration_config": {"type": "StochasticSampling"}, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 1, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "torch_ddp_kwargs": {}, "torch_skip_nan_gradients": false, "env": "<class 'train_utils.WarehouseMultiAgentEnv'>", "env_config": {"env_id": "tarware-extralarge-14agvs-7pickers-partialobs-chg-v1"}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "_is_atari": null, "disable_env_checking": false, "render_env": true, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 3, "create_local_env_runner": true, "num_envs_per_env_runner": 1, "gym_env_vectorize_mode": "SYNC", "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "episodes_to_numpy": true, "max_requests_in_flight_per_env_runner": 1, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "merge_env_runner_states": "training_only", "broadcast_env_runner_states": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "sampler_perf_stats_ema_coef": null, "_is_online": true, "num_learners": 0, "num_gpus_per_learner": 1, "num_cpus_per_learner": "auto", "num_aggregator_actors_per_learner": 0, "max_requests_in_flight_per_aggregator_actor": 3, "local_gpu_idx": 0, "max_requests_in_flight_per_learner": 3, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "_train_batch_size_per_learner": null, "train_batch_size": 4000, "num_epochs": 10, "minibatch_size": 256, "shuffle_batch_per_epoch": true, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "log_std_clip_param": 20.0, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1, "_disable_preprocessor_api": false, "_disable_action_flattening": false}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "_learner_class": null, "callbacks_on_algorithm_init": null, "callbacks_on_env_runners_recreated": null, "callbacks_on_offline_eval_runners_recreated": null, "callbacks_on_checkpoint_loaded": null, "callbacks_on_environment_created": null, "callbacks_on_episode_created": null, "callbacks_on_episode_start": null, "callbacks_on_episode_step": null, "callbacks_on_episode_end": null, "callbacks_on_evaluate_start": null, "callbacks_on_evaluate_end": null, "callbacks_on_evaluate_offline_start": null, "callbacks_on_evaluate_offline_end": null, "callbacks_on_sample_end": null, "callbacks_on_train_result": null, "explore": true, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "_prior_exploration_config": null, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function train.<locals>.<lambda> at 0x782de3b3dd80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "offline_data_class": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "input_read_episodes": false, "input_read_sample_batches": false, "input_read_batch_size": null, "input_filesystem": null, "input_filesystem_kwargs": {}, "input_compress_columns": ["obs", "new_obs"], "input_spaces_jsonable": true, "materialize_data": false, "materialize_mapped_data": true, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "ignore_final_observation": false, "prelearner_class": null, "prelearner_buffer_class": null, "prelearner_buffer_kwargs": {}, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "output_max_rows_per_file": null, "output_write_remaining_data": false, "output_write_method": "write_parquet", "output_write_method_kwargs": {}, "output_filesystem": null, "output_filesystem_kwargs": {}, "output_write_episodes": true, "offline_sampling": false, "evaluation_interval": 10, "evaluation_duration": 5, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_auto_duration_min_env_steps_per_sample": 100, "evaluation_auto_duration_max_env_steps_per_sample": 2000, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": {"explore": false}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "offline_evaluation_interval": null, "num_offline_eval_runners": 0, "offline_evaluation_type": null, "offline_eval_runner_class": null, "offline_loss_for_module_fn": null, "offline_evaluation_duration": 1, "offline_evaluation_parallel_to_training": false, "offline_evaluation_timeout_s": 120.0, "num_cpus_per_offline_eval_runner": 1, "num_gpus_per_offline_eval_runner": 0, "custom_resources_per_offline_eval_runner": {}, "restart_failed_offline_eval_runners": true, "ignore_offline_eval_runner_failures": false, "max_num_offline_eval_runner_restarts": 1000, "offline_eval_runner_restore_timeout_s": 1800.0, "max_requests_in_flight_per_offline_eval_runner": 1, "validate_offline_eval_runners_after_construction": true, "offline_eval_runner_health_probe_timeout_s": 30.0, "offline_eval_rl_module_inference_only": false, "broadcast_offline_eval_runner_states": false, "offline_eval_batch_size_per_runner": 256, "dataset_num_iters_per_eval_runner": 1, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "log_gradients": false, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "restart_failed_env_runners": true, "ignore_env_runner_failures": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30.0, "env_runner_restore_timeout_s": 1800.0, "_model_config": {}, "_rl_module_spec": null, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "_validate_config": true, "_use_msgpack_checkpoints": false, "_torch_grad_scaler_class": null, "_torch_lr_scheduler_classes": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "env_task_fn": -1, "enable_connectors": -1, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "clip_param": 0.2, "vf_clip_param": 10.0, "entropy_coeff_schedule": null, "lr_schedule": null, "sgd_minibatch_size": -1, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.95, "input": "sampler", "policies": {"agent_0": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_1": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_2": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_3": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_4": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_5": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_6": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_7": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_8": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_9": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_10": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_11": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_12": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_13": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_14": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_15": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_16": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_17": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_18": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_19": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_20": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}]}, "callbacks": "<class 'ray.rllib.callbacks.callbacks.RLlibCallback'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 183.02412843704224, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 9.276190476190475, "ram_util_percent": 27.72142857142857, "gpu_util_percent0": 0.23642857142857143, "vram_util_percent0": 0.09475422802242539}}
