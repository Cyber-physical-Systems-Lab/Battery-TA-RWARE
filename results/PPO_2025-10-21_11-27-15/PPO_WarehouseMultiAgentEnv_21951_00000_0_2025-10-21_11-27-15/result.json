{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_8": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 17.266673697531225, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 1.912749481573701, "policy_loss": 0.2678333709947765, "vf_loss": 1.398474855720997, "vf_explained_var": 0.6023866236209869, "kl": 1.232206266373396, "entropy": 5.6581295996904375, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 80.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_3": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 19.2765034198761, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 0.8623014410957694, "policy_loss": 0.25071155233308673, "vf_loss": 0.33934872917598113, "vf_explained_var": 0.811811687797308, "kl": 1.3612058013677597, "entropy": 5.662417912483216, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 80.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_13": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 13.196428109705447, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 4.02763005644083, "policy_loss": 0.2927488387562335, "vf_loss": 3.487608700990677, "vf_explained_var": 0.14613339863717556, "kl": 1.2363625675439835, "entropy": 5.880098813772202, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 80.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_14": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 20.192493650317193, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 2.0833961732685564, "policy_loss": 0.33410715735517443, "vf_loss": 1.2823597366455943, "vf_explained_var": 0.8296544820070266, "kl": 2.3346463821828367, "entropy": 5.195355021953583, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 80.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_9": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 13.034267295897006, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 0.7796917239204049, "policy_loss": 0.282958878390491, "vf_loss": 0.1895460644736886, "vf_explained_var": 0.7921521380543709, "kl": 1.5359338596463203, "entropy": 5.592905443906784, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 80.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_5": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 22.068405029177665, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 1.1371217612177134, "policy_loss": 0.3729673271998763, "vf_loss": 0.46821719422005115, "vf_explained_var": 0.6680873487144708, "kl": 1.4796861238777637, "entropy": 5.823843744397164, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 80.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 12.893773598968982, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 1.0383264098316431, "policy_loss": 0.2804919536691159, "vf_loss": 0.4757853014743887, "vf_explained_var": 0.8916256122291089, "kl": 1.4102457873523235, "entropy": 5.697649341821671, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 80.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_2": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 11.339051720499992, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 0.8609419148415327, "policy_loss": 0.2836095533333719, "vf_loss": 0.30976579553680494, "vf_explained_var": 0.8745932832360268, "kl": 1.3378328174352645, "entropy": 5.680043157935143, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 80.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_15": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 12.749152809381485, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 1.2486518044024706, "policy_loss": 0.3335559335537255, "vf_loss": 0.4163617027690634, "vf_explained_var": 0.8558564029633999, "kl": 2.4936707824468614, "entropy": 5.370348918437958, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 80.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_4": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 24.00425755828619, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 1.0384707326069473, "policy_loss": 0.2703935275785625, "vf_loss": 0.5262323212111368, "vf_explained_var": 0.7323980685323477, "kl": 1.2092243161052465, "entropy": 5.785391330718994, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 80.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_6": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 15.803759545087814, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 1.0367766723036766, "policy_loss": 0.3036585438065231, "vf_loss": 0.534283936326392, "vf_explained_var": 0.7232303645461797, "kl": 0.9941709924489259, "entropy": 5.845677587389946, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 80.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_17": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 18.578431689739226, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 2.676910500973463, "policy_loss": 0.41167367063462734, "vf_loss": 1.6362798772752285, "vf_explained_var": 0.6447305768728256, "kl": 3.1447847485542297, "entropy": 5.171684184670449, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 80.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_11": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 14.246959300339222, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 0.9532715782523156, "policy_loss": 0.27838723969180135, "vf_loss": 0.4431702871341258, "vf_explained_var": 0.8812451377511025, "kl": 1.1585702091455459, "entropy": 5.791368904709816, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 80.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_12": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 13.45315557718277, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 1.047021115384996, "policy_loss": 0.3049146162811667, "vf_loss": 0.5159893227741122, "vf_explained_var": 0.8781603563576936, "kl": 1.1305858861654996, "entropy": 5.751939103007317, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 80.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_7": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 15.631174229085445, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 0.9515332283452154, "policy_loss": 0.3289456249214709, "vf_loss": 0.35840720443520696, "vf_explained_var": 0.7825770892202855, "kl": 1.320901955664158, "entropy": 5.794049686193466, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 80.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_19": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 63.56436614990234, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 3.7539526641368868, "policy_loss": 0.8913074555806816, "vf_loss": 2.1171680986881256, "vf_explained_var": 0.5953539475798607, "kl": 3.7273855924606325, "entropy": 4.501098313927651, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 80.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_10": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.028745637834072, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 0.6412949849851429, "policy_loss": 0.25473324714694173, "vf_loss": 0.18618293947074563, "vf_explained_var": 0.9306786961853504, "kl": 1.001893975585699, "entropy": 5.75657852590084, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 80.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_20": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 18.559524789452553, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 1.3155425686389208, "policy_loss": 0.3360132156405598, "vf_loss": 0.3906945665832609, "vf_explained_var": 0.7499874081462622, "kl": 2.9441739127039908, "entropy": 5.165288844704628, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 80.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 18.290300746262073, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 1.0963908672332763, "policy_loss": 0.2798730296548456, "vf_loss": 0.568675288988743, "vf_explained_var": 0.8425313573330641, "kl": 1.2392126761376858, "entropy": 5.742567920684815, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 80.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_16": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 29.77094351798296, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 1.4426046423614025, "policy_loss": 0.3975033051334321, "vf_loss": 0.575622373027727, "vf_explained_var": 0.46746392622590066, "kl": 2.3473946802318095, "entropy": 5.243687143921852, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 80.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_18": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 18.60914866030216, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 1.454843719676137, "policy_loss": 0.3348616022616625, "vf_loss": 0.46071540396660565, "vf_explained_var": 0.7534473378211259, "kl": 3.2963335052132607, "entropy": 4.677692371606827, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 80.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}}, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 84000, "num_agent_steps_trained": 84000}, "env_runners": {"episode_reward_max": -45.52000000000064, "episode_reward_min": -74.55000000000193, "episode_reward_mean": -57.31333333333469, "episode_len_mean": 500.0, "episode_media": {}, "episodes_timesteps_total": 3000, "policy_reward_min": {"agent_0": -5.180000000000026, "agent_1": -1.2399999999999987, "agent_2": -5.350000000000028, "agent_3": -5.300000000000027, "agent_4": -5.350000000000028, "agent_5": -5.340000000000028, "agent_6": -5.240000000000027, "agent_7": -5.250000000000027, "agent_8": -5.310000000000027, "agent_9": -4.840000000000023, "agent_10": -3.950000000000013, "agent_11": -5.210000000000027, "agent_12": -5.330000000000028, "agent_13": -5.330000000000028, "agent_14": -4.970000000000024, "agent_15": -5.000000000000024, "agent_16": -5.240000000000028, "agent_17": -4.750000000000021, "agent_18": -4.870000000000023, "agent_19": -5.020000000000024, "agent_20": -4.790000000000022}, "policy_reward_max": {"agent_0": -0.5000000000000003, "agent_1": -0.5000000000000003, "agent_2": -0.5000000000000003, "agent_3": -0.5000000000000003, "agent_4": -0.5000000000000003, "agent_5": -0.5000000000000003, "agent_6": -0.5000000000000003, "agent_7": -0.5000000000000003, "agent_8": -0.5000000000000003, "agent_9": -0.5000000000000003, "agent_10": -0.5000000000000003, "agent_11": -0.5000000000000003, "agent_12": -0.5000000000000003, "agent_13": -0.5000000000000003, "agent_14": -3.8100000000000125, "agent_15": -3.600000000000009, "agent_16": -3.8200000000000127, "agent_17": -4.130000000000015, "agent_18": -3.580000000000009, "agent_19": -3.4900000000000078, "agent_20": -3.5500000000000087}, "policy_reward_mean": {"agent_0": -2.0916666666666757, "agent_1": -0.6233333333333334, "agent_2": -2.0450000000000084, "agent_3": -2.0566666666666755, "agent_4": -2.905000000000013, "agent_5": -3.0566666666666795, "agent_6": -1.7133333333333376, "agent_7": -1.2916666666666714, "agent_8": -2.0283333333333418, "agent_9": -1.2233333333333374, "agent_10": -1.5966666666666705, "agent_11": -1.2850000000000046, "agent_12": -2.7633333333333456, "agent_13": -2.096666666666676, "agent_14": -4.510000000000019, "agent_15": -4.436666666666684, "agent_16": -4.48500000000002, "agent_17": -4.440000000000018, "agent_18": -4.208333333333349, "agent_19": -4.371666666666685, "agent_20": -4.085000000000014}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-51.580000000000936, -45.52000000000064, -56.42000000000127, -56.4600000000011, -74.55000000000193, -59.35000000000224], "episode_lengths": [500, 500, 500, 500, 500, 500], "policy_agent_0_reward": [-0.5000000000000003, -5.180000000000026, -5.090000000000026, -0.5000000000000003, -0.5000000000000003, -0.7800000000000006], "policy_agent_1_reward": [-0.5000000000000003, -1.2399999999999987, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003], "policy_agent_2_reward": [-4.920000000000023, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.350000000000028, -0.5000000000000003], "policy_agent_3_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.300000000000027, -5.040000000000025], "policy_agent_4_reward": [-0.5000000000000003, -0.5000000000000003, -4.830000000000022, -5.220000000000026, -5.350000000000028, -1.0300000000000005], "policy_agent_5_reward": [-0.5000000000000003, -1.519999999999996, -0.5000000000000003, -5.330000000000028, -5.340000000000028, -5.150000000000026], "policy_agent_6_reward": [-2.669999999999999, -0.5000000000000003, -0.8700000000000007, -0.5000000000000003, -5.240000000000027, -0.5000000000000003], "policy_agent_7_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.250000000000027, -0.5000000000000003], "policy_agent_8_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -4.8600000000000225, -0.5000000000000003, -5.310000000000027], "policy_agent_9_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -4.840000000000023], "policy_agent_10_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -3.950000000000013, -3.6300000000000097], "policy_agent_11_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.210000000000027, -0.5000000000000003, -0.5000000000000003], "policy_agent_12_reward": [-5.330000000000028, -0.5000000000000003, -5.310000000000027, -0.5000000000000003, -4.440000000000018, -0.5000000000000003], "policy_agent_13_reward": [-5.250000000000027, -0.5000000000000003, -5.330000000000028, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003], "policy_agent_14_reward": [-4.3100000000000165, -4.970000000000024, -4.1900000000000155, -4.850000000000023, -4.930000000000024, -3.8100000000000125], "policy_agent_15_reward": [-3.600000000000009, -4.330000000000018, -5.000000000000024, -4.360000000000017, -4.550000000000019, -4.780000000000022], "policy_agent_16_reward": [-5.240000000000028, -3.8200000000000127, -4.370000000000017, -4.870000000000023, -4.090000000000014, -4.520000000000019], "policy_agent_17_reward": [-4.130000000000015, -4.560000000000019, -4.450000000000018, -4.210000000000016, -4.54000000000002, -4.750000000000021], "policy_agent_18_reward": [-3.580000000000009, -4.870000000000023, -4.180000000000016, -3.890000000000012, -4.490000000000019, -4.240000000000016], "policy_agent_19_reward": [-3.4900000000000078, -5.020000000000024, -4.750000000000022, -4.810000000000023, -3.940000000000013, -4.220000000000016], "policy_agent_20_reward": [-4.060000000000014, -4.510000000000019, -3.5500000000000087, -3.850000000000012, -4.790000000000022, -3.750000000000012]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.8277954359929065, "mean_inference_ms": 8.89465329819617, "mean_action_processing_ms": 0.7169887815074975, "mean_env_wait_ms": 2.683987721951721, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0024326263912140375, "StateBufferConnector_ms": 0.001327953641376798, "ViewRequirementAgentConnector_ms": 0.02961291207207574}, "num_episodes": 6, "episode_return_max": -45.52000000000064, "episode_return_min": -74.55000000000193, "episode_return_mean": -57.31333333333469, "episodes_this_iter": 6}, "num_healthy_workers": 3, "actor_manager_num_outstanding_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 84000, "num_agent_steps_trained": 84000, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 134.72863515193234, "num_env_steps_trained_throughput_per_sec": 134.72863515193234, "timesteps_total": 4000, "num_env_steps_sampled_lifetime": 4000, "num_agent_steps_sampled_lifetime": 84000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 84000, "timers": {"training_iteration_time_ms": 29689.318, "restore_workers_time_ms": 0.016, "training_step_time_ms": 29689.266, "sample_time_ms": 19229.307, "learn_time_ms": 10436.52, "learn_throughput": 383.27, "synch_weights_time_ms": 21.129}, "counters": {"num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 84000, "num_agent_steps_trained": 84000}, "done": false, "training_iteration": 1, "trial_id": "21951_00000", "date": "2025-10-21_11-27-53", "timestamp": 1761038873, "time_this_iter_s": 29.700037240982056, "time_total_s": 29.700037240982056, "pid": 3303346, "hostname": "xuezhi-Precision-3660", "node_ip": "130.238.16.41", "config": {"exploration_config": {"type": "StochasticSampling"}, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 1, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "torch_ddp_kwargs": {}, "torch_skip_nan_gradients": false, "env": "<class 'train_utils.WarehouseMultiAgentEnv'>", "env_config": {"env_id": "tarware-extralarge-14agvs-7pickers-partialobs-chg-v1"}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "_is_atari": null, "disable_env_checking": false, "render_env": true, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 3, "create_local_env_runner": true, "num_envs_per_env_runner": 1, "gym_env_vectorize_mode": "SYNC", "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "episodes_to_numpy": true, "max_requests_in_flight_per_env_runner": 1, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "merge_env_runner_states": "training_only", "broadcast_env_runner_states": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "sampler_perf_stats_ema_coef": null, "_is_online": true, "num_learners": 0, "num_gpus_per_learner": 1, "num_cpus_per_learner": "auto", "num_aggregator_actors_per_learner": 0, "max_requests_in_flight_per_aggregator_actor": 3, "local_gpu_idx": 0, "max_requests_in_flight_per_learner": 3, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "_train_batch_size_per_learner": null, "train_batch_size": 4000, "num_epochs": 10, "minibatch_size": 256, "shuffle_batch_per_epoch": true, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "log_std_clip_param": 20.0, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1, "_disable_preprocessor_api": false, "_disable_action_flattening": false}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "_learner_class": null, "callbacks_on_algorithm_init": null, "callbacks_on_env_runners_recreated": null, "callbacks_on_offline_eval_runners_recreated": null, "callbacks_on_checkpoint_loaded": null, "callbacks_on_environment_created": null, "callbacks_on_episode_created": null, "callbacks_on_episode_start": null, "callbacks_on_episode_step": null, "callbacks_on_episode_end": null, "callbacks_on_evaluate_start": null, "callbacks_on_evaluate_end": null, "callbacks_on_evaluate_offline_start": null, "callbacks_on_evaluate_offline_end": null, "callbacks_on_sample_end": null, "callbacks_on_train_result": null, "explore": true, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "_prior_exploration_config": null, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function train.<locals>.<lambda> at 0x7ec4385fa440>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "offline_data_class": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "input_read_episodes": false, "input_read_sample_batches": false, "input_read_batch_size": null, "input_filesystem": null, "input_filesystem_kwargs": {}, "input_compress_columns": ["obs", "new_obs"], "input_spaces_jsonable": true, "materialize_data": false, "materialize_mapped_data": true, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "ignore_final_observation": false, "prelearner_class": null, "prelearner_buffer_class": null, "prelearner_buffer_kwargs": {}, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "output_max_rows_per_file": null, "output_write_remaining_data": false, "output_write_method": "write_parquet", "output_write_method_kwargs": {}, "output_filesystem": null, "output_filesystem_kwargs": {}, "output_write_episodes": true, "offline_sampling": false, "evaluation_interval": 10, "evaluation_duration": 5, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_auto_duration_min_env_steps_per_sample": 100, "evaluation_auto_duration_max_env_steps_per_sample": 2000, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": {"explore": false}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "offline_evaluation_interval": null, "num_offline_eval_runners": 0, "offline_evaluation_type": null, "offline_eval_runner_class": null, "offline_loss_for_module_fn": null, "offline_evaluation_duration": 1, "offline_evaluation_parallel_to_training": false, "offline_evaluation_timeout_s": 120.0, "num_cpus_per_offline_eval_runner": 1, "num_gpus_per_offline_eval_runner": 0, "custom_resources_per_offline_eval_runner": {}, "restart_failed_offline_eval_runners": true, "ignore_offline_eval_runner_failures": false, "max_num_offline_eval_runner_restarts": 1000, "offline_eval_runner_restore_timeout_s": 1800.0, "max_requests_in_flight_per_offline_eval_runner": 1, "validate_offline_eval_runners_after_construction": true, "offline_eval_runner_health_probe_timeout_s": 30.0, "offline_eval_rl_module_inference_only": false, "broadcast_offline_eval_runner_states": false, "offline_eval_batch_size_per_runner": 256, "dataset_num_iters_per_eval_runner": 1, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "log_gradients": false, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "restart_failed_env_runners": true, "ignore_env_runner_failures": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30.0, "env_runner_restore_timeout_s": 1800.0, "_model_config": {}, "_rl_module_spec": null, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "_validate_config": true, "_use_msgpack_checkpoints": false, "_torch_grad_scaler_class": null, "_torch_lr_scheduler_classes": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "env_task_fn": -1, "enable_connectors": -1, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "clip_param": 0.2, "vf_clip_param": 10.0, "entropy_coeff_schedule": null, "lr_schedule": null, "sgd_minibatch_size": -1, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.95, "input": "sampler", "policies": {"agent_0": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_1": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_2": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_3": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_4": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_5": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_6": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_7": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_8": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_9": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_10": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_11": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_12": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_13": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_14": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_15": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_16": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_17": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_18": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_19": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_20": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}]}, "callbacks": "<class 'ray.rllib.callbacks.callbacks.RLlibCallback'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 29.700037240982056, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 8.454761904761904, "ram_util_percent": 25.576190476190476, "gpu_util_percent0": 0.2314285714285714, "vram_util_percent0": 0.08497336404029125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_8": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.7513717919588085, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.010883082225336693, "policy_loss": -0.04707439043559134, "vf_loss": 0.033502137096365917, "vf_explained_var": 0.90639891885221, "kl": 0.008963900686831039, "entropy": 5.866344311833382, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 240.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_3": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.195921909809113, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.005273456295253709, "policy_loss": -0.04516509855457116, "vf_loss": 0.03722339884843677, "vf_explained_var": 0.9000306699424983, "kl": 0.008894144413531946, "entropy": 5.850503665208817, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 240.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_13": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.096417216956615, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.008628408599179238, "policy_loss": -0.04461695885838708, "vf_loss": 0.03304535448551178, "vf_explained_var": 0.9078593987971544, "kl": 0.009810656193894828, "entropy": 5.9458595484495165, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 240.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_14": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.107058182358742, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": 0.05561259220994543, "policy_loss": -0.04486880516051315, "vf_loss": 0.0956887636333704, "vf_explained_var": 0.9375937730073929, "kl": 0.015975442410842623, "entropy": 5.4539883643388745, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 240.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_9": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.99122359007597, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": 0.003932653108495288, "policy_loss": -0.04522024888574379, "vf_loss": 0.045504886721028016, "vf_explained_var": 0.8874105107039213, "kl": 0.012160054477717664, "entropy": 5.797430646419525, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 240.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_5": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.085206365585327, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": 0.020282293151831256, "policy_loss": -0.03536650963069406, "vf_loss": 0.05319809154607356, "vf_explained_var": 0.9341958925127983, "kl": 0.00816903651057146, "entropy": 5.931694453954696, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 240.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.305714531242847, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.0019296447120723315, "policy_loss": -0.04827681069436949, "vf_loss": 0.04294400090002455, "vf_explained_var": 0.9359269592911005, "kl": 0.01134388477058792, "entropy": 5.834829559922218, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 240.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_2": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.167686569690704, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": 0.006350690103136003, "policy_loss": -0.047406011194107124, "vf_loss": 0.05034961107885465, "vf_explained_var": 0.9107765138149262, "kl": 0.011356966983311881, "entropy": 5.831650638580323, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 240.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_15": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.963249397277832, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": 0.00913555172883207, "policy_loss": -0.04708558102029201, "vf_loss": 0.05223456474486739, "vf_explained_var": 0.9145101215690374, "kl": 0.01328855842181682, "entropy": 5.486091634631157, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 240.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_4": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.404020828008652, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.017187066852056888, "policy_loss": -0.04728503709775396, "vf_loss": 0.02756355901947245, "vf_explained_var": 0.8396760404109955, "kl": 0.008448034542460245, "entropy": 5.868224167823792, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 240.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_6": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.525499371439219, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": 0.014825949695659802, "policy_loss": -0.03556231783586554, "vf_loss": 0.04770884515019134, "vf_explained_var": 0.8905378349125386, "kl": 0.008931410614885093, "entropy": 5.952022132277489, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 240.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_17": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.430921128392219, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": 0.032793041587865446, "policy_loss": -0.04366967446985655, "vf_loss": 0.07221448310883716, "vf_explained_var": 0.9270023968070745, "kl": 0.014160772199447221, "entropy": 5.582088762521744, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 240.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_11": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.367885966598988, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": 0.0063726505119120706, "policy_loss": -0.04346115171574638, "vf_loss": 0.047050955833401534, "vf_explained_var": 0.9216853301972151, "kl": 0.009276152484631156, "entropy": 5.950122925639152, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 240.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_12": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.9642467498779297, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.005072640493744984, "policy_loss": -0.04690074185782578, "vf_loss": 0.038527219666866584, "vf_explained_var": 0.961366669088602, "kl": 0.01100293540161873, "entropy": 5.9127748101949695, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 240.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_7": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.233117835223675, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.015288263399270363, "policy_loss": -0.04927478625031654, "vf_loss": 0.03144827439100482, "vf_explained_var": 0.920455177500844, "kl": 0.008460829148929854, "entropy": 5.900209352374077, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 240.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_19": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.665655905008316, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": 0.09079080121882725, "policy_loss": -0.0292431498557562, "vf_loss": 0.11557742143049836, "vf_explained_var": 0.9373989541083574, "kl": 0.014855096803338342, "entropy": 4.826420444250107, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 240.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_10": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.672328183054924, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.014478442828112748, "policy_loss": -0.04589362131373491, "vf_loss": 0.028559078584657983, "vf_explained_var": 0.9675710611045361, "kl": 0.009520334304376089, "entropy": 5.932765227556229, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 240.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_20": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 10.56097187846899, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": 0.03748181846312946, "policy_loss": -0.046587459591683, "vf_loss": 0.07951030823169276, "vf_explained_var": 0.8967395398765803, "kl": 0.015196566113034719, "entropy": 5.485957631468773, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 240.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.8905621215701105, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.008522707750671543, "policy_loss": -0.04360491302795708, "vf_loss": 0.03233917928300798, "vf_explained_var": 0.9084282409399748, "kl": 0.00914342067593163, "entropy": 5.8741401642560955, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 240.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_16": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.231877914071083, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": 0.03216696794697782, "policy_loss": -0.05024713609891478, "vf_loss": 0.0786105023813434, "vf_explained_var": 0.8940635029226541, "kl": 0.01267867424375133, "entropy": 5.542787203192711, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 240.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_18": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.509040638804436, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": 0.01947889065486379, "policy_loss": -0.04686304486822337, "vf_loss": 0.06231863159919158, "vf_explained_var": 0.90450927503407, "kl": 0.013411012492773433, "entropy": 5.252370193600655, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 240.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}}, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 168000, "num_agent_steps_trained": 168000}, "env_runners": {"episode_reward_max": -37.26000000000046, "episode_reward_min": -78.1400000000011, "episode_reward_mean": -57.63600000000145, "episode_len_mean": 500.0, "episode_media": {}, "episodes_timesteps_total": 7500, "policy_reward_min": {"agent_0": -5.180000000000026, "agent_1": -5.310000000000027, "agent_2": -5.350000000000028, "agent_3": -5.300000000000027, "agent_4": -5.350000000000028, "agent_5": -5.350000000000028, "agent_6": -5.310000000000027, "agent_7": -5.250000000000027, "agent_8": -5.310000000000027, "agent_9": -5.270000000000027, "agent_10": -5.300000000000027, "agent_11": -5.290000000000028, "agent_12": -5.330000000000028, "agent_13": -5.3700000000000285, "agent_14": -5.340000000000028, "agent_15": -5.350000000000028, "agent_16": -5.290000000000028, "agent_17": -5.000000000000024, "agent_18": -5.170000000000027, "agent_19": -5.270000000000027, "agent_20": -4.910000000000023}, "policy_reward_max": {"agent_0": -0.5000000000000003, "agent_1": -0.5000000000000003, "agent_2": -0.5000000000000003, "agent_3": -0.5000000000000003, "agent_4": -0.5000000000000003, "agent_5": -0.5000000000000003, "agent_6": -0.5000000000000003, "agent_7": -0.5000000000000003, "agent_8": -0.5000000000000003, "agent_9": -0.5000000000000003, "agent_10": -0.5000000000000003, "agent_11": -0.5000000000000003, "agent_12": -0.5000000000000003, "agent_13": -0.5000000000000003, "agent_14": -3.8100000000000125, "agent_15": -3.600000000000009, "agent_16": -3.8200000000000127, "agent_17": -3.71000000000001, "agent_18": -3.580000000000009, "agent_19": -3.4900000000000078, "agent_20": -3.5500000000000087}, "policy_reward_mean": {"agent_0": -1.9986666666666746, "agent_1": -1.8066666666666735, "agent_2": -1.974000000000008, "agent_3": -2.138000000000008, "agent_4": -2.076666666666675, "agent_5": -2.5366666666666764, "agent_6": -2.2280000000000086, "agent_7": -1.404000000000005, "agent_8": -1.5020000000000047, "agent_9": -1.3933333333333384, "agent_10": -1.8793333333333402, "agent_11": -1.712000000000006, "agent_12": -2.2413333333333414, "agent_13": -1.463333333333339, "agent_14": -4.502666666666685, "agent_15": -4.54400000000002, "agent_16": -4.640000000000021, "agent_17": -4.422000000000017, "agent_18": -4.418000000000019, "agent_19": -4.490666666666685, "agent_20": -4.264666666666683}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-51.580000000000936, -45.52000000000064, -56.42000000000127, -56.4600000000011, -74.55000000000193, -59.35000000000224, -37.26000000000046, -67.26000000000289, -78.1400000000011, -65.86000000000345, -64.38000000000294, -52.460000000001266, -57.78000000000117, -43.85999999999988, -53.660000000000366], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_agent_0_reward": [-0.5000000000000003, -5.180000000000026, -5.090000000000026, -0.5000000000000003, -0.5000000000000003, -0.7800000000000006, -0.5000000000000003, -0.5000000000000003, -4.890000000000023, -4.420000000000018, -0.5000000000000003, -0.5000000000000003, -5.120000000000026, -0.5000000000000003, -0.5000000000000003], "policy_agent_1_reward": [-0.5000000000000003, -1.2399999999999987, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.310000000000027, -5.130000000000026, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.250000000000027, -0.5000000000000003, -5.170000000000027], "policy_agent_2_reward": [-4.920000000000023, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.350000000000028, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -3.940000000000013, -5.050000000000025, -5.350000000000028, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003], "policy_agent_3_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.300000000000027, -5.040000000000025, -0.5000000000000003, -4.9400000000000235, -0.5000000000000003, -2.6299999999999986, -4.700000000000021, -0.5000000000000003, -4.960000000000024, -0.5000000000000003, -0.5000000000000003], "policy_agent_4_reward": [-0.5000000000000003, -0.5000000000000003, -4.830000000000022, -5.220000000000026, -5.350000000000028, -1.0300000000000005, -0.5000000000000003, -5.130000000000026, -5.090000000000026, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003], "policy_agent_5_reward": [-0.5000000000000003, -1.519999999999996, -0.5000000000000003, -5.330000000000028, -5.340000000000028, -5.150000000000026, -0.5000000000000003, -5.350000000000028, -5.070000000000025, -4.800000000000022, -0.5000000000000003, -1.9899999999999916, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003], "policy_agent_6_reward": [-2.669999999999999, -0.5000000000000003, -0.8700000000000007, -0.5000000000000003, -5.240000000000027, -0.5000000000000003, -0.5000000000000003, -5.310000000000027, -0.5000000000000003, -4.960000000000024, -5.300000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.070000000000025], "policy_agent_7_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.250000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.050000000000025, -0.5000000000000003, -4.760000000000022, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003], "policy_agent_8_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -4.8600000000000225, -0.5000000000000003, -5.310000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.070000000000025, -1.7899999999999936, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003], "policy_agent_9_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -4.840000000000023, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.270000000000027, -0.5000000000000003, -4.790000000000022], "policy_agent_10_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -3.950000000000013, -3.6300000000000097, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.220000000000026, -0.5000000000000003, -5.090000000000026, -0.5000000000000003, -5.300000000000027, -0.5000000000000003], "policy_agent_11_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.210000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -1.509999999999996, -3.4700000000000077, -5.290000000000028, -5.200000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003], "policy_agent_12_reward": [-5.330000000000028, -0.5000000000000003, -5.310000000000027, -0.5000000000000003, -4.440000000000018, -0.5000000000000003, -1.3199999999999978, -3.210000000000005, -5.250000000000027, -0.5000000000000003, -0.5000000000000003, -4.450000000000018, -0.5000000000000003, -0.8100000000000006, -0.5000000000000003], "policy_agent_13_reward": [-5.250000000000027, -0.5000000000000003, -5.330000000000028, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.3700000000000285, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003], "policy_agent_14_reward": [-4.3100000000000165, -4.970000000000024, -4.1900000000000155, -4.850000000000023, -4.930000000000024, -3.8100000000000125, -4.170000000000015, -5.340000000000028, -4.090000000000014, -3.890000000000012, -4.1900000000000155, -4.960000000000024, -4.780000000000022, -4.180000000000016, -4.880000000000023], "policy_agent_15_reward": [-3.600000000000009, -4.330000000000018, -5.000000000000024, -4.360000000000017, -4.550000000000019, -4.780000000000022, -4.170000000000015, -4.560000000000019, -5.350000000000028, -4.330000000000017, -3.600000000000009, -5.140000000000025, -4.370000000000017, -5.130000000000026, -4.890000000000023], "policy_agent_16_reward": [-5.240000000000028, -3.8200000000000127, -4.370000000000017, -4.870000000000023, -4.090000000000014, -4.520000000000019, -4.800000000000022, -4.910000000000023, -4.100000000000015, -5.220000000000027, -4.690000000000021, -5.290000000000028, -4.530000000000019, -4.660000000000021, -4.490000000000019], "policy_agent_17_reward": [-4.130000000000015, -4.560000000000019, -4.450000000000018, -4.210000000000016, -4.54000000000002, -4.750000000000021, -3.920000000000013, -4.54000000000002, -4.790000000000021, -3.71000000000001, -3.8100000000000107, -4.830000000000022, -5.000000000000024, -4.49000000000002, -4.60000000000002], "policy_agent_18_reward": [-3.580000000000009, -4.870000000000023, -4.180000000000016, -3.890000000000012, -4.490000000000019, -4.240000000000016, -4.010000000000014, -4.63000000000002, -4.890000000000024, -4.990000000000025, -4.430000000000018, -4.160000000000015, -4.100000000000015, -4.64000000000002, -5.170000000000027], "policy_agent_19_reward": [-3.4900000000000078, -5.020000000000024, -4.750000000000022, -4.810000000000023, -3.940000000000013, -4.220000000000016, -4.290000000000017, -4.960000000000024, -5.270000000000027, -4.210000000000016, -4.720000000000021, -4.890000000000024, -4.490000000000019, -4.060000000000014, -4.240000000000016], "policy_agent_20_reward": [-4.060000000000014, -4.510000000000019, -3.5500000000000087, -3.850000000000012, -4.790000000000022, -3.750000000000012, -4.080000000000014, -4.060000000000014, -3.890000000000012, -3.6400000000000095, -4.560000000000019, -4.870000000000024, -4.910000000000023, -4.590000000000019, -4.8600000000000225]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.8635224008818867, "mean_inference_ms": 8.943812504605331, "mean_action_processing_ms": 0.7018433878065605, "mean_env_wait_ms": 2.6930385866772837, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0025086932712131077, "StateBufferConnector_ms": 0.001396603054470486, "ViewRequirementAgentConnector_ms": 0.03123200128948878}, "num_episodes": 9, "episode_return_max": -37.26000000000046, "episode_return_min": -78.1400000000011, "episode_return_mean": -57.63600000000145, "episodes_this_iter": 9}, "num_healthy_workers": 3, "actor_manager_num_outstanding_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 168000, "num_agent_steps_trained": 168000, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 134.84531102264927, "num_env_steps_trained_throughput_per_sec": 134.84531102264927, "timesteps_total": 8000, "num_env_steps_sampled_lifetime": 8000, "num_agent_steps_sampled_lifetime": 168000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 168000, "timers": {"training_iteration_time_ms": 29676.474, "restore_workers_time_ms": 0.018, "training_step_time_ms": 29676.42, "sample_time_ms": 19368.928, "learn_time_ms": 10286.66, "learn_throughput": 388.853, "synch_weights_time_ms": 19.094}, "counters": {"num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 168000, "num_agent_steps_trained": 168000}, "done": false, "training_iteration": 2, "trial_id": "21951_00000", "date": "2025-10-21_11-28-23", "timestamp": 1761038903, "time_this_iter_s": 29.674118518829346, "time_total_s": 59.3741557598114, "pid": 3303346, "hostname": "xuezhi-Precision-3660", "node_ip": "130.238.16.41", "config": {"exploration_config": {"type": "StochasticSampling"}, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 1, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "torch_ddp_kwargs": {}, "torch_skip_nan_gradients": false, "env": "<class 'train_utils.WarehouseMultiAgentEnv'>", "env_config": {"env_id": "tarware-extralarge-14agvs-7pickers-partialobs-chg-v1"}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "_is_atari": null, "disable_env_checking": false, "render_env": true, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 3, "create_local_env_runner": true, "num_envs_per_env_runner": 1, "gym_env_vectorize_mode": "SYNC", "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "episodes_to_numpy": true, "max_requests_in_flight_per_env_runner": 1, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "merge_env_runner_states": "training_only", "broadcast_env_runner_states": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "sampler_perf_stats_ema_coef": null, "_is_online": true, "num_learners": 0, "num_gpus_per_learner": 1, "num_cpus_per_learner": "auto", "num_aggregator_actors_per_learner": 0, "max_requests_in_flight_per_aggregator_actor": 3, "local_gpu_idx": 0, "max_requests_in_flight_per_learner": 3, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "_train_batch_size_per_learner": null, "train_batch_size": 4000, "num_epochs": 10, "minibatch_size": 256, "shuffle_batch_per_epoch": true, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "log_std_clip_param": 20.0, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1, "_disable_preprocessor_api": false, "_disable_action_flattening": false}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "_learner_class": null, "callbacks_on_algorithm_init": null, "callbacks_on_env_runners_recreated": null, "callbacks_on_offline_eval_runners_recreated": null, "callbacks_on_checkpoint_loaded": null, "callbacks_on_environment_created": null, "callbacks_on_episode_created": null, "callbacks_on_episode_start": null, "callbacks_on_episode_step": null, "callbacks_on_episode_end": null, "callbacks_on_evaluate_start": null, "callbacks_on_evaluate_end": null, "callbacks_on_evaluate_offline_start": null, "callbacks_on_evaluate_offline_end": null, "callbacks_on_sample_end": null, "callbacks_on_train_result": null, "explore": true, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "_prior_exploration_config": null, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function train.<locals>.<lambda> at 0x7ec4384a3760>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "offline_data_class": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "input_read_episodes": false, "input_read_sample_batches": false, "input_read_batch_size": null, "input_filesystem": null, "input_filesystem_kwargs": {}, "input_compress_columns": ["obs", "new_obs"], "input_spaces_jsonable": true, "materialize_data": false, "materialize_mapped_data": true, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "ignore_final_observation": false, "prelearner_class": null, "prelearner_buffer_class": null, "prelearner_buffer_kwargs": {}, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "output_max_rows_per_file": null, "output_write_remaining_data": false, "output_write_method": "write_parquet", "output_write_method_kwargs": {}, "output_filesystem": null, "output_filesystem_kwargs": {}, "output_write_episodes": true, "offline_sampling": false, "evaluation_interval": 10, "evaluation_duration": 5, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_auto_duration_min_env_steps_per_sample": 100, "evaluation_auto_duration_max_env_steps_per_sample": 2000, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": {"explore": false}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "offline_evaluation_interval": null, "num_offline_eval_runners": 0, "offline_evaluation_type": null, "offline_eval_runner_class": null, "offline_loss_for_module_fn": null, "offline_evaluation_duration": 1, "offline_evaluation_parallel_to_training": false, "offline_evaluation_timeout_s": 120.0, "num_cpus_per_offline_eval_runner": 1, "num_gpus_per_offline_eval_runner": 0, "custom_resources_per_offline_eval_runner": {}, "restart_failed_offline_eval_runners": true, "ignore_offline_eval_runner_failures": false, "max_num_offline_eval_runner_restarts": 1000, "offline_eval_runner_restore_timeout_s": 1800.0, "max_requests_in_flight_per_offline_eval_runner": 1, "validate_offline_eval_runners_after_construction": true, "offline_eval_runner_health_probe_timeout_s": 30.0, "offline_eval_rl_module_inference_only": false, "broadcast_offline_eval_runner_states": false, "offline_eval_batch_size_per_runner": 256, "dataset_num_iters_per_eval_runner": 1, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "log_gradients": false, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "restart_failed_env_runners": true, "ignore_env_runner_failures": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30.0, "env_runner_restore_timeout_s": 1800.0, "_model_config": {}, "_rl_module_spec": null, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "_validate_config": true, "_use_msgpack_checkpoints": false, "_torch_grad_scaler_class": null, "_torch_lr_scheduler_classes": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "env_task_fn": -1, "enable_connectors": -1, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "clip_param": 0.2, "vf_clip_param": 10.0, "entropy_coeff_schedule": null, "lr_schedule": null, "sgd_minibatch_size": -1, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.95, "input": "sampler", "policies": {"agent_0": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_1": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_2": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_3": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_4": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_5": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_6": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_7": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_8": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_9": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_10": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_11": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_12": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_13": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_14": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_15": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_16": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_17": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_18": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_19": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_20": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}]}, "callbacks": "<class 'ray.rllib.callbacks.callbacks.RLlibCallback'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 59.3741557598114, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 9.039024390243902, "ram_util_percent": 27.387804878048783, "gpu_util_percent0": 0.2390243902439024, "vram_util_percent0": 0.0951136106378162}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_8": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.440777656435967, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.019123829204181673, "policy_loss": -0.05000049272493925, "vf_loss": 0.028165858413558453, "vf_explained_var": 0.9603252142667771, "kl": 0.009036018616102214, "entropy": 5.821658512949943, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 400.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_3": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.40763392150402, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.018421549510094337, "policy_loss": -0.048833321261918174, "vf_loss": 0.02794059465522878, "vf_explained_var": 0.8649981092661619, "kl": 0.00823725787994139, "entropy": 5.840130236744881, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 400.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_13": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.884323188662529, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.02338560958887683, "policy_loss": -0.0499444703629706, "vf_loss": 0.024062003282597288, "vf_explained_var": 0.9075346473604441, "kl": 0.008322859774967318, "entropy": 5.930158594250679, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 400.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_14": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.830739250779152, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": 0.004431506156106479, "policy_loss": -0.05242370642896503, "vf_loss": 0.053391529549844566, "vf_explained_var": 0.9046084478497505, "kl": 0.011545608371962113, "entropy": 5.43395819067955, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 400.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_9": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.426269961893558, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.011865339937503449, "policy_loss": -0.04794572226819582, "vf_loss": 0.03306622189702466, "vf_explained_var": 0.9084695369005203, "kl": 0.010047203210556754, "entropy": 5.768150481581688, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 400.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_5": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.149158537387848, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.009140529469004833, "policy_loss": -0.03937231252784841, "vf_loss": 0.02835375644499436, "vf_explained_var": 0.8587444044649601, "kl": 0.006260093560561597, "entropy": 5.917952609062195, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 400.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.663129626214504, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.02622255205787951, "policy_loss": -0.05482244565791916, "vf_loss": 0.025804609968326987, "vf_explained_var": 0.9521394394338131, "kl": 0.009317612787193336, "entropy": 5.78471374809742, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 400.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_2": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.144642530381679, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.014202849443245213, "policy_loss": -0.04592702746740542, "vf_loss": 0.02918550937320106, "vf_explained_var": 0.9087878502905369, "kl": 0.008462232556075321, "entropy": 5.845145985484123, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 400.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_15": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.186875763535499, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.005679623149626422, "policy_loss": -0.05185650573694147, "vf_loss": 0.04229037759359926, "vf_explained_var": 0.9336950983852148, "kl": 0.012955015315321916, "entropy": 5.384360271692276, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 400.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_4": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.7091985359787945, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.017930750527011697, "policy_loss": -0.04997439259313978, "vf_loss": 0.02938775818911381, "vf_explained_var": 0.8610927309840918, "kl": 0.008852947961450914, "entropy": 5.810923179984092, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 400.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_6": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.167493204772472, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.007806376751977951, "policy_loss": -0.04199120037665125, "vf_loss": 0.03177512801485136, "vf_explained_var": 0.8935589458793401, "kl": 0.00803232018957407, "entropy": 5.925321450829506, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 400.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_17": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.546970164775848, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": 0.011622391612036154, "policy_loss": -0.04711903763818555, "vf_loss": 0.05475054428679869, "vf_explained_var": 0.8991166617721319, "kl": 0.01330294849185847, "entropy": 5.565475875139237, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 400.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_11": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.254546397924424, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.01321317413385259, "policy_loss": -0.04473113988642581, "vf_loss": 0.029177670122589917, "vf_explained_var": 0.871981130540371, "kl": 0.007800984572369152, "entropy": 5.934655514359474, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 400.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_12": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.7322096690535544, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.019192799754819134, "policy_loss": -0.046096101115108465, "vf_loss": 0.0244261041196296, "vf_explained_var": 0.9448375426232815, "kl": 0.008257324364075242, "entropy": 5.893210765719414, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 400.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_7": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.7506640389561654, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.022600848601723556, "policy_loss": -0.04824763048673049, "vf_loss": 0.02337072176160291, "vf_explained_var": 0.9088593620806933, "kl": 0.007586870289680314, "entropy": 5.856456595659256, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 400.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_19": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.764614593982696, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": 0.04192120864172466, "policy_loss": -0.03827025669743307, "vf_loss": 0.07648665896849707, "vf_explained_var": 0.842915891110897, "kl": 0.012349351030011974, "entropy": 4.826272168755532, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 400.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_10": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.6319836124777796, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.025423375073296485, "policy_loss": -0.049978895924868996, "vf_loss": 0.022072256982210093, "vf_explained_var": 0.9333256892859936, "kl": 0.008277544880470555, "entropy": 5.947900032997131, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 400.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_20": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.44466585367918, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": 0.01436269093392184, "policy_loss": -0.048708308837376535, "vf_loss": 0.05953361694701016, "vf_explained_var": 0.9386262729763984, "kl": 0.01179127272029903, "entropy": 5.443072372674942, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 400.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.8801984041929245, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.02031107611110201, "policy_loss": -0.048160270333755764, "vf_loss": 0.025473611638881268, "vf_explained_var": 0.93125378228724, "kl": 0.007918611933878017, "entropy": 5.823302710056305, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 400.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_16": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.710758548974991, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": 0.022797083733894396, "policy_loss": -0.0452641347903409, "vf_loss": 0.06457030720775947, "vf_explained_var": 0.937677351757884, "kl": 0.011636367078649073, "entropy": 5.577865540981293, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 400.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}, "agent_18": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.066883300244808, "cur_kl_coeff": 0.3, "cur_lr": 5.000000000000001e-05, "total_loss": -0.0020915689106914214, "policy_loss": -0.049651179448119365, "vf_loss": 0.04430045121116564, "vf_explained_var": 0.8476901315152645, "kl": 0.010863863435611165, "entropy": 5.241888076066971, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 250.0, "num_grad_updates_lifetime": 400.5, "diff_num_grad_updates_vs_sampler_policy": 79.5}}, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 252000, "num_agent_steps_trained": 252000}, "env_runners": {"episode_reward_max": -37.26000000000046, "episode_reward_min": -78.1400000000011, "episode_reward_mean": -57.191363636365054, "episode_len_mean": 500.0, "episode_media": {}, "episodes_timesteps_total": 11000, "policy_reward_min": {"agent_0": -5.180000000000026, "agent_1": -5.310000000000027, "agent_2": -5.350000000000028, "agent_3": -5.300000000000027, "agent_4": -5.350000000000028, "agent_5": -5.3700000000000285, "agent_6": -5.310000000000027, "agent_7": -5.290000000000028, "agent_8": -5.310000000000027, "agent_9": -5.270000000000027, "agent_10": -5.300000000000027, "agent_11": -5.290000000000028, "agent_12": -5.330000000000028, "agent_13": -5.3700000000000285, "agent_14": -5.340000000000028, "agent_15": -5.350000000000028, "agent_16": -5.290000000000028, "agent_17": -5.040000000000025, "agent_18": -5.250000000000026, "agent_19": -5.270000000000027, "agent_20": -5.330000000000028}, "policy_reward_max": {"agent_0": -0.5000000000000003, "agent_1": -0.5000000000000003, "agent_2": -0.5000000000000003, "agent_3": -0.5000000000000003, "agent_4": -0.5000000000000003, "agent_5": -0.5000000000000003, "agent_6": -0.5000000000000003, "agent_7": -0.5000000000000003, "agent_8": -0.5000000000000003, "agent_9": -0.5000000000000003, "agent_10": -0.5000000000000003, "agent_11": -0.5000000000000003, "agent_12": -0.5000000000000003, "agent_13": -0.5000000000000003, "agent_14": -3.71000000000001, "agent_15": -3.600000000000009, "agent_16": -3.6400000000000095, "agent_17": -3.71000000000001, "agent_18": -3.580000000000009, "agent_19": -3.4900000000000078, "agent_20": -3.5500000000000087}, "policy_reward_mean": {"agent_0": -1.521818181818187, "agent_1": -1.895000000000007, "agent_2": -2.0850000000000084, "agent_3": -2.4122727272727356, "agent_4": -2.1209090909091, "agent_5": -2.325454545454555, "agent_6": -1.837272727272733, "agent_7": -1.5268181818181872, "agent_8": -1.35545454545455, "agent_9": -1.5209090909090968, "agent_10": -1.652272727272733, "agent_11": -2.169545454545463, "agent_12": -2.0050000000000066, "agent_13": -1.3168181818181863, "agent_14": -4.481818181818201, "agent_15": -4.5509090909091094, "agent_16": -4.618636363636384, "agent_17": -4.435000000000018, "agent_18": -4.532727272727292, "agent_19": -4.443636363636382, "agent_20": -4.384090909090928}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-51.580000000000936, -45.52000000000064, -56.42000000000127, -56.4600000000011, -74.55000000000193, -59.35000000000224, -37.26000000000046, -67.26000000000289, -78.1400000000011, -65.86000000000345, -64.38000000000294, -52.460000000001266, -57.78000000000117, -43.85999999999988, -53.660000000000366, -52.03000000000093, -52.16000000000041, -69.84000000000306, -53.53000000000034, -62.28000000000296, -51.360000000000944, -52.470000000000624], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_agent_0_reward": [-0.5000000000000003, -5.180000000000026, -5.090000000000026, -0.5000000000000003, -0.5000000000000003, -0.7800000000000006, -0.5000000000000003, -0.5000000000000003, -4.890000000000023, -4.420000000000018, -0.5000000000000003, -0.5000000000000003, -5.120000000000026, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003], "policy_agent_1_reward": [-0.5000000000000003, -1.2399999999999987, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.310000000000027, -5.130000000000026, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.250000000000027, -0.5000000000000003, -5.170000000000027, -0.5000000000000003, -0.5000000000000003, -4.430000000000018, -0.5000000000000003, -5.300000000000027, -2.860000000000001, -0.5000000000000003], "policy_agent_2_reward": [-4.920000000000023, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.350000000000028, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -3.940000000000013, -5.050000000000025, -5.350000000000028, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -4.530000000000019, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -4.60000000000002, -0.5000000000000003, -5.130000000000026], "policy_agent_3_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.300000000000027, -5.040000000000025, -0.5000000000000003, -4.9400000000000235, -0.5000000000000003, -2.6299999999999986, -4.700000000000021, -0.5000000000000003, -4.960000000000024, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -4.220000000000016, -2.559999999999998, -0.5000000000000003, -5.250000000000027, -2.669999999999999, -5.300000000000027], "policy_agent_4_reward": [-0.5000000000000003, -0.5000000000000003, -4.830000000000022, -5.220000000000026, -5.350000000000028, -1.0300000000000005, -0.5000000000000003, -5.130000000000026, -5.090000000000026, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.040000000000025, -3.5600000000000085, -4.910000000000023, -0.5000000000000003, -0.5000000000000003], "policy_agent_5_reward": [-0.5000000000000003, -1.519999999999996, -0.5000000000000003, -5.330000000000028, -5.340000000000028, -5.150000000000026, -0.5000000000000003, -5.350000000000028, -5.070000000000025, -4.800000000000022, -0.5000000000000003, -1.9899999999999916, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.3700000000000285, -5.240000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003], "policy_agent_6_reward": [-2.669999999999999, -0.5000000000000003, -0.8700000000000007, -0.5000000000000003, -5.240000000000027, -0.5000000000000003, -0.5000000000000003, -5.310000000000027, -0.5000000000000003, -4.960000000000024, -5.300000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.070000000000025, -0.5000000000000003, -0.5000000000000003, -1.8199999999999932, -0.5000000000000003, -2.679999999999999, -0.5000000000000003, -0.5000000000000003], "policy_agent_7_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.250000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.050000000000025, -0.5000000000000003, -4.760000000000022, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.290000000000028, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -4.300000000000017, -0.9400000000000007], "policy_agent_8_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -4.8600000000000225, -0.5000000000000003, -5.310000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.070000000000025, -1.7899999999999936, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -4.290000000000028, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003], "policy_agent_9_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -4.840000000000023, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.270000000000027, -0.5000000000000003, -4.790000000000022, -0.5000000000000003, -0.5000000000000003, -5.150000000000026, -0.5000000000000003, -0.5000000000000003, -4.910000000000023, -0.5000000000000003], "policy_agent_10_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -3.950000000000013, -3.6300000000000097, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.220000000000026, -0.5000000000000003, -5.090000000000026, -0.5000000000000003, -5.300000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.160000000000026, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003], "policy_agent_11_reward": [-0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.210000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -1.509999999999996, -3.4700000000000077, -5.290000000000028, -5.200000000000027, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -4.9400000000000235, -0.5000000000000003, -5.240000000000027, -5.270000000000027, -0.5000000000000003, -5.100000000000025], "policy_agent_12_reward": [-5.330000000000028, -0.5000000000000003, -5.310000000000027, -0.5000000000000003, -4.440000000000018, -0.5000000000000003, -1.3199999999999978, -3.210000000000005, -5.250000000000027, -0.5000000000000003, -0.5000000000000003, -4.450000000000018, -0.5000000000000003, -0.8100000000000006, -0.5000000000000003, -2.669999999999999, -0.5000000000000003, -5.320000000000028, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003], "policy_agent_13_reward": [-5.250000000000027, -0.5000000000000003, -5.330000000000028, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -5.3700000000000285, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -4.020000000000014, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003, -0.5000000000000003], "policy_agent_14_reward": [-4.3100000000000165, -4.970000000000024, -4.1900000000000155, -4.850000000000023, -4.930000000000024, -3.8100000000000125, -4.170000000000015, -5.340000000000028, -4.090000000000014, -3.890000000000012, -4.1900000000000155, -4.960000000000024, -4.780000000000022, -4.180000000000016, -4.880000000000023, -4.280000000000015, -4.910000000000023, -4.920000000000025, -4.450000000000018, -4.640000000000019, -4.150000000000015, -3.71000000000001], "policy_agent_15_reward": [-3.600000000000009, -4.330000000000018, -5.000000000000024, -4.360000000000017, -4.550000000000019, -4.780000000000022, -4.170000000000015, -4.560000000000019, -5.350000000000028, -4.330000000000017, -3.600000000000009, -5.140000000000025, -4.370000000000017, -5.130000000000026, -4.890000000000023, -3.8200000000000114, -4.130000000000015, -5.310000000000027, -4.160000000000015, -4.870000000000023, -5.140000000000025, -4.530000000000019], "policy_agent_16_reward": [-5.240000000000028, -3.8200000000000127, -4.370000000000017, -4.870000000000023, -4.090000000000014, -4.520000000000019, -4.800000000000022, -4.910000000000023, -4.100000000000015, -5.220000000000027, -4.690000000000021, -5.290000000000028, -4.530000000000019, -4.660000000000021, -4.490000000000019, -4.560000000000019, -4.470000000000018, -5.110000000000026, -4.880000000000023, -3.6400000000000095, -4.400000000000017, -4.950000000000024], "policy_agent_17_reward": [-4.130000000000015, -4.560000000000019, -4.450000000000018, -4.210000000000016, -4.54000000000002, -4.750000000000021, -3.920000000000013, -4.54000000000002, -4.790000000000021, -3.71000000000001, -3.8100000000000107, -4.830000000000022, -5.000000000000024, -4.49000000000002, -4.60000000000002, -4.090000000000014, -4.880000000000023, -4.680000000000021, -5.040000000000025, -4.1900000000000155, -4.030000000000014, -4.330000000000017], "policy_agent_18_reward": [-3.580000000000009, -4.870000000000023, -4.180000000000016, -3.890000000000012, -4.490000000000019, -4.240000000000016, -4.010000000000014, -4.63000000000002, -4.890000000000024, -4.990000000000025, -4.430000000000018, -4.160000000000015, -4.100000000000015, -4.64000000000002, -5.170000000000027, -5.110000000000025, -4.440000000000018, -5.050000000000025, -5.250000000000026, -4.050000000000014, -4.440000000000018, -5.110000000000025], "policy_agent_19_reward": [-3.4900000000000078, -5.020000000000024, -4.750000000000022, -4.810000000000023, -3.940000000000013, -4.220000000000016, -4.290000000000017, -4.960000000000024, -5.270000000000027, -4.210000000000016, -4.720000000000021, -4.890000000000024, -4.490000000000019, -4.060000000000014, -4.240000000000016, -4.180000000000016, -3.970000000000013, -3.6300000000000088, -5.020000000000024, -4.470000000000018, -4.940000000000024, -4.1900000000000155], "policy_agent_20_reward": [-4.060000000000014, -4.510000000000019, -3.5500000000000087, -3.850000000000012, -4.790000000000022, -3.750000000000012, -4.080000000000014, -4.060000000000014, -3.890000000000012, -3.6400000000000095, -4.560000000000019, -4.870000000000024, -4.910000000000023, -4.590000000000019, -4.8600000000000225, -4.480000000000018, -5.330000000000028, -4.290000000000018, -5.270000000000027, -4.410000000000018, -4.520000000000019, -4.180000000000016]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.8764381826564593, "mean_inference_ms": 8.973492318451276, "mean_action_processing_ms": 0.7000202001635146, "mean_env_wait_ms": 2.6974570557864577, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.002535648676224085, "StateBufferConnector_ms": 0.0014171455845688329, "ViewRequirementAgentConnector_ms": 0.03176736625242027}, "num_episodes": 7, "episode_return_max": -37.26000000000046, "episode_return_min": -78.1400000000011, "episode_return_mean": -57.191363636365054, "episodes_this_iter": 7}, "num_healthy_workers": 3, "actor_manager_num_outstanding_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 252000, "num_agent_steps_trained": 252000, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 133.7108686058454, "num_env_steps_trained_throughput_per_sec": 133.7108686058454, "timesteps_total": 12000, "num_env_steps_sampled_lifetime": 12000, "num_agent_steps_sampled_lifetime": 252000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 252000, "timers": {"training_iteration_time_ms": 29756.084, "restore_workers_time_ms": 0.017, "training_step_time_ms": 29756.032, "sample_time_ms": 19485.358, "learn_time_ms": 10250.733, "learn_throughput": 390.216, "synch_weights_time_ms": 18.297}, "counters": {"num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 252000, "num_agent_steps_trained": 252000}, "done": false, "training_iteration": 3, "trial_id": "21951_00000", "date": "2025-10-21_11-28-53", "timestamp": 1761038933, "time_this_iter_s": 29.92588758468628, "time_total_s": 89.30004334449768, "pid": 3303346, "hostname": "xuezhi-Precision-3660", "node_ip": "130.238.16.41", "config": {"exploration_config": {"type": "StochasticSampling"}, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 1, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "torch_ddp_kwargs": {}, "torch_skip_nan_gradients": false, "env": "<class 'train_utils.WarehouseMultiAgentEnv'>", "env_config": {"env_id": "tarware-extralarge-14agvs-7pickers-partialobs-chg-v1"}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "_is_atari": null, "disable_env_checking": false, "render_env": true, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 3, "create_local_env_runner": true, "num_envs_per_env_runner": 1, "gym_env_vectorize_mode": "SYNC", "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "episodes_to_numpy": true, "max_requests_in_flight_per_env_runner": 1, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "merge_env_runner_states": "training_only", "broadcast_env_runner_states": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "sampler_perf_stats_ema_coef": null, "_is_online": true, "num_learners": 0, "num_gpus_per_learner": 1, "num_cpus_per_learner": "auto", "num_aggregator_actors_per_learner": 0, "max_requests_in_flight_per_aggregator_actor": 3, "local_gpu_idx": 0, "max_requests_in_flight_per_learner": 3, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "_train_batch_size_per_learner": null, "train_batch_size": 4000, "num_epochs": 10, "minibatch_size": 256, "shuffle_batch_per_epoch": true, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "log_std_clip_param": 20.0, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1, "_disable_preprocessor_api": false, "_disable_action_flattening": false}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "_learner_class": null, "callbacks_on_algorithm_init": null, "callbacks_on_env_runners_recreated": null, "callbacks_on_offline_eval_runners_recreated": null, "callbacks_on_checkpoint_loaded": null, "callbacks_on_environment_created": null, "callbacks_on_episode_created": null, "callbacks_on_episode_start": null, "callbacks_on_episode_step": null, "callbacks_on_episode_end": null, "callbacks_on_evaluate_start": null, "callbacks_on_evaluate_end": null, "callbacks_on_evaluate_offline_start": null, "callbacks_on_evaluate_offline_end": null, "callbacks_on_sample_end": null, "callbacks_on_train_result": null, "explore": true, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "_prior_exploration_config": null, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function train.<locals>.<lambda> at 0x7ec4384a3d00>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "offline_data_class": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "input_read_episodes": false, "input_read_sample_batches": false, "input_read_batch_size": null, "input_filesystem": null, "input_filesystem_kwargs": {}, "input_compress_columns": ["obs", "new_obs"], "input_spaces_jsonable": true, "materialize_data": false, "materialize_mapped_data": true, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "ignore_final_observation": false, "prelearner_class": null, "prelearner_buffer_class": null, "prelearner_buffer_kwargs": {}, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "output_max_rows_per_file": null, "output_write_remaining_data": false, "output_write_method": "write_parquet", "output_write_method_kwargs": {}, "output_filesystem": null, "output_filesystem_kwargs": {}, "output_write_episodes": true, "offline_sampling": false, "evaluation_interval": 10, "evaluation_duration": 5, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_auto_duration_min_env_steps_per_sample": 100, "evaluation_auto_duration_max_env_steps_per_sample": 2000, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": {"explore": false}, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "offline_evaluation_interval": null, "num_offline_eval_runners": 0, "offline_evaluation_type": null, "offline_eval_runner_class": null, "offline_loss_for_module_fn": null, "offline_evaluation_duration": 1, "offline_evaluation_parallel_to_training": false, "offline_evaluation_timeout_s": 120.0, "num_cpus_per_offline_eval_runner": 1, "num_gpus_per_offline_eval_runner": 0, "custom_resources_per_offline_eval_runner": {}, "restart_failed_offline_eval_runners": true, "ignore_offline_eval_runner_failures": false, "max_num_offline_eval_runner_restarts": 1000, "offline_eval_runner_restore_timeout_s": 1800.0, "max_requests_in_flight_per_offline_eval_runner": 1, "validate_offline_eval_runners_after_construction": true, "offline_eval_runner_health_probe_timeout_s": 30.0, "offline_eval_rl_module_inference_only": false, "broadcast_offline_eval_runner_states": false, "offline_eval_batch_size_per_runner": 256, "dataset_num_iters_per_eval_runner": 1, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "log_gradients": false, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "restart_failed_env_runners": true, "ignore_env_runner_failures": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30.0, "env_runner_restore_timeout_s": 1800.0, "_model_config": {}, "_rl_module_spec": null, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "_validate_config": true, "_use_msgpack_checkpoints": false, "_torch_grad_scaler_class": null, "_torch_lr_scheduler_classes": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "env_task_fn": -1, "enable_connectors": -1, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "clip_param": 0.2, "vf_clip_param": 10.0, "entropy_coeff_schedule": null, "lr_schedule": null, "sgd_minibatch_size": -1, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.95, "input": "sampler", "policies": {"agent_0": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_1": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_2": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_3": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_4": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_5": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_6": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_7": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_8": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_9": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_10": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_11": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_12": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_13": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_14": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_15": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_16": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_17": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_18": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_19": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}], "agent_20": [null, null, null, {"model": {"custom_model": "warehouse_marl_model"}}]}, "callbacks": "<class 'ray.rllib.callbacks.callbacks.RLlibCallback'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 89.30004334449768, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 8.673170731707316, "ram_util_percent": 27.52682926829268, "gpu_util_percent0": 0.23390243902439023, "vram_util_percent0": 0.095298294946799}}
